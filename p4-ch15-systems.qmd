::: {.callout-warning .content-visible when-profile="draft"}
**TODO:**

- Add figure: Multi-omics integration strategies diagram showing early, intermediate, and late fusion approaches with representative models
- Add figure: GNN-based cancer subtyping comparison showing MoGCN patient-level graphs vs. CGMega gene-level modules
- Add figure: DeepRVAT set-based architecture showing variant aggregation into gene-level impairment scores
- Add figure: G2PT hierarchical structure from variants → genes → systems → phenotypes
- Add figure: Deep PGS architecture comparison showing Delphi and related approaches
- Add table: Comparison of multi-omics integration methods (GLUE, MoGCN, CGMega, etc.) with columns for input modalities, graph type, primary use case, and scalability
- Add table: Design patterns summary showing the five key patterns with representative methods and typical applications
- Consider adding conceptual diagram showing the trajectory from single-omic models toward whole-patient foundation models
:::


# Multi-Omics & Systems Biology  {#sec-systems}

The preceding chapter examined foundation models for individual data types: single-cell transcriptomics, DNA methylation, and three-dimensional genome structure. Real biological systems, however, do not respect these modality boundaries. Complex traits arise from systems-level interactions where genetic variants perturb molecular networks, networks span multiple omics layers, and these layers interact with environment, development, and clinical context. A model that sees only one layer rarely captures the full story.

This chapter surveys how deep learning extends beyond single-omics to integrate multiple data types into unified representations. We examine integration strategies that differ in when and how modalities are combined. We explore graph neural network approaches that use patient similarity networks and gene-level graphs for cancer subtyping and biomarker discovery. We address rare variants and epistasis through set-based architectures and hierarchical modeling that capture effects linear polygenic scores miss. We consider deep learning frameworks for polygenic risk and fine-mapping that extend the traditional PGS paradigm with nonlinear architectures and foundation model features. Throughout, the emphasis is on design patterns that recur across methods and on the trajectory toward whole-patient foundation models that jointly encode multiple omics and clinical data.# Chapter 15: Multi-Omics Integration and Systems Biology {#sec-systems}

## Introduction
- Why single-omics models are insufficient
- The promise of integrated multi-modal representations
- Chapter scope: integration strategies, hierarchy, systems principles

## Multi-Omics Integration Strategies
### Early Fusion
- Feature-level concatenation
- Challenges: scale, dimensionality, missing data

### Intermediate Fusion
- Modality-specific encoders with shared latent spaces
- Reconstruction and contrastive alignment
- GLUE as exemplar

### Late Fusion
- Ensemble and meta-model approaches
- Independence and robustness to missing modalities

### Choosing Integration Strategies
- When to use each approach
- Hybrid strategies in practice

## Cross-Modal Foundation Models
### Principles of Cross-Modal Learning
- Contrastive objectives across modalities
- Translation between data types
- Shared vs. modality-specific representations

### Examples: GLUE, Life-Code, and Related Models
- Multi-omic encoders and guidance graphs
- Central dogma-inspired architectures
- Handling unpaired and mosaic data

## Hierarchical and Multi-Scale Modeling
### Biological Hierarchy
- Variants → genes → pathways → systems → phenotypes
- Multi-resolution regulatory organization

### G2PT: Hierarchical Genotype-to-Phenotype
- Transformer blocks at each hierarchy level
- Prior knowledge as structural constraints
- Interpretable attention over biological systems

### Multi-Scale Regulatory Models
- Seq2PRINT and multi-scale footprinting
- Cell type to tissue to organism scales

## Rare Variants in Systems Context
### The Challenge of Rare Variants
- Individual rarity, collective importance
- Limitations of per-variant statistics

### DeepRVAT: Set-Based Burden Modeling
- Variants as unordered sets within genes
- Permutation-invariant aggregation
- Gene-level impairment scores

### From Burden to Systems-Level Risk
- Connecting gene impairment to pathways
- Aggregating across biological systems

## Systems Biology Principles for Deep Learning
### Network Motifs and Regulatory Logic
- Feedforward loops, autoregulation, feedback
- Alon's design principles in gene circuits
- Learning motif structure from data

### Robustness and Canalization
- Why biological networks are robust
- Implications for model generalization
- Redundancy and compensation

### Dynamical Systems Perspectives
- Attractor states and cell identity
- State transitions and differentiation
- Time-series modeling in systems context

## Systems Medicine and Clinical Integration
### From Molecular Networks to Patient Phenotypes
- Disease as network perturbation
- Personal omics profiles

### Multi-Omic Risk Scores
- Delphi and deep PGS frameworks
- Beyond linear polygenic scores
- Cross-ancestry generalization

### Fine-Mapping in Systems Context
- MIFM and foundation model features
- Integrating functional annotations with GWAS

## Practical Challenges
### Batch Effects Across Modalities
- Platform and laboratory variation
- Harmonization strategies

### Sample Size and Missing Modalities
- Imputation and partial observations
- Transfer learning across cohorts

### Population Diversity
- Non-European representation in multi-omics
- Equity considerations in systems models

### Evaluation Complexity
- Proxy metrics vs. clinical utility
- Multi-level validation strategies

## Toward Whole-Patient Foundation Models
- Vision: unified patient representations
- Integrating genotype, epigenome, transcriptome, proteome, EHR
- Challenges: privacy, scale, causality
- The path forward

## Summary

## Why Single-Omics Models Are Not Enough

Earlier chapters emphasized how sequence-based models can predict variant effects from local DNA or protein context. These models already improve causal variant prioritization and polygenic risk scoring. However, they typically assume a narrow view of biology.

Most sequence models operate on a single molecular layer. A convolutional network or transformer may see only DNA sequence, or only expression values, without access to the other layers that mediate the flow of genetic information. Even when multiple outputs are predicted simultaneously, as in multi-task models like Enformer, the input remains a single modality.

Many downstream uses treat variant effects as additively summing across loci. The PGS framework from @sec-pgs exemplifies this assumption: effects of individual variants are estimated independently and combined through weighted sums. While linear models have well-understood statistical properties and interpretability, they cannot capture interactions between variants or between molecular layers.

Models rarely account for dynamic cellular state. The same sequence may have different regulatory consequences depending on cell type, developmental stage, or environmental exposure. Static sequence-to-function models provide context-averaged predictions that may not reflect biology in any particular condition.

Real diseases violate all three of these assumptions. Regulation is inherently multi-layered: genetic variants alter chromatin accessibility and DNA methylation, which modulate transcription, which affects splicing and translation, which determines protein levels and modifications. A variant's consequences propagate through this cascade in ways that single-layer models cannot fully capture.

Effects are context-dependent. A variant might be benign in one tissue and pathogenic in another, depending on which genes are expressed, which transcription factors are present, and how the local chromatin environment is configured.

Interactions between variants can be biologically important. Epistasis, where the effect of one variant depends on genotypes at other loci, is theoretically expected from network biology and has been documented empirically for many traits. Models that ignore interactions may miss important biology and underperform for individual-level prediction.

## Multi-Omics Integration Strategies

How should multiple data types be combined? Three broad strategies have emerged, each with distinct tradeoffs.

### Early Fusion

Early fusion, also called feature-level integration, concatenates normalized features from multiple omics and feeds them into a single model. This approach is straightforward to implement and allows the model to learn arbitrary interactions between features. However, early fusion is sensitive to differences in scale and dimensionality between modalities, handles missing data poorly since any sample lacking one modality must be imputed or excluded, and can be dominated by whichever modality has the most features or highest signal-to-noise ratio.

### Intermediate Fusion

Intermediate fusion, also called shared latent space integration, learns modality-specific encoders that map each omic into a common embedding space. Alignment between modalities is encouraged through reconstruction losses that require each encoder's latent representation to support decoding back to its original features, contrastive terms that pull together representations of the same biological entity across modalities, or graph constraints that enforce consistency with known biological relationships.

Intermediate fusion is the dominant design in modern multi-omics deep learning because it handles missing modalities gracefully (only the available encoder needs to fire), allows modality-specific preprocessing and architectures, and can incorporate biological prior knowledge through the alignment objectives. GLUE and related methods from @sec-epi exemplify this approach.

### Late Fusion

Late fusion, also called prediction-level integration, trains separate models for each modality and combines their outputs through ensemble methods or a meta-model. This approach is robust to missing modalities since each sub-model operates independently, and it allows each modality to use whatever architecture works best for its data type. However, late fusion may underutilize cross-omic structure that could inform predictions, since interactions between modalities can only be captured at the final combination stage.

### Graph-Guided Integration

Modern frameworks like GLUE and multi-omics graph neural networks predominantly adopt intermediate fusion, often augmented with graphs that encode known or inferred biological relationships. Gene-peak edges in single-cell multi-omics link chromatin accessibility peaks to the genes they regulate. Gene-transcription factor edges connect genes to the factors that bind their promoters and enhancers. Protein-protein interaction edges capture physical and functional relationships. Sample similarity edges connect patients or cells with similar molecular profiles.

## Graph Neural Networks for Cancer Subtyping

Cancer classification provides a compelling use case for multi-omics integration. Tumors are characterized by complex molecular alterations spanning mutations, copy number changes, epigenetic modifications, and expression programs. Different subtypes may require different treatments, and identifying the molecular basis of subtypes can reveal therapeutic targets.

### MoGCN: Patient Similarity Networks

MoGCN, a multi-omics integration model based on graph convolutional networks, was developed for cancer subtype classification and analysis [@li_mogcn_2022]. The approach constructs patient similarity networks from multi-omic data and applies graph convolutions to learn subtype-discriminative representations.

The architecture proceeds in several stages. First, autoencoders reduce dimensionality for each omic layer, producing compressed representations of genomic, transcriptomic, and proteomic profiles. Second, similarity network fusion constructs a patient similarity network (PSN) from these reduced representations, connecting patients whose molecular profiles are similar across modalities. Third, the compressed features and the PSN are input to a graph convolutional network for subtype classification.

In analysis of multi-dimensional omics data for breast invasive carcinoma (BRCA) samples from TCGA, MoGCN achieved the highest accuracy in cancer subtype classification compared with several popular algorithms. Beyond classification, MoGCN can extract the most significant features of each omics layer and provide candidate functional molecules for further analysis. Network visualization showed that MoGCN could support clinically intuitive diagnosis by revealing the molecular relationships underlying subtype distinctions.

### CGMega: Gene-Level Modules

While MoGCN operates at the patient level, connecting samples with similar profiles, CGMega takes a complementary approach by constructing gene-level graphs that capture multi-omic relationships among genes [@li_cgmega_2024]. This gene-centric view enables identification of gene modules that drive subtype differences and provides more mechanistically interpretable results.

The architecture builds graphs where nodes represent genes and edges capture relationships across omics layers: co-expression from transcriptomics, co-methylation from epigenomics, and protein interactions from proteomics. Graph neural network layers learn gene embeddings that integrate information across these different relationship types. Gene-level importance scores derived from the model identify candidate biomarkers and therapeutic targets.

### Design Themes in Cancer Subtyping

Common themes emerge across these methods. Modality-specific encoders with shared latent spaces appear repeatedly, allowing flexible handling of missing modalities while enabling cross-modal interactions. Graphs capturing patient-patient or gene-gene relationships structure the learning problem and provide interpretability. Emphasis on biological interpretability through clusters, modules, or attention patterns helps translate model outputs into biological hypotheses.

These cancer subtyping models illustrate how multi-omics integration naturally leads to graph-structured genomic foundation models. Sequences, epigenetics, and expression become nodes in learned biological networks, and the models learn to reason over these networks rather than treating each measurement in isolation.

## Rare Variants and Epistasis in Systems Context

@sec-pgs discussed how standard PGS methods largely ignore rare variants and epistatic interactions, despite their importance for individual-level risk and disease mechanism. Rare variants, though individually uncommon, collectively explain substantial phenotypic variance and often have larger effect sizes than common variants. Epistasis, the non-additive interaction between variants, is theoretically expected from network biology and has been documented empirically for many traits. Multi-omics and systems models offer a framework to incorporate these effects more effectively than linear approaches.

### DeepRVAT: Set-Based Rare Variant Burden Modeling

DeepRVAT, Deep Rare Variant Association Testing, addresses a fundamental statistical challenge: rare variants have too few carriers to achieve individual statistical significance, yet collectively they carry important phenotypic information [@clarke_deeprvat_2024]. Traditional burden tests collapse all rare variants in a gene into a single count, losing information about variant severity. DeepRVAT instead learns gene-level impairment scores from variant annotations using set neural networks.

The architecture treats each gene's rare variants as an unordered set, reflecting the biological reality that the order of variants along a gene is not informative for their combined effect. Each variant is characterized by a vector of annotations including predicted functional impact, conservation, and structural features. A permutation-invariant neural network aggregates these annotations into a gene-level impairment score.

Crucially, DeepRVAT learns trait-agnostic representations. The gene impairment scores are trained to be predictive across multiple phenotypes simultaneously, which provides regularization and enables transfer to new traits. This multi-task learning encourages the model to learn biologically meaningful notions of gene damage rather than overfitting to any single phenotype.

The result improves both gene discovery and risk prediction. For gene discovery, DeepRVAT identifies more significant gene-trait associations than linear burden tests, particularly for genes where variant effects are heterogeneous. For risk prediction, the learned impairment scores identify individuals with high rare variant burden across multiple genes, enabling personalized risk assessment that linear PGS cannot capture.

DeepRVAT bridges the gap between variant-level annotations and gene-level burden, making it naturally compatible with sequence-based variant effect models from earlier chapters. Annotations from models like SpliceAI, AlphaMissense, or DNA foundation models can serve as input features, and the set neural network learns how to combine them into predictive gene-level scores.

### NeEDL: Network-Based Epistasis Detection

NeEDL, Network-based Epistasis Detection via Local search, addresses the complementary challenge of identifying epistatic interactions among variants [@kessler_needl_2023]. The search space for epistasis is enormous: even considering only pairwise interactions among a million variants yields approximately 500 billion pairs to test. NeEDL uses network structure and optimization algorithms to make this search tractable.

The approach builds on network medicine principles. Genes and variants are embedded in a network based on biological prior knowledge, including protein-protein interactions, pathway membership, and co-expression relationships, as well as GWAS signals that suggest which variants influence the trait. Local search strategies explore combinations of variants that are close in this network and that jointly influence disease.

The optimization uses algorithms that efficiently explore the combinatorial space of variant combinations. Rather than exhaustively testing all pairs or higher-order combinations, the search focuses on biologically plausible interaction sets defined by network proximity.

NeEDL does not operate as a full genomic foundation model, but it points toward systems-level combinatorial reasoning that future models will need to support. The network structure provides biological constraints that make the epistasis search feasible, and the discovered interactions map onto interpretable pathways and cellular processes.

### G2PT: Hierarchical Genotype-to-Phenotype Transformers

G2PT, Genotype-to-Phenotype Transformer, explicitly models the hierarchical structure connecting variants to phenotypes [@lee_g2pt_2025]. Rather than treating variants as independent features to be weighted and summed, G2PT organizes variants into genes, genes into systems such as pathways and tissues, and systems into phenotype predictions.

The architecture uses transformer blocks at each level of this hierarchy. Variant-level attention captures interactions between variants within a gene. Gene-level attention captures interactions between genes within a system. System-level attention captures how different pathways and tissues contribute to phenotype risk.

Prior biological knowledge structures these attention patterns. Gene-pathway membership from databases like KEGG and Reactome defines which genes belong to which systems. Tissue expression patterns from GTEx indicate where each gene is active. These priors constrain the attention patterns, ensuring that the model learns biologically plausible interaction structures rather than arbitrary statistical correlations.

The hierarchical structure provides interpretability. After training, attention weights can be examined to understand which variants, genes, and systems most strongly contribute to risk for a given individual. This enables explanations like "high risk is driven by variants in genes A and B that together perturb pathway X in tissue Y."

As proof-of-concept, G2PT was applied to model the genetics of the triglycerides to high-density lipoprotein cholesterol ratio (TG/HDL), an indicator of metabolic health. G2PT predicted this trait via attention to 1,395 variants underlying at least 20 systems, including immune response and cholesterol transport, with accuracy exceeding state-of-the-art methods. It implicated 40 epistatic interactions, including epistasis between APOA4 and CETP in phospholipid transfer, a target pathway for cholesterol modification.

G2PT can be viewed as an early example of a systems-aware genomic foundation model for genotype data. It unifies additive and interaction effects within a single deep architecture, using prior knowledge to guide learning toward biologically meaningful structure.

## Deep Learning-Enhanced Polygenic Risk and Fine-Mapping

@sec-pgs framed polygenic scores as linear weighted sums of variant effects. This approach has attractive statistical properties including interpretability, efficiency, and well-characterized uncertainty. However, it misses nonlinear effects, cannot incorporate rich sequence-based features, and struggles with rare variants and cross-ancestry generalization. Deep learning extends the PGS paradigm along each of these dimensions.

### Deep-Learning PGS Frameworks

Deep-learning PGS frameworks like Delphi replace the linear combination of variant effects with flexible neural networks that learn complex functions of genotype and covariates [@georgantas_delphi_2024].

The key technical contribution is enabling neural networks to handle genome-wide inputs. A typical GWAS includes hundreds of thousands to millions of variants, far more than can be naively input to a neural network. Delphi addresses this through efficient architectures that can process hundreds of thousands of variants while remaining computationally tractable.

The resulting models can capture dominance effects where heterozygotes differ from the midpoint of homozygotes, epistatic interactions where variant effects depend on genetic background, and gene-environment interactions where variant effects depend on non-genetic covariates. These effects are learned from data rather than specified a priori, allowing the model to discover whatever structure best predicts the phenotype.

Empirical evaluations demonstrate improved discrimination compared to linear PGS across several traits, with the gains being largest for traits where nonlinear effects are most important. Delphi showed relative increases in percentage variance explained of 11.4% for body mass index, 18.9% for systolic blood pressure, 7.5% for LDL cholesterol, 35% for C-reactive protein, 16.2% for height, and 29.6% for pulse rate compared to state-of-the-art linear methods.

Importantly, Delphi also shows improved cross-ancestry generalization: the learned representations transfer more effectively than linear weights to populations not well represented in training data. This suggests that deep learning can partially address the well-documented portability problem of polygenic scores.

From a systems perspective, deep-learning PGS frameworks represent a move toward whole-patient risk modeling. While still primarily based on genotype plus covariates without explicit multi-omics integration, they demonstrate that the linear PGS paradigm can be extended to capture more biological complexity.

### MIFM and Multi-Ancestry Fine-Mapping

Fine-mapping addresses a fundamental challenge in human genetics: GWAS identifies loci but cannot usually pinpoint causal variants. Within each associated locus, linkage disequilibrium means that many variants are correlated with the causal variant and show similar association signals. Fine-mapping methods attempt to distinguish causal variants from these correlated passengers.

Multiple-instance fine-mapping frameworks like MIFM address the key bottleneck that per-variant causal labels are rarely available [@rakowski_mifm_2025]. Instead, we typically know only that some variant or variants within a locus are causal. MIFM treats this as a multiple-instance learning problem where each locus is a "bag" of variants, only some of which are causal.

The framework learns to score variants based on sequence-derived features from genomic foundation models, conservation, and functional annotations. The training objective encourages the model to identify variants that distinguish causal loci from matched control regions, without requiring explicit labels for individual variants.

By incorporating foundation model embeddings, MIFM can leverage the rich sequence representations learned from large-scale pretraining. Variants in similar regulatory contexts receive similar scores, even if they have not been directly observed in fine-mapping studies. This enables transfer to new loci and populations where fine-mapping data are limited.

## Design Patterns Across Multi-Omics Models

Several design patterns provide conceptual vocabulary for understanding existing methods and designing new ones.

**Modality-specific encoders with shared latent spaces** appear in GLUE, CpGPT, and many multi-omics subtyping models. Each omic has its own encoder architecture tailored to its data characteristics, whether that involves treating methylation as a sequence, using variational autoencoders for scRNA-seq, or applying graph convolutions to patient similarity networks. These modality-specific encoders map into a common embedding space where downstream tasks operate. This design supports flexible inference with missing modalities, since only the available encoders need to fire, and allows incremental addition of new data types by training new encoders without retraining existing components.

**Graph-guided integration** structures learning through biological prior knowledge. GLUE's feature graph links peaks to genes and transcription factors. CGMega's gene-level graphs encode multi-omic relationships. NeEDL's epistasis networks capture pathway structure and protein interactions. Graph neural networks, graph transformers, and attention mechanisms over graph edges provide natural tools for encoding these biological networks and learning representations that respect network structure.

**Hierarchical modeling** captures the organization of biological systems across scales. G2PT formalizes the hierarchy from variants to genes to systems to phenotypes. Similar hierarchies can be defined for omics layers: sequence gives rise to chromatin state, which influences methylation patterns, which affect transcription, which determines protein levels, which ultimately connect to clinical traits. Architectures that respect this hierarchy can learn more interpretable and generalizable representations than flat models that treat all features equivalently.

**Set-based and bag-based learning** handles collections of variants or features that lack natural ordering. DeepRVAT treats variants within a gene as an unordered set, using permutation-invariant architectures to aggregate them into gene-level scores. MIFM treats variants within a fine-mapping locus as a bag, learning to identify causal variants without explicit per-variant labels. This pattern is crucial when sample sizes are large, labels are sparse, and biological order is meaningless.

**Foundation pretraining with task-specific adaptation** follows the broader paradigm that defines foundation models. CpGPT is pretrained on massive methylation datasets covering diverse tissues and conditions, then adapted through fine-tuning or linear probing to specific tasks like age prediction or mortality risk. This pattern could extend to multi-omics pretraining, where models learn joint representations of sequence, chromatin, methylation, expression, and clinical data before specialization for particular applications.

## Practical Challenges

Multi-omics foundation models introduce additional practical challenges beyond those facing single-modality approaches.

Batch effects multiply when combining data from multiple platforms, laboratories, and time points. Each modality may have its own batch structure, and batch effects can correlate with biological signals in complex ways. Harmonization methods must address batch effects within each modality while preserving cross-modal relationships.

Sample size limitations become more severe when requiring samples with measurements across all modalities. While imputation can address missing modalities, the reliability of imputed values depends on how well the relationship between modalities is captured by training data.

Most large multi-omics datasets come from European-ancestry populations in high-resource healthcare systems. Models trained on these data may perform poorly or behave differently in other populations. Multi-omics models risk amplifying disparities if trained primarily on non-representative cohorts, since the richer feature sets provide more opportunity for overfitting to population-specific patterns.

Evaluation complexity increases with the number of modalities and the breadth of potential applications. Multi-omics models can be evaluated at many levels: predictive performance on held-out data, biological consistency of learned representations with known biology, plausibility of inferred networks compared to experimental validation, and clinical utility when deployed in real-world settings. Overfitting to proxy metrics that are easy to compute may not translate to performance on the metrics that ultimately matter.

Interpretability and causal inference remain challenging. Attention scores and feature importance values provide some insight into model behavior, but they are not guarantees of causal mechanism. A model might attend to a feature because that feature is causal, or because it is correlated with something causal, or for spurious reasons related to batch effects or data collection. Integrating deep models with perturbation data from CRISPR screens and gene knockouts, and with robust causal inference frameworks, remains an open frontier.

## Outlook: Toward Whole-Patient Foundation Models

The methods in this chapter sketch an endgame for genomic deep learning that extends far beyond sequence-only models. The trajectory moves through several stages that the book has traced across its chapters.

Genome-wide variant and sequence representation through hybrid CNN, transformer, and state-space model architectures established the foundation in earlier chapters. These models learn rich representations of sequence that capture regulatory grammar, variant effects, and long-range dependencies.

Single-cell and epigenomic foundation models from @sec-epi bring methylation, cellular identity, and 3D genome structure into the picture. CpGPT treats methylation as a foundation modeling problem. scGPT and Geneformer learn cellular representations from massive transcriptomic corpora. GLUE enables integration across modalities measured in different cells.

Multi-omics integration through graph-guided latent spaces adds new dimensions. MoGCN and CGMega demonstrate how graph neural networks can integrate patient-level or gene-level multi-omic data for cancer subtyping and biomarker discovery.

Systems-level reasoning about rare variants and epistasis addresses effects that linear models miss. DeepRVAT learns gene-level impairment from rare variant sets. NeEDL searches for epistatic interactions guided by network structure. G2PT provides hierarchical models that explicitly represent the flow from variants through genes and pathways to phenotypes.

Clinically oriented risk modeling with deep PGS and fine-mapping connects genomic representations to patient outcomes. Delphi-like frameworks extend PGS to capture nonlinear effects and improve cross-ancestry generalization. MIFM-like methods integrate sequence-based variant features with GWAS evidence for more accurate fine-mapping.

A future whole-patient foundation model might unify all these threads. Such a model would jointly encode genotype, methylome, chromatin state, expression, proteomics, imaging, and electronic health record data. It would provide unified representations across tissues, cell types, and time points, capturing the dynamic nature of biological state. It would offer calibrated, equitable predictions of disease risk and treatment response across diverse populations. It would support mechanistic queries like "which pathways mediate this variant's effect in this tissue?" or "which interventions might counteract rare variant burden in this patient?"

Realizing this vision will require advances across multiple fronts. Data sharing and privacy-preserving learning must enable training on sensitive multi-omic and clinical data at scale. Scalable architecture design must handle the computational demands of truly multi-modal foundation models. Causal validation must distinguish correlative patterns from mechanistic understanding. Equity and fairness considerations must guide data collection and model development from the outset.

The methods surveyed here show that moving beyond single-omics is not merely incremental improvement but a qualitative change in what kinds of questions genomic models can address. The path from isolated sequence models to systems-level, clinically actionable genomics is becoming visible, even if substantial work remains to traverse it.

## Summary

This chapter has surveyed how deep learning extends beyond single-omics to integrate multiple data types into unified representations. We examined integration strategies spanning early, intermediate, and late fusion, with intermediate fusion augmented by graph structure emerging as the dominant approach. Graph neural network methods including MoGCN and CGMega showed how patient-level and gene-level graphs can integrate genomics, transcriptomics, and proteomics for cancer subtyping. DeepRVAT, NeEDL, and G2PT addressed rare variants and epistasis through set-based architectures and hierarchical modeling. Deep learning frameworks for polygenic risk (Delphi) and fine-mapping (MIFM) extended the PGS paradigm with nonlinear architectures and foundation model features.

Several design patterns emerged as common threads: modality-specific encoders with shared latent spaces, graph-guided integration, hierarchical modeling, set-based learning, and foundation pretraining with task-specific adaptation. These patterns provide conceptual vocabulary for understanding existing methods and designing new ones.

Practical challenges including batch effects, sample size limitations, population diversity, and evaluation complexity require careful attention. But the trajectory toward whole-patient foundation models that jointly encode multiple omics and clinical data is becoming clear.

The remaining chapters will address cross-cutting issues of evaluation, confounding, and interpretability that apply across all the models surveyed in this book, then explore how genomic foundation models translate into clinical practice.