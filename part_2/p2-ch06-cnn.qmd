# Convolutional Networks {#sec-ch06-cnn}

In 2015, a **convolutional neural network** trained on ENCODE chromatin data learned to recognize transcription factor binding motifs that matched entries in the JASPAR database, despite never seeing those motifs during training [@zhou_deepsea_2015]. The network had discovered, through gradient descent on raw sequence, patterns that experimental biologists had spent decades cataloging. This was not merely a demonstration that deep learning could match human-curated databases. The deeper insight was that learned representations could transcend existing annotations: predicting regulatory effects for any sequence, in any genomic context, including regions never assayed in any experiment. For the first time, computational methods could move beyond annotating known regulatory elements to predicting the functional consequences of sequence variation genome-wide.

The early convolutional models established paradigms that persist in modern genomic AI. *DeepSEA* demonstrated that CNNs could predict chromatin marks and transcription factor binding directly from DNA sequence, enabling variant effect prediction without requiring experimental measurements for every variant of interest. *Basset* extended this approach to chromatin accessibility across cell types, learning representations that transferred to new cellular contexts. *SpliceAI* achieved clinical-grade accuracy for splice site prediction, demonstrating that deep learning could match or exceed hand-crafted algorithms developed over decades. Each model followed a common pattern: train on functional genomics data, learn sequence features through convolutional filters, and apply to variant interpretation. The success was substantial; the paradigm seemed complete.

Yet these models revealed a fundamental architectural limitation. Convolutional networks integrate information only within their **receptive fields**, the local region of input that contributes to each output position. Genomic regulation routinely operates across distances that exceed practical receptive field sizes: enhancers control genes across tens of kilobases, topologically associating domains span megabases, GWAS variants often lie far from the genes they affect. A model analyzing a variant 50 kilobases from a gene promoter cannot connect the variant to its target using local convolutions alone. Understanding both what CNNs achieved and where they reached this architectural ceiling establishes the foundation for the attention mechanisms examined in @sec-ch07-attention.

## Convolutions as Sequence Pattern Detectors {#sec-ch06-convolutions}

A variant in an enhancer 50 kilobases from its target gene cannot be connected to that gene by a model that sees only 1,000 base pairs of context. Consider a patient with familial hypercholesterolemia whose whole-genome sequencing reveals a novel variant upstream of *LDLR*. The variant sits within a known enhancer region, but the enhancer and the *LDLR* promoter lie beyond the window any convolutional layer can span. The model might correctly identify regulatory features at the variant position, but it cannot learn that those features regulate *LDLR* rather than some other gene. This receptive field constraint, inherent to convolutional architectures, determines what relationships these networks can and cannot discover. The constraint is not a limitation of training data or compute; it is architectural.

A convolutional filter slides across an input sequence, computing similarity scores at each position. For genomic applications, the input is typically **one-hot encoded** DNA: a binary matrix with four rows (A, C, G, T) and columns for each position (see @sec-ch05-representations for detailed treatment of sequence encoding strategies). Filters learn weight patterns that respond to specific nucleotide arrangements. A filter of width 8 nucleotides, for instance, computes a weighted sum of the underlying nucleotides at each position, producing high activation when the sequence matches its learned pattern and low activation otherwise. This operation is mathematically equivalent to scanning a position weight matrix across the sequence, but with a crucial difference: the filter weights are learned during training rather than derived from aligned binding site sequences.

The first layer of a genomic CNN typically contains hundreds of such filters, each learning to detect different local patterns. Analysis of trained filters consistently reveals correspondence to known transcription factor binding motifs. The CTCF insulator motif, the ETS family consensus sequence, the AP-1 binding site: these patterns emerge from training on chromatin data without any explicit motif supervision. The network identifies them because they predict the training labels. Supervision on chromatin state induces discovery of the sequence patterns that create chromatin state, providing unsupervised motif learning as a byproduct of supervised prediction.

Deeper layers operate on the output of earlier layers rather than raw sequence. A second-layer filter might learn to detect specific arrangements of first-layer motifs: two ETS sites within 20 base pairs, or a CTCF motif flanked by particular spacing patterns. This hierarchical feature learning enables CNNs to capture regulatory grammar beyond individual motifs, including spacing constraints, orientation preferences, and combinatorial requirements that govern transcription factor cooperativity.

::: {#fig-conv-pattern-detector layout-ncol=3}
![**FIGURE PLACEHOLDER A**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20A)

![**FIGURE PLACEHOLDER B**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20B)

![**FIGURE PLACEHOLDER C**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20C)

[Essential] Three-panel figure showing convolution mechanics. Panel A: Single convolutional filter (width 8) sliding across one-hot encoded DNA, producing activation scores at each position; show high activation where filter matches a motif. Panel B: Learned filter weights visualized as sequence logo (PWM-style), aligned to corresponding JASPAR motif showing the biological pattern discovered. Panel C: Multiple filters from first convolutional layer, each detecting different motifs (CTCF, ETS, AP-1), showing diverse pattern detection.
:::

Between convolutional layers, spatial resolution must decrease while the receptive field expands. **Pooling** operations achieve this tradeoff: max pooling selects the strongest activation within a window, achieving position-invariant detection where the network responds to a motif's presence somewhere in a region rather than its exact position. This property suits regulatory genomics, where binding site positions within an enhancer often matter less than their presence and combination.

The receptive field of a convolutional network defines how much input sequence can influence a single output prediction. For a network with kernel width $k$, pooling factor $p$, and $L$ layers, the receptive field grows with depth but remains fundamentally limited by architecture. A three-layer network with typical parameters might integrate information from 200 to 1,000 base pairs. Reaching further requires either more layers (increasing computational cost and training difficulty) or **dilated convolutions** that space filter weights to sample larger regions. When biological dependencies span tens of kilobases, this receptive field ceiling becomes the fundamental constraint that no amount of training data can overcome.

## *DeepSEA*: Regulatory Prediction from Sequence {#sec-ch06-deepsea}

A patient presents with a rare disease phenotype, and whole-genome sequencing reveals a novel variant in an intron 15 kilobases from the nearest exon. The variant does not disrupt any annotated regulatory element. No prior patient in any database carries this exact change. The clinician must decide: is this variant pathogenic, or is it an irrelevant passenger? Annotation-based methods offer no guidance. The variant overlaps nothing cataloged, so overlap-based interpretation returns nothing useful. Yet introns harbor splice regulatory elements, and 15 kilobases places the variant well within range of enhancers that might control the adjacent gene.

Existing approaches to noncoding variant interpretation relied on this overlap paradigm. If a variant fell within a ChIP-seq peak or DNase hypersensitive site, it might be flagged as potentially regulatory. The strategy grounded predictions in experimental observations, but it could not predict whether a variant would strengthen or weaken regulatory activity, could not score variants in regions lacking experimental coverage, and provided no mechanism for quantifying effect magnitude. A variant might fall within an enhancer, but would it matter? The data indicated where regulatory elements existed; they did not indicate how sequence changes would affect them.

*DeepSEA*, introduced by Zhou and Troyanskaya, reframed the problem: rather than asking whether a variant overlaps known annotations, ask what regulatory activities a sequence encodes and how mutations would alter them [@zhou_deepsea_2015]. The shift from annotation lookup to sequence-based prediction enabled scoring any variant in any genomic context, including regions never assayed in any experiment. This reframing would prove more consequential than any specific architectural choice.

::: {#fig-deepsea-architecture layout-ncol=3}
![**FIGURE PLACEHOLDER A**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20A)

![**FIGURE PLACEHOLDER B**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20B)

![**FIGURE PLACEHOLDER C**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20C)

[High] Three-panel figure. Panel A: Architecture schematic showing input (1000bp one-hot), three convolutional layers with pooling (320→480→960 filters), fully connected layer, and 919 sigmoid outputs for chromatin features. Panel B: First-layer filter aligned to JASPAR motif (e.g., CTCF), demonstrating learned = known biology. Panel C: Scatter plot of predicted vs. observed allelic imbalance for DNase-seq, showing correlation that validates variant effect prediction.
:::


### Architecture and Training {#sec-ch06-deepsea-architecture}

The clinical scenario described above demands a model that can predict function from sequence alone. *DeepSEA*'s architecture was deliberately simple by contemporary standards, placing the emphasis on the learning framework rather than architectural complexity.

Input sequences of 1,000 base pairs, one-hot encoded, passed through three convolutional layers with 320, 480, and 960 filters respectively. Max pooling after each convolution compressed spatial dimensions. A fully connected layer with 925 units integrated information across the compressed representation, and a final output layer with 919 sigmoid units produced independent probability predictions for each chromatin profile.

Training data came from ENCODE and Roadmap Epigenomics (see @sec-ch02-data for comprehensive treatment of these resources): 690 transcription factor binding profiles, 104 histone modification profiles, and 125 DNase I hypersensitivity profiles spanning diverse cell types [@kagda_encode_2025; @kundaje_roadmap_2015]. For each 1,000 bp input, the model predicted whether the central 200 bp region exhibited each chromatin feature. Chromosome 8 was held out for evaluation.

The **multi-task learning** formulation proved essential for generalization. Predicting 919 features simultaneously forced the network to learn shared representations useful across many prediction problems. The first convolutional layer learns general sequence patterns (GC content, common dinucleotides, ubiquitous motifs); these representations then feed task-specific combinations in later layers. Joint training provides implicit regularization, preventing overfitting to any single task while amortizing the cost of learning basic sequence features across all outputs.


### Learned Representations and Biological Validation {#sec-ch06-deepsea-validation}

Any sequence model faces a fundamental question: do learned features correspond to biological reality, or do they exploit statistical shortcuts that happen to correlate with labels? *DeepSEA* provided the first large-scale evidence that deep learning could recover genuine regulatory logic.

Analysis of first-layer filters revealed learned patterns matching known transcription factor motifs. The network had independently recovered sequence preferences cataloged in JASPAR and TRANSFAC, confirming that the training objective (predicting chromatin state) induced biologically meaningful feature extraction. This interpretability distinguished deep learning from prior black-box approaches and suggested that the models captured genuine regulatory logic rather than spurious correlations. Systematic methods for extracting and visualizing these learned representations, from filter analysis to attribution mapping, are examined in @sec-ch24-interpretability.

Deeper layers combined first-layer patterns into more complex representations, capturing motif spacing requirements, orientation preferences, and cooperative binding arrangements. The network encoded relationships between sequence features that position weight matrices, operating independently at each motif, could not represent.

*DeepSEA* outperformed gkm-SVM (gapped $k$-mer support vector machines) on nearly all transcription factor binding prediction tasks *[Citation Needed]*. The pattern of improvement revealed something fundamental: gkm-SVM showed no benefit from longer input sequences, while *DeepSEA* performance improved substantially with additional context. *K*-mer methods tally motif occurrences but cannot learn relationships between patterns at different positions. Hierarchical feature learning enables exactly what $k$-mer methods cannot provide: representations of combinatorial regulatory logic.


### Variant Effect Prediction {#sec-ch06-deepsea-vep}

With a trained sequence-to-chromatin model, variant scoring becomes straightforward: predict chromatin profiles for reference and alternative sequences, compute the difference. This **in silico mutagenesis** produces a 919-dimensional vector describing predicted changes across all features. The model never encounters variant data during training; effect prediction emerges from learned sequence-function relationships applied to mutations the model has never seen.

Validation used allelic imbalance data from digital genomic footprinting. For variants showing allele-specific DNase I sensitivity, *DeepSEA* predictions correlated with experimentally observed biases: variants predicted to increase accessibility tended to show higher accessibility on the corresponding allele. This correlation would not exist if the model merely learned coarse sequence features insensitive to point mutations.

Systematic characterization of regulatory elements requires more than single-variant scoring. **In silico saturation mutagenesis** predicts effects of all possible substitutions across a regulatory element, identifying positions where mutations most strongly perturb function. These critical positions typically correspond to transcription factor binding motifs, providing motif discovery that emerges from learned representations rather than explicit sequence alignment. The approach enables characterization of any regulatory element, including those in cell types or conditions never experimentally profiled. Foundation models extend these principles to longer contexts and richer representations (@sec-ch14-vep-fm), while clinical integration requires calibration approaches that map model outputs to actionable categories (@sec-ch26-rare-disease).


## Cell-Type Specificity and Regulatory Grammar {#sec-ch06-basset}

A variant that disrupts cardiac-specific gene regulation may be lethal in the heart but entirely silent in neurons. A regulatory element active during embryonic development may be permanently silenced in adult tissues. Clinical variant interpretation therefore requires models that capture not just what sequence patterns predict regulatory activity, but how those predictions vary across the dozens of cell types and developmental stages where a variant might act. *DeepSEA*'s 919 chromatin features spanned multiple cell types, but the question remained: could architectural modifications better capture cell-type-specific programs or learn richer representations of the combinatorial grammar governing transcription factor cooperativity?

*Basset*, introduced by Kelley et al. in 2016, focused specifically on predicting chromatin accessibility from sequence [@kelley_basset_2016]. Rather than *DeepSEA*'s diverse chromatin features, *Basset* predicted DNase-seq peaks across 164 cell types, enabling detailed analysis of cell-type-specific regulatory activity. The architectural refinements *Basset* introduced would influence subsequent models: **batch normalization** after convolutional layers stabilized training and enabled deeper networks, while larger filters in early layers (19 nucleotides in the first layer) captured longer motifs directly rather than requiring the network to compose them from smaller patterns.

The key contribution was demonstrating that *in silico* saturation mutagenesis profiles from trained models could identify causal variants underlying disease-associated haplotypes. GWAS identifies associated regions but cannot distinguish the causal variant from nearby variants in linkage disequilibrium (see @sec-ch03-gwas for the statistical foundations of association studies). *Basset*'s saturation mutagenesis provided a principled approach: the variant with the strongest predicted regulatory effect within an associated haplotype is the most likely causal candidate. Foundation models like *Enformer* (@sec-ch13-regulatory) extend this principle to longer contexts that capture more distal regulatory influences on GWAS signals. This moved beyond simple peak overlap toward mechanistic variant prioritization, and subsequent validation studies confirmed that model-prioritized variants showed higher rates of experimental confirmation than lead SNPs selected purely by association strength *[Citation Needed]*.

*DanQ* explored whether regulatory grammar involves sequential dependencies that convolutions alone might miss, combining convolutional layers with bidirectional LSTMs to integrate motif detections across the input window [@quang_danq_2016]. The hybrid architecture achieved modest improvements on chromatin prediction benchmarks, though the recurrent components introduced costs examined in @sec-ch06-sequential.

These variations illustrated a broader principle: multiple architectures could learn useful regulatory representations from sequence. The specific choices (filter sizes, layer depths, recurrent components) mattered less than the fundamental framework of learning from one-hot encoded sequence to predict chromatin labels. This robustness suggested that the underlying signal, sequence determinants of regulatory activity, was strong enough to be captured by diverse architectural approaches. For clinical applications, prediction quality depends more on training data quality and task definition than on architectural details within the CNN family.


## *ExPecto*: From Chromatin to Expression {#sec-ch06-expecto}

A patient's tumor harbors a somatic variant in a putative enhancer region. Chromatin profiling in matching tissue shows the region is accessible. The variant is predicted to disrupt a transcription factor binding site. Yet the clinician's question remains unanswered: does this variant actually change expression of a target gene? Which gene? By how much? In which tissues?

Chromatin accessibility and transcription factor binding are intermediate phenotypes, means rather than ends. The ultimate functional readout for most regulatory variants is their effect on gene expression. A variant might disrupt a binding site, but sites can be redundant, effects can be buffered, and the relationship between binding and expression is not one-to-one. Predicting expression change from sequence requires integrating regulatory signals across distances that determine which enhancers control which promoters. A variant that disrupts binding but does not alter expression is unlikely to be pathogenic, while a variant with modest chromatin effects but strong expression consequences may drive disease.

*ExPecto*, introduced by Zhou et al. in 2018, addressed these questions by extending sequence-to-chromatin prediction toward tissue-specific gene expression [@zhou_expecto_2018]. The framework predicts expression levels across 218 tissues and cell types by integrating predicted chromatin signals across a 40 kb promoter-proximal window. This context expansion, from *DeepSEA*'s 1 kb to *ExPecto*'s 40 kb, represented a significant architectural commitment: expression prediction requires integrating regulatory signals from distances far exceeding typical motif sizes.

::: {#fig-expecto-pipeline}
![**FIGURE PLACEHOLDER**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER)

[Enhancing] Three-component pipeline diagram. Component 1: Beluga CNN scanning 40kb window around TSS with sliding 2kb windows, producing chromatin predictions at 200 spatial positions. Component 2: Spatial transformation with exponential decay functions (upstream and downstream), reducing to ~20,000 features. Component 3: 218 tissue-specific linear regression models, producing per-tissue expression predictions. Show example delta scores for variant effect.
:::

### Modular Architecture {#sec-ch06-expecto-architecture}

*ExPecto* comprises three sequential components, each addressing a distinct computational challenge. The separation proved essential: jointly optimizing all components end-to-end would be computationally prohibitive, and the modular design enables interpretability at each stage.

The first component, an enhanced CNN called *Beluga*, predicts 2,002 chromatin profiles from 2,000 bp input sequences. *Beluga* incorporated architectural improvements over *DeepSEA*: six convolutional layers with **residual connections**, expanded chromatin targets, and broader cell-type coverage. This CNN scans the 40 kb region surrounding each transcription start site with a moving window, generating chromatin predictions at 200 spatial positions and producing over 400,000 features per gene.

The second component transforms these high-dimensional features through spatial aggregation. Ten exponential decay functions, applied separately to upstream and downstream regions, encode the prior belief that nearby elements contribute more than distant ones. This transformation reduces dimensionality while preserving spatial relationships, producing approximately 20,000 features per gene that capture both which chromatin features are predicted and where they occur relative to the TSS.

The final component comprises 218 *L*₂-regularized linear regression models, one per tissue, predicting log expression from spatially-transformed features. Linear models were chosen deliberately: they provide interpretability, prevent overfitting given the high-dimensional feature space, and enable coefficient analysis to identify which chromatin features drive expression in each tissue. The combination of a shared sequence-to-chromatin CNN with separate tissue-specific linear heads cleanly separates sequence-level regulatory grammar from tissue-specific regulatory programs.


### Expression Prediction and Variant Effects {#sec-ch06-expecto-validation}

*ExPecto* achieved 0.819 median Spearman correlation between predicted and observed expression across tissues. Analysis of model coefficients revealed automatic learning of cell-type-relevant features: the liver expression model weighted HepG2-derived transcription factor features most heavily; breast tissue models emphasized estrogen receptor features from breast cancer cell lines. These tissue-specific patterns emerged purely from learning to predict expression, without tissue identity information provided to the chromatin model.

Variant effect prediction follows the same logic as *DeepSEA*: compare expression predictions for reference and alternative sequences. Because the model never trains on variant data, predictions are unconfounded by linkage disequilibrium, a critical distinction from association-based methods (see @sec-ch22-confounding for detailed treatment of confounding in genomic models). *ExPecto* correctly predicted expression change direction for 92% of the strongest GTEx eQTL variants, and experimental validation confirmed that model-prioritized variants (not the GWAS lead SNPs) showed allele-specific regulatory activity in reporter assays *[Citation Needed]*.

The 40 kb window represents an empirically optimized trade-off. Smaller windows decreased performance; larger windows showed negligible improvement. Most promoter-proximal regulatory information lies within 40 kb of the TSS, at least within *ExPecto*'s linear modeling framework. Distal enhancers beyond this window, while biologically important, require architectural approaches that can model longer-range dependencies. This limitation points toward the transformer architectures and hybrid models examined in @sec-ch13-regulatory.


## *SpliceAI*: Clinical-Grade Splicing Prediction {#sec-ch06-spliceai}

A child presents with developmental delay and dysmorphic features consistent with a known genetic syndrome. Clinical exome sequencing reveals no pathogenic coding variants in the implicated gene. The case is signed out as "unsolved," the family left without answers. Three years later, research RNA sequencing identifies aberrant splicing in the syndromic gene: an intronic variant 150 base pairs from the nearest exon creates a cryptic splice site, inserting a premature stop codon. The diagnosis was hiding in plain sight, invisible to methods that only examine canonical splice dinucleotides.

This scenario, replicated across thousands of unsolved rare disease cases, illustrates a systematic blind spot in clinical genomics. Splice-disrupting mutations represent a major mechanism of Mendelian disease (see @sec-ch26-rare-disease for broader treatment of rare disease diagnosis), yet variants affecting splicing outside canonical GT/AG dinucleotides are systematically underascertained. Prior splice prediction methods captured essential splice site motifs but could not model the long-range determinants contributing to splicing specificity. *MaxEntScan* operates on approximately 9 bp of context around donor and acceptor sites [@yeo_maxentscan_2004]. These methods produced many false positives and missed variants acting through distal mechanisms: branch points, exonic splicing enhancers, and intron length constraints that previous models could not see.

*SpliceAI*, introduced by Jaganathan et al. in 2019, demonstrated that deep neural networks could learn splicing rules with near-spliceosomal precision [@jaganathan_spliceai_2019]. The model predicts splice site locations directly from pre-mRNA sequence using 10,000 nucleotides of context, an order of magnitude beyond prior methods. This context expansion enabled recognition of distant splicing determinants invisible to annotation-based approaches.


### Architecture: Depth and Dilation {#sec-ch06-spliceai-architecture}

Learning splicing rules from 10 kb of sequence context requires an architecture that can integrate information across this entire span while maintaining nucleotide-level resolution. *SpliceAI* achieves this through two innovations: extreme depth enabled by residual connections, and dilated convolutions that expand receptive fields without proportional parameter growth.

*SpliceAI* employs an ultra-deep residual network with 32 convolutional layers. Residual connections address the **vanishing gradient problem** that otherwise prevents training at this depth:

$$
\text{output} = \text{input} + F(\text{input})
$$

By learning residual functions rather than direct mappings, the network can propagate gradients through dozens of layers. Skip connections from every fourth residual block feed directly to the penultimate layer, further stabilizing training dynamics.

Dilated convolutions expand the receptive field efficiently. A dilated convolution with rate *d* samples input positions at intervals of *d* rather than consecutively. Stacking convolutions with increasing dilation rates (1, 2, 4, 8, 16, and so on) allows the network to integrate information across the full 10 kb window while maintaining sensitivity to local patterns. Standard convolutions with small kernels would require impractical depth to achieve equivalent receptive fields.

For each position in the pre-mRNA sequence, *SpliceAI* outputs three probabilities: splice acceptor, splice donor, or neither. This per-position classification enables fine-grained predictions across entire transcripts. Training used GENCODE annotations, with odd and even chromosomes split for training and testing.

::: {#fig-spliceai-architecture layout-ncol=2}
![**FIGURE PLACEHOLDER A**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20A)

![**FIGURE PLACEHOLDER B**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20B)

[High] Two-panel figure. Panel A: Diagram showing how dilated convolutions expand receptive field without proportional parameter growth. Show dilation rates (1, 2, 4, 8, 16...) with gaps between filter taps, illustrating how 32 layers with dilation reach 10kb context. Panel B: *SpliceAI*'s residual block structure with skip connections from every 4th block to output, enabling gradient flow through 32 layers.
:::

### Performance and Validation {#sec-ch06-spliceai-performance}

*SpliceAI* achieved 95% top-$k$ accuracy for splice site identification (compared to 57% for *MaxEntScan*) and 0.98 precision-recall area under the curve (auPRC). Complex genes exceeding 100 kb are often reconstructed to nucleotide precision. Performance improved dramatically with context length:

| Model Variant | Context (each side) | auPRC |
|---------------|---------------------|-------|
| *SpliceAI*-80nt | 40 bp | 0.87 |
| *SpliceAI*-400nt | 200 bp | 0.93 |
| *SpliceAI*-2k | 1,000 bp | 0.96 |
| *SpliceAI*-10k | 5,000 bp | 0.98 |

This progression confirms that distal sequence features contribute meaningfully to splicing decisions. The diminishing returns above 2 kb suggest that most splicing determinants lie within this range, though the additional context still provides measurable benefit.

The delta score quantifies variant effects by comparing predictions for reference and alternative sequences:

$$
\Delta\text{score} = \max_{|p - v| \leq 50} \left| P_{\text{alt}}(p) - P_{\text{ref}}(p) \right|
$$

Validation against GTEx RNA-seq showed that mutations with higher delta scores showed higher validation rates at novel splice junctions: approximately 50% at Δ ≥ 0.2, 75% at Δ ≥ 0.5, and 85% at Δ ≥ 0.8. Population genetics provided orthogonal support: predicted cryptic splice variants showed 78% depletion at common allele frequencies, nearly matching the depletion of frameshift and stop-gain variants. Natural selection treats these variants as deleterious, confirming their functional impact.


### Clinical Impact {#sec-ch06-spliceai-clinical}

*SpliceAI*'s most significant contribution may be quantifying cryptic splice mutations as a major, previously underappreciated cause of rare genetic disorders. Analysis of *de novo* mutations in over 4,000 individuals with intellectual disability found significant enrichment of predicted splice-disrupting variants compared to unaffected controls (1.51-fold, p = 4.2×10⁻⁴). Approximately 9% of pathogenic *de novo* mutations in intellectual disability act through cryptic splicing *[Citation Needed]*. Including these variants in gene discovery analyses identified additional candidate genes that would have fallen below discovery thresholds when considering only protein-coding mutations.

This clinical utility explains *SpliceAI*'s rapid adoption. Illumina integrated *SpliceAI* into their annotation pipelines. Clinical genetics laboratories worldwide use delta scores to flag potential splice-affecting variants for RNA-seq follow-up. The model exemplifies how task-specific deep learning can achieve clinical-grade accuracy on well-defined problems. *SpliceAI*'s integration into modern variant interpretation workflows is examined in @sec-ch14-vep-fm, and its role in rare disease diagnosis pipelines appears in @sec-ch26-rare-disease.


## Receptive Field Ceiling {#sec-ch06-receptive-field}

Consider a 45-year-old woman with early-onset breast cancer and a family history suggesting hereditary risk. Whole-genome sequencing identifies a novel variant 80 kilobases upstream of *BRCA1*, within an established enhancer region. The enhancer is known to regulate *BRCA1* expression in mammary epithelium. Does this variant reduce *BRCA1* expression enough to increase cancer risk? *DeepSEA* can predict whether the variant disrupts transcription factor binding at that position. *SpliceAI* confirms no splice effects. *ExPecto*'s 40 kb window cannot reach from the variant to the *BRCA1* promoter. No convolutional model can connect the enhancer variant to its target gene because the distance exceeds their receptive fields. The clinical question remains unanswered.

This case illustrates a fundamental limitation rooted in architecture: convolutional networks can only integrate information within their receptive fields. *DeepSEA*'s three-layer architecture effectively considers roughly 1 kb of context. *ExPecto*'s *Beluga* component operates on 2 kb windows, aggregated across a 40 kb region by the spatial transformation layer. *SpliceAI* pushes to 10 kb through dilated convolutions and 32 layers. Each expansion required significant architectural engineering, and each reached a practical ceiling beyond which further expansion yielded diminishing returns or became computationally prohibitive.

The limitation matters because genomic regulation routinely operates across distances these models cannot reach. Enhancers regulate promoters 50 to 500 kilobases away. The *beta-globin* locus control region sits 40 to 60 kb from the genes it activates. Polycomb-mediated repression involves chromatin contacts spanning megabases. Topologically associating domains organize regulatory interactions across hundreds of kilobases (see @sec-ch17-3d-genome for detailed treatment of chromatin architecture). When regulatory elements and their targets lie beyond a model's receptive field, the model cannot learn their relationship regardless of how much training data is available. The constraint is architectural, not statistical. Attention mechanisms (@sec-ch07-attention) provide the architectural solution, while hybrid models like *Enformer* (@sec-ch13-regulatory) combine convolutional motif detection with transformer-based long-range integration.

This creates a systematic mismatch between biological importance and computational accessibility. A variant within a distal enhancer may have profound effects on gene expression, but a model with a 10 kb receptive field cannot connect the enhancer sequence to its target promoter. The model might correctly predict that the enhancer sequence contains regulatory features, but it cannot predict which gene those features regulate or how strongly. We can predict local regulatory potential, yet we cannot predict long-range regulatory effects.

The architectural response to this challenge evolved through two stages. Recurrent networks initially seemed promising, carrying context through hidden states rather than expanding receptive fields. When recurrence proved insufficient, attention mechanisms provided the architectural solution that modern genomic models required.

::: {#fig-receptive-field-ceiling}
![**FIGURE PLACEHOLDER**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER)

[Essential] Horizontal genome diagram comparing effective context windows across CNN architectures. Show: *DeepSEA* (~1 kb), *ExPecto*/*Beluga* (2 kb windows, 40 kb aggregated), *SpliceAI* (10 kb), and for contrast, *Enformer* (200 kb). Overlay biologically relevant distances: typical TF binding site (~10bp), promoter region (~1kb), enhancer-gene distance (10-100kb), TAD size (~1Mb). Highlight the gap: "Most enhancer-promoter interactions exceed CNN receptive fields."
:::

## Sequential Approaches and Their Costs {#sec-ch06-sequential}

If convolutional networks cannot reach far enough, why not simply carry information forward through the sequence? Recurrent neural networks offered an intuitive solution to the receptive field problem: maintain a hidden state that accumulates context as the network processes each position in turn. Where a convolutional filter sees only its local window, a **recurrent neural network (RNN)**'s hidden state can, in principle, carry information from the beginning of a sequence to its end. For biological sequences, this seemed natural. DNA is read by polymerases in one direction; transcripts are processed sequentially by ribosomes; regulatory elements exert effects that propagate through chromatin. A computational architecture that mirrors this sequential logic appeared well-suited to genomic modeling.

The hidden state mechanism works as follows. At each position *t*, the network combines the current input $x_t$ with the previous hidden state $h_{t-1}$ to produce a new hidden state $h_t$. This recurrence allows information from early positions to influence computations at later positions through the chain of hidden states. A regulatory element at position 1,000 can, in theory, affect predictions at position 50,000 because its influence persists in the hidden state across all intervening positions. No receptive field limits this reach; the constraint becomes whether information survives the journey.

### Vanishing Gradient Problem {#sec-ch06-vanishing-gradient}

Information rarely survives. Training RNNs requires backpropagating gradients through time, computing how errors at late positions depend on parameters applied at early positions. These gradients pass through the same recurrent weight matrix at each step. When gradients are multiplied through hundreds or thousands of steps, they either explode (growing exponentially) or vanish (shrinking toward zero). The vanishing gradient problem makes it nearly impossible for RNNs to learn dependencies spanning more than a few dozen positions. A regulatory element 10,000 base pairs upstream might as well not exist: by the time gradients propagate backward through 10,000 recurrent steps, they have decayed to numerical insignificance.

Gating mechanisms that control information flow resolved the vanishing gradient problem. **Long Short-Term Memory (LSTM)** networks achieve this through a separate cell state with learned gates that determine what information to store, what to forget, and what to output [@hochreiter_long_1997]. The forget gate can preserve information indefinitely by setting its value near one, allowing gradients to flow through the cell state without repeated multiplication by small values. **Gated Recurrent Units (GRUs)** simplified this design by combining gates while retaining the core insight: learned gating prevents gradient decay [@cho_learning_2014].

These gated architectures extended effective memory from tens to hundreds of positions, sometimes thousands. For natural language, where most dependencies span fewer than 50 words, LSTMs proved transformative. For genomic sequences, where relevant context can span tens of kilobases (tens of thousands of nucleotides), even gated recurrence falls short. The mathematics of gradient propagation through recurrent connections imposes limits that no gating mechanism fully overcomes.

### *DanQ*: Combining Convolutions and Recurrence {#sec-ch06-danq}

The *DanQ* model represented the most influential attempt to apply recurrent architectures to regulatory genomics [@quang_danq_2016]. Rather than replacing convolutions entirely, *DanQ* combined them: convolutional layers first extracted local sequence motifs, then a bidirectional LSTM integrated these motif detections across the 1,000 base pair input window. The architecture recognized that convolutions excel at detecting local patterns while recurrence might capture their long-range relationships.

*DanQ* processed sequences in both directions simultaneously (bidirectional recurrence), allowing each position to incorporate context from both upstream and downstream. Training on the same *DeepSEA* chromatin prediction task, *DanQ* achieved modest improvements over the purely convolutional baseline, with the LSTM component learning to weight motif combinations based on their relative positions and co-occurrence patterns.

The improvement was real but limited. Within a 1,000 base pair window, convolutional receptive fields already capture most relevant dependencies, leaving less room for recurrence to contribute. The fundamental problem remained: neither convolutions nor recurrence could reach the 50 to 100 kilobase distances where enhancers regulate their target genes. *DanQ* demonstrated that hybrid architectures could outperform pure convolutions, but the gains did not justify the added complexity for most applications. The model saw limited adoption compared to simpler convolutional alternatives.

### Sequential Bottleneck {#sec-ch06-sequential-bottleneck}

Even if recurrence could maintain gradients across genomic distances, a more fundamental constraint would remain. RNNs process sequences one position at a time. Each hidden state $h_t$ depends on the previous hidden state $h_{t-1}$, creating an inherently sequential computation that cannot be parallelized. Training on a 100,000 base pair sequence requires 100,000 sequential steps, each waiting for the previous step to complete. Modern GPUs achieve their speed through massive parallelism; sequential dependencies eliminate this advantage.

This computational bottleneck made RNNs impractical for the long contexts that genomic applications require. A transformer processes all positions simultaneously, computing attention scores in parallel across the entire sequence. For a 100 kilobase context, a transformer performs one parallel operation where an RNN would require 100,000 sequential steps. The difference in training time is not incremental; it is the difference between feasible and infeasible. When *Enformer* extended genomic modeling to 200 kilobase contexts (see @sec-ch13-regulatory), recurrent architectures were not considered. The sequential bottleneck had already disqualified them.

The attention mechanism resolved both limitations simultaneously. **Self-attention** computes direct interactions between all positions without sequential dependencies, enabling parallel processing across arbitrary context lengths. Attention weights are computed through matrix operations that GPUs execute efficiently, and gradients flow directly between any two positions without passing through intermediate states. The path from position 1 to position 100,000 involves a single attention computation rather than 100,000 recurrent steps. This architectural shift, examined in @sec-ch07-attention, enabled the long-range modeling that genomic applications demand.

## Specialization and Its Limits {#sec-ch06-specialization}

The convolutional models examined here established paradigms that persist in modern genomic AI. End-to-end learning from one-hot encoded sequence demonstrated that gradient descent on functional labels could discover regulatory patterns without encoding human assumptions about what matters. Multi-task training across hundreds of chromatin features showed that shared representations improve both accuracy and generalization. *In silico* mutagenesis, comparing predictions for reference and alternative sequences, established the dominant approach for deep learning-based variant effect prediction: scoring variants without training on variant labels, thereby avoiding the ascertainment biases that confound association-based methods (see @sec-ch22-confounding).

These principles carry forward into foundation model architectures. What CNNs could not resolve was the receptive field limitation. Genomic regulation operates across scales that exceed practical convolutional depth: enhancers modulating genes across hundreds of kilobases, topologically associating domains spanning megabases. Dilated convolutions and deeper networks extend reach but cannot fundamentally escape the constraint that convolutions aggregate local information through hierarchical composition.

Yet specialization retains value even as general-purpose models advance. *SpliceAI* achieves clinical-grade splice site prediction that broader foundation models have not matched. When the prediction target is well-defined, training data abundant, and the relevant context fits within architectural constraints, task-specific models remain competitive with or superior to general-purpose approaches. This tension between specialized accuracy and general capability defines architectural choices across genomic AI. For clinical deployment requiring high reliability on specific tasks, specialized architectures may remain preferred. For discovery applications requiring broad coverage across diverse molecular mechanisms, the foundation model paradigm (see @sec-ch10-fm-principles) offers different trade-offs. Attention mechanisms provide the architectural substrate for long-range modeling while inheriting the end-to-end learning principles that convolutional networks established. The tension between specialized accuracy and general capability reappears throughout this book: for splice prediction and motif detection where CNNs excel, task-specific architectures remain competitive; for regulatory prediction requiring long-range integration, the foundation model approaches in Part III offer different tradeoffs (@sec-ch10-fm-principles).