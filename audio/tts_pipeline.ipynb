{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFM Book Text-to-Speech Pipeline\n",
    "\n",
    "Converts Quarto book chapters to audio using Google Cloud TTS.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Google Cloud account with TTS API enabled\n",
    "- `gcloud` CLI installed and authenticated\n",
    "\n",
    "**Cost:** ~62K chars per chapter, 1M chars/month free tier covers the full book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q google-cloud-texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with GCP (run once, follow the browser prompt)\n",
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from google.cloud import texttospeech\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to gfm-book repository\n",
    "BOOK_ROOT = Path(\"/root/gfm-book\")  # Update this path as needed\n",
    "\n",
    "# Chapter to convert (update for different chapters)\n",
    "CHAPTER_FILE = BOOK_ROOT / \"part_2\" / \"p2-ch05-representations.qmd\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(\".\")  # Current directory, or set to BOOK_ROOT / \"audio\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Voice options (uncomment preferred voice)\n",
    "VOICE_NAME = \"en-US-Neural2-D\"  # Male, natural (recommended)\n",
    "# VOICE_NAME = \"en-US-Neural2-F\"  # Female, natural\n",
    "# VOICE_NAME = \"en-US-Studio-O\"   # Male, highest quality\n",
    "# VOICE_NAME = \"en-US-Wavenet-D\"  # Male, good balance\n",
    "\n",
    "# Speaking rate (0.25 to 4.0, default 1.0)\n",
    "SPEAKING_RATE = 0.95  # Slightly slower for technical content\n",
    "\n",
    "print(f\"Chapter: {CHAPTER_FILE.name}\")\n",
    "print(f\"Voice: {VOICE_NAME}\")\n",
    "print(f\"Rate: {SPEAKING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_qmd_to_text(qmd_path: Path) -> str:\n",
    "    \"\"\"Convert Quarto file to plain text using pandoc.\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"pandoc\", str(qmd_path), \"-t\", \"plain\", \"--wrap=none\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Pandoc failed: {result.stderr}\")\n",
    "    return result.stdout\n",
    "\n",
    "\n",
    "def preprocess_for_tts(text: str) -> str:\n",
    "    \"\"\"Clean text for TTS consumption.\"\"\"\n",
    "    \n",
    "    # Remove display math blocks\n",
    "    text = re.sub(r'\\$\\$.*?\\$\\$', ' [Equation omitted] ', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove inline math\n",
    "    text = re.sub(r'\\$[^$]+\\$', '', text)\n",
    "    \n",
    "    # Expand cross-references\n",
    "    text = re.sub(r'@sec-ch(\\d+)-[\\w-]+', r'Section \\1', text)\n",
    "    text = re.sub(r'@fig-[\\w-]+', 'the figure', text)\n",
    "    text = re.sub(r'@tbl-[\\w-]+', 'the table', text)\n",
    "    text = re.sub(r'@eq-[\\w-]+', 'the equation', text)\n",
    "    \n",
    "    # Clean citations\n",
    "    text = re.sub(r'\\[@[\\w_-]+(?:;\\s*@[\\w_-]+)*\\]', '[citation]', text)\n",
    "    text = re.sub(r'@[\\w_-]+', '[citation]', text)\n",
    "    \n",
    "    # Remove callout markers but keep content\n",
    "    text = re.sub(r':::\\s*\\{\\.callout-(\\w+)[^}]*\\}', r'[\\1]: ', text)\n",
    "    text = re.sub(r':::', '', text)\n",
    "    \n",
    "    # Clean figure references\n",
    "    text = re.sub(r'!\\[([^\\]]*)\\]\\([^)]+\\)', r'[Figure: \\1]', text)\n",
    "    \n",
    "    # Remove Quarto layout directives\n",
    "    text = re.sub(r'\\{#[\\w-]+[^}]*\\}', '', text)\n",
    "    text = re.sub(r'\\{layout[^}]*\\}', '', text)\n",
    "    \n",
    "    # Remove HTML comments\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove code blocks\n",
    "    text = re.sub(r'```[\\s\\S]*?```', ' [Code block omitted] ', text)\n",
    "    \n",
    "    # Clean markdown headers\n",
    "    text = re.sub(r'^#+\\s+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove markdown emphasis\n",
    "    text = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', text)\n",
    "    text = re.sub(r'\\*([^*]+)\\*', r'\\1', text)\n",
    "    text = re.sub(r'__([^_]+)__', r'\\1', text)\n",
    "    text = re.sub(r'_([^_]+)_', r'\\1', text)\n",
    "    text = re.sub(r'`([^`]+)`', r'\\1', text)\n",
    "    \n",
    "    # Remove markdown links\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^)]+\\)', r'\\1', text)\n",
    "    \n",
    "    # Clean list markers\n",
    "    text = re.sub(r'^\\s*[-*+]\\s+', '  ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^\\s*\\d+\\.\\s+', '  ', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = re.sub(r' \\n', '\\n', text)\n",
    "    text = re.sub(r'\\n ', '\\n', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "print(\"Preprocessing functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TTS Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text: str, max_bytes: int = 4500) -> list:\n",
    "    \"\"\"Split text into chunks that fit within API byte limits.\"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    sentences = text.replace('\\n\\n', '\\n.\\n').split('. ')\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "        \n",
    "        if not sentence.endswith(('.', '?', '!')):\n",
    "            sentence += '.'\n",
    "        \n",
    "        test_chunk = current_chunk + ' ' + sentence if current_chunk else sentence\n",
    "        if len(test_chunk.encode('utf-8')) > max_bytes:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "        else:\n",
    "            current_chunk = test_chunk\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def generate_audio(text: str, output_path: Path, voice_name: str, speaking_rate: float) -> None:\n",
    "    \"\"\"Generate audio from text using Google Cloud TTS.\"\"\"\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "    \n",
    "    chunks = split_text_into_chunks(text)\n",
    "    total_chars = sum(len(c) for c in chunks)\n",
    "    print(f\"Processing {len(chunks)} chunks ({total_chars:,} characters)...\")\n",
    "    \n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=voice_name\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3,\n",
    "        speaking_rate=speaking_rate,\n",
    "        pitch=0.0\n",
    "    )\n",
    "    \n",
    "    audio_segments = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"  Chunk {i+1}/{len(chunks)}...\", end=\" \", flush=True)\n",
    "        \n",
    "        synthesis_input = texttospeech.SynthesisInput(text=chunk)\n",
    "        response = client.synthesize_speech(\n",
    "            input=synthesis_input,\n",
    "            voice=voice,\n",
    "            audio_config=audio_config\n",
    "        )\n",
    "        audio_segments.append(response.audio_content)\n",
    "        print(\"done\")\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        for segment in audio_segments:\n",
    "            f.write(segment)\n",
    "    \n",
    "    size_mb = output_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"\\nSaved: {output_path} ({size_mb:.1f} MB)\")\n",
    "\n",
    "\n",
    "print(\"TTS functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert Quarto to plain text\n",
    "print(f\"Converting {CHAPTER_FILE.name}...\")\n",
    "raw_text = convert_qmd_to_text(CHAPTER_FILE)\n",
    "print(f\"  Raw text: {len(raw_text):,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess for TTS\n",
    "print(\"Preprocessing...\")\n",
    "clean_text = preprocess_for_tts(raw_text)\n",
    "print(f\"  Clean text: {len(clean_text):,} characters\")\n",
    "print(f\"  Equations omitted: {clean_text.count('[Equation omitted]')}\")\n",
    "print(f\"  Citations: {clean_text.count('[citation]')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the cleaned text\n",
    "print(\"=\" * 60)\n",
    "print(\"PREVIEW (first 2000 chars):\")\n",
    "print(\"=\" * 60)\n",
    "print(clean_text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate audio\n",
    "chapter_name = CHAPTER_FILE.stem.replace(\".\", \"-\")\n",
    "output_file = OUTPUT_DIR / f\"{chapter_name}.mp3\"\n",
    "\n",
    "print(f\"Generating audio with voice: {VOICE_NAME}\")\n",
    "generate_audio(clean_text, output_file, VOICE_NAME, SPEAKING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing (Optional)\n",
    "\n",
    "Generate audio for multiple chapters at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available chapters\n",
    "chapters = sorted(BOOK_ROOT.glob(\"part_*/p*-ch*.qmd\"))\n",
    "print(f\"Found {len(chapters)} chapters:\")\n",
    "for i, ch in enumerate(chapters[:10]):\n",
    "    print(f\"  {i+1}. {ch.relative_to(BOOK_ROOT)}\")\n",
    "if len(chapters) > 10:\n",
    "    print(f\"  ... and {len(chapters) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch convert selected chapters (uncomment and modify as needed)\n",
    "# WARNING: This will use API quota for each chapter\n",
    "\n",
    "# chapters_to_convert = [\n",
    "#     BOOK_ROOT / \"part_2\" / \"p2-ch05-representations.qmd\",\n",
    "#     BOOK_ROOT / \"part_2\" / \"p2-ch06-cnns.qmd\",\n",
    "#     BOOK_ROOT / \"part_2\" / \"p2-ch07-attention.qmd\",\n",
    "# ]\n",
    "\n",
    "# for chapter in chapters_to_convert:\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Processing: {chapter.name}\")\n",
    "#     print(f\"{'='*60}\")\n",
    "#     \n",
    "#     raw = convert_qmd_to_text(chapter)\n",
    "#     clean = preprocess_for_tts(raw)\n",
    "#     output = OUTPUT_DIR / f\"{chapter.stem}.mp3\"\n",
    "#     generate_audio(clean, output, VOICE_NAME, SPEAKING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Voice Comparison (Optional)\n",
    "\n",
    "Generate samples with different voices to compare quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text for voice comparison\n",
    "sample_text = clean_text[:3000]  # First 3000 chars\n",
    "\n",
    "voices_to_test = [\n",
    "    \"en-US-Neural2-D\",  # Male, natural\n",
    "    \"en-US-Neural2-F\",  # Female, natural\n",
    "    # \"en-US-Studio-O\",   # Male, studio (highest quality)\n",
    "]\n",
    "\n",
    "# Uncomment to generate samples\n",
    "# for voice in voices_to_test:\n",
    "#     output = OUTPUT_DIR / f\"sample_{voice}.mp3\"\n",
    "#     print(f\"\\nGenerating sample with {voice}...\")\n",
    "#     generate_audio(sample_text, output, voice, SPEAKING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "**Voices:**\n",
    "- `en-US-Neural2-D` (Male) - Natural, recommended for technical content\n",
    "- `en-US-Neural2-F` (Female) - Natural, clear\n",
    "- `en-US-Studio-O` (Male) - Highest quality, more expressive\n",
    "- `en-US-Wavenet-D` (Male) - Good balance of quality and cost\n",
    "\n",
    "**Pricing:**\n",
    "- Neural2/WaveNet: $16/1M chars (1M free/month)\n",
    "- Standard: $4/1M chars (4M free/month)\n",
    "- Full book (~900K chars) fits within free tier\n",
    "\n",
    "**Full voice list:** https://cloud.google.com/text-to-speech/docs/voices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
