@misc{marin_bend_2024,
	title = {{BEND}: {Benchmarking} {DNA} {Language} {Models} on biologically meaningful tasks},
	shorttitle = {{BEND}},
	url = {http://arxiv.org/abs/2311.12570},
	doi = {10.48550/arXiv.2311.12570},
	abstract = {The genome sequence contains the blueprint for governing cellular processes. While the availability of genomes has vastly increased over the last decades, experimental annotation of the various functional, non-coding and regulatory elements encoded in the DNA sequence remains both expensive and challenging. This has sparked interest in unsupervised language modeling of genomic DNA, a paradigm that has seen great success for protein sequence data. Although various DNA language models have been proposed, evaluation tasks often differ between individual works, and might not fully recapitulate the fundamental challenges of genome annotation, including the length, scale and sparsity of the data. In this study, we introduce BEND, a Benchmark for DNA language models, featuring a collection of realistic and biologically meaningful downstream tasks defined on the human genome. We find that embeddings from current DNA LMs can approach performance of expert methods on some tasks, but only capture limited information about long-range features. BEND is available at https://github.com/frederikkemarin/BEND.},
	language = {en},
	urldate = {2025-06-30},
	publisher = {arXiv},
	author = {Marin, Frederikke Isa and Teufel, Felix and Horlacher, Marc and Madsen, Dennis and Pultz, Dennis and Winther, Ole and Boomsma, Wouter},
	month = apr,
	year = {2024},
	note = {arXiv:2311.12570 [q-bio]},
	keywords = {Printed, Read},
	file = {PDF:/Users/meehl.joshua/Zotero/storage/PAK9JYZT/2024-04-09 - Marin et al. - BEND Benchmarking DNA Language Models on biologically meaningful tasks.pdf:application/pdf},
}

@misc{rao_evaluating_2019,
	title = {Evaluating {Protein} {Transfer} {Learning} with {TAPE}},
	url = {http://arxiv.org/abs/1906.08230},
	doi = {10.48550/arXiv.1906.08230},
	abstract = {Protein modeling is an increasingly popular area of machine learning research. Semi-supervised learning has emerged as an important paradigm in protein modeling due to the high cost of acquiring supervised protein labels, but the current literature is fragmented when it comes to datasets and standardized evaluation techniques. To facilitate progress in this field, we introduce the Tasks Assessing Protein Embeddings (TAPE), a set of five biologically relevant semi-supervised learning tasks spread across different domains of protein biology. We curate tasks into specific training, validation, and test splits to ensure that each task tests biologically relevant generalization that transfers to real-life scenarios. We benchmark a range of approaches to semi-supervised protein representation learning, which span recent work as well as canonical sequence learning techniques. We find that self-supervised pretraining is helpful for almost all models on all tasks, more than doubling performance in some cases. Despite this increase, in several cases features learned by self-supervised pretraining still lag behind features extracted by state-of-the-art non-neural techniques. This gap in performance suggests a huge opportunity for innovative architecture design and improved modeling paradigms that better capture the signal in biological sequences. TAPE will help the machine learning community focus effort on scientifically relevant problems. Toward this end, all data and code used to run these experiments are available at https://github.com/songlab-cal/tape.},
	urldate = {2025-12-16},
	publisher = {arXiv},
	author = {Rao, Roshan and Bhattacharya, Nicholas and Thomas, Neil and Duan, Yan and Chen, Xi and Canny, John and Abbeel, Pieter and Song, Yun S.},
	month = jun,
	year = {2019},
	note = {arXiv:1906.08230 [cs]},
	file = {Preprint PDF:/Users/meehl.joshua/Zotero/storage/X4TJYPJC/2019-06-19 - Rao et al. - Evaluating Protein Transfer Learning with TAPE.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/J4FV7EDU/1906.html:text/html},
}

@misc{dallago_flip_2022,
	title = {{FLIP}: {Benchmark} tasks in fitness landscape inference for proteins},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {{FLIP}},
	url = {https://www.biorxiv.org/content/10.1101/2021.11.09.467890v2},
	doi = {10.1101/2021.11.09.467890},
	abstract = {Machine learning could enable an unprecedented level of control in protein engineering for therapeutic and industrial applications. Critical to its use in designing proteins with desired properties, machine learning models must capture the protein sequence-function relationship, often termed fitness landscape. Existing bench-marks like CASP or CAFA assess structure and function predictions of proteins, respectively, yet they do not target metrics relevant for protein engineering. In this work, we introduce Fitness Landscape Inference for Proteins (FLIP), a benchmark for function prediction to encourage rapid scoring of representation learning for protein engineering. Our curated tasks, baselines, and metrics probe model generalization in settings relevant for protein engineering, e.g. low-resource and extrapolative. Currently, FLIP encompasses experimental data across adeno-associated virus stability for gene therapy, protein domain B1 stability and immunoglobulin binding, and thermostability from multiple protein families. In order to enable ease of use and future expansion to new tasks, all data are presented in a standard format. FLIP scripts and data are freely accessible at https://benchmark.protein.properties.},
	language = {en},
	urldate = {2025-12-24},
	publisher = {bioRxiv},
	author = {Dallago, Christian and Mou, Jody and Johnston, Kadina E. and Wittmann, Bruce J. and Bhattacharya, Nicholas and Goldman, Samuel and Madani, Ali and Yang, Kevin K.},
	month = jan,
	year = {2022},
	note = {Pages: 2021.11.09.467890
Section: New Results},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/9S58BPCB/2022-01-19 - Dallago et al. - FLIP Benchmark tasks in fitness landscape inference for proteins.pdf:application/pdf},
}


@article{gresova_genomic_2023,
	title = {Genomic benchmarks: a collection of datasets for genomic sequence classification},
	volume = {24},
	issn = {2730-6844},
	shorttitle = {Genomic benchmarks},
	url = {https://doi.org/10.1186/s12863-023-01123-8},
	doi = {10.1186/s12863-023-01123-8},
	abstract = {Recently, deep neural networks have been successfully applied in many biological fields. In 2020, a deep learning model AlphaFold won the protein folding competition with predicted structures within the error tolerance of experimental methods. However, this solution to the most prominent bioinformatic challenge of the past 50 years has been possible only thanks to a carefully curated benchmark of experimentally predicted protein structures. In Genomics, we have similar challenges (annotation of genomes and identification of functional elements) but currently, we lack benchmarks similar to protein folding competition.},
	number = {1},
	urldate = {2025-07-25},
	journal = {BMC Genomic Data},
	author = {Grešová, Katarína and Martinek, Vlastimil and Čechák, David and Šimeček, Petr and Alexiou, Panagiotis},
	month = may,
	year = {2023},
	note = {33 citations (Crossref/DOI) [2025-10-22]},
	keywords = {Printed, Read},
	pages = {25},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/3ESJLWSM/2023-05-01 - Grešová et al. - Genomic benchmarks a collection of datasets for genomic sequence classification.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/62PT4KDI/s12863-023-01123-8.html:text/html},
}

@article{mukherjee_embedgem_2024,
	title = {{EmbedGEM}: a framework to evaluate the utility of embeddings for genetic discovery},
	volume = {4},
	shorttitle = {{EmbedGEM}},
	url = {https://dx.doi.org/10.1093/bioadv/vbae135},
	doi = {10.1093/bioadv/vbae135},
	abstract = {AbstractSummary. Machine learning-derived embeddings are a compressed representation of high content data modalities. Embeddings can capture detailed infor},
	language = {en},
	number = {1},
	urldate = {2025-07-11},
	journal = {Bioinformatics Advances},
	author = {Mukherjee, Sumit and McCaw, Zachary R. and Pei, Jingwen and Merkoulovitch, Anna and Soare, Tom and Tandon, Raghav and Amar, David and Somineni, Hari and Klein, Christoph and Satapati, Santhosh and Lloyd, David and Probert, Christopher and Team, Insitro Research and Koller, Daphne and O’Dushlaine, Colm and Karaletsos, Theofanis},
	month = jan,
	year = {2024},
	note = {2 citations (Crossref/DOI) [2025-10-22]
Publisher: Oxford Academic},
	keywords = {Printed, Read},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/INMU3Z95/2024-01-05 - Mukherjee et al. - EmbedGEM a framework to evaluate the utility of embeddings for genetic discovery.pdf:application/pdf},
}

@article{notin_proteingym_2024,
	title = {{ProteinGym}: {Large}-{Scale} {Benchmarks} for {Protein} {Fitness} {Prediction} and {Design}},
	volume = {36},
	shorttitle = {{ProteinGym}},
	url = {https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html},
	language = {en},
	urldate = {2025-05-28},
	journal = {Advances in Neural Information Processing Systems},
	author = {Notin, Pascal and Kollasch, Aaron and Ritter, Daniel and van Niekerk, Lood and Paul, Steffanie and Spinner, Han and Rollins, Nathan and Shaw, Ada and Orenbuch, Rose and Weitzman, Ruben and Frazer, Jonathan and Dias, Mafalda and Franceschi, Dinko and Gal, Yarin and Marks, Debora},
	month = dec,
	year = {2023},
	keywords = {Printed, Read},
	pages = {64331--64379},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/G7F5ZNHE/2023-12-15 - Notin et al. - ProteinGym Large-Scale Benchmarks for Protein Fitness Prediction and Design.pdf:application/pdf},
}

@article{breiman_statistical_2001,
	title = {Statistical {Modeling}: {The} {Two} {Cultures}},
	volume = {16},
	shorttitle = {Statistical {Modeling}},
	url = {https://doi.org/10.1214/ss/1009213726},
	doi = {10.1214/ss/1009213726},
	abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
	number = {3},
	journal = {Statistical Science},
	author = {Breiman, Leo},
	year = {2001},
	pages = {199--231},
}
