# Single-Cell & Epigenomic Models  {#sec-epi}

The preceding chapters traced how genomic foundation models evolved from early convolutional networks for local regulatory elements to large transformers that operate directly on DNA, RNA, and protein sequences. Those models treat the genome primarily as a one-dimensional string and learn how sequence encodes local biochemical activities and variant effects.

Single-cell and epigenomic assays add a different perspective. Rather than asking "what does this sequence do in isolation?", they capture the state of cells and tissues as they develop, respond to environment, and progress toward disease. DNA methylation, chromatin accessibility, histone marks, and three-dimensional genome folding provide multi-scale readouts of regulatory state that sequence-only models cannot fully capture. Single-cell RNA-seq and multi-omics further reveal how this state varies across individual cells, rather than in bulk averages.

This chapter surveys foundation models at three interconnected levels. First, we examine CpGPT, which treats DNA methylation as a sequence-like object amenable to transformer-based pretraining. Second, we explore cellular language models including Geneformer, scGPT, and TranscriptFormer that learn from massive single-cell transcriptomic corpora. Third, we examine GLUE and SCGLUE, which enable integration across modalities when different omics are measured in different cells. Finally, we survey models like Akita that predict three-dimensional chromatin contacts from DNA sequence alone. Throughout, a recurring theme is that these models treat high-dimensional, noisy measurements as tokens in a learned "language" of cellular state, then leverage large pretraining corpora to transfer across tasks, tissues, species, and technologies.

::: {.callout-warning .content-visible when-profile="draft"}
**TODO:**

- Add figure: Opening schematic situating this chapter within the book's progression (sequence models → cellular state models → systems integration)
- Add figure: CpGPT architecture showing masked modeling objective, sample embeddings, and downstream task adaptation
- Add figure: Single-cell foundation model comparison showing scGPT, Geneformer, and TranscriptFormer architectures with tokenization strategies
- Add figure: GLUE framework diagram illustrating modality-specific VAEs, feature graph structure, and adversarial alignment objectives
- Add figure: 3D genome prediction model comparison showing Akita and related architectures
- Add table: Comparison of single-cell foundation models (training scale, tokenization, pretraining objectives, modalities, key tasks)
- Add table: 3D genome prediction methods comparing input context, output resolution, and validated applications
:::

## CpGPT: A Foundation Model for DNA Methylation

### Methylation as a Systems Hub

DNA methylation occupies a privileged position in the regulatory hierarchy, sitting at a junction between genotype, environment, and phenotype. Methylation patterns integrate genetic influences, since sequence context affects which CpG sites can be methylated and polymorphisms can create or destroy CpG dinucleotides. They also integrate developmental programs, since methylation landscapes are extensively remodeled during differentiation and establish cell-type-specific regulatory states. Environmental exposures including diet, smoking, toxins, and stress leave lasting methylation signatures that persist long after the exposure ends.

Beyond serving as an integrative readout, methylation encodes rich information about cellular identity and state. Cell types can be distinguished by their methylation profiles, and within a cell type, methylation captures information about age, health status, and disease risk. Epigenetic clocks built from methylation data predict chronological age with remarkable accuracy, and deviations from predicted age correlate with mortality risk and disease burden [@camillo_cpgpt_2024].

Traditional methylation models have been task-specific: one model for age prediction, another for mortality risk, another for tissue classification. Each model is trained from scratch on labeled data for its particular task, learning whatever methylation patterns happen to be predictive without necessarily capturing general structure. CpGPT reframes methylation as a foundation modeling problem, using large-scale pretraining to learn representations that transfer across tasks.

### Architecture and Pretraining

CpGPT, the Cytosine-phosphate-Guanine Pretrained Transformer, treats methylomes as sequences or sets of CpG sites and uses transformer-style self-attention to model their structure [@camillo_cpgpt_2024]. The model was pretrained on over 1,500 DNA methylation datasets encompassing more than 100,000 samples from diverse tissues and conditions.

Several aspects of methylation structure make it amenable to transformer modeling. Local CpG correlations arise because nearby CpG sites tend to share methylation status, particularly within CpG islands. Long-range coordination reflects the fact that methylation patterns at distant genomic regions can be correlated through shared regulatory programs or chromatin compartmentalization. Global sample-level variation captures the systematic differences between samples that reflect tissue identity, age, disease status, and other biological variables.

The input representation tokenizes each methylation sample as a sequence of CpG sites with probe or genomic position identifiers, methylation beta values (often transformed or discretized), and optional metadata such as platform or tissue. The model combines local sequence context around each CpG with relative position along the genome and global sample-level embeddings representing tissue and condition.

CpGPT uses masked modeling objectives analogous to BERT-style language model pretraining. During training, a fraction of CpG methylation values are masked, and the model learns to predict the masked values from the surrounding context. This objective encourages the model to learn both local correlations between neighboring CpG sites and global patterns that distinguish different tissues or conditions.

The resulting embeddings capture sample-level representations that summarize methylation state. These embeddings can serve as inputs to downstream predictors, providing rich methylation features for risk scores, prognosis models, or treatment response prediction. They can function as one modality in a shared latent space that also includes expression, proteomics, and other data types. They can inject epigenetic state information into otherwise sequence-centric genomic foundation models, providing context about cellular identity and regulatory status.

### Downstream Applications and Transfer Learning

Once pretrained, CpGPT supports several capabilities with minimal or no additional supervised training. The model can impute methylation levels at CpG sites not directly measured on a given array platform, effectively enabling array conversion between platforms such as EPIC and 450K by leveraging sequence context and co-methylation structure [@camillo_cpgpt_2024]. This addresses a persistent challenge in methylation research where different studies use different array technologies.

For biological age prediction, fine-tuned CpGPT models match or exceed the performance of purpose-built epigenetic clocks while using a more general architecture. The learned embeddings cluster by tissue type without explicit supervision during pretraining, suggesting that the model captures biologically meaningful variation. For disease-associated methylation patterns, CpGPT can be adapted to distinguish cases from controls across multiple disease contexts through transfer learning.

The foundation model paradigm offers several advantages over task-specific methylation models. New tasks can be addressed through fine-tuning or linear probing rather than training from scratch. Representations learned from diverse tissues and conditions may generalize better than those learned from narrow disease-specific cohorts. The model provides a unified framework for understanding methylation variation across biological contexts.

Because CpGPT is transformer-based, its attention patterns and learned embeddings can be probed to rank CpGs by their contribution to specific predictions. This offers a route toward mechanistic insight, complementing purely statistical epigenetic clocks. However, important limitations remain. Most training data are bulk methylation, so cell-type-specific signals may be entangled. Methylation is a downstream readout of regulatory processes, so CpGPT captures associations but not necessarily causal mechanisms. Training remains constrained by the coverage and diversity of available cohorts in terms of ancestry, tissue types, and environmental exposures.

## Single-Cell Foundation Models

### The Promise of Cellular Language Models

The explosion of single-cell sequencing data has created training corpora of unprecedented scale for modeling cellular biology. Public repositories now contain tens of millions of single-cell transcriptomes spanning diverse tissues, developmental stages, disease states, and species. This scale approaches the data volumes that enabled large language models, motivating researchers to ask whether similar foundation model approaches could work for cellular data.

The analogy between language and single-cell biology runs deeper than dataset scale. In language, words combine according to grammatical rules to form sentences that convey meaning. In cells, genes combine according to regulatory programs to form expression profiles that define cellular identity and function. Just as language models learn syntax and semantics by predicting masked words, single-cell foundation models might learn regulatory logic by predicting masked genes.

Several groups have pursued this vision, producing models with different architectures, pretraining objectives, and downstream applications. The resulting cellular language models treat cells as documents or sentences, genes or features as tokens, and expression levels as token attributes. If a model can learn the "grammar" of which genes co-occur and how their expression levels vary across contexts, it may provide context-aware embeddings of genes and cells, support zero-shot or few-shot transfer to new datasets, and enable in silico perturbations where the model predicts how changing one gene or pathway affects the rest of the transcriptome.

### Geneformer: Network Biology Through Pretraining

Geneformer was developed as a context-aware, attention-based model pretrained on approximately 30 million single-cell transcriptomes to enable context-specific predictions in network biology [@theodoris_geneformer_2023]. The model's key insight is that during pretraining, it gained a fundamental understanding of network dynamics, encoding network hierarchy in attention weights in a completely self-supervised manner.

The architecture treats each cell as a sentence, with genes serving as tokens. Rather than using raw expression counts, Geneformer ranks genes by their expression level relative to their typical expression across the training corpus. This rank-based encoding emphasizes which genes are unusually active or silent in each cell, capturing the contextual information that defines cell state. The representation discards absolute counts but preserves relative ordering, which is often more stable across datasets and platforms.

Pretraining uses a masked gene prediction objective. A fraction of genes are masked in each cell, and the model learns to predict which genes were masked based on the remaining expression context. This forces the model to learn co-expression patterns, regulatory relationships, and the gene combinations that characterize different cell states. The objective encourages learning of which genes tend to co-occur at particular ranks in specific cellular contexts, implicitly capturing regulatory modules and pathways.

After pretraining, Geneformer can be fine-tuned for diverse downstream tasks. Cell type annotation achieves high accuracy even with limited labeled examples, leveraging the general biological knowledge acquired during pretraining. Multi-batch integration benefits from representations that capture biological variation while being robust to technical artifacts. Perturbation response prediction uses the model's implicit understanding of gene networks to anticipate how cells will respond to genetic or chemical perturbations. The model can also prioritize genes according to their influence on specific cell states or disease-relevant phenotypes.

Applied to disease modeling with limited patient data, Geneformer identified candidate therapeutic targets for cardiomyopathy by analyzing how disease-associated genes fit within the learned network structure [@theodoris_geneformer_2023]. This demonstrates the potential for foundation models to accelerate discovery in rare diseases where large datasets are unavailable. Because the model encodes context-aware network information, it can often perform well in data-scarce settings.

### scGPT: Generative Pretraining for Multi-Omics

scGPT extends the foundation model paradigm to single-cell multi-omics, training a generative pretrained transformer on over 33 million cells to learn representations useful across diverse downstream applications [@cui_scgpt_2024]. The model is designed as a generalist backbone for single-cell analysis pipelines, analogous to how general-purpose language models serve text applications.

The model architecture includes several innovations tailored to single-cell data. Gene tokens are embedded using both learnable embeddings and position encodings that capture genomic location. Expression values are discretized into bins to handle the wide dynamic range and zero-inflation characteristic of single-cell data. Special tokens mark cell boundaries and indicate modality when multi-omic data are available. Attention masks and positional encodings are adapted so that the model can handle the unordered nature of gene sets while still benefiting from sequence-like inductive biases.

scGPT uses multiple pretraining objectives simultaneously. Masked gene prediction, analogous to BERT, encourages learning of co-expression patterns. Autoregressive generation predicts expression of one set of genes conditioned on others, enabling sampling and imputation. Contrastive objectives encourage cells from the same type or condition to cluster in embedding space while separating different types. These objectives are applied across diverse datasets to learn shared gene and cell embeddings that are reusable across tasks and modalities [@cui_scgpt_2024].

The combination of objectives and the scale of pretraining enable scGPT to excel across multiple downstream applications. Cell type annotation benefits from the rich representations learned during pretraining, including fine-grained subtypes. Multi-batch integration aligns cells from different experiments while preserving biological variation, addressing the pervasive batch effects in single-cell data. Multi-omic integration learns joint representations when cells have both RNA-seq and ATAC-seq measurements. Perturbation response prediction anticipates transcriptional changes following CRISPR knockouts or drug treatments. Gene network inference extracts regulatory relationships from attention patterns.

### TranscriptFormer and Cross-Species Modeling

TranscriptFormer extends single-cell foundation models across evolutionary time, training on over 112 million cells spanning 1.5 billion years of evolution across 12 species [@pearce_transcriptformer_2025]. This cross-species approach tests whether foundation models can learn regulatory principles that generalize beyond individual organisms.

The model uses a novel generative architecture that jointly models genes and transcripts, with specialized heads and attention mechanisms to capture their relationships. The autoregressive objective predicts genes and their expression levels in a causal fashion, enabling it to generate synthetic cells conditioned on prompts such as species, tissue, or cell type. Because the vocabulary spans multiple species, the model functions as a virtual instrument for probing cellular biology.

In zero-shot settings, TranscriptFormer demonstrates superior performance on both in-distribution and out-of-distribution cell type classification, with robust performance even for species separated by over 685 million years of evolutionary distance. This cross-species perspective reveals that core principles of cellular regulation are deeply conserved.

Cross-species transfer enables several applications not possible with single-species models. Cell type annotations can be transferred across species boundaries, accelerating atlas construction for less-studied organisms. Disease state identification in human cells benefits from regulatory patterns conserved across evolution. Gene-gene interactions predicted by the model align with independent experimental observations across species. The model can suggest conserved transcription factors and regulatory logic that operate across phylogeny.

The success of cross-species foundation models suggests that models trained on diverse organisms can capture universal patterns more effectively than models trained on any single species. This has implications for understanding both evolution and disease, as conserved regulatory programs often represent the most fundamental aspects of cellular function.

## GLUE: Graph-Linked Unified Embedding for Single-Cell Multi-Omics

### The Unpaired Integration Challenge

Single-cell experiments often profile different modalities in different cells. A typical study might include scRNA-seq data from one set of cells, scATAC-seq data from another set, and perhaps a small subset with both modalities measured simultaneously through multiome protocols. The central challenge is building a unified atlas that aligns these cells in a common space, recovers cell types and trajectories, and infers regulatory networks connecting chromatin to expression [@cao_glue_2022].

This problem is harder than standard data integration because the feature spaces are entirely different. RNA-seq measures gene expression across roughly 20,000 genes. ATAC-seq measures chromatin accessibility across hundreds of thousands of peaks. There is no direct correspondence between features: a gene is not the same object as a peak. Aligning cells across modalities requires reasoning about how features in one modality relate to features in another.

Previous approaches addressed this through explicit feature conversion, for example by assigning ATAC-seq peaks to nearby genes and treating the resulting gene-level accessibility as comparable to expression. This conversion is straightforward but loses information, since the detailed structure of chromatin accessibility within a gene's regulatory region is collapsed into a single number. It also introduces arbitrary choices about how to define gene-peak assignments.

GLUE, Graph-Linked Unified Embedding, addresses this problem by combining modality-specific encoders with a graph of biological prior knowledge linking features across omics. Rather than converting features, GLUE explicitly encodes regulatory relationships into a guidance graph and learns cell embeddings that are consistent with this graph.

### Architecture and Training

GLUE consists of three key components that work together to align cells across modalities while respecting biological relationships between features [@cao_glue_2022].

Modality-specific variational autoencoders provide the foundation. Each omic has its own encoder-decoder pair. Encoders map cells to a low-dimensional latent embedding, and decoders reconstruct modality-specific features from these embeddings. The variational structure encourages smooth, interpretable latent spaces. Generative distributions differ by modality to match data characteristics: negative binomial for count data, Bernoulli or Gaussian for others.

The feature graph encodes biological prior knowledge about relationships between features across modalities. Nodes represent genes, peaks, regulatory elements, and other genomic features. Edges connect ATAC peaks to the genes they might regulate based on genomic proximity or evidence from chromatin conformation capture experiments. Edges connect genes to the transcription factors that bind their promoters. The graph structure is provided as input rather than learned, allowing incorporation of external biological knowledge from databases, literature, and prior experiments.

A graph variational autoencoder learns feature embeddings from this guidance graph. These feature embeddings are then used in the decoders of the modality-specific VAEs, tying them to a common regulatory backbone. This ensures that biologically related features have similar representations and helps align the latent spaces of different modalities.

Adversarial alignment ensures that the latent embeddings from different modalities are truly integrated rather than merely correlated. A discriminator tries to distinguish which modality produced each latent embedding, and the encoders are trained to fool the discriminator. This adversarial objective forces the encoders to produce embeddings that are indistinguishable across modalities, creating a unified cell embedding space where cells from different modalities occupy a shared manifold.

### Applications and Extensions

GLUE enables several applications beyond basic integration. Triple-omics integration combines gene expression, chromatin accessibility, and DNA methylation measured in different cells from the same tissue, producing unified cell type annotations that leverage all three data types. Regulatory inference uses the learned feature embeddings to identify candidate enhancer-gene links that can be validated against chromatin conformation capture data or eQTL evidence. The guidance graph and learned embeddings provide a regularized view of peak-gene-TF relationships that is more principled than simple distance-based assignment.

Cross-modal prediction becomes possible when cells are aligned in a common space. The model can predict chromatin accessibility from expression or vice versa, enabling imputation of missing modalities. Atlas construction at scale handles millions of cells across many batches and datasets, with the graph structure helping to distinguish biological variation from technical artifacts.

SCGLUE extends the framework specifically for single-cell applications, with optimizations for the scale and sparsity of single-cell data [@cao_glue_2022]. The adversarial alignment is refined to handle the batch effects common in single-cell experiments, and the graph structure is expanded to include tissue-specific regulatory relationships. SCGLUE scales to millions of cells while maintaining the biological grounding provided by the guidance graph.

The success of GLUE demonstrates that graph-guided integration, where biological prior knowledge structures the alignment objective, provides a more principled approach than feature conversion or purely data-driven alignment. The feature graph allows the model to learn biologically meaningful relationships while the adversarial objective ensures genuine integration across modalities. This pattern of combining learned representations with structured biological knowledge recurs throughout foundation models for genomics.

## 3D Genome Prediction Models

### The Structural Dimension of Gene Regulation

The linear genome folds into a complex three-dimensional structure that brings distant regulatory elements into spatial proximity with their target genes. This folding is not random: specific sequence features, particularly CTCF binding sites with their characteristic orientation dependence, organize the genome into topologically associating domains (TADs) and create specific chromatin contacts between enhancers and promoters.

Understanding how sequence encodes 3D structure is crucial for interpreting regulatory variants. A variant might sit far from any gene in linear distance but be brought into contact with a promoter through chromatin looping. Sequence-to-structure models that predict chromatin contacts from DNA sequence can identify such variants and predict how structural variants, which may create or disrupt loops, affect gene regulation. From a modeling perspective, 3D genome structure matters because many regulatory elements act over tens to hundreds of kilobases, disrupting chromatin loops can misregulate genes even when local sequence motifs remain intact, and structural variation and rearrangements are often key drivers of cancer and developmental disorders.

Hi-C, Micro-C, and related assays measure chromatin contacts but are expensive and typically low-resolution. Predictive models of 3D structure from sequence promise to infer structural consequences of non-coding SNVs and SVs, provide structural priors to sequence-to-expression models, and enable in silico mutagenesis of regulatory landscapes at scale.

### Akita: Sequence-to-Contact Prediction

Akita demonstrated that convolutional neural networks can accurately predict genome folding from DNA sequence alone [@fudenberg_akita_2020]. The model takes megabase-scale sequence as input and outputs predicted Hi-C contact maps, capturing the spatial proximity relationships between all pairs of positions in the input window.

The architecture uses an encoder-decoder structure. The input is a one-hot encoded DNA sequence of fixed length, typically around 1 megabase, centered on the region of interest. Deep convolutional blocks in the encoder extract hierarchical sequence features at multiple scales, capturing both the local motifs (particularly CTCF sites) that anchor chromatin loops and the broader sequence context that influences compartmentalization. Dilated convolutions and pooling expand receptive fields to capture long-range dependencies. The decoder reconstructs the two-dimensional contact matrix from the encoded sequence representation, typically at around 2 kilobase resolution.

Akita is trained on Hi-C and Micro-C contact maps from specific cell types, optimizing a loss function over predicted versus observed contact matrices. The model's representations underscore the importance of an orientation-specific grammar for CTCF binding sites. Akita learns that CTCF sites pointing toward each other tend to anchor chromatin loops, while sites pointing away do not. This orientation dependence, known from molecular biology, emerges automatically from training on Hi-C data without explicit supervision.

Once trained, Akita enables rapid in silico predictions. Saturation mutagenesis experiments, prohibitively expensive to perform experimentally across megabase regions, can be simulated computationally by predicting the effect of every possible single-nucleotide change on chromatin structure. This reveals which positions are most critical for maintaining normal genome folding and which mutations might cause structural disruption.

Applications include interpreting eQTLs through the lens of 3D structure, making predictions for structural variants that create or delete CTCF sites, and probing species-specific genome folding by applying models trained on one species to sequences from another. The model can score the impact of every possible SNV or small indel on local contact patterns, suggesting which non-coding variants perturb loop structures relevant to gene expression [@fudenberg_akita_2020].

### Extensions and Related Models

Several models have extended Akita's sequence-to-structure paradigm. Orca scales to longer input contexts and higher resolution outputs, enabling prediction of finer structural features. DeepC uses transfer learning to predict 3D folding at megabase scales across different cell types. C.Origami incorporates additional training data and architectural refinements.

Subsequent work has also developed hierarchical and multi-scale models that predict contact maps at multiple resolutions and genomic scales. Architectures that better handle structural variants, including large deletions, inversions, and translocations, explicitly model rearranged sequence segments. Integration of 3D structure with expression predictors has emerged as a natural direction, where 3D models provide features or inductive biases to sequence-to-expression networks.

HiCDiffusion addresses a limitation of encoder-decoder architectures: the tendency to produce blurred contact maps that lack the sharp features of experimental Hi-C data. By combining the encoder-decoder with a diffusion model, HiCDiffusion produces high-resolution matrices that better resemble experimental results while maintaining similar correlation with ground truth.

These models collectively establish that 3D genome structure can be predicted from sequence, opening new possibilities for understanding how variants affect gene regulation through structural mechanisms that sequence-to-expression models like Enformer capture only indirectly. The mapping from sequence to 3D structure is sufficiently regular that deep learning can decode aspects of the structural grammar of the genome.

## Design Patterns and Practical Considerations

Several design patterns recur across the models surveyed in this chapter, revealing common strategies for handling cellular and epigenomic data.

Tokenization strategies for cellular data require careful consideration. Geneformer's rank-based encoding emphasizes relative expression and is stable across datasets and platforms. scGPT's discretization handles the dynamic range of count data while enabling discrete prediction objectives. CpGPT tokenizes CpG sites with their methylation values and genomic positions. 3D genome models operate on fixed-length sequence windows. The choice of tokenization affects what biological signals the model can capture and how well representations transfer across datasets with different technical characteristics.

Pretraining objectives shape what models learn and which downstream tasks they support. Masked prediction encourages learning of co-occurrence patterns and local dependencies. Generative objectives enable sampling and imputation. Contrastive objectives emphasize discriminative features that separate cell types or conditions. Multi-task pretraining can combine benefits of multiple objectives, as demonstrated by scGPT's simultaneous use of masked prediction, autoregressive generation, and contrastive learning. The choice of objective reflects assumptions about which aspects of biological structure are most important.

Graph structure provides biological grounding that can regularize learning and improve interpretability. GLUE's feature graph encodes regulatory relationships that guide integration across modalities. Similar graph structures could incorporate protein-protein interactions, pathway membership, or other biological networks to constrain what models learn. This pattern of combining learned representations with structured biological knowledge helps ensure that models respect known biology while discovering new patterns.

Scale of pretraining enables generalization across contexts. Models trained on tens of millions of cells or hundreds of thousands of samples learn representations that transfer to new contexts better than models trained on smaller datasets. This argues for continued investment in large-scale data generation and aggregation. However, scale alone does not guarantee utility: the diversity of training data (across tissues, species, conditions, and platforms) matters as much as raw sample count.

## Practical Challenges

Several challenges complicate the application of single-cell and epigenomic foundation models in practice.

Batch effects remain pervasive in single-cell data. Technical differences between experiments, protocols, and platforms can dominate biological signal. Foundation models that are robust to batch effects in their training data may struggle when applied to new batches not represented during pretraining. The field continues to grapple with distinguishing genuine biological variation from technical artifacts.

Cell type imbalance affects what models learn. Common cell types are overrepresented in training corpora, while rare populations may be poorly captured. Models may excel at identifying well-represented cell types while struggling with rare or novel populations. This has equity implications when rare cell types are disease-relevant or when certain tissues or conditions are systematically undersampled.

Evaluation complexity increases when ground truth is uncertain. Cell type labels in training data reflect current annotations that may be incomplete or inconsistent. Performance metrics on held-out data conflate model quality with annotation quality. Regulatory network predictions face similar challenges, as gold standard interaction sets are incomplete and context-dependent. Evaluation protocols must acknowledge these uncertainties rather than treating benchmarks as definitive.

Data imbalance and coverage biases extend beyond cell types. Common ancestries dominate current corpora, as do certain tissues and experimental protocols. Rare cell types, underrepresented populations, and less-studied organisms may be poorly modeled, with consequences for equity and generalizability. The field must invest in diverse data generation while developing methods that can generalize despite limited training examples.

Computational requirements for training and inference remain substantial. While smaller than the largest language models, single-cell foundation models still require significant GPU resources that may limit accessibility. Techniques such as distillation, quantization, and parameter-efficient fine-tuning are essential for broader adoption. Making models accessible to researchers without extensive computational infrastructure remains an important goal.

Domain shift between training and deployment contexts poses persistent challenges. Models trained on one technology platform, tissue type, or species may not transfer well to others. Even when transfer is possible, performance may degrade in ways that are difficult to predict or diagnose. Understanding the boundaries of model applicability requires careful characterization of both training data and deployment contexts.

## Summary

This chapter has surveyed foundation models that operate on epigenomic and single-cell readouts rather than primary DNA sequence alone. CpGPT demonstrates that methylation can be modeled as a sequence-like object amenable to transformer-based pretraining, with applications spanning biological age prediction, tissue classification, disease association, and platform conversion. Single-cell foundation models including Geneformer, scGPT, and TranscriptFormer learn cellular representations from massive transcriptomic corpora that transfer to diverse downstream tasks including cell type annotation, perturbation response prediction, gene network inference, and cross-species analysis. GLUE shows how graph-linked embeddings can align cells across modalities when different omics are measured in different cells, using biological prior knowledge to guide integration. 3D genome prediction models including Akita and its successors predict chromatin contacts from sequence, revealing how variants affect gene regulation through structural mechanisms.

These models extend the foundation model paradigm from sequence-only representations to the rich landscape of cellular identity and genome organization. They demonstrate that the principles enabling language models (large-scale pretraining, transfer learning, context-aware representations) can be adapted to biological domains where tokens represent genes, CpG sites, or genomic positions rather than words. The success of these adaptations depends critically on choosing appropriate tokenization strategies, pretraining objectives, and architectural inductive biases that reflect the structure of biological data.

Looking forward, several directions promise to enhance these models' utility. Integration across levels of organization (sequence, epigenome, 3D structure, cellular state) could yield multi-scale representations that capture regulatory logic more completely than any single modality. Cross-species pretraining can reveal conserved principles while highlighting evolutionary innovations. Incorporation of temporal dynamics through developmental trajectories or disease progression could better capture how cellular states transition over time. The evaluation and interpretability principles developed in later chapters become especially important for these models, where ground truth is often uncertain and deployment stakes are high.