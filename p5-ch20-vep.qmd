# Variant Effect Prediction  {#sec-vep}

## From Handcrafted Scores to Foundation Models

Variant effect prediction sits at the heart of modern genomics. Most variants discovered in clinical sequencing are rare and lack direct experimental evidence, yet clinicians must still decide whether a change is likely benign, pathogenic, or uncertain. The goal of variant effect prediction (VEP) is to map a variant and its context to a quantitative estimate of functional impact or disease risk that can support this decision.

Early computational approaches relied on hand-engineered features and relatively simple models. Conservation and heuristic-based scores such as SIFT and PolyPhen combine information about amino acid properties, sequence conservation, and protein domains to estimate whether a missense variant is damaging [@ng_sift_2003; @adzhubei_polyphen_2010]. CADD extends this idea to genome-wide scoring, integrating many annotations (e.g., conservation, regulatory marks, local sequence context) into a single pathogenicity score [@rentzsch_cadd_2019; @sec-cadd]. These methods were a major step forward, but they are fundamentally limited by the expressiveness of the hand-crafted features and by biases in the labeled data they use (@sec-confound).

Deep learning methods widened the scope of VEP. Convolutional models like DeepSEA and ExPecto learn regulatory sequence features directly from raw DNA; splicing-focused models such as SpliceAI target specific molecular mechanisms, predicting how sequence changes alter splice donor/acceptor usage (@sec-splice). Protein language models (@sec-prot) learn high-dimensional representations of protein sequences that can be adapted for missense variant effect prediction, often outperforming feature-based scores.

The current frontier is defined by foundation models that treat DNA, RNA, and protein as languages, learning rich sequence representations from massive unlabeled corpora and then reusing those representations for variant interpretation. These models differ in their input modalities (protein vs DNA vs multi-species alignments), architectural choices (CNNs, transformers, state-space models), and training objectives (masked language modeling, autoregressive modeling, multi-task prediction), but they all aim to capture the evolutionary and regulatory constraints that shape observed variation.

This chapter focuses on four landmark systems that illustrate what modern foundation models look like when specialized for variant interpretation: AlphaMissense, a proteome-wide missense pathogenicity predictor that combines protein language models with structural context [@cheng_alphamissense_2023]; GPN-MSA, an alignment-based DNA language model that scores variants using multi-species sequence constraint [@benegas_gpn-msa_2024]; Evo 2, a generalist genomic language model trained across species and modalities, providing zero-shot variant scores [@brixi_evo_2025; @manzo_comparative_2025]; and AlphaGenome, a unified 1 Mb context model that predicts multi-omic readouts and regulatory effects, enabling end-to-end noncoding VEP [@avsec_alphagenome_2025].

We first revisit zero-shot protein language model approaches, then dive into these four systems, compare their design choices, and close with open challenges for future VEP models.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion – big-picture overview**

Add a small schematic showing the progression from:
1. Handcrafted scores (SIFT/PolyPhen/CADD) →  
2. Task-specific deep models (SpliceAI, regulatory CNNs) →  
3. Foundation-model-based VEP (protein LMs, Evo 2, AlphaGenome).

This could be a left-to-right timeline with example inputs (protein, DNA, MSA) and outputs (pathogenicity, regulatory effect, multi-omic profiles).
:::


## Zero-Shot Protein Language Models for Variant Scoring

Before specialized systems like AlphaMissense, a key development was the realization that unsupervised protein sequence models can already provide useful variant effect scores with no task-specific training.

### Evolutionary Models Over MSAs: EVE and popEVE

EVE (Evolutionary model of Variant Effect) fits a generative model to a multiple sequence alignment (MSA) of homologs for a single protein [@frazer_eve_2021]. The model learns a probability distribution over sequences such that variants that strongly violate evolutionary constraints (e.g., breaking conserved motifs or co-evolution patterns) receive low probability.

Variant effect scores are derived from log-likelihood differences: the change in sequence log-probability under the model when a reference amino acid is replaced by an alternative. These raw scores are then calibrated against labeled variants (e.g., ClinVar) to produce categorical calls and confidence levels analogous to ACMG evidence.

popEVE extends the approach by training models across many proteins and incorporating population allele frequencies, enabling proteome-wide scoring and better calibration across genes [@orenbuch_popeve_2025]. Together, these methods showed that strong performance is possible with purely unsupervised training on evolutionary data, MSA quality and depth critically influence performance and coverage, and calibration against clinical labels is essential for practical use (@sec-eval).

### Large Protein LMs: ESM-1v and Related Models

ESM-1v and related protein language models push beyond MSAs by training transformers on large corpora of unaligned protein sequences [@meier_esm-1v_2021]. These models use masked language modeling: given a sequence with masked amino acids, the model predicts the masked tokens, implicitly learning structural and functional constraints.

Zero-shot variant scoring follows the same principle as in EVE. The model computes the log-probability of the wild-type amino acid at a position, computes the log-probability of the mutant amino acid, and uses the difference as a variant effect score (often aggregated over both directions and context windows).

Compared to MSA-based models, large protein LMs provide much broader coverage since they do not require explicit MSAs per protein, capture global patterns such as secondary/tertiary structure and remote homology (@sec-prot), and still require calibration and interpretation to be clinically useful.

### Cross-Protein Transfer from Deep Mutational Scanning

Despite their success, zero-shot approaches face a persistent challenge: the gap between experimental fitness assays and clinical labels. Deep mutational scanning (DMS) experiments measure the functional effects of thousands of variants in a single protein, but only for a small subset of proteins. Conversely, clinical variant databases span many genes but are sparse and biased.

CPT-1 (Cross-Protein Transfer 1) is a recent approach that tries to bridge this gap [@jagota_cross-protein_2023]. The key idea is to leverage cross-protein transfer. For a subset of proteins with DMS data, the model extracts features from protein language models (e.g., ESM-derived embeddings), structure (experimental or AlphaFold2-predicted), and conservation and other biologically motivated descriptors. A shared predictor is trained that maps these features to DMS-measured effects, then this predictor is transferred to new proteins by feeding in the same feature types, even when no DMS data exist for that protein.

CPT-1 demonstrates substantial gains in high-sensitivity recall and ranking of pathogenic variants compared to purely zero-shot methods, complementarity between foundation model features and task-specific experimental supervision, and a template for systematically using DMS data as a bridge between large-scale representations and clinically relevant outcomes.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestions – zero-shot protein VEP**

1. Small cartoon comparing EVE vs ESM-1v:
   - EVE: MSA stack, generative model, Δ log-likelihood score.
   - ESM-1v: single sequence, transformer, masked token prediction.
2. Schematic for CPT-1:
   - DMS assays (per-protein fitness landscapes) → feature extraction (LM embeddings, structure) → shared predictor → transfer to new proteins.
:::


## AlphaMissense: Proteome-Wide Missense Pathogenicity

AlphaMissense, developed by DeepMind, is a large-scale system that provides precomputed pathogenicity scores for essentially all possible missense variants in the human proteome [@cheng_alphamissense_2023]. It combines the strengths of protein language models and structural information from AlphaFold2 to produce calibrated probability scores interpretable as "pathogenic" vs "benign".

### Combining Sequence and Structure

AlphaMissense rests on two main pillars. First, sequence-based representations. A protein language model is used to encode the wild-type amino acid sequence and the position-specific context of a mutation. The model learns evolutionary constraints from massive protein sequence databases and captures subtle patterns such as remote homology, local structural motifs, and co-evolution across residues.

Second, structure-based representations. Structural information is derived from AlphaFold2 predictions, providing a 3D context around each residue. Features include local geometry (e.g., solvent exposure, secondary structure, packing density) and longer-range contacts. Mutations at buried sites or within critical interaction interfaces can be distinguished from those in flexible, solvent-exposed regions.

For a proposed missense variant, AlphaMissense integrates the wild-type sequence, the mutant amino acid at a specific position, and local structural features from AlphaFold2 into a neural network that outputs a continuous pathogenicity probability between 0 and 1.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion – AlphaMissense architecture**

Insert an architecture schematic showing:
- Input: protein sequence + AlphaFold2 structure,
- Encoding: protein LM and structural feature extraction,
- Fusion: joint network combining sequence and structure,
- Output: pathogenicity probability.

A zoom-in panel could highlight how local 3D neighborhood (e.g., proximity to active site) modulates the score.
:::

### Training and Calibration

AlphaMissense uses a hybrid training strategy. Self-supervised pretraining on protein sequences and structures ensures that representations capture generic biophysical and evolutionary constraints. Supervised fine-tuning on labeled clinical and population data uses pathogenic and benign missense variants from ClinVar and other curated resources, along with high-frequency variants from population databases such as gnomAD, treated as likely benign under standard assumptions (@sec-confound).

Raw model outputs are then calibrated so that scores near 0 correspond to variants observed to behave like benign in curated sets, scores near 1 correspond to variants consistently observed as pathogenic, and intermediate scores are interpretable as uncertain or conflicting evidence, which can be integrated into ACMG-like decision frameworks (@sec-eval).

### Performance and Clinical Utility

Across diverse benchmarks including ClinVar, expert-curated panels, and deep mutational scanning datasets, AlphaMissense achieves higher AUC and precision–recall than many prior missense predictors, strong correlation with experimental functional readouts, and robustness across different genes and variant spectra.

Its precomputed proteome-wide score release makes it particularly attractive in practice: users can simply look up scores instead of running heavy inference per variant. This facilitates downstream tasks such as prioritizing variants of uncertain significance (VUS), supporting gene discovery and burden tests, and annotating large sequencing cohorts.

### Limitations and Caveats

Despite its strengths, AlphaMissense has several important limitations. It only handles missense variants; other coding and noncoding variant types require separate tools. Calibration depends on existing clinical and population labels, which are themselves biased by ascertainment and ancestry (@sec-confound). The model is largely opaque: it provides a scalar score but limited mechanistic explanations (@sec-interp). Structural features rely on predicted rather than experimentally determined structures for most proteins; errors or uncertainties in AlphaFold2 predictions can propagate into scores.

Guidelines thus recommend using AlphaMissense as a strong supporting line of evidence, but not as a standalone decision-maker. Scores are best interpreted in combination with segregation data, population frequencies, functional assays, and gene-level context (@sec-trans).


## GPN-MSA: Alignment-Based DNA Language Modeling

Noncoding variants present a different challenge: there is no straightforward notion of a "protein structure" to rely on, and the relevant functional constraints are often encoded in subtle motifs and long-range regulatory elements. GPN-MSA (Genomic Pre-trained Network with Multi-Species Alignments) addresses this by combining raw DNA sequence with multi-species conservation in a language modeling framework [@benegas_gpn-msa_2024].

### Alignment-Based DNA Language Model

GPN-MSA extends earlier GPN models by ingesting multi-species sequence alignments over kilobase-scale genomic windows. For each genomic position, the input includes the reference DNA base in the focal species (e.g., human), the aligned bases (or gaps) from multiple other species, and masking patterns to indicate which positions and species are visible.

The model is trained with a masked language modeling objective analogous to BERT. The training procedure randomly masks bases across the alignment and predicts the masked bases given surrounding context across positions and species. Through this objective, GPN-MSA learns which bases are strongly constrained across evolution (highly predictable) and which positions tolerate more variability.

### Variant Scoring Strategies

Several strategies map GPN-MSA outputs to variant effect scores. Likelihood-based scoring compares the log-likelihood of reference and alternative alleles at a position, capturing how much the variant deviates from conservation patterns. Contextual perturbation assesses how a variant perturbs model predictions or hidden representations across a window, capturing disruption of local motifs or multi-base patterns. Embedding-based features use learned representations as features in downstream supervised models for pathogenicity or specific regulatory phenotypes.

Because GPN-MSA directly uses multi-species alignments, it excels at capturing deep evolutionary constraint in genomic regions that are noncoding but functionally important, such as enhancers, promoters, and untranslated regions.

### Benchmarking and Applications

On genome-wide variant pathogenicity benchmarks and regulatory variant datasets (e.g., from high-throughput reporter assays), GPN-MSA outperforms simpler conservation scores (e.g., phyloP, phastCons) when evaluated fairly, offers strong prefiltering ability by enriching for likely functional variants out of large candidate sets, and provides a principled way to combine alignment information with learned sequence features.

Its limitations include dependence on high-quality multi-species alignments, which may be missing or unreliable in repetitive regions, and coverage gaps for species or loci with poor comparative genomics resources.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion – GPN-MSA input and objective**

Add a figure showing:
- A stack of aligned sequences (species × position),
- Masked tokens highlighted,
- The model predicting masked bases across positions and species.

A side panel can illustrate how a single nucleotide variant changes the alignment column and how that translates into a Δ log-likelihood score.
:::


## Evo 2: A Generalist Genomic Language Model

Evo 2 pushes the foundation model paradigm further by acting as a generalist genomic language model: a single model trained across species and genomic contexts with very long input sequences [@brixi_evo_2025; @manzo_comparative_2025]. Conceptually, Evo 2 for genomes plays a similar role to large language models for text.

### Scale and Architecture

Evo 2 introduces several distinctive features. Long context length is enabled by the StripedHyena 2 architecture, which efficiently handles context lengths up to approximately 1 Mb, enabling it to model both local motifs and long-range dependencies (e.g., enhancer-promoter links). The model is trained on a diverse corpus: OpenGenome2, a large collection of genomes spanning many branches of the tree of life. This cross-species training encourages learning general principles of genomic organization and constraint. Flexible tokenization strategies range from single nucleotides to longer k-mer or hybrid schemes, balancing resolution and efficiency (@sec-token).

The training objective is primarily autoregressive or masked language modeling on raw DNA, learning to predict bases or tokens given the surrounding context.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion – Evo 2 architecture**

Insert a high-level diagram of Evo 2:
- Input: 1 Mb genomic window,
- Backbone: StripedHyena 2 blocks (recurrent/state-space-like) enabling long-range context,
- Output: per-position token probabilities.

A small inset could compare Evo 2's context length to earlier CNN/transformer models (e.g., 1–10 kb vs 1 Mb).
:::

### Zero-Shot Variant Effect Scoring

Variant scoring with Evo 2 mirrors the logic of zero-shot protein LMs. The model computes token-level log-probabilities for the reference sequence, substitutes the variant allele in context, recomputes log-probabilities, and derives a score based on the log-likelihood change.

Because Evo 2 sees long genomic neighborhoods, its scores implicitly capture local motif disruption (e.g., TF binding sites), altered higher-order patterns (e.g., CpG content, nucleosome positioning signals), and constraints arising from interactions between multiple elements within the window. This makes Evo 2 particularly suited for noncoding and regulatory variants, where context far beyond the immediate base often matters.

### Fine-Tuning and Task-Specific Heads

While zero-shot scores are already competitive, Evo 2 can be fine-tuned or paired with task-specific heads for regulatory prediction (e.g., chromatin accessibility, histone marks), splicing outcomes, and gene expression levels. Such adapters reuse Evo 2's representations as a generic backbone, mirroring how text LLMs are adapted via lightweight fine-tuning and prompting (@sec-foundation).


## AlphaGenome: Unified Multi-Omic VEP at 1 Mb Context

AlphaGenome is a unified model that takes a 1 Mb DNA sequence as input and jointly predicts a wide panel of multi-omic readouts: chromatin accessibility, histone modifications, TF binding, 3D contacts, and splicing features [@avsec_alphagenome_2025]. It can then be used to estimate how variants perturb these readouts, providing a mechanistic view of noncoding variant effects.

### Architecture and Training

The AlphaGenome architecture combines multiple components. Convolutional front-ends extract local motif-level features (akin to models like DeepSEA and Enformer). Long-range attention or state-space blocks propagate information across hundreds of kilobases (@sec-hybrid). Multi-task prediction heads handle different assay types (e.g., ATAC-seq, ChIP-seq marks, Hi-C contact maps, splice junction usage).

Training relies on large-scale functional genomics data from many cell types and assays (@sec-reg). The model is optimized to jointly predict 1D tracks (e.g., coverage profiles), 2D contact maps (e.g., Hi-C), and sequence-derived splicing features (e.g., junction usage, splice site scores).

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion – AlphaGenome unified architecture**

Add a block diagram showing:
- Input: 1 Mb DNA sequence,
- Layers: convolutional encoder → long-range blocks → multi-task heads,
- Outputs: example tracks (ATAC, H3K27ac), a 3D contact map panel, and splicing predictions.

Highlight that the same backbone supports all these modalities.
:::

### Variant Effect Prediction Across Modalities

For VEP, AlphaGenome compares predictions for the reference and alternate sequences. Regulatory impact is captured through changes in predicted chromatin accessibility or histone marks at enhancers/promoters. 3D genome structure effects appear as shifts in predicted contact maps, particularly enhancer-promoter interactions that may be weakened or strengthened. Splicing effects manifest as altered splice junction usage or cryptic splice site activation.

This enables multi-modal variant effect scores that unify many previously separate tools (e.g., promoter/enhancer predictors, splicing models, TAD-perturbation models). On benchmarks spanning regulatory MPRAs, splicing assays, and disease-associated noncoding variants, AlphaGenome achieves state-of-the-art performance while providing mechanistically interpretable outputs.

Its main challenges include heavy computational cost (1 Mb windows with many outputs), potential brittleness when extrapolating beyond the training distribution (e.g., rare tissues, extreme cell states), and the difficulty of calibrating multi-omic changes into clinical pathogenicity categories.


## Comparing Design Choices Across Modern VEP Models

The models surveyed in this chapter span different points in a multidimensional design space. The table below summarizes some of the key axes:

| Model        | Input Modality                            | Context Length    | Pretraining Data                                       | Variant Types         | Primary Outputs                                      |
|--------------|-------------------------------------------|-------------------|--------------------------------------------------------|-----------------------|-----------------------------------------------------|
| AlphaMissense | Protein sequence + structure             | Protein-length    | Protein sequence corpora + AlphaFold2 structures      | Missense only         | Pathogenicity probability                           |
| GPN-MSA      | Multi-species DNA alignments             | kb-scale windows  | Whole-genome MSAs across many species                 | Coding + noncoding    | Likelihood / embedding-based scores                 |
| Evo 2        | Raw DNA sequence                         | Up to ~1 Mb       | OpenGenome2 (multi-species genomes)                   | All variant types     | Zero-shot likelihood-based scores + representations |
| AlphaGenome  | Raw DNA sequence                         | 1 Mb              | Human genome + multi-omic tracks across cell types    | All variant types     | Multi-omic tracks + delta effects                   |

Several key contrasts emerge. AlphaMissense focuses on proteins and missense variants, while GPN-MSA, Evo 2, and AlphaGenome operate directly on DNA, with varying emphasis on coding vs noncoding variants. Shorter context models (e.g., GPN-MSA) excel at capturing local conservation, whereas Evo 2 and AlphaGenome can model long-range regulatory interactions. AlphaMissense outputs a single pathogenicity probability; Evo 2 primarily offers likelihood-based scores and representations; AlphaGenome produces rich multi-omic profiles that can support mechanistic hypotheses (@sec-interp). AlphaMissense and GPN-MSA emphasize evolutionary constraints; Evo 2 adds cross-species genomic syntax; AlphaGenome emphasizes functional genomics.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestions – comparative performance and design**

1. A bar chart or ROC/AUPRC plot comparing model performance on ClinVar (missense), MAVE/DMS datasets, and regulatory MPRA datasets.

2. A schematic table (expanded from the one above) highlighting modality, context length, training data types, output types, and example use cases (clinical vs research).
:::


### Specialized vs General Regulatory Models

A recurring tension in regulatory VEP is whether to build specialized models for a specific tissue/assay or general models that span many contexts. TREDNet exemplifies the specialized strategy: it is trained to predict regulatory activity (e.g., TF binding, chromatin marks) for a specific cell type and assay configuration [@hudaiberdiev_trednet_2023]. Such specialization concentrates model capacity on a well-defined biological context, often yields strong performance for that context, and facilitates interpretation in terms of a particular regulatory program.

In contrast, models like AlphaGenome and Evo 2 are generalist backbones that can be adapted across many contexts via multi-task heads or fine-tuning. Generalist models provide a single representation that can be reused across tasks (@sec-foundation), enable transfer to cell types or assays with limited data, and support unified analyses that integrate multiple regulatory modalities.

In practice, specialized vs general models are complementary. Specialized models may be preferable when the disease mechanism is tightly linked to a particular cell type and high-quality matched functional data exist for that context. Generalist backbones are more attractive when data are sparse or heterogeneous and we wish to systematically explore variant effects across many cell types and assays (@sec-reg).


### Combining Predictors in Practice

No single VEP model is universally optimal. Practical workflows often combine multiple predictors. For example, use GPN-MSA or Evo 2 for initial genome-wide filtering, prioritizing variants under strong evolutionary or language-model-derived constraint. Use AlphaMissense for missense variants in protein-coding regions, especially when strong structural context is available. Use AlphaGenome (or similar regulatory models) to evaluate noncoding variants affecting enhancers, promoters, or splicing.

These combinations are typically integrated with population allele frequencies (e.g., gnomAD), gene-level constraint metrics, clinical and segregation data, and task-specific experimental assays when available (@sec-eval; @sec-trans).

A key challenge is to avoid overcounting correlated signals (e.g., multiple scores derived from similar evolutionary data) and to calibrate evidence contributions within frameworks like ACMG, as discussed further in Chapters 17 and 18 (@sec-eval; @sec-confound).

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion – practical VEP workflow**

Add a workflow diagram showing:
1. Input: variant list from sequencing,
2. Branches by variant type (missense, synonymous, noncoding),
3. Tools used per branch (AlphaMissense, Evo 2, AlphaGenome, GPN-MSA, TREDNet),
4. Integration with population, gene-level, and clinical data,
5. Output: prioritized variant set and evidence summary.

This could be reused across later translation chapters.
:::


## Open Challenges and Future Directions

Even state-of-the-art systems like AlphaMissense, GPN-MSA, Evo 2, and AlphaGenome leave major gaps. These open challenges define the frontier of variant effect prediction research.

### Ancestry and Population Bias

Training data and labels remain skewed toward certain ancestries, genes, and disease phenotypes. ClinVar submissions are dominated by variants from individuals of European ancestry, population databases underrepresent many global populations, and functional assays are concentrated on a limited set of genes and pathways. These biases can distort both calibration and ranking of variants across ancestries (@sec-confound). Future VEP models will need more diverse training datasets, explicit modeling of population structure, and evaluation frameworks that surface ancestry-specific performance disparities (@sec-benchmarks).

### Complex Variant Patterns

Most current models focus on single-nucleotide variants (SNVs) or single amino acid substitutions. However, real genomes contain indels and frameshifts, structural variants (SVs), haplotypes involving multiple nearby variants, and compound heterozygosity and gene-gene interactions. Extending models to capture combinatorial variant patterns is challenging: the space of possible multi-variant configurations is enormous, training data for interactions are sparse, and long-range and higher-order epistasis can be hard to represent even in large models. Foundation models with long contexts (like Evo 2 and AlphaGenome) provide a promising substrate, but new objectives and datasets will be needed to robustly model multi-variant effects.

### Integrating Multi-Omics and Longitudinal Data

AlphaGenome takes a first step toward unified multi-omic prediction, but real tissues and organisms exhibit dynamic regulatory programs across development and aging, responses to environmental perturbations, and cell-type heterogeneity and spatial organization. Integrating single-cell, spatial, and longitudinal omics into VEP frameworks will be crucial for capturing context-specific variant effects (@sec-systems). This will likely require new multi-scale architectures that span from sequence to cell states, careful treatment of batch effects and confounders, and benchmarks that explicitly evaluate context-specific predictions (@sec-benchmarks).

### Interpretability and Clinical Communication

As models grow more complex, interpretability becomes a central concern (@sec-interp). Clinicians need explanations that connect model scores to mechanism (e.g., "disrupts a conserved splice acceptor, predicted to cause exon skipping"). Researchers need tools to trace predictions back to motifs, domains, or 3D contacts that can be experimentally tested. Future work will involve model-based attribution methods adapted to sequence and structure, counterfactual reasoning over variant sets, and interfaces that present model outputs in clinically meaningful formats.

### Safe Deployment and Continual Learning

Finally, VEP systems are increasingly deployed in clinical and research pipelines that continuously generate new data. This raises questions about continual learning (how to integrate new functional and clinical labels without destabilizing existing predictions), versioning and reproducibility (how to ensure that changes in models and training data are tracked and interpretable to downstream users), and safety and governance (how to prevent misuse, ensure transparency about limitations, and embed these tools within responsible clinical workflows) (@sec-trans; @sec-eval).

In subsequent chapters, we connect these VEP systems to broader end-to-end frameworks for variant interpretation, including risk prediction, rare disease diagnosis, and therapeutic target discovery. Together with careful evaluation and interpretation, foundation-model-based VEP promises to transform how we understand and act on genomic variation.