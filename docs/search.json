[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genomic Foundation Models",
    "section": "",
    "text": "Introduction\nGenomics is in the middle of a quiet phase change.\nOn one side, sequencing has become routine: biobanks now contain hundreds of thousands to millions of genomes, exomes, and transcriptomes, cataloging billions of variants across diverse populations. On the other side, deep learning and large-scale sequence modeling have transformed how we represent language, proteins, and now DNA itself (Zhou and Troyanskaya 2015; Avsec et al. 2021; He et al. 2023; Benegas, Batra, and Song 2023; Benegas, Ye, et al. 2024; Zhang et al. 2024).\nThis book is about the intersection: genomic foundation models (GFMs)—large, reusable models trained on genomic and related data that can be adapted to many downstream tasks, from variant interpretation to clinical risk prediction.\nRather than offering a general introduction to genomics or machine learning, the goal here is narrower and more opinionated:\nThe chapters that follow connect classic genomics pipelines, early deep regulatory models, sequence language models, and multi-omic GFMs into a single narrative arc.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#why-genomic-foundation-models",
    "href": "index.html#why-genomic-foundation-models",
    "title": "Genomic Foundation Models",
    "section": "Why Genomic Foundation Models?",
    "text": "Why Genomic Foundation Models?\nTraditional genomic modeling has typically been task-specific:\n\nA variant caller designed only to distinguish sequencing errors from real variants.\nA convolutional network trained to predict chromatin marks in a fixed panel of cell types.\nA risk score tuned for coronary artery disease in one ancestry group.\n\nThese models can work well within their narrow domains, but they do not usually offer a single, reusable representation of genomic variation.\nBy contrast, the “foundation model” paradigm—popularized in natural language and protein modeling—rests on three ideas:\n\nScale\nTrain large models on massive, heterogeneous datasets (e.g., whole genomes across species, genome-wide chromatin maps, population variation).\nSelf-supervision\nUse objectives such as masked-token prediction, next-token modeling, or multi-task sequence-to-function training that do not require dense human labels (Benegas, Batra, and Song 2023; Zvyagin et al. 2022; Nguyen et al. 2023; Schiff et al. 2024).\nReusability\nTreat the model as a backbone: for any new task, you probe or fine-tune it, rather than training from scratch. Variant effect prediction, enhancer classification, GWAS fine-mapping priors, and clinical risk models all become “adapters” on top of a shared representation (Benegas, Ye, et al. 2024; Fishman et al. 2025).\n\nIn genomics, this paradigm is still evolving and remains empirically contested: some studies report large gains from pretraining, while others argue that simple baselines remain competitive (Vishniakov et al. 2024). This book deliberately leans into that tension. Throughout the chapters we will ask:\n\nWhen does large-scale pretraining actually help?\nWhat do these models learn about regulatory logic, evolution, and molecular mechanisms?\nHow can they be plugged into real decision-making pipelines without overclaiming?",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#what-this-book-is-and-is-not",
    "href": "index.html#what-this-book-is-and-is-not",
    "title": "Genomic Foundation Models",
    "section": "What This Book Is (and Is Not)",
    "text": "What This Book Is (and Is Not)\nThis is not:\n\nA full genomics textbook.\nA comprehensive review of every published DNA or protein model.\nA mathematical introduction to deep learning from first principles.\n\nInstead, it aims to be:\n\nA roadmap to the main families of models and data that matter for genomic foundation modeling today.\nA bridge between classic statistical genetics (GWAS, PRS, deleteriousness scores) and modern sequence models.\nA practical guide to how these models are built, trained, evaluated, and deployed—emphasizing caveats, confounders, and failure modes.\n\nThe assumed background is a working familiarity with basic genomics (variants, genes, regulatory elements) and some exposure to machine learning. Where needed, earlier chapters provide primers before moving into more advanced models.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-the-book-is-organized",
    "href": "index.html#how-the-book-is-organized",
    "title": "Genomic Foundation Models",
    "section": "How the Book Is Organized",
    "text": "How the Book Is Organized\nThe book is organized into five parts. Each part can be read on its own, but they are designed to build on each other.\n\nPart I — Data & Pre-DL Methods (Chapters 1–4)\nPart I lays the genomic and statistical foundation that later models rest on.\n\nChapter 1 — NGS & Variant Calling\nIntroduces next-generation sequencing, alignment, and variant calling. It traces the evolution from hand-crafted statistical pipelines (e.g., GATK) to deep learning-based callers such as DeepVariant, highlighting how even “upstream” tools have transitioned to learned models.\nChapter 2 — PRS & GWAS Basics\nCovers the genome-wide association study (GWAS) paradigm, summary statistics, linkage disequilibrium, and polygenic risk scores (PRS). This chapter sets up the statistical framing of “variant-to-trait” associations that later GFMs must interface with.\nChapter 3 — Deleteriousness Scores\nSurveys conservation-based and machine learning-based variant pathogenicity scores (e.g., CADD and related tools), emphasizing how hand-crafted features and population constraint metrics are combined into early genome-wide predictors (Rentzsch et al. 2019; Schubach et al. 2024).\nChapter 4 — Foundational Genomics Data\nReviews the major data resources that fuel modern models: ENCODE and Roadmap epigenomics for chromatin and accessibility, large expression atlases, population resources like gnomAD, and biobanks linking genomes to phenotypes. These datasets become the training targets and evaluation benchmarks for the deep models in later parts.\n\nTogether, Part I answers: What are the core data, statistical tools, and baseline methods that any genomic foundation model must respect, integrate with, or improve upon?\n\n\n\nPart II — CNN Seq-to-Function Models (Chapters 5–7)\nPart II turns to the first wave of deep sequence-to-function models, largely built on convolutional neural networks (CNNs).\n\nChapter 5 — Regulatory Prediction\nFocuses on models that predict chromatin accessibility and transcription factor binding from DNA sequence (e.g., DeepSEA and successors) (Zhou and Troyanskaya 2015; Chen et al. 2022; Avsec et al. 2021). It introduces one-hot sequence encodings, convolutional filters as motif detectors, and multi-task training over many assays.\nChapter 6 — Transcriptional Effects\nMoves from local chromatin states to gene-level transcriptional readouts, including models such as ExPecto and related architectures. It emphasizes the challenge of mapping sequences to expression in specific cell types and conditions, and introduces ideas like distance-dependent kernels.\nChapter 7 — Splicing Prediction\nExamines specialized sequence models for splicing, such as SpliceAI, which use deep receptive fields to capture intronic and exonic context. This chapter shows how tailored architectures can achieve state-of-the-art performance on particular mechanisms, foreshadowing the mechanism-aware GFMs of Part IV.\n\nPart II illustrates how task-specific supervised models can uncover rich regulatory logic, but also how their narrow training objectives limit reuse.\n\n\n\nPart III — Transformer Models (Chapters 8–11)\nPart III explores the sequence modeling architectures that underpin many GFMs, with an emphasis on transformers and long-range variants.\n\nChapter 8 — Sequence Representation & Tokens\nDiscusses how to tokenize DNA, RNA, and protein sequences (nucleotides vs k-mers vs learned tokens) and how those choices affect model capacity, context length, and interpretability. It also introduces positional encodings and other tricks needed for very long sequences.\nChapter 9 — Protein Language Models\nProvides a primer on protein language models—ESM, AlphaMissense-style models, and related architectures—that learn from large multiple sequence alignments or unaligned protein corpora (Cheng et al. 2023). These models serve as a conceptual and technical template for DNA-based LMs and illustrate how representations can support both structure prediction and variant effect prediction.\nChapter 10 — DNA Foundation Models\nIntroduces DNA language models and related self-supervised architectures (e.g., GPN, GenSLMs, HyenaDNA) (Benegas, Batra, and Song 2023; Zvyagin et al. 2022; Nguyen et al. 2023; Benegas, Ye, et al. 2024). It contrasts them with the supervised CNNs of Part II, focusing on objectives, pretraining corpora, and usage modes (frozen probes, fine-tuning, zero-shot).\nChapter 11 — Long-range Hybrid Models\nSurveys architectures that integrate long-range context and multi-task supervision, including models like Enformer, Caduceus, and hybrid convolution–transformer–SSM designs (Avsec et al. 2021; Schiff et al. 2024). These models blur the line between “language model” and “sequence-to-function” network and motivate the broader GFM framing in Part IV.\n\nPart III answers: What architectural tools are available for modeling genomic sequences at kilobase to megabase scale, and how do they differ from classic CNNs?\n\n\n\nPart IV — GFMs & Multi-omics (Chapters 12–16)\nPart IV is the conceptual heart of the book, focusing explicitly on genomic foundation models and their multi-omic extensions.\n\nChapter 12 — Genomic FMs: Principles & Practice\nProvides a working definition of GFMs, tracing the progression from deleteriousness scores and CNNs to self-supervised DNA and protein LMs (He et al. 2023; Benegas, Ye, et al. 2024; Dalla-Torre et al. 2023; Nguyen et al. 2023). It distills design principles around pretraining objectives, context length, conditioning (cell type, species), and deployment patterns.\nChapter 13 — Variant Effect Prediction\nRecasts variant effect prediction in the GFM era, spanning conservation-based scores, protein LMs, sequence-to-function models, and multi-modal systems like AlphaMissense and MSA-enhanced models (Cheng et al. 2023; Benegas, Albors, et al. 2024; Brixi et al. 2025). It emphasizes how GFMs act as feature generators for downstream prioritization and association analyses.\nChapter 14 — Confounders in Model Training\nDetails the many sources of confounding—batch effects, ancestry and population structure, data leakage between train and test, label bias—that can inflate reported performance or create spurious signals. This chapter provides a checklist for stress-testing GFMs and their derivatives.\nChapter 15 — Interpretability & Mechanisms\nExplores how to probe GFMs and related models for mechanistic insight: motif discovery, saliency maps, in silico mutagenesis, causal perturbation experiments, and connections to biophysical or evolutionary models. The emphasis is on turning black-box predictions into hypotheses about regulatory grammar and molecular mechanisms.\nChapter 16 — Multi-omics and Systems Context\nBroadens the view from isolated sequences to multi-omic and network-level models, integrating chromatin, expression, protein–protein interaction networks, and other modalities. It discusses graph-based models, multi-modal encoders, and how GFMs can provide a common representation layer for multi-omic integration (X. Li et al. 2022; Chandak, Huang, and Zitnik 2023; Cornman et al. 2024).\n\nPart IV pulls together themes from every earlier chapter, focusing on how to design, train, and interrogate models that aspire to be genuinely foundational within genomics.\n\n\n\nPart V — Applications (Chapters 17–19)\nPart V turns outward, focusing on applications and deployment in clinical and translational settings.\n\nChapter 17 — Clinical Risk Prediction\nDescribes how GFMs and related models can be used to build clinical risk scores and decision support tools, often combining genomic features with electronic health record (EHR) and other data sources (Cao and Gao 2022; Georgantas, Kutalik, and Richiardi 2024; Clarke et al. 2024; Rakowski and Lippert 2025). It covers calibration, uncertainty, fairness, and regulatory considerations for high-stakes predictions.\nChapter 18 — Pathogenic Variant Discovery\nFocuses on discovery workflows: ranking variants and genes for follow-up, integrating GFMs into fine-mapping, network-based gene prioritization, and the design of CRISPR and MPRA experiments for functional validation (Benegas, Albors, et al. 2024; Avsec et al. 2021; Linder et al. 2025; H. Li et al. 2024; Wu et al. 2024).\nChapter 19 — Drug Discovery & Biotech\nZooms out to drug discovery and biotech pipelines: target identification, genetic validation, functional genomics screens, and early-stage safety and efficacy prediction. It highlights where GFMs are already useful, where they remain speculative, and how they might integrate with broader scientific LLM ecosystems (Ma et al. 2023; Zhang et al. 2024).\n\nThese chapters emphasize end-to-end workflows: how a model trained on sequences ends up influencing a clinical report, a gene nomination list, or a preclinical portfolio.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-to-read-this-book",
    "href": "index.html#how-to-read-this-book",
    "title": "Genomic Foundation Models",
    "section": "How to Read This Book",
    "text": "How to Read This Book\nDifferent readers will want to enter at different points:\n\nIf you are primarily a computational biologist or statistical geneticist, you may want to skim Part I (to align terminology) and then focus on Parts II–IV to understand how deep models are constructed and evaluated.\nIf you are a machine learning researcher, Chapters 5–11 and 12–16 provide the most relevant architectural and modeling details, with Part I serving as biological context and Part V illustrating application constraints.\nIf you are a clinician, translational scientist, or industry practitioner, you may wish to read Chapters 1–4 and 12–19, treating the technical architectural chapters as optional references.\n\nThe chapters are intentionally cross-referenced. When a later chapter relies heavily on earlier material—for example, Chapter 13 on variant effect prediction drawing from Chapters 3, 5–7, 9, and 10—this is called out explicitly.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#a-moving-target",
    "href": "index.html#a-moving-target",
    "title": "Genomic Foundation Models",
    "section": "A Moving Target",
    "text": "A Moving Target\nGenomic foundation models are a moving target. New architectures, training corpora, and evaluation benchmarks continue to appear at a rapid pace (He et al. 2023; Benegas, Ye, et al. 2024; Zhang et al. 2024; Vishniakov et al. 2024; Fishman et al. 2025). This book does not aim to be the final word on any particular model; instead, it offers a framework for understanding and comparing them.\nIf the book succeeds, you should finish it able to:\n\nRead a new GFM paper and place it in the landscape of data, architecture, objective, and application.\nDesign experiments that use GFMs as components—features, priors, or simulators—without overclaiming.\nRecognize common pitfalls in training, evaluation, and deployment, especially in clinical and translational contexts.\nForm your own views about where genomic foundation models are genuinely transformative, and where simpler baselines or traditional methods may suffice.\n\nThe rest of the book now turns to the foundations: how we get from raw sequencing reads to high-confidence variants and the statistical tools that predate deep learning, setting the stage for the models to come.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBenegas, Gonzalo, Sanjit Singh Batra, and Yun S. Song. 2023. “[GPN] DNA Language Models Are Powerful Predictors of Genome-Wide Variant Effects.” Proceedings of the National Academy of Sciences 120 (44): e2311219120. https://doi.org/10.1073/pnas.2311219120.\n\n\nBenegas, Gonzalo, Chengzhong Ye, Carlos Albors, Jianan Canal Li, and Yun S. Song. 2024. “Genomic Language Models: Opportunities and Challenges.” arXiv. https://doi.org/10.48550/arXiv.2407.11435.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. “[Evo 2] Genome Modeling and Design Across All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nChandak, Payal, Kexin Huang, and Marinka Zitnik. 2023. “[PrimeKG] Building a Knowledge Graph to Enable Precision Medicine.” Scientific Data 10 (1): 67. https://doi.org/10.1038/s41597-023-01960-3.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus Wahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024. “[DeepRVAT] Integration of Variant Annotations Using Deep Set Networks Boosts Rare Variant Association Testing.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nCornman, Andre, Jacob West-Roberts, Antonio Pedro Camargo, Simon Roux, Martin Beracochea, Milot Mirdita, Sergey Ovchinnikov, and Yunha Hwang. 2024. “[gLM2] The OMG Dataset: An Open MetaGenomic Corpus for Mixed-Modality Genomic Language Modeling.” bioRxiv. https://doi.org/10.1101/2024.08.14.607850.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nFishman, Veniamin, Yuri Kuratov, Aleksei Shmelev, Maxim Petrov, Dmitry Penzar, Denis Shepelin, Nikolay Chekanov, Olga Kardymon, and Mikhail Burtsev. 2025. “GENA-LM: A Family of Open-Source Foundational DNA Language Models for Long Sequences.” Nucleic Acids Research 53 (2): gkae1310. https://doi.org/10.1093/nar/gkae1310.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nHe, Shujun, Baizhen Gao, Rushant Sabnis, and Qing Sun. 2023. “Nucleic Transformer: Classifying DNA Sequences with Self-Attention and Convolutions.” ACS Synthetic Biology 12 (11): 3205–14. https://doi.org/10.1021/acssynbio.3c00154.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai, et al. 2024. “CGMega: Explainable Graph Neural Network Framework with Attention Mechanisms for Cancer Gene Module Dissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and Yunping Zhu. 2022. “MoGCN: A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Analysis.” Frontiers in Genetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nMa, Jiani, Jiangning Song, Neil D. Young, Bill C. H. Chang, Pasi K. Korhonen, Tulio L. Campos, Hui Liu, and Robin B. Gasser. 2023. “’Bingo’-a Large Language Model- and Graph Neural Network-Based Workflow for the Prediction of Essential Genes from Protein Data.” Briefings in Bioinformatics 25 (1): bbad472. https://doi.org/10.1093/bib/bbad472.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nSchiff, Yair, Chia-Hsiang Kao, Aaron Gokaslan, Tri Dao, Albert Gu, and Volodymyr Kuleshov. 2024. “Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling.” arXiv. https://doi.org/10.48550/arXiv.2403.03234.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nVishniakov, Kirill, Karthik Viswanathan, Aleksandr Medvedev, Praveenkumar Kanithi, Marco AF Pimentel, and Shadab Khan. 2024. “Genomic Foundationless Models: Pretraining Does Not Promise Performance,” October. https://openreview.net/forum?id=kDZKEtDnT1.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nZhang, Qiang, Keyang Ding, Tianwen Lyv, Xinda Wang, Qingyu Yin, Yiwen Zhang, Jing Yu, et al. 2024. “Scientific Large Language Models: A Survey on Biological & Chemical Domains.” arXiv. https://doi.org/10.48550/arXiv.2401.14656.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.\n\n\nZvyagin, Maxim, Alexander Brace, Kyle Hippe, Yuntian Deng, Bin Zhang, Cindy Orozco Bohorquez, Austin Clyde, et al. 2022. “GenSLMs: Genome-Scale Language Models Reveal SARS-CoV-2 Evolutionary Dynamics.” bioRxiv. https://doi.org/10.1101/2022.10.10.511571.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "Who This Book Is For\nGenomics is in the middle of a quiet revolution.\nFor years, “machine learning in genetics” meant hand-crafted features, linear models, and carefully tuned statistical pipelines. Variant calling relied on logistic regression and hidden Markov models. Genome-wide association studies (GWAS) and polygenic risk scores (PRS) summarized common variant effects. Deleteriousness scores like CADD distilled curated annotations into prioritization heuristics. Functional genomics resources—ENCODE, GTEx, large biobanks—arrived in waves, but each new dataset was bolted onto bespoke tools and task-specific models.\nOver roughly the last decade, that picture has changed. Convolutional neural networks (CNNs) began to learn regulatory code directly from sequence. Transformers and protein language models showed how self-supervision on massive unlabeled corpora could extract rich biological structure. Genomic foundation models (GFMs) now promise reusable representations of DNA, RNA, protein, and multi-omic context that can be adapted to everything from variant effect prediction to clinical risk scoring.\nThis book is my attempt to make sense of that transition—from sequence variation to genomic foundation models and back again to clinical and biological questions—in a way that is coherent, historically grounded, and practically useful.\nThis book is written for readers who sit somewhere in the triangle between genomics, statistics, and machine learning:\nSome familiarity with probability, linear models, and basic genomics (variants, genes, regulatory elements) will help, but the early chapters are designed to be a gentle ramp rather than a gate.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#who-this-book-is-for",
    "href": "preface.html#who-this-book-is-for",
    "title": "Preface",
    "section": "",
    "text": "Computational biologists and statistical geneticists\nwho want to understand how deep learning and foundation models fit alongside GWAS, PRS, rare variant association, and functional genomics.\nMachine learning researchers and engineers\nwho are comfortable with CNNs, transformers, and language models, and want a pragmatic guide to what makes genomic data different from text or images.\nClinicians and translational researchers\nwho increasingly see “AI scores,” “foundation models,” or “genomic LLMs” in papers, reports, and grant proposals, and want a grounded view of what these tools can and cannot do in practice.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#how-the-book-is-organized",
    "href": "preface.html#how-the-book-is-organized",
    "title": "Preface",
    "section": "How the Book Is Organized",
    "text": "How the Book Is Organized\nThe book is organized into five parts that mirror how the field itself has evolved—from data and pre-deep-learning methods to CNNs, transformers, foundation models, and finally clinical and translational applications. :contentReferenceoaicite:0\n\nPart I: Data & Pre-DL Methods (Chapters 1–4)\nWe start from the raw materials: next-generation sequencing and variant calling, GWAS and PRS basics, classical deleteriousness scores, and foundational functional genomics resources. This part establishes the statistical and biological context that later deep models must respect.\nPart II: CNN Seq-to-Function Models (Chapters 5–7)\nWe then move into supervised sequence-to-function models like DeepSEA, ExPecto, and SpliceAI. These chapters show how CNNs can learn regulatory code, link chromatin to expression, and predict splicing, and they surface early lessons about architecture, context windows, and training data.\nPart III: Transformer Models (Chapters 8–11)\nWith that foundation, we broaden to representation learning and long-range modeling. We discuss sequence tokenization and context representation, protein language models, DNA foundation models, and hybrid architectures that couple CNNs and transformers to capture long-range regulatory interactions.\nPart IV: GFMs & Multi-omics (Chapters 12–16)\nHere we step back and ask: what makes a genomic model a foundation model? We examine principles for designing GFMs, how variant effect prediction is being reshaped by foundation models, and how confounding, interpretability, and multi-omic integration become more critical as models grow larger and more general.\nPart V: Applications (Chapters 17–19)\nFinally, we move from methods to workflows: clinical risk prediction, pathogenic variant discovery, and drug discovery/biotech applications. These chapters focus less on novel architectures and more on how GFMs plug into broader pipelines, evaluation strategies, and decision-making processes.\n\nYou do not have to read the book linearly. If you are already comfortable with GWAS and classical variant scores, you might skim Part I and start with the CNN or transformer chapters. If you care primarily about clinical or biotech applications, you may wish to read Part V early, referring back to earlier chapters as needed.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#key-themes-across-the-book",
    "href": "preface.html#key-themes-across-the-book",
    "title": "Preface",
    "section": "Key Themes Across the Book",
    "text": "Key Themes Across the Book\nSeveral themes recur throughout the chapters, and the rest of the book can be read as a deepening of each of these:\n\nData → Architecture Evolution\nWe trace how data availability and representation drove model design:\n\nFrom hand-engineered features and shallow models (e.g., CADD-style scores)\n\nTo supervised CNNs that learn regulatory motifs and grammars directly from sequence\n\nTo transformers and structured state-space models (SSMs) that operate on longer contexts and richer tokenizations\n\nTo GFMs trained to be reused across tasks, tissues, and species\n\nAt each stage, the goal is not simply “more complex models,” but better alignment between what the data contain and what the model can express.\n\n\nContext Length Scaling: 1 kb → 100 kb → 1 Mb\nMany of the most interesting genomic questions are non-local:\n\nEnhancers regulate genes hundreds of kilobases away.\n\nChromatin conformation creates long-range dependencies.\n\nPolygenic traits aggregate effects across the entire genome.\n\nWe follow how context windows grew from ~1 kb promoter-centric CNNs, to tens of kilobases in ExPecto-style models, to 100 kb–1 Mb in modern hybrid and SSM-based architectures—and how each jump in context length changes both modeling tactics and biological interpretation.\n\n\nSelf-Supervision: Leveraging Unlabeled Genomic Data\nUnlike labeled regulatory or clinical datasets, the raw genome is cheap and abundant. We explore how self-supervised objectives—masked language modeling, next-token prediction, denoising tasks—allow models to learn useful representations from unlabeled sequences, and how these representations transfer to:\n\nVariant effect prediction\n\nRegulatory element annotation\n\nCross-species generalization\n\nDownstream clinical prediction tasks\n\n\n\nTransfer Learning: Protein LMs → DNA LMs; Human → Cross-Species\nGenomic foundation models are fundamentally about transfer:\n\nFrom protein language models to variant effect prediction and structure-informed tasks\n\nFrom human-focused models to cross-species models that incorporate evolutionary signal\n\nFrom pretraining on large unlabeled corpora to fine-tuning on smaller, task-specific or cell-type-specific datasets\n\nWe emphasize both the opportunities and the pitfalls: where transfer learning works remarkably well, and where naive reuse can bake in biases or violate domain assumptions.\n\n\nClinical Translation: VEP, PRS, Rare Disease, and Beyond\nThroughout the book we keep returning to a basic question:\n\nWhen, if ever, do these models change decisions in medicine and biology?\n\nWe examine how GFMs augment or reshape:\n\nVariant effect prediction pipelines for rare disease diagnosis\n\nPolygenic and multi-omic risk prediction for complex traits\n\nFine-mapping and gene prioritization in drug target discovery\n\nBiomarker development, patient stratification, and trial design\n\nThe focus is on workflows and evaluation: calibration, robustness, fairness, and reproducibility in real clinical and translational settings.\n\n\nInterpretability: From Black Box to Mechanistic Insight\nFinally, we treat interpretability not as an afterthought, but as a central design constraint. As models grow larger and more flexible, we ask:\n\nCan we extract motifs, grammars, and regulatory programs from sequence models in a way that aligns with experimental biology?\n\nHow can we distinguish genuine mechanism from confounded shortcuts and benchmark leakage?\n\nWhat tools—from saliency and attribution to mechanistic interpretability—are actually useful in genomics practice?\n\nThese themes tie together discussions of confounders, evaluation, and mechanistic modeling across Parts II–V.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#what-this-book-is-not",
    "href": "preface.html#what-this-book-is-not",
    "title": "Preface",
    "section": "What This Book Is Not",
    "text": "What This Book Is Not\nTo keep the narrative focused, this book deliberately avoids trying to be:\n\nA comprehensive survey of every published model or dataset.\n\nA software manual for specific tools, APIs, or cloud platforms.\n\nA proof-heavy textbook on statistical genetics or deep learning theory.\n\nInstead, the goal is to provide a conceptual map and a set of worked examples that will help you navigate the rapidly evolving space of genomic foundation models, understand their assumptions and limitations, and decide where they fit into your own research or clinical practice.\nWhere detailed tutorials, code, or benchmarks are helpful, I point to external resources rather than reproducing them in full.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#how-to-read-and-use-this-book",
    "href": "preface.html#how-to-read-and-use-this-book",
    "title": "Preface",
    "section": "How to Read and Use This Book",
    "text": "How to Read and Use This Book\nA few practical suggestions:\n\nUse the early chapters as shared vocabulary.\nEven if you are already familiar with NGS pipelines or GWAS, skimming Chapters 1–4 ensures we share terminology and assumptions.\nPick application-driven paths.\nIf your primary interest is clinical risk prediction, you might follow a path like: Chapters 2–3 → 5–7 → 10–13 → 17. For variant discovery: Chapters 1–4 → 9–13 → 18. For biotech and drug discovery: Chapters 3–4 → 9–12 → 16–19.\nMove back and forth between methods and applications.\nThe later application chapters are written to be readable on their own, but they gain depth if you revisit relevant method chapters (e.g., SpliceAI in Chapter 7 when thinking about splice-disrupting variants in Chapter 18).\nTreat the references as a roadmap.\nThe citations are curated to point to primary papers and representative follow-ups rather than exhaustive lists. Following those threads is often the fastest way to get from this conceptual overview to the cutting edge in a particular niche.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#acknowledgments",
    "href": "preface.html#acknowledgments",
    "title": "Preface",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis book grew directly out of work with the Mayo Clinic GenAI team, and I owe a special debt of gratitude to the colleagues who made that environment so generative.\nTo the principal investigators and clinicians who grounded our models in real clinical questions:\nDrs. Shant Ayanian, Elena Myasoedova, and Alexander Ryu.\nTo leadership for carving out the space, support, and vision for this work:\nDr. Matthew Callstrom, Dr. Panos Korfiatis, and Matt Redlon.\nTo my Data Science and Machine Learning Engineering colleagues, whose ideas, code, and patience shaped many of the workflows and examples in this book:\nBridget Toomey, Carl Molnar, Zach Jensen, and Marc Blasi.\nI am also grateful for the architectural creativity and technical depth of our collaborators at Cerebras:\nNatalia Vassilieva, Jason Wolfe, Omid Shams Solari, Vinay Pondenkandath, Bhargav Kanakiya, and Faisal Al-khateeb.\nAnd to our collaborators at GoodFire, whose partnership helped push these ideas closer to interpretable and deployable systems:\nDaniel Balsam, Nicholas Wang, Michael Pearce, and Mark Bissell.\nI also want to thank my former colleagues at LGC for foundational work on protein language models and for the conversations that helped shape my thinking about PLMs:\nPrasad Siddavatam and Robin Butler.\nFinally, beyond these named groups, this book owes a great deal to the broader community of people building and using genomic models: the teams who generated large-scale sequencing and functional genomics datasets; the authors of classical tools like CADD and PGS; the many groups pushing forward CNNs, transformers, and foundation models for DNA, RNA, and protein; and the clinicians, statisticians, and experimental biologists who keep all of us honest about what actually matters.\nIf this book helps you connect a new model to a real biological question, or use genomic foundation models a bit more thoughtfully in your own work, then it will have done its job.\n— Josh Meehl",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "ch-p1-ngs.html",
    "href": "ch-p1-ngs.html",
    "title": "1  NGS & Variant Calling",
    "section": "",
    "text": "1.1 The Challenge of NGS Data\nNext-generation sequencing has revolutionized genomics by enabling the rapid generation of billions of short sequence reads from an individual’s genome. However, these reads are inherently error-prone, with error rates ranging from approximately 0.1% to 10% depending on the platform and chemistry (Poplin et al. 2018). The errors arise from a complex process that depends on properties of the sequencing instrument, preceding data processing tools, and the genome sequence itself.\nTraditional variant calling methods like the Genome Analysis Toolkit (GATK) rely on a combination of hand-crafted statistical models to distinguish true genetic variants from sequencing artifacts:\nWhile these techniques achieve high accuracy on the Illumina platform, generalizing them to other sequencing technologies (e.g., Ion Torrent, PacBio) has proven difficult due to the need to manually retune or extend the statistical models for each platform’s unique error profile (Poplin et al. 2018).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>NGS & Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch-p1-ngs.html#the-challenge-of-ngs-data",
    "href": "ch-p1-ngs.html#the-challenge-of-ngs-data",
    "title": "1  NGS & Variant Calling",
    "section": "",
    "text": "Logistic regression to model base errors\nHidden Markov models to compute read likelihoods\nNaive Bayes classification to identify variants\nGaussian mixture models with hand-crafted features to filter likely false positives",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>NGS & Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch-p1-ngs.html#deepvariant-deep-learning-for-variant-calling",
    "href": "ch-p1-ngs.html#deepvariant-deep-learning-for-variant-calling",
    "title": "1  NGS & Variant Calling",
    "section": "1.2 DeepVariant: Deep Learning for Variant Calling",
    "text": "1.2 DeepVariant: Deep Learning for Variant Calling\nDeepVariant (Poplin et al. 2018) replaces the assortment of statistical modeling components with a single deep convolutional neural network (CNN), demonstrating that deep learning can learn to call genetic variants more accurately than state-of-the-art methods without specialized knowledge about genomics or sequencing.\n\n1.2.1 Architecture\nDeepVariant uses a three-stage pipeline:\n\nCandidate Generation: Standard algorithmic preprocessing identifies candidate SNPs and indels with high sensitivity but low specificity.\nPileup Image Encoding: Read alignments around each candidate variant are encoded as multi-channel images (pileup images), capturing:\n\nReference sequence\nRead bases and quality scores\nMapping quality\nStrand orientation\n\nCNN Classification: An Inception-architecture CNN processes each pileup image and emits probabilities for each of the three diploid genotypes (homozygous reference, heterozygous, homozygous alternate).\n\n\n\n1.2.2 Learning Complex Dependencies\nA key limitation of traditional variant callers like GATK is their assumption that read errors are independent. Though this has long been recognized as invalid, the true likelihood function that models multiple reads simultaneously is unknown. Deep neural networks are universal function approximators, enabling DeepVariant to learn an approximation to this complex, interdependent likelihood function directly from data (Poplin et al. 2018).\n\n\n1.2.3 Cross-Technology Generalization\nDeepVariant demonstrates remarkable generalization across sequencing technologies. When retrained on platform-specific data, the model achieves high positive predictive values (PPVs) across diverse technologies:\n\n\n\nTechnology\nInitial PPV\nFinal PPV\nNotes\n\n\n\n\nIllumina WGS\n96.5%\n99.9%\nStandard short-read\n\n\nPacBio WGS\n22.1%\n97.3%\nHigh indel error rate\n\n\nSOLiD WGS\n14.3%\n99.0%\nColor-space artifacts\n\n\nIon Ampliseq\n8.1%\n99.7%\nExome, amplification artifacts\n\n\n\nThe model even generalizes across species—a model trained on human data achieved high accuracy (F1 = 98.29%) when applied to mouse sequencing data, outperforming training on mouse data alone (Poplin et al. 2018).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>NGS & Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch-p1-ngs.html#clinical-validation",
    "href": "ch-p1-ngs.html#clinical-validation",
    "title": "1  NGS & Variant Calling",
    "section": "1.3 Clinical Validation",
    "text": "1.3 Clinical Validation\nIn a clinical comparison using whole-exome sequencing (WES) trio analysis of 80 families, DeepVariant demonstrated superior performance over GATK HaplotypeCaller (Lin et al. 2022):\n\n\n\nMetric\nDeepVariant\nGATK\np-value\n\n\n\n\nMendelian error rate\n3.09 ± 0.83%\n5.25 ± 0.91%\n&lt; 0.001\n\n\nTi/Tv ratio\n2.38 ± 0.02\n2.04 ± 0.07\n&lt; 0.001\n\n\nExecution time (trio)\n~1.5 hours\n~2.5 hours\n0.046\n\n\n\nThe higher transition-to-transversion (Ti/Tv) ratio achieved by DeepVariant suggests proportionally more true positive calls, as biological SNVs exhibit a characteristic Ti/Tv ratio near 2.1 for exomes. The lower Mendelian error rate—variants in a child that violate expected inheritance patterns—provides direct evidence of improved accuracy in real clinical samples.\nBoth pipelines detected nearly identical sets of disease-causing variants (62 vs. 61 of 63 total), with DeepVariant detecting one additional variant missed by GATK due to low coverage (Lin et al. 2022).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>NGS & Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch-p1-ngs.html#significance-for-genomic-deep-learning",
    "href": "ch-p1-ngs.html#significance-for-genomic-deep-learning",
    "title": "1  NGS & Variant Calling",
    "section": "1.4 Significance for Genomic Deep Learning",
    "text": "1.4 Significance for Genomic Deep Learning\nDeepVariant established several paradigms that recur throughout this book:\n\nImage-based encoding: Representing genomic data as images enables the application of powerful computer vision architectures.\nEnd-to-end learning: Replacing hand-crafted feature engineering with learned representations from raw data.\nTransfer learning: Models trained on data-rich settings (human genomes with ground truth) can generalize to data-poor settings (non-model organisms).\nTechnology agnosticism: A single architecture can adapt to diverse sequencing platforms through retraining, rather than requiring platform-specific statistical models.\n\nThese principles—learning from data rather than encoding expert knowledge, and generalizing across contexts—form the foundation of the deep learning approaches to genomic interpretation covered in subsequent chapters.\n\n\n\n\nLin, Yi-Lin, Pi-Chuan Chang, Ching Hsu, Miao-Zi Hung, Yin-Hsiu Chien, Wuh-Liang Hwu, FeiPei Lai, and Ni-Chung Lee. 2022. “[DeepVariant] Comparison of GATK and DeepVariant by Trio Sequencing.” Scientific Reports 12 (1): 1809. https://doi.org/10.1038/s41598-022-05833-4.\n\n\nPoplin, Ryan, Pi-Chuan Chang, David Alexander, Scott Schwartz, Thomas Colthurst, Alexander Ku, Dan Newburger, et al. 2018. “[DeepVariant] A Universal SNP and Small-Indel Variant Caller Using Deep Neural Networks.” Nature Biotechnology 36 (10): 983–87. https://doi.org/10.1038/nbt.4235.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>NGS & Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch-p1-prs.html",
    "href": "ch-p1-prs.html",
    "title": "2  PRS & GWAS Basics",
    "section": "",
    "text": "2.1 The GWAS Paradigm\nGenome-wide association studies (GWAS) have transformed our understanding of the genetic architecture of complex traits and diseases. By testing millions of common genetic variants across large populations, GWAS identify single nucleotide polymorphisms (SNPs) statistically associated with phenotypes of interest. The NHGRI-EBI GWAS Catalog now contains tens of thousands of robust associations across hundreds of traits.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>PRS & GWAS Basics</span>"
    ]
  },
  {
    "objectID": "ch-p1-prs.html#the-gwas-paradigm",
    "href": "ch-p1-prs.html#the-gwas-paradigm",
    "title": "2  PRS & GWAS Basics",
    "section": "",
    "text": "2.1.1 Key Concepts\nEffect sizes and summary statistics: For each tested variant, GWAS produces summary statistics including:\n\nEffect size (β): The estimated change in phenotype per copy of the effect allele\nStandard error: Uncertainty in the effect estimate\nP-value: Statistical significance of the association\nAllele frequency: Population prevalence of the variant\n\nMost GWAS-identified variants have small individual effects—typically explaining less than 1% of phenotypic variance each—reflecting the highly polygenic nature of complex traits.\nLinkage disequilibrium (LD): Variants that are physically close on a chromosome tend to be inherited together, creating correlations in genotype data. This LD structure means that GWAS signals often implicate blocks of correlated variants rather than pinpointing causal variants directly. LD patterns vary substantially across populations due to different demographic histories, creating challenges for cross-ancestry analyses.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>PRS & GWAS Basics</span>"
    ]
  },
  {
    "objectID": "ch-p1-prs.html#the-fine-mapping-challenge",
    "href": "ch-p1-prs.html#the-fine-mapping-challenge",
    "title": "2  PRS & GWAS Basics",
    "section": "2.2 The Fine-Mapping Challenge",
    "text": "2.2 The Fine-Mapping Challenge\nA central challenge in post-GWAS analysis is distinguishing causal variants from those merely correlated with causal variants through LD. Fine-mapping methods attempt to resolve this by computing posterior inclusion probabilities (PIPs) for each variant being causal.\nStatistical fine-mapping approaches like SuSiE identify credible sets of variants likely to contain the causal variant (Avsec et al. 2021). For 48 well-powered traits in the UK Biobank, genome-wide fine-mapping identified causal variants collectively explaining 17% of SNP-based heritability, though reaching 50% would require approximately 2 million samples on average (Wu et al. 2024).\nThe majority of GWAS-identified variants are spuriously correlated with the phenotype through LD rather than being truly causal. Fine-mapping—predicting which variants are causal—is crucial for downstream tasks including uncovering biological mechanisms and constructing robust polygenic risk scores (Rakowski and Lippert 2025).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>PRS & GWAS Basics</span>"
    ]
  },
  {
    "objectID": "ch-p1-prs.html#constructing-polygenic-risk-scores",
    "href": "ch-p1-prs.html#constructing-polygenic-risk-scores",
    "title": "2  PRS & GWAS Basics",
    "section": "2.3 Constructing Polygenic Risk Scores",
    "text": "2.3 Constructing Polygenic Risk Scores\nPolygenic risk scores (PRS) aggregate the effects of many genetic variants into a single measure of an individual’s genetic predisposition to a trait or disease.\n\n2.3.1 Traditional PRS Methods\nClumping and thresholding (C+T): The simplest approach:\n\nSelect variants below a p-value threshold\n“Clump” correlated variants, keeping only the most significant per LD block\nSum effect sizes weighted by genotype dosage\n\nLDpred and Bayesian methods: More sophisticated approaches model the joint distribution of effect sizes while accounting for LD structure, typically improving prediction accuracy over C+T methods.\nLinear assumptions: Most PRS methods assume that variant effects:\n\nScale linearly with allele count (additive model)\nAre constant across individuals\nCombine additively across the genome\n\nWhile computationally convenient, these assumptions increase error, particularly for individuals from underrepresented populations (Georgantas, Kutalik, and Richiardi 2024).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>PRS & GWAS Basics</span>"
    ]
  },
  {
    "objectID": "ch-p1-prs.html#heritability-and-its-partitioning",
    "href": "ch-p1-prs.html#heritability-and-its-partitioning",
    "title": "2  PRS & GWAS Basics",
    "section": "2.4 Heritability and Its Partitioning",
    "text": "2.4 Heritability and Its Partitioning\nSNP-based heritability (\\(h^2_{SNP}\\)) estimates the proportion of phenotypic variance explained by all measured common variants. This is typically lower than family-based heritability estimates, a phenomenon termed “missing heritability.”\nLD Score Regression (LDSR) enables partitioning of heritability using only GWAS summary statistics. By correlating test statistics with LD scores, LDSR can estimate:\n\nTotal SNP heritability\nHeritability enrichment in functional annotations\nGenetic correlations between traits\n\nAnalysis of UK Biobank GWAS revealed that heritability partitions distinctly across regulatory sequence classes, with tissue-specific enhancers explaining substantial heritability for relevant traits—for example, monocyte/macrophage enhancers for monocyte count, and brain enhancers for cognitive traits (Chen et al. 2022).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>PRS & GWAS Basics</span>"
    ]
  },
  {
    "objectID": "ch-p1-prs.html#limitations-of-current-approaches",
    "href": "ch-p1-prs.html#limitations-of-current-approaches",
    "title": "2  PRS & GWAS Basics",
    "section": "2.5 Limitations of Current Approaches",
    "text": "2.5 Limitations of Current Approaches\n\n2.5.1 Ancestry Bias\nThe vast majority of GWAS have been conducted in populations of European ancestry. This creates systematic problems:\n\nReduced prediction accuracy: PRS derived from European GWAS perform substantially worse in non-European populations due to differences in LD structure and allele frequencies\nHealth disparities: Clinical deployment of ancestry-biased PRS could exacerbate existing health inequities\nMissed variants: Causal variants common in non-European populations but rare in Europeans may be missed entirely\n\n\n\n2.5.2 Missing Heritability\nSNP-based heritability estimates typically capture only 20-50% of family-based heritability, attributed to:\n\nRare variants: GWAS are underpowered to detect rare variant associations\nStructural variants: Most arrays and imputation panels miss copy number variants and other structural variation\nGene-gene interactions (epistasis): Standard additive models ignore non-linear interactions\nGene-environment interactions: Effects that depend on environmental context\n\n\n\n2.5.3 Mechanistic Opacity\nGWAS associations rarely identify causal genes or mechanisms directly:\n\nMost significant variants lie in non-coding regions\nThe nearest gene is often not the causal gene\nRegulatory effects may act over large genomic distances",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>PRS & GWAS Basics</span>"
    ]
  },
  {
    "objectID": "ch-p1-prs.html#the-promise-of-deep-learning",
    "href": "ch-p1-prs.html#the-promise-of-deep-learning",
    "title": "2  PRS & GWAS Basics",
    "section": "2.6 The Promise of Deep Learning",
    "text": "2.6 The Promise of Deep Learning\nThese limitations motivate the deep learning approaches covered in subsequent chapters. Sequence-based models can:\n\nPredict variant effects ab initio: Models like ExPecto and Enformer predict functional consequences from sequence alone, enabling prioritization of likely causal variants within LD blocks (Zhou et al. 2018; Avsec et al. 2021)\nImprove fine-mapping: Functional predictions can be integrated with statistical fine-mapping to improve causal variant identification. Hybrid CNN-transformer models like Borzoi show superior performance in identifying causal SNPs within LD blocks (Manzo, Borkowski, and Ovcharenko 2025)\nEnable cross-ancestry transfer: By learning functional effects from sequence rather than population-specific LD patterns, sequence models may generalize better across ancestries. Variants prioritized by sequence-based models construct PRS that transfer better to non-European target populations (Rakowski and Lippert 2025)\nCapture non-linear effects: Deep learning architectures can model complex, non-linear relationships between genotype and phenotype. Methods like Delphi relax linear assumptions to produce more predictive PRS, with relative improvements of 11-35% in variance explained across traits (Georgantas, Kutalik, and Richiardi 2024)\nIncorporate rare variants: Approaches like DeepRVAT learn gene impairment scores from rare variant annotations, facilitating refinement of PRS by accounting for rare variant effects that standard GWAS miss.\n\nThe chapters that follow trace the development of these capabilities, from early CNN-based regulatory prediction through modern transformer architectures that integrate long-range genomic context.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025. “Comparative Analysis of Deep Learning Models for Predicting Causative Regulatory Variants.” bioRxiv: The Preprint Server for Biology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[ExPecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>PRS & GWAS Basics</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html",
    "href": "ch-p1-cadd.html",
    "title": "3  Deleteriousness Scores",
    "section": "",
    "text": "3.1 The Variant Prioritization Challenge\nThe human genome harbors millions of genetic variants, the vast majority of which have unknown functional consequences. While Chapter 1 addressed distinguishing true variants from sequencing artifacts and Chapter 2 examined statistical association with phenotypes, a complementary challenge remains: predicting which variants are likely deleterious across the entire genome, including both coding and non-coding regions.\nTraditional approaches to variant prioritization suffer from critical limitations:\nCombined Annotation-Dependent Depletion (CADD) addresses these limitations through a fundamentally different approach: rather than training directly on known pathogenic variants, CADD learns to distinguish variants that survived evolutionary selection from those that did not (Rentzsch et al. 2019).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html#the-variant-prioritization-challenge",
    "href": "ch-p1-cadd.html#the-variant-prioritization-challenge",
    "title": "3  Deleteriousness Scores",
    "section": "",
    "text": "Single-feature scores: Most methods exploit a single information type (e.g., conservation) and cannot integrate diverse signals\nRestricted scope: Many tools focus exclusively on missense variants or specific genomic contexts\nTraining set bias: Supervised methods trained on ClinVar or HGMD pathogenic variants inherit biases toward well-studied genes and variant types",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html#the-evolutionary-proxy-training-strategy",
    "href": "ch-p1-cadd.html#the-evolutionary-proxy-training-strategy",
    "title": "3  Deleteriousness Scores",
    "section": "3.2 The Evolutionary Proxy Training Strategy",
    "text": "3.2 The Evolutionary Proxy Training Strategy\nCADD’s innovation lies in its training data construction. Rather than relying on curated pathogenic/benign labels—which are sparse, biased, and incomplete—CADD exploits evolutionary history as a proxy for deleteriousness.\n\n3.2.1 Proxy-Neutral Variants\nThe proxy-neutral training set consists of approximately 15 million SNVs and 1.8 million indels that are:\n\nHuman-derived: Present in modern humans but absent in the inferred human-ape ancestor genome\nFixed or nearly fixed: Allele frequency of 95–100% in human populations\n\nThese variants have persisted through millions of years of purifying selection since the human-chimpanzee divergence. By virtue of reaching fixation, they are overwhelmingly neutral or at most weakly deleterious—strong deleterious effects would have been purged by natural selection.\n\n\n3.2.2 Proxy-Deleterious Variants\nThe proxy-deleterious set is generated through simulation, matching the sequence composition, substitution frequencies, and local mutation rate patterns of the proxy-neutral variants. These simulated “de novo” variants are free from selective pressure—they represent the full spectrum of possible mutations, including those that would be deleterious in a real genome.\nWhile many simulated variants are indeed neutral, an unknown but substantial fraction would be harmful if they occurred in an individual. The key insight is that the relative enrichment of deleterious variants differs systematically between the two sets: proxy-neutral variants are depleted for deleterious alleles, while proxy-deleterious variants contain a representative sample.\n\n\n3.2.3 Training Objective\nA machine learning classifier trained to distinguish proxy-neutral from proxy-deleterious variants effectively learns which annotation features characterize variants likely to be “observed” (survived selection) versus “simulated” (potentially deleterious). Higher CADD scores indicate variants more similar to the simulated set—and thus more likely to have functional consequences.\nThis approach provides several advantages over pathogenicity-based training:\n\n\n\nAspect\nCADD Approach\nPathogenicity Training\n\n\n\n\nTraining set size\n~30 million variants\nThousands of variants\n\n\nGenome coverage\nAll regions equally\nBiased toward coding\n\n\nGene bias\nMinimal\nConcentrated in disease genes\n\n\nVariant type bias\nMinimal\nBiased toward missense",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html#integration-of-diverse-annotations",
    "href": "ch-p1-cadd.html#integration-of-diverse-annotations",
    "title": "3  Deleteriousness Scores",
    "section": "3.3 Integration of Diverse Annotations",
    "text": "3.3 Integration of Diverse Annotations\nCADD’s strength derives from integrating more than 60 distinct genomic annotations into a unified framework. These annotations span multiple categories:\n\n3.3.1 Gene Model Annotations\nEnsembl Variant Effect Predictor (VEP) provides consequence predictions including:\n\nTranscript location (exon, intron, UTR, intergenic)\nProtein-coding effects (synonymous, missense, nonsense, frameshift)\nDistance to splice sites and transcript features\nAmino acid properties for missense variants\n\n\n\n3.3.2 Conservation and Constraint\nMultiple evolutionary conservation scores capture selective pressure across different timescales:\n\nPhyloP: Position-specific conservation across 46 vertebrate species\nPhastCons: Probability of negative selection estimated from multiple alignments\nGERP++: Rejected substitution scores indicating purifying selection\nGerpN/GerpS: Neutral evolution and constrained element scores\n\n\n\n3.3.3 Epigenetic and Regulatory Activity\nData from ENCODE and NIH Roadmap Epigenomics provide chromatin state information:\n\nDNase I hypersensitivity\nHistone modifications (H3K4me1, H3K4me3, H3K27ac, etc.)\nTranscription factor binding sites\nChromatin accessibility across cell types\n\n\n\n3.3.4 Additional Features\n\nCpG dinucleotide context and mutation rates\nSequence properties (GC content, repeat regions)\nPopulation genetics metrics (allele frequency distributions)\nProtein domain annotations",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html#model-architecture-and-scoring",
    "href": "ch-p1-cadd.html#model-architecture-and-scoring",
    "title": "3  Deleteriousness Scores",
    "section": "3.4 Model Architecture and Scoring",
    "text": "3.4 Model Architecture and Scoring\n\n3.4.1 Machine Learning Framework\nCADD v1.0 employed a support vector machine (SVM) with a linear kernel. Subsequent versions transitioned to logistic regression, which provides:\n\nFaster training and inference\nInterpretable feature weights\nEfficient handling of crossed features\n\nTo capture non-linear relationships between annotations, CADD creates crossed feature annotations—for example, combining conservation scores with consequence labels to allow the model to weight conservation differently for missense versus synonymous variants.\n\n\n3.4.2 PHRED-Scaled Scores\nRaw CADD scores are difficult to interpret across genomic contexts. To enable meaningful comparisons, CADD transforms raw scores into PHRED-like scaled scores based on genome-wide rank:\n\\[\\text{CADD}_\\text{PHRED} = -10 \\cdot \\log_{10}\\left(\\frac{\\text{rank}}{N}\\right)\\]\nwhere \\(N\\) ≈ 9 billion represents all possible single nucleotide substitutions in the reference genome. A CADD score of 10 indicates the variant is in the top 10% most deleterious; a score of 20 indicates the top 1%; a score of 30 indicates the top 0.1%.\nThis scaling provides intuitive interpretation: CADD 15–20 typically indicates likely functional variants, while CADD &gt; 30 suggests strong deleteriousness.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html#cadd-v1.7-integration-of-deep-learning-predictions",
    "href": "ch-p1-cadd.html#cadd-v1.7-integration-of-deep-learning-predictions",
    "title": "3  Deleteriousness Scores",
    "section": "3.5 CADD v1.7: Integration of Deep Learning Predictions",
    "text": "3.5 CADD v1.7: Integration of Deep Learning Predictions\nThe most recent CADD release (v1.7) demonstrates how the annotation integration framework can incorporate predictions from deep learning models (Schubach et al. 2024). This represents a bridge between traditional annotation-based approaches and the sequence-to-function models covered in subsequent chapters.\n\n3.5.1 Protein Language Model Features\nCADD v1.7 incorporates scores from Meta ESM-1v, a protein language model trained on millions of protein sequences. ESM-1v provides:\n\nPer-residue fitness predictions based on evolutionary plausibility\nImproved missense variant prioritization\nContext-aware amino acid substitution scoring\n\nThese features substantially improve CADD’s performance on coding variants, particularly for missense mutations in conserved protein regions.\n\n\n3.5.2 Regulatory CNN Predictions\nFor non-coding variants, CADD v1.7 integrates predictions from a custom convolutional neural network trained on regions of open chromatin. This model:\n\nPredicts regulatory activity from DNA sequence\nProvides variant effect scores for regulatory elements\nCaptures sequence patterns associated with transcription factor binding\n\n\n\n3.5.3 Extended Conservation Scores\nThe Zoonomia project’s alignment of &gt;240 mammalian genomes provides deeper evolutionary context through:\n\nBroader phylogenetic sampling\nImproved resolution of constrained elements\nBetter detection of lineage-specific selection\n\n\n\n3.5.4 Performance Improvements\nEvaluation on multiple benchmarks demonstrates consistent gains:\n\n\n\nBenchmark\nCADD v1.6\nCADD v1.7\nImprovement\n\n\n\n\nClinVar pathogenic vs. common\n0.94\n0.95\n+1%\n\n\nDeep mutational scanning (31 datasets)\n0.78\n0.81\n+3%\n\n\nRegulatory saturation mutagenesis\n0.68\n0.72\n+4%\n\n\n\nThe regulatory variant improvements are particularly notable, as this has historically been CADD’s weakest domain.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html#benchmarking-against-alternative-approaches",
    "href": "ch-p1-cadd.html#benchmarking-against-alternative-approaches",
    "title": "3  Deleteriousness Scores",
    "section": "3.6 Benchmarking Against Alternative Approaches",
    "text": "3.6 Benchmarking Against Alternative Approaches\nCADD’s genome-wide applicability allows direct comparison with specialized scores:\n\n3.6.1 Coding Variants\nFor missense variant classification separating ClinVar pathogenic from high-frequency ExAC variants, CADD performs comparably to dedicated tools like PolyPhen-2 and PROVEAN while maintaining broader applicability. The integration of ESM-1v features in v1.7 further improves coding variant prediction.\n\n\n3.6.2 Non-coding Variants\nCADD demonstrates strong performance on regulatory variants, though recent benchmarks suggest functional-genomics-supervised models like Enformer and Borzoi may perform better for certain variant classes. Interestingly, alignment-based models including CADD and GPN-MSA compare favorably for Mendelian and complex disease traits, while expression-predicting models excel for complex non-disease traits (Benegas, Eraslan, and Song 2025).\n\n\n3.6.3 Population Frequency Correlation\nA key validation of CADD’s evolutionary proxy approach is the strong inverse correlation between CADD scores and population allele frequency. Higher-scoring variants are systematically rarer in population databases like gnomAD, consistent with purifying selection removing deleterious alleles—the same principle underlying the training strategy.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-cadd.html#significance-for-genomic-deep-learning",
    "href": "ch-p1-cadd.html#significance-for-genomic-deep-learning",
    "title": "3  Deleteriousness Scores",
    "section": "3.7 Significance for Genomic Deep Learning",
    "text": "3.7 Significance for Genomic Deep Learning\nCADD established several important paradigms that inform the deep learning approaches covered in subsequent chapters:\n\nAnnotation integration: The principle of combining multiple information sources into unified predictions extends naturally to multi-headed neural network architectures that jointly predict diverse genomic features.\nEvolutionary training signals: Using evolutionary conservation as a proxy for function—rather than curated pathogenicity labels—avoids biases and provides genome-wide coverage. This approach reappears in protein language models and genomic foundation models.\nGenome-wide applicability: CADD demonstrated that a single framework could score any variant anywhere in the genome, setting expectations for the comprehensive coverage that sequence-to-function models now achieve.\nContinuous improvement through feature addition: The progression from CADD v1.0 to v1.7 shows how deep learning predictions can be incorporated as features into existing frameworks, providing a practical integration path.\n\nThe chapters that follow trace how deep learning models moved from providing features to CADD-like integrators toward directly predicting variant effects from DNA sequence—learning the regulatory grammar that explains why evolutionary conservation patterns emerge.\n\n\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html",
    "href": "ch-p1-data.html",
    "title": "4  Foundational Genomics Data",
    "section": "",
    "text": "4.1 Functional Genomics Data\nThe preceding chapters established methods for identifying genetic variants (Chapter 1), associating them with phenotypes (Chapter 2), and scoring their likely deleteriousness (Chapter 3). These approaches and the deep learning models that follow depend on large-scale public data resources spanning chromatin profiling, population genetics, clinical variant databases, expression atlases, biobanks, and experimental benchmarks.\nThis chapter surveys the foundational data resources that underpin modern genomic machine learning. These datasets serve multiple roles: training targets for supervised models, validation benchmarks for variant effect prediction, and population references for interpreting rare variants.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#chromatin-profiling-encode-and-roadmap-epigenomics",
    "href": "ch-p1-data.html#chromatin-profiling-encode-and-roadmap-epigenomics",
    "title": "4  Foundational Genomics Data",
    "section": "4.2 Chromatin Profiling: ENCODE and Roadmap Epigenomics",
    "text": "4.2 Chromatin Profiling: ENCODE and Roadmap Epigenomics\nThe ENCODE (Encyclopedia of DNA Elements) (Kagda et al. 2025) and Roadmap Epigenomics consortia generated genome-wide profiles of regulatory activity across hundreds of cell types, providing both biological insight and training data for sequence-to-function models.\n\n4.2.1 Data Types and Scale\n\n\n\n\n\n\n\n\n\nAssay\nTarget\nENCODE Coverage\nRoadmap Coverage\n\n\n\n\nDNase-seq / ATAC-seq\nOpen chromatin\n684 datasets\n53 samples\n\n\nChIP-seq (TF)\nTranscription factor binding\n2,131 datasets\n—\n\n\nChIP-seq (histone)\nHistone modifications\n1,860 datasets\n127 samples\n\n\nCAGE\nTranscription start sites\n638 datasets\n—\n\n\n\nThe Cistrome Project systematically reprocesses public ChIP-seq data, contributing ~20,000 profiles that supplement ENCODE (Zheng et al. 2019). Combined, these resources enable models like Sei to predict 21,907 chromatin targets across &gt;1,300 cell types (Chen et al. 2022).\n\n\n4.2.2 Key Histone Modifications\nHistone modifications mark distinct regulatory states:\n\nH3K4me3: Active promoters\nH3K4me1 + H3K27ac: Active enhancers\nH3K4me1 + H3K27me3: Poised/bivalent enhancers\nH3K27me3: Polycomb-repressed regions\nH3K9me3: Constitutive heterochromatin\n\nThese combinatorial patterns define the training targets for models including DeepSEA, ExPecto, and Enformer (Chapters 5, 6, and 11).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#population-genetics-resources",
    "href": "ch-p1-data.html#population-genetics-resources",
    "title": "4  Foundational Genomics Data",
    "section": "4.3 Population Genetics Resources",
    "text": "4.3 Population Genetics Resources\n\n4.3.1 gnomAD\nThe Genome Aggregation Database (gnomAD) aggregates exome and genome sequencing data from large-scale projects, providing allele frequencies and constraint metrics essential for variant interpretation.\nCurrent scale: gnomAD v4 includes &gt;800,000 exomes and &gt;76,000 genomes spanning diverse global populations.\nKey applications for deep learning:\n\nAllele frequency filtering: Rare variants (AF &lt; 0.01%) are enriched for functional effects; common variants have largely survived purifying selection\nConstraint metrics: pLI (probability of loss-of-function intolerance) and LOEUF (loss-of-function observed/expected upper bound fraction) quantify selective pressure on genes\nTraining signal: CADD’s evolutionary proxy approach uses allele frequency distributions to validate that predicted deleterious variants are depleted from the population (Rentzsch et al. 2019)\n\n\n\n4.3.2 1000 Genomes Project\nThe 1000 Genomes Project catalogued genetic variation across 26 populations, providing:\n\nReference panel for genotype imputation\nLD structure for fine-mapping and PRS construction\nBenchmarking variants for sequence models (e.g., Sei variant effect analyses use 1000 Genomes SNPs) (Chen et al. 2022)",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#clinical-variant-databases",
    "href": "ch-p1-data.html#clinical-variant-databases",
    "title": "4  Foundational Genomics Data",
    "section": "4.4 Clinical Variant Databases",
    "text": "4.4 Clinical Variant Databases\n\n4.4.1 ClinVar\nClinVar is the primary public archive for clinically interpreted genetic variants, aggregating submissions from clinical laboratories, research groups, and expert panels.\nContent: &gt;2.5 million variant submissions covering pathogenic, likely pathogenic, benign, likely benign, and variants of uncertain significance (VUS).\nRole in model development:\n\nBenchmarking: ClinVar pathogenic/benign classifications provide standard evaluation sets for variant effect predictors. CADD v1.7 reports ~1% improvement on ClinVar variants compared to previous versions (Schubach et al. 2024).\nTraining labels: Some supervised approaches use ClinVar annotations as training targets, though this risks circularity if evaluated on the same database.\n\nLimitations: Ascertainment bias toward well-studied genes; classification criteria vary across submitters; benign variants are underrepresented relative to pathogenic.\n\n\n4.4.2 HGMD\nThe Human Gene Mutation Database provides curated disease-causing mutations, though access requires subscription. HGMD’s “regulatory” category has been used to benchmark non-coding variant effect predictions (Chen et al. 2022).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#expression-resources",
    "href": "ch-p1-data.html#expression-resources",
    "title": "4  Foundational Genomics Data",
    "section": "4.5 Expression Resources",
    "text": "4.5 Expression Resources\n\n4.5.1 GTEx\nThe Genotype-Tissue Expression (GTEx) project provides RNA-seq expression profiles and eQTL maps across 54 human tissues from ~1,000 donors.\nKey applications:\n\neQTL validation: Signed linkage disequilibrium profile (SLDP) regression tests whether model-predicted variant effects correlate with measured expression changes. Enformer showed improved SLDP Z-scores relative to Basenji2 across GTEx tissues (Avsec et al. 2021).\nTissue-specific expression: Enhancer sequence class scores correlate with tissue-specific gene expression in corresponding tissues (Chen et al. 2022).\nCross-ancestry analysis: GTEx’s population diversity enables evaluation of model generalization.\n\n\n\n4.5.2 FANTOM\nThe FANTOM consortium’s CAGE atlas maps transcription start sites at single-nucleotide resolution across hundreds of human and mouse samples. CAGE data serve as direct training targets for expression-predicting models—Enformer predicts 638 CAGE tracks, enabling TSS-level activity predictions (Avsec et al. 2021).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#biobank-resources",
    "href": "ch-p1-data.html#biobank-resources",
    "title": "4  Foundational Genomics Data",
    "section": "4.6 Biobank Resources",
    "text": "4.6 Biobank Resources\nLarge-scale biobanks linking genomic data to electronic health records and phenotypic measurements are transforming genetic research. These resources enable GWAS discovery, PRS development, and validation of variant effect predictions at population scale.\n\n4.6.1 UK Biobank\nThe UK Biobank enrolled ~500,000 participants aged 40–69 from across the United Kingdom, with comprehensive phenotyping and genomic data.\nData available:\n\nGenotyping array data (all participants)\nWhole exome sequencing (~470,000 participants)\nWhole genome sequencing (~500,000 participants)\nElectronic health records, imaging, and extensive phenotypic measurements\n\nApplications: UK Biobank GWAS summary statistics are used for heritability partitioning by sequence classes, revealing trait-specific regulatory architectures (Chen et al. 2022). Genome-wide fine-mapping of 48 UK Biobank traits identified causal variants explaining 17% of SNP-based heritability (Wu et al. 2024).\n\n\n4.6.2 All of Us Research Program\nThe NIH All of Us Research Program aims to enroll one million diverse US participants, with explicit emphasis on historically underrepresented populations.\nCurrent scale: &gt;245,000 whole genome sequences, with ~45% from participants identifying with underrepresented racial or ethnic groups. The dataset includes &gt;1 billion genetic variants, including &gt;275 million previously unreported variants.\nUnique features:\n\nDiversity: 77% of participants are from communities historically underrepresented in biomedical research\nLongitudinal EHR: Linked electronic health records with median 10+ years of data for many participants\nMulti-modal data: Surveys, physical measurements, Fitbit wearable data, and genomics\nRapid access: Researcher Workbench enables data access with median 29 hours from registration\n\nAll of Us addresses a critical gap: over 90% of participants in prior large genomics studies were of European descent, limiting generalizability of findings and perpetuating health disparities.\n\n\n4.6.3 Mayo Clinic Tapestry\nThe Tapestry study represents Mayo Clinic’s largest genomics initiative, combining clinical exome sequencing with longitudinal EHR linkage.\nScale: &gt;98,000 enrolled participants with Exome+ sequencing (whole exome plus ~300,000 informative non-coding SNPs).\nClinical integration: Unlike research-only biobanks, Tapestry returns actionable results directly to participants and their providers:\n\n1.9% of participants carry pathogenic/likely pathogenic variants in CDC Tier 1 genes\nResults for BRCA1/2 (hereditary breast/ovarian cancer), Lynch syndrome genes, and familial hypercholesterolemia genes are entered into EHRs\n\nResearch access: &gt;62,000 participants’ exome data are available for research, with 82 approved investigator requests delivering &gt;1.1 million datasets.\n\n\n4.6.4 Comparative Summary\n\n\n\nBiobank\nParticipants\nSequencing\nDiversity\nEHR Linked\n\n\n\n\nUK Biobank\n~500,000\nWGS + WES\nPrimarily European\nYes\n\n\nAll of Us\n&gt;245,000 WGS\nWGS\n45% underrepresented\nYes\n\n\nMayo Tapestry\n~98,000\nExome+\n~11% underrepresented\nYes",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#experimental-benchmarks",
    "href": "ch-p1-data.html#experimental-benchmarks",
    "title": "4  Foundational Genomics Data",
    "section": "4.7 Experimental Benchmarks",
    "text": "4.7 Experimental Benchmarks\n\n4.7.1 Deep Mutational Scanning\nDeep mutational scanning (DMS) experiments systematically measure the functional effects of thousands of variants in a single assay, providing gold-standard labels for benchmarking variant effect predictors.\nProteinGym: A comprehensive benchmark aggregating DMS data across 217 assays covering diverse proteins. CADD v1.7 reports ~3% improvement on DMS datasets with integration of ESM-1v protein language model scores (Schubach et al. 2024).\nMaveDB: The Multiplexed Assays of Variant Effect Database archives functional scores from MAVE experiments, enabling standardized model evaluation.\nCAGI: The Critical Assessment of Genome Interpretation organizes blinded prediction challenges using experimental data, including saturation mutagenesis of regulatory elements.\n\n\n4.7.2 TraitGym\nTraitGym provides curated regulatory variant benchmarks for evaluating causal variant prediction across Mendelian and complex traits (Benegas, Eraslan, and Song 2025).\nDataset composition:\n\n113 Mendelian traits with known or high-confidence causal regulatory variants\n83 complex traits with fine-mapped candidate causal variants\nCarefully constructed control variants matched for genomic context\n\nKey findings: Alignment-based models (CADD, GPN-MSA) perform favorably for Mendelian and complex disease traits, while functional-genomics-supervised models (Enformer, Borzoi) excel for complex non-disease traits. This suggests complementary information captured by evolutionary constraint versus molecular phenotype prediction.\nTraitGym addresses a critical gap: the field has lacked consistently curated datasets with accurate labels for non-coding variants, making comprehensive benchmarking difficult.\n\n\n4.7.3 Massively Parallel Reporter Assays\nMPRAs test thousands of regulatory sequences in parallel, measuring their ability to drive reporter gene expression. MPRA data from saturation mutagenesis experiments serve as benchmarks for regulatory variant effect prediction—CADD v1.7 shows ~4% improvement on regulatory saturation mutagenesis data (Schubach et al. 2024).",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#data-quality-considerations",
    "href": "ch-p1-data.html#data-quality-considerations",
    "title": "4  Foundational Genomics Data",
    "section": "4.8 Data Quality Considerations",
    "text": "4.8 Data Quality Considerations\n\n4.8.1 Technical Artifacts\nFunctional genomics data contain systematic biases affecting model training:\n\nBatch effects: Technical variation between experiments\nAntibody specificity: ChIP-seq quality depends on antibody performance\nPeak calling thresholds: Binary calls from continuous signals involve arbitrary cutoffs\nCell line artifacts: Immortalized lines may not reflect primary tissue biology\n\n\n\n4.8.2 Ascertainment Bias\nClinical databases and biobanks exhibit ascertainment biases:\n\nClinVar is enriched for variants in well-studied disease genes\nBiobanks may oversample certain demographics or health-seeking populations\nBenign variants are systematically underrepresented in clinical databases\n\n\n\n4.8.3 Population Structure\nAncestry-specific allele frequencies and LD patterns affect model generalization:\n\nPRS developed in European populations transfer poorly to other ancestries\nRare variant interpretation depends on population-matched frequency data\nInitiatives like All of Us explicitly address historical underrepresentation",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p1-data.html#from-data-to-models",
    "href": "ch-p1-data.html#from-data-to-models",
    "title": "4  Foundational Genomics Data",
    "section": "4.9 From Data to Models",
    "text": "4.9 From Data to Models\nThe resources described in this chapter enable the supervised learning framework underlying sequence-to-function models:\n\nChromatin profiles (ENCODE, Roadmap) → Training targets for predicting regulatory activity from sequence\nPopulation genetics (gnomAD, 1000 Genomes) → Evolutionary signal for constraint-based scoring\nClinical databases (ClinVar) → Benchmarking pathogenic variant detection\nExpression data (GTEx, FANTOM) → Validation of predicted expression effects\nBiobanks (UK Biobank, All of Us, Tapestry) → GWAS discovery and phenotype prediction\nExperimental benchmarks (DMS, TraitGym, MPRA) → Ground-truth functional measurements\n\nThe chapters that follow trace how deep learning models leverage these resources: CNNs learning to predict chromatin profiles (DeepSEA, Chapter 5), connecting predictions to expression (ExPecto, Chapter 6), and integrating long-range interactions (Enformer, Chapter 11).\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nKagda, Meenakshi S., Bonita Lam, Casey Litton, Corinn Small, Cricket A. Sloan, Emma Spragins, Forrest Tanaka, et al. 2025. “Data Navigation on the ENCODE Portal.” Nature Communications 16 (1): 9592. https://doi.org/10.1038/s41467-025-64343-9.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nZheng, Rongbin, Changxin Wan, Shenglin Mei, Qian Qin, Qiu Wu, Hanfei Sun, Chen-Hao Chen, et al. 2019. “Cistrome Data Browser: Expanded Datasets and New Tools for Gene Regulatory Analysis.” Nucleic Acids Research 47 (D1): D729–35. https://doi.org/10.1093/nar/gky1094.",
    "crumbs": [
      "Part I: Data & Pre-DL Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html",
    "href": "ch-p2-reg.html",
    "title": "5  Regulatory Prediction",
    "section": "",
    "text": "5.1 The Noncoding Variant Challenge\nThe vast majority of disease-associated variants identified by GWAS lie in noncoding regions of the genome. Yet in 2015, the field lacked systematic methods to predict how these variants affect gene regulation. Existing approaches relied on overlap with known annotations—if a variant fell within a ChIP-seq peak or DNase hypersensitive site, it might be flagged as potentially functional. But this strategy offered no mechanism for predicting the direction or magnitude of effect, and it could not score variants in regions lacking experimental coverage.\nDeepSEA, introduced by Zhou and Troyanskaya in 2015, fundamentally changed this paradigm by learning to predict chromatin features directly from DNA sequence (Zhou and Troyanskaya 2015). Rather than asking “does this variant overlap a known regulatory element?”, DeepSEA asks “what regulatory activities does this sequence encode, and how would a mutation change them?”",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html#the-core-innovation-learning-regulatory-code-from-sequence",
    "href": "ch-p2-reg.html#the-core-innovation-learning-regulatory-code-from-sequence",
    "title": "5  Regulatory Prediction",
    "section": "5.2 The Core Innovation: Learning Regulatory Code from Sequence",
    "text": "5.2 The Core Innovation: Learning Regulatory Code from Sequence\nDeepSEA’s central insight was that deep convolutional networks could learn the sequence patterns underlying regulatory activity without explicit feature engineering. Previous methods like gapped k-mer SVMs (gkm-SVM) required defining sequence features a priori—specifying which k-mers to count and how to weight them. DeepSEA instead learned relevant sequence features automatically from data.\n\n5.2.1 Architecture\nThe original DeepSEA architecture comprised:\n\nInput layer: 1000 bp DNA sequence, one-hot encoded (4 channels × 1000 positions)\nThree convolutional layers: Each followed by ReLU activation and max pooling, learning increasingly abstract sequence features\nFully connected layer: Integrating learned features across the sequence\nOutput layer: 919 sigmoid outputs predicting chromatin profile probabilities\n\nThe convolutional layers function analogously to motif scanners, but with crucial differences: they learn motifs from data rather than requiring predefined position weight matrices, and deeper layers can learn combinations of motifs (regulatory “grammar”) rather than just individual binding sites.\n\n\n5.2.2 Training Data\nDeepSEA was trained on 919 chromatin profiles from ENCODE and Roadmap Epigenomics:\n\n\n\nProfile Type\nCount\nExamples\n\n\n\n\nTranscription factor binding\n690\nCTCF, p53, GATA1\n\n\nHistone modifications\n104\nH3K4me3, H3K27ac\n\n\nDNase I hypersensitivity\n125\nOpen chromatin across cell types\n\n\n\nFor each 1000 bp sequence, the model predicts the probability that the central 200 bp region exhibits each chromatin feature. Training used sequences from the human genome with chromosome 8 held out for testing.\n\n\n5.2.3 Multi-Task Learning\nA key architectural decision was predicting all 919 features simultaneously rather than training separate models. This multi-task learning approach offers several advantages:\n\nShared representations: Early convolutional layers learn general sequence features (e.g., GC content, common motifs) useful across tasks\nRegularization: Jointly predicting correlated features prevents overfitting to any single task\nEfficiency: One model serves all prediction tasks",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html#predicting-variant-effects",
    "href": "ch-p2-reg.html#predicting-variant-effects",
    "title": "5  Regulatory Prediction",
    "section": "5.3 Predicting Variant Effects",
    "text": "5.3 Predicting Variant Effects\nDeepSEA enables variant effect prediction through a straightforward procedure: predict chromatin profiles for both reference and alternative allele sequences, then compute the difference. This produces a 919-dimensional vector describing how the variant is predicted to alter regulatory activity across all profiled features.\n\n5.3.1 Single-Nucleotide Sensitivity\nThe model achieves single-nucleotide sensitivity—changing one base can substantially alter predictions. This was validated using allelic imbalance data from digital genomic footprinting. For 57,407 variants showing allele-specific DNase I sensitivity across 35 cell types, DeepSEA predictions correlated strongly with the experimentally observed allelic bias.\n\n\n5.3.2 In Silico Saturation Mutagenesis\nBy systematically predicting effects of all possible single-nucleotide substitutions within a sequence, DeepSEA enables “in silico saturation mutagenesis” (ISM). This computational experiment reveals which positions are most critical for regulatory function—equivalent to a CRISPR tiling screen, but performed entirely computationally.\nISM analysis of regulatory elements reveals sequence positions where mutations would most strongly perturb function, often corresponding to transcription factor binding motifs learned by the model.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html#functional-variant-prioritization",
    "href": "ch-p2-reg.html#functional-variant-prioritization",
    "title": "5  Regulatory Prediction",
    "section": "5.4 Functional Variant Prioritization",
    "text": "5.4 Functional Variant Prioritization\nBeyond predicting chromatin effects, DeepSEA introduced a framework for prioritizing likely functional variants among large sets of candidates.\n\n5.4.1 eQTL Prioritization\nExpression quantitative trait loci (eQTLs) represent variants associated with gene expression changes. However, most eQTL signals reflect linkage disequilibrium rather than causal variants. DeepSEA demonstrated improved ability to distinguish true eQTLs from nearby non-causal variants compared to overlap-based methods.\n\n\n5.4.2 GWAS Variant Prioritization\nSimilarly, for GWAS-identified disease associations, DeepSEA helped prioritize which variants in LD blocks were most likely causal. The model outperformed contemporary methods including GWAVA (which was trained on known regulatory mutations) on held-out benchmarks.\n\n\n5.4.3 Comparison to Prior Methods\nDeepSEA’s performance advantage over gkm-SVM was particularly notable for transcription factor binding prediction:\n\nDeep CNN achieved higher AUC for nearly all transcription factors\ngkm-SVM showed no improvement with increased context sequence length\nDeepSEA performance improved substantially with context (200 bp → 500 bp → 1000 bp)\n\nThis demonstrated that the deep learning architecture could exploit longer-range sequence context that simpler models could not capture.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html#evolution-of-the-deepsea-framework",
    "href": "ch-p2-reg.html#evolution-of-the-deepsea-framework",
    "title": "5  Regulatory Prediction",
    "section": "5.5 Evolution of the DeepSEA Framework",
    "text": "5.5 Evolution of the DeepSEA Framework\nThe original DeepSEA established the sequence-to-chromatin prediction paradigm. Subsequent work from the same group expanded and refined this approach.\n\n5.5.1 DeepSEA Beluga (2018)\nExPecto, published in 2018, included an updated chromatin prediction model nicknamed “Beluga” (Zhou et al. 2018). Key improvements included:\n\nExpanded prediction targets: 2,002 chromatin profiles (up from 919)\nDeeper architecture: Additional convolutional layers with residual connections\nLarger context: 2000 bp input sequences\nIntegration with expression prediction: Chromatin predictions serve as intermediate features for tissue-specific expression prediction (Chapter 6)\n\n\n\n5.5.2 Sei (2022)\nSei represents the current state of the DeepSEA lineage, predicting 21,907 chromatin profiles—a 24-fold expansion over the original (Chen et al. 2022). Architectural innovations include:\n\nDual linear/nonlinear paths: Parallel convolution blocks, one with activation functions and one without, allowing the model to learn both complex nonlinear patterns and simpler linear relationships\nDilated convolutions: Expanding receptive field without reducing spatial resolution\nSpatial basis functions: Memory-efficient integration of information across positions\n\nSei improved over Beluga by 19% on average (measured by AUROC/(1-AUROC)) on the 2,002 profiles predicted by both models.\n\n\n\nModel\nYear\nChromatin Targets\nInput Length\nArchitecture\n\n\n\n\nDeepSEA\n2015\n919\n1000 bp\n3 conv + FC\n\n\nBeluga\n2018\n2,002\n2000 bp\nDeep residual CNN\n\n\nSei\n2022\n21,907\n4000 bp\nDual-path + dilated conv",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html#what-deepsea-learns",
    "href": "ch-p2-reg.html#what-deepsea-learns",
    "title": "5  Regulatory Prediction",
    "section": "5.6 What DeepSEA Learns",
    "text": "5.6 What DeepSEA Learns\n\n5.6.1 Motif Discovery\nAnalysis of DeepSEA’s convolutional filters reveals learned sequence patterns corresponding to known transcription factor binding motifs. First-layer filters often match canonical motifs from databases like JASPAR, while deeper layers capture more complex patterns including motif combinations.\n\n\n5.6.2 Regulatory Grammar\nBeyond individual motifs, DeepSEA implicitly learns aspects of regulatory “grammar”—the rules governing how motifs combine to produce regulatory activity. This includes:\n\nMotif spacing: Some TF pairs require specific distances between binding sites\nMotif orientation: Directionality of certain motifs affects function\nCombinatorial logic: Multiple weak motifs can synergize, or compete through overlapping sites\n\nHowever, the original DeepSEA architecture’s limited receptive field (due to pooling operations) constrained its ability to learn long-range dependencies. This limitation motivated later architectures with expanded context windows (Enformer, Chapter 11).",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html#limitations-and-considerations",
    "href": "ch-p2-reg.html#limitations-and-considerations",
    "title": "5  Regulatory Prediction",
    "section": "5.7 Limitations and Considerations",
    "text": "5.7 Limitations and Considerations\n\n5.7.1 Cell Type Specificity\nDeepSEA predicts chromatin profiles for specific cell types included in training, but the same sequence may have different regulatory activity in cell types not represented. The model cannot predict activity in novel cell types without relevant training data.\n\n\n5.7.2 Context Independence\nThe model treats each input sequence independently, without considering:\n\n3D chromatin structure (which brings distant sequences into proximity)\nCurrent transcriptional state (which affects chromatin accessibility)\nOther variants in the same individual (epistasis)\n\n\n\n5.7.3 Quantitative Accuracy\nWhile DeepSEA accurately predicts binary presence/absence of chromatin features, quantitative predictions of signal strength are less reliable. Later models like Basenji addressed this by predicting continuous coverage rather than binary peaks.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-reg.html#significance-for-the-field",
    "href": "ch-p2-reg.html#significance-for-the-field",
    "title": "5  Regulatory Prediction",
    "section": "5.8 Significance for the Field",
    "text": "5.8 Significance for the Field\nDeepSEA established several paradigms that shaped subsequent genomic deep learning:\n\nSequence-in, function-out: Learning regulatory activity directly from sequence without hand-engineered features\nMulti-task chromatin prediction: Jointly modeling many related tasks improves both performance and efficiency\nVariant effect prediction via comparison: Score variants by comparing predictions for reference and alternative alleles\nAb initio prediction: Make predictions for any sequence, including novel mutations never observed in training data\n\nThe approach demonstrated that deep learning could extract biologically meaningful patterns from raw sequence data at scale. This opened the door to increasingly sophisticated sequence-to-function models—predicting not just chromatin state, but gene expression (ExPecto, Chapter 6), splicing (SpliceAI, Chapter 7), and eventually long-range regulatory interactions (Enformer, Chapter 11).\nDeepSEA’s public web server (http://deepsea.princeton.edu/) and code release also established a model for making genomic deep learning tools accessible to the broader research community—a practice that has become standard in the field.\n\n\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[ExPecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html",
    "href": "ch-p2-transc.html",
    "title": "6  Transcriptional Effects",
    "section": "",
    "text": "6.1 From Chromatin to Expression\nDeepSEA (Chapter 5) demonstrated that deep learning could predict chromatin features from DNA sequence alone. Yet chromatin accessibility and transcription factor binding are intermediate phenotypes—the ultimate functional readout for most regulatory variants is their effect on gene expression. A variant might disrupt a transcription factor binding site, but does that binding site actually regulate a nearby gene? In which tissues? By how much?\nExPecto, introduced by Zhou et al. in 2018, addressed these questions by extending the sequence-to-chromatin paradigm to predict tissue-specific gene expression levels (Zhou et al. 2018). The framework’s name reflects its core capability: Expression prediction. Rather than stopping at chromatin predictions, ExPecto integrates predicted regulatory signals across a 40 kb promoter-proximal region to predict absolute expression levels in 218 tissues and cell types.\nCritically, ExPecto predicts expression effects ab initio from sequence—without training on any variant data. This enables scoring of rare variants, de novo mutations, and even hypothetical mutations never observed in any population.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#the-modular-architecture",
    "href": "ch-p2-transc.html#the-modular-architecture",
    "title": "6  Transcriptional Effects",
    "section": "6.2 The Modular Architecture",
    "text": "6.2 The Modular Architecture\nExPecto comprises three sequential components, each addressing a distinct computational challenge.\n\n6.2.1 Component 1: Epigenomic Effects Model (Beluga CNN)\nThe first component is an enhanced version of DeepSEA, predicting 2,002 chromatin profiles (histone marks, transcription factor binding, and DNase hypersensitivity) across &gt;200 cell types. Key architectural improvements over the original DeepSEA include:\n\n\n\nFeature\nDeepSEA (2015)\nExPecto/Beluga (2018)\n\n\n\n\nChromatin targets\n919\n2,002\n\n\nInput window\n1,000 bp\n2,000 bp\n\n\nConvolution layers\n3\n6 (with residual connections)\n\n\nCell types\n~125\n&gt;200\n\n\n\nThe CNN scans the 40 kb region surrounding each transcription start site (TSS) with a moving window (200 bp step size), generating chromatin predictions at 200 spatial positions. For each gene, this produces 2,002 × 200 = 400,400 features representing the predicted spatial chromatin organization around the TSS.\n\n\n6.2.2 Component 2: Spatial Feature Transformation\nThe 400,400-dimensional feature space poses optimization challenges for downstream expression prediction. ExPecto addresses this through spatial transformation—a biologically motivated dimensionality reduction that captures the known distance-dependent relationship between regulatory elements and their target promoters.\nThe transformation applies ten exponential decay functions separately to upstream and downstream regions. The full model specification is:\n\\[\n\\text{expression} = \\sum_{i,k} \\left( \\beta_{ik}^{\\text{up}} \\cdot \\mathbf{1}(t_d &lt; 0) + \\beta_{ik}^{\\text{down}} \\cdot \\mathbf{1}(t_d &gt; 0) \\right) \\cdot \\sum_{d \\in D} p_{id} \\cdot e^{-a_k \\cdot |t_d|}\n\\]\nwhere \\(p_{id}\\) is the predicted probability for chromatin feature \\(i\\) at spatial bin \\(d\\), \\(t_d\\) is the mean distance to TSS for bin \\(d\\), and \\(a_k\\) represents decay constants (0.01, 0.02, 0.05, 0.1, 0.2). The indicator functions \\(\\mathbf{1}(\\cdot)\\) allow separate coefficients for upstream (\\(\\beta^{\\text{up}}\\)) and downstream (\\(\\beta^{\\text{down}}\\)) regions.\nThis transformation reduces dimensionality 20-fold (to 20,020 features) while preserving spatial information—features with higher decay rates are concentrated near the TSS, while lower decay rates capture more distal signals. The transformation is not learned but prespecified, equivalent to constraining the model to learn smooth spatial patterns as linear combinations of basis functions.\n\n\n6.2.3 Component 3: Tissue-Specific Linear Models\nThe final component comprises 218 L2-regularized linear regression models (one per tissue), each predicting log RPKM expression from spatially-transformed features. Linear models were chosen deliberately: they provide interpretability, prevent overfitting given the high-dimensional feature space, and enable straightforward coefficient analysis to identify which chromatin features drive expression in each tissue.\nTraining used gradient boosting with L2 regularization (λ=100, shrinkage η=0.01), with chromosome 8 held out for evaluation (990 genes). The chromosome-level holdout prevents data leakage through overlapping regulatory regions and sequence homology.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#expression-prediction-performance",
    "href": "ch-p2-transc.html#expression-prediction-performance",
    "title": "6  Transcriptional Effects",
    "section": "6.3 Expression Prediction Performance",
    "text": "6.3 Expression Prediction Performance\nExPecto achieved 0.819 median Spearman correlation between predicted and observed expression (log RPKM) across 218 tissues and cell types—a substantial improvement over prior sequence-based expression models, which were typically limited to narrower regulatory regions (&lt;2 kb) and fewer cell types.\n\n6.3.1 Tissue Specificity\nBeyond predicting absolute expression levels, ExPecto captures tissue-specific expression patterns. Expression predictions correlate more strongly with experimental measurements from the matching tissue than from other tissues, indicating the model learns tissue-specific regulatory logic rather than generic sequence features.\nAnalysis of model coefficients reveals automatic learning of cell-type-relevant features without explicit tissue labels:\n\nLiver model: Top weighted features correspond to seven transcription factors in HepG2 (liver-derived) cells\nBreast model: All top five positive features are estrogen receptor (ER-α) and glucocorticoid receptor (GR) in breast cancer cell lines T-47D and ECC-1\nBlood model: All top five features derive from blood cell lines and erythroblast cells\n\n\n\n6.3.2 Feature Importance\nModel coefficients reveal the relative contributions of different chromatin feature types:\n\nTranscription factors and histone marks receive consistently higher weights, reflecting their direct mechanistic roles in transcriptional regulation\nDNase I features receive significantly lower weights (p = 6.9×10⁻²⁵, Wilcoxon rank sum test) despite indicating regulatory activity—likely because DNase hypersensitivity marks presence of regulatory activity without specifying type (activating vs. repressing) or causal relationship to expression",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#variant-effect-prediction",
    "href": "ch-p2-transc.html#variant-effect-prediction",
    "title": "6  Transcriptional Effects",
    "section": "6.4 Variant Effect Prediction",
    "text": "6.4 Variant Effect Prediction\nExPecto’s expression predictions enable scoring variant effects through in silico mutagenesis: predict expression with reference allele, predict with alternative allele, and compute the difference. Because the model never trains on variant data, predictions are unconfounded by linkage disequilibrium—a fundamental advantage over statistical eQTL approaches.\n\n6.4.1 Computing Variant Effects\nFor any variant, ExPecto computes effects by comparing predictions:\n\\[\n\\Delta \\text{expression} = f(\\text{sequence}_{\\text{alt}}) - f(\\text{sequence}_{\\text{ref}})\n\\]\nThis approach predicts the direction and magnitude of expression change in each of 218 tissues for any single nucleotide variant within the 40 kb promoter region.\n\n\n6.4.2 eQTL Validation\nExPecto correctly predicted the direction of expression change for 92% of the top 500 strongest-effect GTEx eQTL variants. Prediction accuracy increases with predicted effect magnitude: variants with stronger predicted effects show higher eQTL direction concordance, consistent with the expectation that true causal variants should have larger predicted effects.\nUnlike traditional eQTL studies, which are biased toward common variants with sufficient statistical power, ExPecto predictions work equally well across the allele frequency spectrum. This makes the framework particularly valuable for rare variant interpretation where population data is sparse.\n\n\n6.4.3 Advantages Over eQTL Mapping\nTraditional eQTL studies face fundamental limitations:\n\nLD confounding: Only 3.5–11.7% of GTEx lead variants are estimated to be truly causal, meaning &lt;1% of all reported eQTL variants directly affect expression\nAllele frequency bias: Rare variants lack statistical power for detection\nTissue availability: eQTL mapping requires large sample sizes in the tissue of interest\n\nExPecto’s sequence-based predictions sidestep all three limitations: they score based on predicted functional impact rather than population associations, work identically for any allele frequency, and leverage expression training data from many tissues even when eQTL data is unavailable.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#gwas-causal-variant-prioritization",
    "href": "ch-p2-transc.html#gwas-causal-variant-prioritization",
    "title": "6  Transcriptional Effects",
    "section": "6.5 GWAS Causal Variant Prioritization",
    "text": "6.5 GWAS Causal Variant Prioritization\nA major application of ExPecto is prioritizing causal variants within GWAS-identified loci, where LD typically prevents identification of the true functional variant.\n\n6.5.1 Systematic Prioritization\nZhou et al. applied ExPecto to prioritize variants from ~3,000 GWAS studies. Key findings:\n\nGWAS loci with stronger predicted effect variants were significantly more likely to replicate in independent studies (p = 6.3×10⁻¹⁸⁹, Wald test with logistic regression)\nStronger predicted effect variants were more likely to be the exact replicated variant (p = 5.6×10⁻¹⁴)\n\nFor example, an early venous thromboembolism GWAS identified rs3756008 as the lead variant near the F11 locus. ExPecto prioritized a different LD variant, rs4253399, which was subsequently discovered as the true association in a larger cohort study.\n\n\n6.5.2 Experimental Validation\nThe authors experimentally validated three top-ranked ExPecto predictions for immune-related diseases using luciferase reporter assays. In all cases, the ExPecto-prioritized variants showed significant allele-specific regulatory activity, while the original GWAS lead variants showed no differential activity:\n\n\n\n\n\n\n\n\n\n\n\nDisease\nExPecto-Prioritized SNP\nGene\nReporter Effect\np-value\nGWAS Lead SNP\n\n\n\n\nCrohn’s disease / IBD\nrs1174815\nIRGM\nDecreased expression\n3×10⁻⁶\nNot significant\n\n\nBehçet’s disease\nrs147398495\nCCR1\nChanged activity\n7×10⁻¹⁰\nNot significant\n\n\nChronic HBV infection\nrs381218\nHLA-DOA\n4-fold change\n1×10⁻⁹\nNot significant\n\n\n\nExPecto correctly predicted the direction of expression change for all three validated variants. These results demonstrate that sequence-based expression models can identify functional variants that statistical association studies cannot distinguish from linked non-functional variants.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#in-silico-saturation-mutagenesis",
    "href": "ch-p2-transc.html#in-silico-saturation-mutagenesis",
    "title": "6  Transcriptional Effects",
    "section": "6.6 In Silico Saturation Mutagenesis",
    "text": "6.6 In Silico Saturation Mutagenesis\nThe computational efficiency of ExPecto enables exhaustive characterization of the regulatory mutation space. The authors computed predicted effects for all possible single nucleotide substitutions within ±1 kb of each TSS—over 140 million mutations across 23,779 human Pol II-transcribed genes. This identified &gt;1.1 million mutations with strong predicted expression effects.\n\n6.6.1 Variation Potential\nFor each gene, the comprehensive mutagenesis profile defines its “variation potential” (VP)—the collective effects of all possible mutations on that gene’s expression. VP reflects the regulatory sensitivity of each gene:\n\nHigh VP genes: Expression easily perturbed by sequence changes; regulatory regions densely packed with functional elements\nLow VP genes: Expression robust to mutations; potentially fewer regulatory constraints or more redundant regulatory architecture\n\nVP correlates with known biological properties: tissue-specific genes show lower VP than broadly expressed genes, and genes under stronger evolutionary constraint tend to have higher VP.\n\n\n6.6.2 Constraint Violation Scores\nBy comparing predicted mutational effects to observed population variation, ExPecto enables inference of evolutionary constraints. A “constraint violation score” measures whether observed variants push expression in the “wrong” direction relative to inferred evolutionary constraint:\n\nGenes with negative VP directionality (mutations tend to reduce expression) are typically actively expressed—loss-of-function mutations are deleterious\nGenes with positive VP directionality (mutations tend to increase expression) are typically repressed—gain-of-expression mutations are deleterious\n\nThis framework successfully predicts GWAS risk alleles without any prior variant-disease association data. Positive violation scores are significantly associated with alternative alleles being risk alleles (p = 0.002, Wilcoxon rank sum test, AUC = 0.67), demonstrating potential for ab initio disease variant identification.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#the-40-kb-regulatory-window",
    "href": "ch-p2-transc.html#the-40-kb-regulatory-window",
    "title": "6  Transcriptional Effects",
    "section": "6.7 The 40 kb Regulatory Window",
    "text": "6.7 The 40 kb Regulatory Window\nExPecto’s ±20 kb window around each TSS represents an empirically optimized trade-off:\n\nSmaller windows: Decreased prediction performance\nLarger windows (50–200 kb): Negligible performance improvement\n\nThis suggests that most regulatory information for promoter-proximal expression lies within 40 kb of the TSS—at least within the linear modeling framework employed by ExPecto. Distal enhancers beyond this window, while biologically important, likely require more sophisticated integration approaches to capture (addressed by Enformer, Chapter 11, with its 200 kb effective receptive field).",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#relationship-to-the-deepsea-lineage",
    "href": "ch-p2-transc.html#relationship-to-the-deepsea-lineage",
    "title": "6  Transcriptional Effects",
    "section": "6.8 Relationship to the DeepSEA Lineage",
    "text": "6.8 Relationship to the DeepSEA Lineage\nExPecto represents a conceptual extension of the DeepSEA framework:\n\n\n\nModel\nYear\nPrimary Output\nContext Window\n\n\n\n\nDeepSEA\n2015\n919 chromatin profiles\n1 kb\n\n\nExPecto/Beluga\n2018\nGene expression (218 tissues)\n40 kb\n\n\nSei\n2022\n21,907 chromatin profiles + sequence classes\n4 kb\n\n\n\nWhile DeepSEA predicts regulatory intermediate phenotypes, ExPecto predicts the downstream transcriptional consequence. For GWAS variant prioritization, ExPecto predictions proved more effective than DeepSEA alone—variants may alter chromatin features without affecting expression, but expression effects are more directly tied to phenotypic consequences.\nThe chromatin prediction component of ExPecto (Beluga) became the foundation for Sei (discussed in Chapter 5), which expanded chromatin targets to 21,907 profiles and introduced sequence class annotations for interpretability.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#limitations-and-considerations",
    "href": "ch-p2-transc.html#limitations-and-considerations",
    "title": "6  Transcriptional Effects",
    "section": "6.9 Limitations and Considerations",
    "text": "6.9 Limitations and Considerations\n\n6.9.1 Linear Expression Model\nWhile the chromatin CNN captures nonlinear sequence patterns, the final expression model is linear. This prevents modeling of complex regulatory logic:\n\nSynergistic interactions between elements\nCompetitive binding or mutual exclusion\nThreshold effects where element contributions are context-dependent\n\nThe choice was pragmatic—linear models require less data and offer interpretability—but may sacrifice predictive power for genes with complex regulatory logic.\n\n\n6.9.2 Context Window Constraints\nThe 40 kb promoter-proximal window misses:\n\nDistal enhancers operating over hundreds of kilobases\n3D chromatin interactions that bring distant elements into proximity\nEnhancer-promoter specificity (which enhancer regulates which gene among nearby alternatives)\n\n\n\n6.9.3 TSS-Centric Framework\nExPecto requires a defined TSS for each gene, potentially limiting predictions for:\n\nGenes with multiple alternative promoters\nNovel or unannotated transcription start sites\nTissue-specific promoter usage\n\n\n\n6.9.4 Training Data Biases\nExpression models trained on GTEx, Roadmap, and ENCODE data inherit their biases:\n\nAncestry composition (GTEx is primarily European)\nTissue representation (some tissues well-covered, others sparse)\nCell line artifacts (immortalized cells may not reflect primary tissue biology)",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-transc.html#significance-for-the-field",
    "href": "ch-p2-transc.html#significance-for-the-field",
    "title": "6  Transcriptional Effects",
    "section": "6.10 Significance for the Field",
    "text": "6.10 Significance for the Field\nExPecto established several paradigms that influenced subsequent genomic deep learning:\n\nModular sequence-to-expression prediction: Decomposing the problem into chromatin prediction, spatial integration, and expression modeling enables interpretability and component-wise improvement\nAb initio variant effect prediction: Training without variant data avoids LD confounding, enabling causal inference rather than association\nScalable in silico mutagenesis: Computational efficiency enables exhaustive characterization of mutational effects at genome scale\nTissue-specific regulatory learning: The framework learns tissue-relevant regulatory features without explicit tissue labels for chromatin inputs\nExperimental validation standard: Demonstrating functional validation of computational predictions with reporter assays\n\nThe framework demonstrated that deep learning could move beyond predicting intermediate molecular phenotypes (chromatin state) to predict cellular phenotypes (expression levels) directly from sequence. This progression—from sequence to chromatin to expression to disease—prefigured the increasingly ambitious goals of later genomic foundation models.\nExPecto’s public web portal (http://hb.flatironinstitute.org/expecto) and code release (https://github.com/FunctionLab/ExPecto) maintained the field’s norm of open tool availability established by DeepSEA. The framework continues to serve as a baseline for expression prediction methods and as a component in variant prioritization pipelines.\n\n\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[ExPecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transcriptional Effects</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html",
    "href": "ch-p2-splice.html",
    "title": "7  Splicing Prediction",
    "section": "",
    "text": "7.1 The Splicing Challenge\nWhile DeepSEA and ExPecto (Chapters 5–6) addressed chromatin state and gene expression, a distinct class of functional variants operates through a different mechanism: disruption of pre-mRNA splicing. The spliceosome—the cellular machinery that removes introns and joins exons—achieves remarkable precision, recognizing the correct splice sites among millions of potential candidates in the human transcriptome. Yet the sequence determinants underlying this specificity remained incompletely understood, limiting interpretation of variants that might alter splicing.\nSpliceAI, introduced by Jaganathan et al. in 2019, demonstrated that deep neural networks could learn the sequence rules governing splicing with near-spliceosomal precision (Jaganathan et al. 2019). The model predicts splice site locations directly from pre-mRNA sequence, enabling identification of “cryptic splice” variants—mutations that create novel splice sites or disrupt existing ones in ways that evade traditional annotation-based detection.\nThe clinical implications are substantial: SpliceAI estimates that 9–11% of pathogenic mutations in rare genetic disorders act through cryptic splicing, representing a previously underappreciated class of disease variation.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#prior-approaches-and-limitations",
    "href": "ch-p2-splice.html#prior-approaches-and-limitations",
    "title": "7  Splicing Prediction",
    "section": "7.2 Prior Approaches and Limitations",
    "text": "7.2 Prior Approaches and Limitations\nBefore SpliceAI, splice site prediction relied on methods with limited context:\n\nMaxEntScan: Models core splice motifs using maximum entropy, limited to ~9 bp context around donor/acceptor sites\nGeneSplicer: Combines Markov models with decision trees\nNNSplice: Early neural network approach with narrow receptive fields\n\nThese methods captured the essential GT (donor) and AG (acceptor) dinucleotides and surrounding consensus sequences, but could not model the long-range determinants—exon/intron length constraints, branch points, enhancers, and silencers—that contribute to splicing specificity. As a result, they produced many false positive predictions and missed variants acting through distal mechanisms.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#the-spliceai-architecture",
    "href": "ch-p2-splice.html#the-spliceai-architecture",
    "title": "7  Splicing Prediction",
    "section": "7.3 The SpliceAI Architecture",
    "text": "7.3 The SpliceAI Architecture\nSpliceAI employs an ultra-deep residual convolutional network that integrates information across 10,000 nucleotides of sequence context—orders of magnitude more than prior methods.\n\n7.3.1 Residual Block Design\nThe architecture’s fundamental unit is the residual block, comprising batch normalization, ReLU activation, and dilated convolutions. Residual connections address the vanishing gradient problem that had limited earlier deep networks:\n\\[\n\\text{output} = \\text{input} + F(\\text{input})\n\\]\nwhere \\(F\\) represents the transformation learned by the convolutional layers. Skip connections from every fourth residual block feed directly to the penultimate layer, accelerating training convergence.\n\n\n7.3.2 Dilated Convolutions for Long-Range Context\nEach residual block uses dilated (atrous) convolutions parameterized by:\n\n\\(N\\): Number of convolutional kernels\n\\(W\\): Window size\n\\(D\\): Dilation rate\n\nA kernel with window size \\(W\\) and dilation rate \\(D\\) spans \\((W-1) \\cdot D\\) neighboring positions. The total receptive field \\(S\\) of the network is:\n\\[\nS = \\sum_{i=1}^{K} 2 \\cdot (W_i - 1) \\cdot D_i\n\\]\nwhere \\(K\\) is the number of residual blocks. By progressively increasing dilation rates through the network, SpliceAI achieves a 10,000 bp receptive field without the computational cost of processing 10,000 positions at full resolution.\n\n\n7.3.3 Architecture Variants\nFour architectures were developed with different context windows:\n\n\n\nModel\nFlanking Sequence\nTotal Context\nResidual Blocks\n\n\n\n\nSpliceAI-80nt\n40 bp each side\n80 bp\n4\n\n\nSpliceAI-400nt\n200 bp each side\n400 bp\n8\n\n\nSpliceAI-2k\n1,000 bp each side\n2,000 bp\n16\n\n\nSpliceAI-10k\n5,000 bp each side\n10,000 bp\n32\n\n\n\nThe 32-layer SpliceAI-10k model substantially outperformed shorter-context variants, demonstrating that long-range sequence features contribute meaningfully to splice site prediction.\n\n\n7.3.4 Output Format\nFor each nucleotide position, SpliceAI outputs three probabilities summing to one:\n\nProbability of being a splice acceptor (first nucleotide of an exon)\nProbability of being a splice donor (last nucleotide of an exon)\nProbability of being neither\n\nThe model operates in sequence-to-sequence mode: given an input of length \\(S/2 + l + S/2\\), it outputs predictions for the central \\(l\\) positions. This enables efficient batch processing where overlapping computations are shared.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#training-and-evaluation",
    "href": "ch-p2-splice.html#training-and-evaluation",
    "title": "7  Splicing Prediction",
    "section": "7.4 Training and Evaluation",
    "text": "7.4 Training and Evaluation\n\n7.4.1 Training Data\nSpliceAI was trained on 20,287 protein-coding genes from GENCODE V24, selecting principal transcripts when multiple isoforms existed. The training/test split used odd versus even chromosomes:\n\nTraining: Chromosomes 2, 4, 6, 8, 10–22, X, Y (13,384 genes, 130,796 donor-acceptor pairs)\nTesting: Chromosomes 1, 3, 5, 7, 9—excluding genes with paralogs on training chromosomes (1,652 genes, 14,289 donor-acceptor pairs)\n\nThe paralog exclusion prevents information leakage through sequence homology.\nFor variant effect prediction, training was augmented with novel splice junctions commonly observed in GTEx RNA-seq data (adding ~67,000 donor and ~63,000 acceptor annotations), improving sensitivity for detecting splice-altering variants, particularly in deep intronic regions.\n\n\n7.4.2 Splice Site Prediction Performance\nSpliceAI-10k achieved:\n\nTop-k accuracy: 95% (at threshold where predicted sites equal actual sites)\nPR-AUC: 0.98\n\nFor comparison, MaxEntScan achieved only 57% top-k accuracy under equivalent conditions. The dramatic improvement reflects SpliceAI’s ability to reject false positive splice sites by considering sequence context beyond the core motif.\nNotably, performance improved substantially with context length (80 bp → 400 bp → 2,000 bp → 10,000 bp), confirming that distal sequence features contribute to splice site recognition.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#variant-effect-prediction",
    "href": "ch-p2-splice.html#variant-effect-prediction",
    "title": "7  Splicing Prediction",
    "section": "7.5 Variant Effect Prediction",
    "text": "7.5 Variant Effect Prediction\n\n7.5.1 The Delta Score\nSpliceAI predicts variant effects by comparing splice site predictions for reference and alternative sequences:\n\\[\n\\Delta\\text{score} = \\max_{|p - v| \\leq 50} \\left| P_{\\text{alt}}(p) - P_{\\text{ref}}(p) \\right|\n\\]\nwhere \\(v\\) is the variant position and \\(p\\) ranges over positions within 50 bp of the variant. The maximum change across all positions captures variants that strengthen existing sites, weaken existing sites, or create entirely new splice sites.\nCritically, the model was trained only on reference transcript sequences and splice junction annotations—it never saw variant data during training. Variant effect prediction is thus a challenging test of whether the network learned genuine sequence determinants of splicing.\n\n\n7.5.2 Cryptic Splice Variant Classes\nSpliceAI detects several classes of splice-altering variants:\n\nDonor/acceptor loss: Disruption of annotated splice sites\nDonor/acceptor gain: Creation of novel splice sites\nExon skipping: Variants causing an exon to be spliced out\nIntron retention: Variants causing an intron to remain in mature mRNA\nCryptic exon activation: Deep intronic variants creating novel exons\n\nTraditional annotation-based methods can identify variants in the essential GT/AG dinucleotides but miss the broader landscape of cryptic splice variants operating through more subtle mechanisms.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#validation-on-gtex-rna-seq",
    "href": "ch-p2-splice.html#validation-on-gtex-rna-seq",
    "title": "7  Splicing Prediction",
    "section": "7.6 Validation on GTEx RNA-seq",
    "text": "7.6 Validation on GTEx RNA-seq\nThe authors validated SpliceAI predictions using RNA-seq data from 149 GTEx individuals with matched whole-genome sequencing. Private variants (present in only one individual) predicted to alter splicing were tested for association with aberrant splice junctions.\n\n7.6.1 Validation Rates\nAt a Δ score threshold of ≥0.5, cryptic splice variants validated at three-quarters the rate of essential GT/AG splice disruptions:\n\n\n\nVariant Class\nValidation Rate\n\n\n\n\nEssential GT/AG disruption\n~100% (by definition)\n\n\nCryptic splice (Δ ≥ 0.8)\n~85%\n\n\nCryptic splice (Δ ≥ 0.5)\n~75%\n\n\nCryptic splice (Δ ≥ 0.2)\n~50%\n\n\n\nValidation rate and effect size both tracked closely with Δ score, confirming that the model’s confidence correlates with functional impact.\n\n\n7.6.2 Position-Dependent Sensitivity\nSensitivity varied by genomic location:\n\nNear exons (≤50 bp from exon-intron boundaries): 71% sensitivity at Δ ≥ 0.5\nDeep intronic (&gt;50 bp from boundaries): 41% sensitivity at Δ ≥ 0.5\n\nDeep intronic variants are more challenging because intronic regions contain fewer of the specificity determinants selected to be present near exons. Nevertheless, SpliceAI substantially outperformed prior methods in both regions.\n\n\n7.6.3 Comparison to Prior Methods\nBenchmarking against MaxEntScan, GeneSplicer, and NNSplice demonstrated SpliceAI’s superior performance across all operating points. At matched sensitivity, SpliceAI achieved higher validation rates; at matched validation rates, SpliceAI achieved higher sensitivity.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#population-genetics-evidence",
    "href": "ch-p2-splice.html#population-genetics-evidence",
    "title": "7  Splicing Prediction",
    "section": "7.7 Population Genetics Evidence",
    "text": "7.7 Population Genetics Evidence\nBeyond RNA-seq validation, the authors assessed whether predicted cryptic splice variants show signatures of negative selection in human populations.\n\n7.7.1 Allele Frequency Depletion\nUsing ExAC/gnomAD data, high-confidence cryptic splice variants (Δ ≥ 0.8) showed 78% depletion at common allele frequencies compared to expectation—comparable to the 82% depletion observed for frameshift, stop-gain, and essential splice-disrupting variants. This indicates that most confidently predicted cryptic splice variants are functional and deleterious.\nThe depletion was stronger for variants predicted to cause frameshifts versus in-frame alterations, consistent with the expectation that frameshift-causing splice variants have more severe fitness consequences.\n\n\n7.7.2 Rare Variant Burden\nThe average human genome carries approximately:\n\n11 rare protein-truncating variants (allele frequency &lt;0.1%)\n5 rare functional cryptic splice variants\n\nCryptic splice variants outnumber essential GT/AG splice-disrupting variants roughly 2:1, highlighting the substantial mutational target space beyond canonical splice sites.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#de-novo-mutations-in-rare-disease",
    "href": "ch-p2-splice.html#de-novo-mutations-in-rare-disease",
    "title": "7  Splicing Prediction",
    "section": "7.8 De Novo Mutations in Rare Disease",
    "text": "7.8 De Novo Mutations in Rare Disease\nThe central clinical finding of SpliceAI is that cryptic splice mutations constitute a major, previously underappreciated cause of rare genetic disorders.\n\n7.8.1 Case-Control Analysis\nThe authors analyzed de novo mutations in:\n\n4,293 individuals with intellectual disability (Deciphering Developmental Disorders cohort)\n3,953 individuals with autism spectrum disorders (Simons Simplex Collection + Autism Sequencing Consortium)\n2,073 unaffected sibling controls\n\nDe novo mutations predicted to disrupt splicing (Δ ≥ 0.1) were significantly enriched in affected individuals:\n\n\n\nCohort\nEnrichment vs. Controls\np-value\n\n\n\n\nIntellectual disability (DDD)\n1.51-fold\n4.2×10⁻⁴\n\n\nAutism spectrum disorder\n1.30-fold\n0.020\n\n\n\nThe enrichment remained significant when restricting to synonymous and intronic mutations, excluding the possibility that results were driven solely by variants with dual protein-coding and splicing effects.\n\n\n7.8.2 Fraction of Pathogenic Mutations\nBased on the excess of de novo mutations in cases versus controls:\n\n9% of pathogenic de novo mutations in intellectual disability act through cryptic splicing\n11% of pathogenic de novo mutations in autism act through cryptic splicing\n\nIn absolute terms, ~250 cases across the cohorts could be explained by de novo cryptic splice mutations, compared to ~909 cases explained by de novo protein-truncating variants.\n\n\n7.8.3 Clinical Penetrance\nCryptic splice mutations showed roughly 50% of the clinical penetrance of classic protein-truncating mutations (stop-gain, frameshift, essential splice). This reduced penetrance reflects that many cryptic splice variants are hypomorphic—producing a mixture of normal and aberrant transcripts rather than complete loss of function.\nWell-characterized examples from Mendelian disease support this interpretation: the c.315-48T&gt;C variant in FECH and c.-32-13T&gt;G in GAA are both hypomorphic cryptic splice alleles associated with milder phenotype or later age of onset.\n\n\n7.8.4 Novel Gene Discovery\nIncluding cryptic splice mutations in gene discovery analyses identified:\n\n5 additional candidate genes for intellectual disability\n2 additional candidate genes for autism\n\nThese genes would have fallen below the discovery threshold (FDR &lt;0.01) when considering only protein-coding mutations.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#experimental-validation-in-autism-patients",
    "href": "ch-p2-splice.html#experimental-validation-in-autism-patients",
    "title": "7  Splicing Prediction",
    "section": "7.9 Experimental Validation in Autism Patients",
    "text": "7.9 Experimental Validation in Autism Patients\nTo directly validate predicted cryptic splice effects, the authors performed deep RNA-seq (~350 million reads per sample, ~10× GTEx coverage) on lymphoblastoid cell lines from 36 autism probands harboring predicted de novo cryptic splice mutations.\n\n7.9.1 Validation Results\nAmong 28 cases with adequate RNA-seq coverage at the gene of interest:\n\n21 (75%) showed unique aberrant splicing events associated with the predicted de novo variant\n7 (25%) showed no aberrant splicing in lymphoblastoid cells\n\nThe 75% validation rate is remarkable given that the relevant tissue (developing brain) was not accessible—some cryptic splice effects may be tissue-specific and not observable in blood-derived cells.\n\n\n7.9.2 Aberrant Splicing Classes\nAmong the 21 validated cases:\n\n\n\nSplicing Aberration\nCount\n\n\n\n\nNovel junction creation\n9\n\n\nExon skipping\n8\n\n\nIntron retention\n4\n\n\n\nThese aberrant events were absent from all other samples (the remaining 35 probands and 149 GTEx individuals), confirming their association with the predicted de novo variants.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#what-spliceai-learns",
    "href": "ch-p2-splice.html#what-spliceai-learns",
    "title": "7  Splicing Prediction",
    "section": "7.10 What SpliceAI Learns",
    "text": "7.10 What SpliceAI Learns\nAnalysis of SpliceAI’s learned representations revealed that the network captures known splicing biology:\n\n7.10.1 Core Splice Motifs\nThe model correctly learned the essential GT donor and AG acceptor dinucleotides, plus surrounding consensus sequences. In silico mutagenesis of these positions produced the largest predicted effects.\n\n\n7.10.2 Branch Point Recognition\nIntroducing the optimal branch point sequence (TACTAAC) at varying distances from splice acceptors showed that SpliceAI learned the expected distance constraints (20–45 bp upstream of acceptors). At distances &lt;20 bp, the branch point disrupts the polypyrimidine tract, and SpliceAI correctly predicted reduced acceptor strength.\n\n\n7.10.3 Exonic Splicing Enhancers\nThe SR-protein binding motif GAAGAA, introduced at various positions, enhanced splice site strength when placed in expected locations within exons, demonstrating that SpliceAI learned the contribution of exonic splicing enhancers.\n\n\n7.10.4 Nucleosome Positioning\nNovel exon-creation events (where variants activate cryptic exons in introns) were significantly associated with existing nucleosome positioning, supporting a causal role for nucleosome occupancy in exon definition. SpliceAI implicitly captures this relationship despite not being trained on chromatin data.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#limitations-and-considerations",
    "href": "ch-p2-splice.html#limitations-and-considerations",
    "title": "7  Splicing Prediction",
    "section": "7.11 Limitations and Considerations",
    "text": "7.11 Limitations and Considerations\n\n7.11.1 Tissue Specificity\nSpliceAI predicts splice sites based on sequence alone, without modeling tissue-specific alternative splicing. The same variant may have different effects across tissues depending on the expression of splicing factors and regulatory RNAs.\n\n\n7.11.2 Incomplete Penetrance\nMany cryptic splice variants produce partial shifts in splicing (alternative splicing) rather than complete disruption. The Δ score correlates with penetrance, but precise quantification of isoform ratios requires experimental validation.\n\n\n7.11.3 Deep Intronic Predictions\nWhile SpliceAI substantially improves deep intronic variant prediction over prior methods, sensitivity remains lower than for variants near exons. The 41% sensitivity (Δ ≥ 0.5) in deep intronic regions suggests that additional sequence features beyond the 10 kb context may contribute to splicing.\n\n\n7.11.4 Training on Canonical Transcripts\nTraining on principal transcripts may not fully capture the diversity of alternative splicing. Augmentation with RNA-seq-derived junctions improved performance, suggesting that expanded training data could further enhance predictions.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p2-splice.html#significance-for-the-field",
    "href": "ch-p2-splice.html#significance-for-the-field",
    "title": "7  Splicing Prediction",
    "section": "7.12 Significance for the Field",
    "text": "7.12 Significance for the Field\nSpliceAI established several important contributions:\n\nClinical impact quantification: The estimate that 9–11% of pathogenic mutations act through cryptic splicing fundamentally changed understanding of the noncoding disease mutation landscape\nDeep context matters: The 32-layer, 10 kb context architecture demonstrated that splicing involves long-range sequence integration, motivating similar approaches in other genomic prediction tasks\nGenome-wide variant scoring: Precomputed Δ scores for all possible single nucleotide substitutions (available at https://github.com/Illumina/SpliceAI) enable routine clinical annotation\nValidation standards: The combination of RNA-seq validation, population genetics evidence, and case-control analysis established a rigorous framework for evaluating variant effect predictors\nSpecialized versus general models: SpliceAI’s success demonstrated that task-specific deep learning models could outperform general-purpose approaches by focusing computational capacity on a well-defined prediction problem\n\nSpliceAI has become a standard component of clinical variant interpretation pipelines, complementing protein-effect predictors and regulatory variant scores. The approach has influenced subsequent work on tissue-specific splicing prediction and integration of splicing effects into comprehensive variant effect models like Borzoi (Chapter 11).\nThe model’s code and precomputed scores are publicly available (https://github.com/Illumina/SpliceAI), enabling widespread adoption in both research and clinical settings.\n\n\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.",
    "crumbs": [
      "Part II: CNN Seq-to-Function Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Splicing Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html",
    "href": "ch-p3-tokens.html",
    "title": "8  Sequence Representation & Tokens",
    "section": "",
    "text": "8.1 From Sequence to Model: The Representation Problem\nEvery genomic deep learning model must answer a fundamental question: how should DNA sequence be represented as numerical input? The previous chapters employed one-hot encoding—a simple, lossless representation where each nucleotide becomes a 4-dimensional binary vector. This approach worked well for CNN-based models like DeepSEA (Chapter 5) and SpliceAI (Chapter 7), but the emergence of transformer-based language models introduced new considerations around tokenization, vocabulary design, and the trade-offs between sequence compression and resolution.\nThis chapter examines the evolution of sequence representation strategies, from one-hot encoding through k-mer tokenization to modern approaches including Byte Pair Encoding (BPE), single-nucleotide tokens, and biologically-informed tokenization schemes. The choice of representation profoundly affects what a model can learn, how efficiently it trains, and what context lengths it can practically achieve.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#one-hot-encoding-the-cnn-baseline",
    "href": "ch-p3-tokens.html#one-hot-encoding-the-cnn-baseline",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.2 One-Hot Encoding: The CNN Baseline",
    "text": "8.2 One-Hot Encoding: The CNN Baseline\n\n8.2.1 Representation\nOne-hot encoding represents each nucleotide as a sparse binary vector:\n\n\n\nNucleotide\nVector\n\n\n\n\nA\n[1, 0, 0, 0]\n\n\nC\n[0, 1, 0, 0]\n\n\nG\n[0, 0, 1, 0]\n\n\nT\n[0, 0, 0, 1]\n\n\n\nA sequence of length \\(L\\) becomes a matrix of dimensions \\(4 \\times L\\), interpretable as 4 “channels” (like RGB channels in images, plus one).\n\n\n8.2.2 Advantages\nOne-hot encoding offers several properties that made it the default for CNN-based genomic models:\n\nLossless: No information is discarded; every nucleotide is explicitly represented\nSingle-nucleotide resolution: Enables detection of effects from individual SNPs\nTranslation equivariance: Convolutional filters learn position-invariant motifs\nSimplicity: No preprocessing, vocabulary construction, or tokenizer training required\n\n\n\n8.2.3 Limitations\nFor transformer architectures, one-hot encoding presents challenges:\n\nSequence length: A 10 kb sequence requires 10,000 tokens, straining attention’s \\(O(L^2)\\) complexity\nNo learned embeddings: Each nucleotide has a fixed, sparse representation rather than a learned dense embedding\nContext constraints: Practical transformer context windows of 512–4,096 tokens translate to only 512–4,096 bp—a tiny fraction of genes or regulatory regions",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#k-mer-tokenization-dnaberts-approach",
    "href": "ch-p3-tokens.html#k-mer-tokenization-dnaberts-approach",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.3 K-mer Tokenization: DNABERT’s Approach",
    "text": "8.3 K-mer Tokenization: DNABERT’s Approach\n\n8.3.1 Concept\nK-mer tokenization treats overlapping subsequences of length \\(k\\) as tokens, analogous to words in natural language. DNABERT (2021) pioneered this approach for genomic transformers, using 6-mers (Ji et al. 2021).\nFor a 6-mer vocabulary: - Vocabulary size: \\(4^6 = 4,096\\) possible tokens - Each token represents 6 consecutive nucleotides - Tokens overlap by \\(k-1 = 5\\) positions\n\n\n8.3.2 Overlapping vs. Non-Overlapping\nDNABERT used overlapping k-mers: for a sequence ACGTACGT, the 3-mer tokens would be:\nPosition:  1   2   3   4   5   6\nSequence:  A   C   G   T   A   C   G   T\n3-mers:   ACG CGT GTA TAC ACG CGT\nThis preserves positional information but creates computational redundancy—the sequence length in tokens equals the sequence length in nucleotides (minus \\(k-1\\)).\n\n\n8.3.3 Problems with K-mer Tokenization\nDNABERT-2 (2024) identified fundamental limitations of k-mer tokenization (Zhou et al. 2024):\n\nNo sequence compression: Overlapping k-mers don’t reduce sequence length, so context window limitations persist\nTokenization ambiguity: A single sequence position contributes to \\(k\\) different tokens, complicating variant effect interpretation\nSample inefficiency: The model must learn that overlapping tokens share nucleotides, rather than this being encoded in the representation\nComputational overhead: Processing \\(L\\) overlapping tokens for an \\(L\\)-bp sequence is no more efficient than one-hot encoding\nFixed vocabulary: The \\(4^k\\) vocabulary doesn’t adapt to corpus statistics; frequent and rare k-mers receive equal representation capacity",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#byte-pair-encoding-learning-the-vocabulary",
    "href": "ch-p3-tokens.html#byte-pair-encoding-learning-the-vocabulary",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.4 Byte Pair Encoding: Learning the Vocabulary",
    "text": "8.4 Byte Pair Encoding: Learning the Vocabulary\n\n8.4.1 The BPE Algorithm\nByte Pair Encoding, originally a data compression algorithm, constructs a vocabulary by iteratively merging the most frequent adjacent token pairs in the training corpus:\n\nInitialize vocabulary with single nucleotides: {A, C, G, T}\nCount all adjacent token pairs in the corpus\nMerge the most frequent pair into a new token\nRepeat until desired vocabulary size is reached\n\nThis produces variable-length tokens that capture frequently occurring sequence patterns, achieving genuine sequence compression.\n\n\n8.4.2 DNABERT-2’s BPE Implementation\nDNABERT-2 replaced 6-mer tokenization with BPE, demonstrating substantial improvements (Zhou et al. 2024):\n\n21× fewer parameters than comparable k-mer models\n92× less GPU time in pretraining\nNon-overlapping tokens: Actual sequence compression, enabling longer effective context\n\nThe BPE vocabulary learns corpus statistics—repetitive elements, common motifs, and frequent sequence patterns receive dedicated tokens, while rare sequences are represented as shorter subunits.\n\n\n8.4.3 GROVER’s Custom BPE\nGROVER (Genome Rules Obtained Via Extracted Representations) trained BPE specifically on the human genome and selected vocabulary using a custom next-k-mer prediction task (Sanabria et al. 2024). Analysis revealed that learned token embeddings encode:\n\nFrequency: Common tokens cluster separately from rare ones\nSequence content: GC-rich versus AT-rich tokens segregate\nLength: Token length correlates with embedding dimensions\nGenomic localization: Some tokens appear primarily in repeats; others distribute broadly",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#single-nucleotide-tokenization-hyenadna",
    "href": "ch-p3-tokens.html#single-nucleotide-tokenization-hyenadna",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.5 Single-Nucleotide Tokenization: HyenaDNA",
    "text": "8.5 Single-Nucleotide Tokenization: HyenaDNA\n\n8.5.1 The Case for Maximum Resolution\nWhile k-mer and BPE tokenization compress sequences, they sacrifice single-nucleotide resolution. A single nucleotide polymorphism (SNP) can completely alter protein function, yet multi-nucleotide tokens obscure the precise position and identity of variants.\nHyenaDNA (2023) took the opposite approach: single-nucleotide tokens with no compression (Nguyen et al. 2023). Each nucleotide (A, C, G, T) is a separate token, preserving:\n\nFull resolution: Every nucleotide is independently represented\nVariant precision: SNP effects can be isolated to specific tokens\nNo tokenization artifacts: No ambiguity about which token contains a variant\n\n\n\n8.5.2 Scaling to 1 Million Base Pairs\nThe challenge with single-nucleotide tokens is sequence length. A 1 Mb region requires 1 million tokens—far beyond standard transformer capacity. HyenaDNA addresses this through the Hyena architecture, which replaces attention with implicit convolutions that scale sub-quadratically:\n\n\n\nModel\nArchitecture\nMax Context\nComplexity\n\n\n\n\nDNABERT\nTransformer\n512 bp\n\\(O(L^2)\\)\n\n\nNucleotide Transformer\nTransformer\n6 kb\n\\(O(L^2)\\)\n\n\nHyenaDNA\nHyena\n1 Mb\n\\(O(L \\log L)\\)\n\n\n\nHyenaDNA achieved a 500× increase in context length over dense attention models while maintaining single-nucleotide resolution.\n\n\n8.5.3 Performance Characteristics\nOn Nucleotide Transformer benchmarks, HyenaDNA reached state-of-the-art on 12 of 18 datasets with orders of magnitude fewer parameters and less pretraining data. On GenomicBenchmarks, it surpassed prior state-of-the-art on 7 of 8 datasets by an average of +10 accuracy points.\nNotably, HyenaDNA demonstrated the first use of in-context learning in genomics—performing tasks based on examples provided in the context window without fine-tuning.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#biologically-informed-tokenization",
    "href": "ch-p3-tokens.html#biologically-informed-tokenization",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.6 Biologically-Informed Tokenization",
    "text": "8.6 Biologically-Informed Tokenization\n\n8.6.1 The Central Dogma as Tokenization Guide: Life-Code\nStandard tokenization treats DNA as a homogeneous string, ignoring the biological reality that different genomic regions serve different functions. Coding sequences follow codon structure (3-nucleotide units encoding amino acids), while noncoding regions have no such constraint.\nLife-Code (2025) proposed codon-aware tokenization that respects the central dogma of molecular biology (Liu et al. 2025):\n\nCoding regions: Tokenized by codons (3-mers in reading frame)\nNoncoding regions: Tokenized by learned patterns\nIntegration: Unified framework spanning DNA, RNA, and protein\n\nThis approach enables Life-Code to: - Learn protein structure through knowledge distillation from protein language models - Capture interactions between coding and noncoding regions - Achieve state-of-the-art results across DNA, RNA, and protein tasks\n\n\n8.6.2 BioToken: Encoding Genomic Annotations\nBioToken (2025) extends tokenization beyond sequence content to include genomic structural annotations (Medvedev et al. 2025):\n\nVariant encoding: Tokens that explicitly represent SNPs, insertions, and deletions\nRegulatory annotations: Encoding of known regulatory elements\nFunctional context: Integration of gene structure, chromatin state, and other annotations\n\nBy incorporating biological inductive biases directly into the token representation, BioToken’s associated model (BioFM) achieves competitive or superior performance to specialized models (Enformer, SpliceAI) with significantly fewer parameters (265M).",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#the-context-length-evolution",
    "href": "ch-p3-tokens.html#the-context-length-evolution",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.7 The Context Length Evolution",
    "text": "8.7 The Context Length Evolution\nThe history of genomic deep learning shows a consistent trend toward longer sequence context:\n\n\n\nEra\nRepresentative Models\nMax Context\nTokenization\n\n\n\n\n2015–2017\nDeepSEA, DeepBind\n1 kb\nOne-hot\n\n\n2018–2020\nExPecto, SpliceAI\n10–40 kb\nOne-hot\n\n\n2021\nDNABERT, Enformer\n512 bp – 200 kb\nK-mer / One-hot\n\n\n2022–2023\nNucleotide Transformer\n6 kb\nK-mer\n\n\n2023–2024\nHyenaDNA, Caduceus\n1 Mb\nSingle-nucleotide\n\n\n2025\nEvo 2\n1 Mb\nSingle-nucleotide (BPE)\n\n\n\nThis expansion reflects biological reality: regulatory elements can influence genes from hundreds of kilobases away, and understanding genome function requires integrating information across these distances.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#trade-offs-in-tokenization-design",
    "href": "ch-p3-tokens.html#trade-offs-in-tokenization-design",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.8 Trade-offs in Tokenization Design",
    "text": "8.8 Trade-offs in Tokenization Design\n\n8.8.1 Compression vs. Resolution\n\n\n\nStrategy\nCompression\nResolution\nVariant Handling\n\n\n\n\nOne-hot\nNone\nSingle-nucleotide\nPrecise\n\n\nOverlapping k-mer\nNone\nK-nucleotide\nAmbiguous\n\n\nNon-overlapping k-mer\n~K×\nK-nucleotide\nFrame-dependent\n\n\nBPE\nVariable\nVariable\nContext-dependent\n\n\nSingle-nucleotide\nNone\nSingle-nucleotide\nPrecise\n\n\n\nHigher compression enables longer context but loses precision for variant effects. BPE offers a middle ground with adaptive compression, but variant positions relative to token boundaries can affect predictions.\n\n\n8.8.2 Vocabulary Size Considerations\n\n\n\nTokenization\nTypical Vocabulary Size\n\n\n\n\nOne-hot / Single-nucleotide\n4 (+ special tokens)\n\n\n6-mer\n4,096\n\n\nBPE (DNABERT-2)\n4,096–32,000\n\n\nCodon-aware\n~64 (codons) + noncoding\n\n\n\nLarger vocabularies increase embedding table size but may capture more complex patterns. Smaller vocabularies are parameter-efficient but require the model to learn compositional structure.\n\n\n8.8.3 Computational Efficiency\nFor a sequence of length \\(L\\) bp:\n\n\n\nTokenization\nTokens\nAttention Cost\n\n\n\n\nOne-hot\n\\(L\\)\n\\(O(L^2)\\)\n\n\nNon-overlapping k-mer\n\\(L/k\\)\n\\(O(L^2/k^2)\\)\n\n\nBPE (average compression \\(c\\))\n\\(L/c\\)\n\\(O(L^2/c^2)\\)\n\n\n\nBPE’s variable compression can achieve substantial speedups, but the benefit depends on corpus statistics and vocabulary size.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#implications-for-variant-effect-prediction",
    "href": "ch-p3-tokens.html#implications-for-variant-effect-prediction",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.9 Implications for Variant Effect Prediction",
    "text": "8.9 Implications for Variant Effect Prediction\nTokenization choice directly affects variant effect prediction:\n\n8.9.1 Single-Nucleotide Tokens (HyenaDNA, Evo 2)\n\nReference and alternate alleles occupy the same token position\nEffects are precisely localized\nNo tokenization artifacts\n\n\n\n8.9.2 K-mer Tokens\n\nA single SNP changes \\(k\\) overlapping tokens\nMust aggregate effects across affected tokens\nBoundary effects if variant is at token junction\n\n\n\n8.9.3 BPE Tokens\n\nVariant may fall within a token or at token boundary\nEffect interpretation depends on token segmentation\nRe-tokenization may be needed for alternate allele\n\nFor clinical variant interpretation, single-nucleotide resolution is often preferred despite computational costs, as subtle genetic variations can have major phenotypic consequences.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#the-emerging-consensus",
    "href": "ch-p3-tokens.html#the-emerging-consensus",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.10 The Emerging Consensus",
    "text": "8.10 The Emerging Consensus\nRecent developments suggest convergence toward:\n\nSingle-nucleotide resolution for maximum precision, enabled by sub-quadratic architectures (Hyena, Mamba, state space models)\nLearned embeddings rather than fixed one-hot vectors, allowing the model to discover meaningful nucleotide representations\nBiologically-informed augmentation where appropriate—encoding codons in coding regions, incorporating annotations, or using species-specific vocabularies\nHybrid approaches combining the efficiency of compression with resolution where needed\n\nThe choice ultimately depends on the task: variant effect prediction demands high resolution, while tasks like species classification or repeat annotation may benefit from compression.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-tokens.html#references-in-context",
    "href": "ch-p3-tokens.html#references-in-context",
    "title": "8  Sequence Representation & Tokens",
    "section": "8.11 References in Context",
    "text": "8.11 References in Context\nThe models discussed in this chapter set the stage for the genomic language models covered in Chapter 10. Understanding tokenization choices clarifies why models like the Nucleotide Transformer use 6-mers (Dalla-Torre et al. 2023), why DNABERT-2 switched to BPE, and why HyenaDNA’s single-nucleotide approach enabled unprecedented context lengths. The hybrid architectures of Chapter 11 (Enformer, Borzoi) largely retained one-hot encoding for its precision, while the long-range models of Chapter 12 explore how sub-quadratic architectures enable single-nucleotide tokenization at genomic scale.\n\n\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025. “Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. “[GROVER] DNA Language Model GROVER Learns Sequence Context in the Human Genome.” Nature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. “DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html",
    "href": "ch-p3-plm.html",
    "title": "9  Protein Language Models",
    "section": "",
    "text": "9.1 Evolutionary Sequences as Natural Language\nBefore transformers revolutionized genomic sequence modeling, they first transformed our ability to model proteins. The success of protein language models (PLMs) established a paradigm that would later inspire genomic foundation models: treat biological sequences as a form of natural language, train large transformer models on massive unlabeled sequence databases, and extract functional knowledge through self-supervised learning.\nThe analogy between protein sequences and natural language runs deeper than mere metaphor. Both encode complex information in linear strings of discrete tokens (amino acids or words). Both exhibit hierarchical structure—motifs combine into domains as words combine into phrases. Both have syntax (structural constraints) and semantics (functional meaning). And crucially, both are shaped by evolutionary pressure: natural selection filters protein sequences just as cultural selection shapes language.\nThis chapter examines how protein language models pioneered biological foundation modeling, from the ESM family’s demonstration that transformers can learn protein structure and function from sequence alone, to their application in variant effect prediction and structure determination. Understanding PLMs provides essential context for the genomic language models covered in subsequent chapters, as many architectural choices and training strategies transfer directly from proteins to DNA.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#the-esm-model-family",
    "href": "ch-p3-plm.html#the-esm-model-family",
    "title": "9  Protein Language Models",
    "section": "9.2 The ESM Model Family",
    "text": "9.2 The ESM Model Family\n\n9.2.1 ESM-1b: Establishing the Paradigm\nThe Evolutionary Scale Modeling (ESM) project, developed at Meta AI Research, demonstrated that transformer language models trained on protein sequences learn biologically meaningful representations without explicit supervision (Rives et al. 2021).\nTraining data: ESM-1b was trained on UniRef50, a clustered database of ~33 million protein sequences covering the known diversity of protein families. UniRef50 clusters sequences at 50% identity, providing broad coverage while reducing redundancy.\nArchitecture: ESM-1b uses a BERT-style bidirectional transformer with 650 million parameters:\n\n\n\nComponent\nSpecification\n\n\n\n\nLayers\n33\n\n\nHidden dimension\n1,280\n\n\nAttention heads\n20\n\n\nParameters\n650M\n\n\nMax sequence length\n1,024 amino acids\n\n\n\nTraining objective: Masked language modeling (MLM)—the model learns to predict randomly masked amino acids given surrounding context. This is analogous to BERT’s masked token prediction, but operating on amino acids rather than words.\n\n\n9.2.2 What ESM Learns\nDespite never seeing structural or functional labels during training, ESM learns representations that capture:\nSecondary structure: Attention patterns in ESM correlate with alpha helices and beta sheets. The model implicitly learns that certain amino acid patterns form specific structural elements.\nContact prediction: ESM’s attention heads capture residue-residue contacts—amino acids that are distant in sequence but close in 3D space. This emergent capability suggests the model learns aspects of protein folding from sequence statistics alone.\nEvolutionary conservation: Masked token predictions correlate with position-specific conservation scores from multiple sequence alignments. ESM effectively learns which positions tolerate variation and which are constrained.\nFunctional sites: Attention concentrates on catalytic residues, binding sites, and other functionally important positions, even without explicit functional annotation.\n\n\n9.2.3 ESM-2: Scaling Up\nESM-2 extended the ESM approach with larger models and improved training (Lin et al. 2022):\n\n\n\nModel\nParameters\nLayers\nPerformance\n\n\n\n\nESM-2 (8M)\n8M\n6\nBaseline\n\n\nESM-2 (35M)\n35M\n12\n+5% contact prediction\n\n\nESM-2 (150M)\n150M\n30\n+8% contact prediction\n\n\nESM-2 (650M)\n650M\n33\n+12% contact prediction\n\n\nESM-2 (3B)\n3B\n36\n+15% contact prediction\n\n\nESM-2 (15B)\n15B\n48\nState-of-the-art\n\n\n\nPerformance scales smoothly with model size across structure prediction, contact prediction, and variant effect tasks—a phenomenon mirroring the scaling laws observed in natural language processing.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#prottrans-alternative-architectures",
    "href": "ch-p3-plm.html#prottrans-alternative-architectures",
    "title": "9  Protein Language Models",
    "section": "9.3 ProtTrans: Alternative Architectures",
    "text": "9.3 ProtTrans: Alternative Architectures\nThe ProtTrans family explored multiple transformer architectures for protein sequences:\nProtBERT: BERT-style bidirectional encoder trained on BFD (Big Fantastic Database), comprising ~2.1 billion protein sequences.\nProtT5: Encoder-decoder architecture based on T5, enabling both understanding and generation tasks.\nProtXLNet: XLNet-style permutation language modeling, capturing bidirectional context without the [MASK] token artifact.\nProtTrans models demonstrated that the protein language modeling paradigm generalizes across architectures. The choice between encoder-only (BERT-style) and encoder-decoder (T5-style) models depends on the downstream application: encoders excel at classification and embedding tasks, while encoder-decoders enable sequence generation.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#esm-1v-zero-shot-variant-effect-prediction",
    "href": "ch-p3-plm.html#esm-1v-zero-shot-variant-effect-prediction",
    "title": "9  Protein Language Models",
    "section": "9.4 ESM-1v: Zero-Shot Variant Effect Prediction",
    "text": "9.4 ESM-1v: Zero-Shot Variant Effect Prediction\nA critical application of protein language models is predicting the effects of amino acid substitutions—missense variants that are the most common type of protein-coding mutation.\n\n9.4.1 The Zero-Shot Approach\nESM-1v (2021) demonstrated that PLMs can predict variant effects without any training on variant labels. The approach exploits masked language modeling: for a variant at position \\(i\\) changing amino acid \\(a\\) to \\(b\\), compute:\n\\[\\Delta \\text{score} = \\log P(b | \\text{context}) - \\log P(a | \\text{context})\\]\nIf the model assigns higher probability to the mutant amino acid than the wild-type, the variant is predicted benign; if lower, deleterious. This “zero-shot” prediction requires no labeled training data—the model’s evolutionary knowledge, learned from sequence databases, directly informs variant interpretation.\n\n\n9.4.2 Genome-Wide Prediction\nBrandes et al. (2023) applied ESM-1b to predict effects for all ~450 million possible missense variants in the human genome (Brandes et al. 2023):\nScale: Every position × every possible substitution across all human proteins\nPerformance on ClinVar: ESM-1b outperformed existing methods in classifying ~150,000 ClinVar/HGMD missense variants as pathogenic or benign\nDeep mutational scanning: Strong correlation with experimental measurements across 28 DMS datasets\nIsoform-specific effects: ~2 million variants annotated as damaging only in specific protein isoforms, highlighting the importance of considering alternative splicing\nThis work established PLMs as practical tools for clinical variant interpretation, capable of scoring variants that lack experimental characterization or evolutionary homologs.\n\n\n9.4.3 Benchmarking on ProteinGym\nProteinGym provides a comprehensive benchmark for variant effect predictors, aggregating 217 deep mutational scanning assays covering diverse proteins (Notin et al. 2023):\n\n\n\nMethod\nMean Spearman ρ\n\n\n\n\nESM-1v\n0.48\n\n\nEVE (evolutionary model)\n0.46\n\n\nDeepSequence\n0.44\n\n\nPolyPhen-2\n0.32\n\n\nSIFT\n0.30\n\n\n\nPLMs achieve competitive or superior performance to methods that explicitly model evolutionary conservation from multiple sequence alignments, despite using only single sequences as input.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#esmfold-structure-from-sequence",
    "href": "ch-p3-plm.html#esmfold-structure-from-sequence",
    "title": "9  Protein Language Models",
    "section": "9.5 ESMFold: Structure from Sequence",
    "text": "9.5 ESMFold: Structure from Sequence\n\n9.5.1 From Language Model to Structure Predictor\nThe most dramatic demonstration of PLM capabilities came with ESMFold, which predicts protein 3D structure directly from ESM-2 embeddings (Lin et al. 2022).\nTraditional structure prediction (including AlphaFold2) relies heavily on multiple sequence alignments (MSAs)—computationally expensive searches against sequence databases that can take hours per protein. ESMFold eliminates this requirement:\nArchitecture: ESMFold couples ESM-2 (15B parameters) with a structure module adapted from AlphaFold2. The language model embeddings replace MSA-derived features.\nSpeed: ~60× faster than AlphaFold2 for typical proteins, enabling metagenomic-scale structure prediction\nAccuracy: Achieves atomic-level accuracy for many proteins, though slightly below AlphaFold2 for proteins that benefit from MSA information\n\n\n9.5.2 What This Reveals About PLMs\nESMFold’s success demonstrates that ESM-2’s internal representations encode sufficient information to determine 3D structure. The language model has learned not just local sequence patterns but global folding principles—what makes a sequence fold into a particular shape.\nThis has profound implications: the “attention” that transformers pay to distant sequence positions during masked prediction is, in some sense, learning the physics of protein folding. Residues that need to be close in 3D space attend to each other in the transformer’s attention matrices.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#transfer-to-genomics-cadd-and-alphamissense",
    "href": "ch-p3-plm.html#transfer-to-genomics-cadd-and-alphamissense",
    "title": "9  Protein Language Models",
    "section": "9.6 Transfer to Genomics: CADD and AlphaMissense",
    "text": "9.6 Transfer to Genomics: CADD and AlphaMissense\n\n9.6.1 CADD v1.7: PLM Features for Variant Prioritization\nThe Combined Annotation Dependent Depletion (CADD) framework integrates diverse annotations to score variant deleteriousness (Chapter 3). CADD v1.7 incorporated ESM-1v predictions as features (Schubach et al. 2024):\nIntegration approach: ESM-1v scores are computed for all missense variants and included alongside conservation scores, functional annotations, and regulatory predictions.\nPerformance gains:\n\n\n\nBenchmark\nCADD v1.6\nCADD v1.7\nImprovement\n\n\n\n\nClinVar pathogenic vs. common\n0.94\n0.95\n+1%\n\n\nDeep mutational scanning (31 datasets)\n0.78\n0.81\n+3%\n\n\n\nThe PLM features particularly improve scoring for variants in regions with limited evolutionary conservation data, where traditional methods struggle.\n\n\n9.6.2 AlphaMissense: Combining PLM and Structure\nAlphaMissense represents the state-of-the-art in missense variant effect prediction, combining PLM representations with structural context (Cheng et al. 2023):\nArchitecture: AlphaMissense adapts AlphaFold’s architecture, fine-tuning on human and primate variant population frequency databases. The model learns to predict pathogenicity by combining:\n\nSequence embeddings from ESM-style language modeling\nStructural context from predicted protein structures\nEvolutionary information from cross-species comparisons\n\nTraining data: Population frequency databases (gnomAD) provide weak labels—common variants are likely benign, absent variants may be deleterious. Critically, AlphaMissense never trains on clinical pathogenicity labels (ClinVar), yet achieves state-of-the-art performance on clinical benchmarks.\nScale: Predictions for all ~71 million possible single amino acid substitutions across the human proteome\nClassification: 89% of missense variants classified as either likely benign or likely pathogenic, providing actionable predictions for the vast majority of possible variants\n\n\n9.6.3 Performance Comparison\n\n\n\nMethod\nClinVar AUC\nDMS Correlation\nTraining Data\n\n\n\n\nSIFT\n0.78\n0.30\nConservation\n\n\nPolyPhen-2\n0.82\n0.32\nConservation + structure\n\n\nCADD v1.7\n0.95\n0.81\nMulti-feature integration\n\n\nESM-1v\n0.89\n0.48\nSequence only (zero-shot)\n\n\nAlphaMissense\n0.94\n0.52\nPLM + structure + population\n\n\n\nAlphaMissense achieves top performance by integrating the strengths of multiple approaches: PLM-derived sequence understanding, AlphaFold-derived structural context, and population genetics-derived evolutionary constraint signals.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#lessons-for-genomic-language-models",
    "href": "ch-p3-plm.html#lessons-for-genomic-language-models",
    "title": "9  Protein Language Models",
    "section": "9.7 Lessons for Genomic Language Models",
    "text": "9.7 Lessons for Genomic Language Models\nThe success of protein language models established several principles that inform genomic foundation modeling:\n\n9.7.1 Self-Supervision Works\nPLMs demonstrated that massive amounts of biological knowledge can be learned from unlabeled sequences. The same evolutionary pressures that shape proteins also shape DNA—purifying selection removes deleterious variants, leaving statistical signatures in sequence databases.\n\n\n9.7.2 Scale Matters\nPerformance improves predictably with model size, motivating the development of larger genomic models. The 8M → 15B parameter progression in ESM-2 showed consistent gains across tasks.\n\n\n9.7.3 Transfer Learning is Effective\nRepresentations learned for one task (masked token prediction) transfer to other tasks (structure prediction, variant effects). This suggests that self-supervised pretraining captures fundamental biological knowledge rather than task-specific shortcuts.\n\n\n9.7.4 Architecture Choices\nThe BERT-style bidirectional encoder proved highly effective for proteins, where the entire sequence context is available. However, genomic sequences present different challenges: much longer lengths (genes span kilobases, genomes span gigabases), different information density (proteins are information-dense, intergenic regions less so), and different symmetries (DNA has reverse-complement structure absent in proteins).\n\n\n9.7.5 Integration with Other Modalities\nAlphaMissense showed that PLM embeddings combine effectively with structural information. Similarly, genomic models benefit from integration with epigenomic data, gene annotations, and other biological context.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#limitations-and-ongoing-challenges",
    "href": "ch-p3-plm.html#limitations-and-ongoing-challenges",
    "title": "9  Protein Language Models",
    "section": "9.8 Limitations and Ongoing Challenges",
    "text": "9.8 Limitations and Ongoing Challenges\n\n9.8.1 Sequence Length\nMost PLMs handle sequences up to ~1,000–2,000 amino acids. While sufficient for most individual proteins, this limits modeling of large protein complexes and doesn’t directly transfer to the much longer sequences in genomics.\n\n\n9.8.2 Orphan Proteins\nPLMs struggle with proteins that have few homologs in training databases. “Orphan” or “dark” proteins—those unique to specific lineages—lack the evolutionary signal that PLMs exploit.\n\n\n9.8.3 Epistasis\nMost variant effect predictions assume independence—the effect of mutation A doesn’t depend on whether mutation B is present. Real proteins exhibit epistasis, where variant effects depend on sequence context.\n\n\n9.8.4 Interpretability\nWhile attention patterns correlate with biological features, understanding exactly what PLMs learn remains challenging. The field is developing interpretation methods (Chapter 15), but PLMs remain partially “black box.”",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-plm.html#significance",
    "href": "ch-p3-plm.html#significance",
    "title": "9  Protein Language Models",
    "section": "9.9 Significance",
    "text": "9.9 Significance\nProtein language models established that transformer architectures can learn deep biological knowledge from sequence data alone. ESM’s ability to predict structure, function, and variant effects without explicit labels demonstrated the power of self-supervised learning on evolutionary data.\nThis success directly motivated the development of genomic language models. If proteins are a language that transformers can learn, perhaps DNA is too. The genomic language models covered in Chapter 10 adapt PLM architectures and training strategies to the distinct challenges of DNA sequences—longer contexts, different alphabets, and the full complexity of gene regulation.\nThe integration path also continues: just as CADD v1.7 and AlphaMissense incorporate PLM predictions, future models will integrate genomic and proteomic language models into unified frameworks (Chapter 13, Chapter 16). The central dogma of molecular biology—DNA → RNA → protein—suggests that models capturing all three modalities may achieve the deepest understanding of how genomes encode life.\n\n\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.” Nature Genetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, et al. 2022. “[ESM-2] Language Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction.” bioRxiv. https://doi.org/10.1101/2022.07.20.500902.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. “ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design.” Advances in Neural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. “[ESM-1b] Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.” Proceedings of the National Academy of Sciences of the United States of America 118 (15): e2016239118. https://doi.org/10.1073/pnas.2016239118.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html",
    "href": "ch-p3-glm.html",
    "title": "10  DNA Foundation Models",
    "section": "",
    "text": "10.1 From Supervised CNNs to Self-Supervised Genomic LMs\nGenomic language models extend the ideas of protein language models (Chapter 9) to the DNA level: they treat genomes themselves as a “corpus,” learn statistical regularities through self-supervision, and reuse those representations for many downstream tasks.\nWhere Chapters 5–7 focused on supervised sequence-to-function CNNs and specialized architectures, and Chapter 8 focused on representation and tokenization, this chapter turns to DNA foundation models—large, often transformer-based or hybrid architectures trained on unlabeled genomic sequence at scale.\nThese models aim to provide a single, reusable backbone for tasks ranging from regulatory annotation and variant effect prediction to cross-species transfer and clinical prioritization. They mark the transition from “a model per dataset” to general-purpose genomic backbones analogous to BERT, GPT, and ESM in natural and protein language modeling.\nThe CNN era (DeepSEA, ExPecto, SpliceAI; Chapters 5–7) shared a common pattern:\nThis approach achieved remarkable performance but suffers from three fundamental constraints:\nProtein language models (Chapter 9) showed a different route: self-supervised learning on unlabeled sequences, with downstream tasks solved by probing or fine-tuning. Genomic language models import this recipe to DNA:\nThe promise is that once a sufficiently powerful backbone is trained, it becomes the default starting point for nearly any DNA-level prediction problem.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#from-supervised-cnns-to-self-supervised-genomic-lms",
    "href": "ch-p3-glm.html#from-supervised-cnns-to-self-supervised-genomic-lms",
    "title": "10  DNA Foundation Models",
    "section": "",
    "text": "Inputs: One-hot encoded DNA sequence around a locus\n\nTargets: Task-specific labels (chromatin marks, expression, splice junctions)\n\nObjective: Predict those labels using supervised loss functions\n\n\n\nLabel dependence – Every new assay, cell type, or phenotype requires new labeled data.\nTask coupling – Model design is tightly coupled to the task (e.g., splice-aware architectures, expression-distance kernels).\nLimited reuse – Features learned for one problem do not automatically transfer to others.\n\n\n\nData: Large collections of genomic sequences across species, individuals, or functional regions.\nObjectives:\n\nMasked language modeling (MLM): predict masked bases or tokens.\nNext-token or sequence modeling: predict the next token in a sequence.\nHybrid tasks: combine MLM with auxiliary objectives (e.g., predicting annotations).\n\nUsage modes:\n\nFreeze the model and train light-weight probes for specific tasks.\nFine-tune the entire model (or adapters) for specialized downstream tasks.\nUse zero-shot or few-shot scoring by comparing log-likelihoods of alternative sequences or alleles.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#early-genomic-transformers-dnabert-and-dnabert-2",
    "href": "ch-p3-glm.html#early-genomic-transformers-dnabert-and-dnabert-2",
    "title": "10  DNA Foundation Models",
    "section": "10.2 Early Genomic Transformers: DNABERT and DNABERT-2",
    "text": "10.2 Early Genomic Transformers: DNABERT and DNABERT-2\n\n10.2.1 DNABERT — BERT for k-merized DNA\nDNABERT applied the BERT masked language modeling framework to genomic sequences, using overlapping k-mers (e.g., 6-mers) as tokens and training on human reference sequences (Ji et al. 2021). As discussed in Chapter 8, this design had several defining characteristics:\n\nTokenization: Overlapping k-mers created a discrete vocabulary of size (4^k).\nObjective: Masked token prediction, exactly as in BERT.\nInput scale: Context windows of a few hundred base pairs (e.g., 512 tokens).\nDownstream evaluation: Fine-tuned on tasks such as promoter classification, splice site prediction, and transcription factor binding.\n\nDNABERT provided proof of concept that:\n\nSelf-supervised pretraining on raw DNA can improve performance over training from scratch.\nLearned embeddings capture biologically meaningful regularities, even when trained only on the reference genome.\nBERT-style architectures can be re-used across multiple downstream tasks.\n\nHowever, the k-mer design also introduced the limitations detailed in Chapter 8:\n\nNo true sequence compression—overlapping k-mers do not reduce sequence length.\nAmbiguity in positional interpretation—each nucleotide participates in multiple tokens.\nLimited context and scaling, due to quadratic attention and redundant overlapping tokens.\n\n\n\n10.2.2 DNABERT-2 — Toward Better Tokenization and Efficiency\nDNABERT-2 revisited both tokenization and architecture, highlighting how much representation matters for genomic LMs (Zhou et al. 2024).\nKey differences relative to DNABERT:\n\nTokenization: Improved schemes (e.g., BPE-style merges) that better compress redundancies and reduce sequence length.\nEfficiency: Models that scale to larger contexts and corpora without prohibitive memory costs.\nPerformance: Consistent gains on a range of seq2label genomics benchmarks over both DNABERT and non-pretrained baselines.\n\nDNABERT and DNABERT-2 collectively established that:\n\nSelf-supervision on DNA works and is competitive with hand-engineered pipelines.\nTokenization choices (Chapter 8) have large practical consequences.\nMasked LM training can produce reusable representations for diverse sequence tasks.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#scaling-context-and-diversity-nucleotide-transformer",
    "href": "ch-p3-glm.html#scaling-context-and-diversity-nucleotide-transformer",
    "title": "10  DNA Foundation Models",
    "section": "10.3 Scaling Context and Diversity: Nucleotide Transformer",
    "text": "10.3 Scaling Context and Diversity: Nucleotide Transformer\nDNABERT showed feasibility, but its context windows and training data were modest relative to the scale of genomes. Nucleotide Transformer pushed much further, emphasizing scale and diversity (Dalla-Torre et al. 2023):\n\nCorpus: Genomic data spanning multiple species and populations.\nModels: Transformer encoders of various sizes, from moderate to very large parameter counts.\nContext length: Up to ~6 kb per input sequence—an order-of-magnitude jump over DNABERT while still using dense attention (Chapter 8).\nTraining objective: Masked language modeling on subsequences sampled from genomes.\n\nThe Nucleotide Transformer work contributed several important ideas:\n\nCross-species pretraining\nTraining on many genomes (rather than a single reference) exposes the model to:\n\nDiverse sequence patterns and GC content.\nDifferent regulatory architectures.\nEvolutionary constraints that recur across lineages.\n\nThis mirrors the use of large multi-species multiple sequence alignments in protein LMs (Chapter 9) but operates at the raw DNA level.\nBenchmark suite\nTo quantify representation quality, Nucleotide Transformer introduced a benchmark panel of genomic tasks, commonly referred to in later work as the Nucleotide Transformer benchmarks (Dalla-Torre et al. 2023). Typical tasks include:\n\nPromoter and enhancer classification.\nHistone mark and chromatin accessibility prediction.\nVariant/pathogenicity proxies.\nRegulatory element type classification.\n\nModels are evaluated via linear probes, shallow classifiers, or light fine-tuning, providing a standard yardstick for later DNA LMs.\nScaling trends\nAs with protein and natural-language models, performance improves predictably with:\n\nLarger models.\nMore pretraining data.\nLonger context windows.\n\nThese scaling curves help forecast the returns from investing in even larger genomic LMs.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#beyond-dense-attention-hyenadna-and-1-mb-context",
    "href": "ch-p3-glm.html#beyond-dense-attention-hyenadna-and-1-mb-context",
    "title": "10  DNA Foundation Models",
    "section": "10.4 Beyond Dense Attention: HyenaDNA and 1 Mb Context",
    "text": "10.4 Beyond Dense Attention: HyenaDNA and 1 Mb Context\nQuadratic attention limits transformer context length to tens of kilobases at best, even with aggressive engineering. HyenaDNA replaces attention with a Hyena long-convolution / state-space architecture that scales sub-quadratically and can process sequences up to 1 Mb (Nguyen et al. 2023).\nAs summarized in Chapter 8:\n\n\n\nModel\nArchitecture\nMax context\nComplexity\n\n\n\n\nDNABERT\nTransformer\n512 bp\n(O(L^2))\n\n\nNucleotide Transformer\nTransformer\n6 kb\n(O(L^2))\n\n\nHyenaDNA\nHyena\n1 Mb\n(O(L L))\n\n\n\nHyenaDNA introduced several qualitative advances:\n\nMegabase-scale context\nProcessing 1 Mb windows allows the model to “see”:\n\nEntire gene bodies plus flanking regulatory regions.\nLong-range enhancer–promoter interactions.\nTopologically associating domain (TAD)-scale structure.\n\nThis aligns better with biological reality, where regulatory interactions often span tens to hundreds of kilobases.\nSingle-nucleotide resolution\nDespite its long context, HyenaDNA maintains base-level resolution, so single-nucleotide variants can be evaluated in the context of megabases of surrounding sequence.\nIn-context learning signals\nOn Nucleotide Transformer benchmarks and additional tasks, HyenaDNA shows in-context learning behaviors—performance improves when examples are included in the input context without updating model weights (Nguyen et al. 2023). This suggests that at sufficient scale, DNA models can adapt to new tasks or distributions via prompts rather than fine-tuning, mirroring phenomena seen in large language models.\nState-of-the-art performance\nOn GenomicBenchmarks and related evaluations, HyenaDNA achieves state-of-the-art results on the majority of tasks, often by large margins, illustrating that architectural innovations can yield both longer context and better predictive accuracy (Nguyen et al. 2023).",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#generative-regulatory-foundation-models-grover",
    "href": "ch-p3-glm.html#generative-regulatory-foundation-models-grover",
    "title": "10  DNA Foundation Models",
    "section": "10.5 Generative Regulatory Foundation Models: GROVER",
    "text": "10.5 Generative Regulatory Foundation Models: GROVER\nMost models above focus on sequence-level objectives (masked or next-token). GROVER shifts attention from sequence to regulatory tracks (Sanabria et al. 2024):\n\nInputs/outputs: GROVER is trained on multi-track functional genomics signals (e.g., ATAC-seq, histone marks) across many cell types and tissues instead of raw sequence alone.\nObjective: Predict masked or held-out regulatory profiles conditioned on neighboring tracks, cell-type embeddings, or limited sequence context.\nArchitecture: A transformer-style backbone tailored to spatiotemporal grids of genomic positions × assays × cell types.\n\nGROVER plays a role analogous to self-supervised vision models for images:\n\nIt treats regulatory profiles as a high-dimensional “image” over the genome.\nIt learns rich representations of regulatory states at each position.\nIt supports tasks like imputation of missing assays, denoising, and cell-type-specific activity prediction.\n\nWhile not a pure DNA language model, GROVER-style systems complement sequence-based LMs:\n\nDNA LMs capture what the genome can do (the encoded potential).\nRegulatory LMs like GROVER capture what the genome is actually doing in specific contexts (cell types, conditions).\n\nLater chapters (Part IV) explore how sequence-based and regulatory foundation models can be combined—e.g., using DNA LMs to parameterize sequence priors and regulatory LMs for context-specific readouts (Sanabria et al. 2024).",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#central-dogma-aware-and-annotation-enriched-models",
    "href": "ch-p3-glm.html#central-dogma-aware-and-annotation-enriched-models",
    "title": "10  DNA Foundation Models",
    "section": "10.6 Central-Dogma-Aware and Annotation-Enriched Models",
    "text": "10.6 Central-Dogma-Aware and Annotation-Enriched Models\nChapter 8 discussed how tokenization can encode biological structure. Some recent models push this further by integrating central dogma and genomic annotations directly into the modeling framework.\n\n10.6.1 Life-Code: Central Dogma as an Inductive Bias\nLife-Code proposes codon-aware, central-dogma-informed tokenization to bridge DNA, RNA, and protein within a single language-modeling framework (Liu et al. 2025):\n\nCoding regions: Tokenized as codons (3-mers in frame), reflecting the genetic code.\nNoncoding regions: Tokenized via learned subword units.\nIntegration: Unified representations span DNA → RNA → protein, enabling knowledge sharing across modalities.\n\nLife-Code uses distillation from protein LMs (Chapter 9) to:\n\nImport protein-level structural knowledge into DNA/RNA sequence representations.\nImprove performance on tasks involving coding sequence, such as predicting missense effects or expression changes.\nAchieve competitive or state-of-the-art results on tasks across the full central dogma (DNA, RNA, protein) (Liu et al. 2025).\n\n\n\n10.6.2 BioToken: Encoding Variants and Structure as Tokens\nBioToken extends tokenization beyond nucleotide content to include explicit genomic annotations (Medvedev et al. 2025):\n\nVariant-aware tokens: Encode SNPs, insertions, and deletions as distinct tokens rather than implicit changes in sequence.\nStructural annotations: Incorporate information about exons, introns, UTRs, promoters, enhancers, and other regulatory elements.\nFunctional context: Include signals such as chromatin state, conservation scores, or known regulatory motifs.\n\nThis design moves toward fully structured genomic LMs, where:\n\nThe input “sentence” is not only DNA bases but also position-specific metadata.\nRepresentations can directly integrate sequence, structure, and functional annotations.\n\nLife-Code and BioToken foreshadow the multi-modal, multi-omic foundation models discussed in Part IV, where sequence is only one of many integrated information streams.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#using-genomic-lms-in-practice",
    "href": "ch-p3-glm.html#using-genomic-lms-in-practice",
    "title": "10  DNA Foundation Models",
    "section": "10.7 Using Genomic LMs in Practice",
    "text": "10.7 Using Genomic LMs in Practice\nJust as protein LMs can be used in different modes (frozen embeddings, fine-tuning, zero-shot scoring; Chapter 9), genomic LMs have multiple usage patterns.\n\n10.7.1 Embeddings as Universal Features\nThe simplest way to use a genomic LM is to:\n\nExtract embeddings for windows around loci of interest (e.g., 1–6 kb segments).\nPool or select positions relevant to the task (e.g., promoters, candidate enhancers, variant sites).\nTrain a light-weight downstream model (linear layer, small MLP, or logistic regression).\n\nApplications include:\n\nRegulatory element classification: Distinguishing promoters, enhancers, silencers, and insulators.\nChromatin state prediction: Predicting ATAC-seq or histone mark presence from sequence alone, as an alternative to models like DeepSEA (Chapter 5).\nVariant effect scoring: Replacing or augmenting hand-crafted features in frameworks like CADD with LM-derived features (analogous to CADD v1.7’s use of PLM features; Chapter 9; Schubach et al. (2024)).\nSplicing and transcript modeling: Combining LM embeddings with splice-aware architectures like SpliceAI (Chapter 7).\n\nBecause the LM is frozen, this approach is computationally efficient and avoids catastrophic forgetting when new tasks are added.\n\n\n10.7.2 Fine-Tuning and Task-Specific Heads\nWhen more labels are available, fine-tuning can significantly improve performance:\n\nFull fine-tuning: Update all LM parameters for a specific task.\nAdapter-based tuning: Insert small bottleneck modules into each layer and update only those, keeping the backbone mostly frozen.\nPrompt-based tuning: Learn task-specific prompts or prefix embeddings that steer the model’s behavior without changing its core weights.\n\nFine-tuning is especially valuable for:\n\nHigh-stakes clinical tasks where every percentage point matters.\nTasks that probe very specific sequence-function relationships (e.g., particular TF binding specificities).\nScenarios where domain shift is large (e.g., applying a cross-species LM to a previously unseen clade).\n\n\n\n10.7.3 Zero-Shot and Few-Shot Variant Scoring\nAnalogous to protein models like ESM-1v and AlphaMissense (Chapter 9; Brandes et al. (2023); Cheng et al. (2023)), genomic LMs can be used to compute zero-shot variant scores by:\n\nComparing the log-likelihood (or pseudo-likelihood) of sequences with reference vs alternate alleles.\nMeasuring changes in masked-token prediction probabilities at variant positions.\nEvaluating the impact of a variant on internal representations (e.g., vector distances between reference and variant embeddings).\n\nThese approaches can:\n\nProvide rapid prioritization of novel variants without task-specific training.\nComplement supervised classifiers trained on clinical or functional labels (e.g., ClinVar, curated datasets).\nOffer a starting point for more specialized models (e.g., exon-specific splice models, enhancer-specific expression predictors).",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#evaluation-benchmarks-and-pitfalls",
    "href": "ch-p3-glm.html#evaluation-benchmarks-and-pitfalls",
    "title": "10  DNA Foundation Models",
    "section": "10.8 Evaluation, Benchmarks, and Pitfalls",
    "text": "10.8 Evaluation, Benchmarks, and Pitfalls\nAs genomic LMs proliferate, evaluation practices become crucial.\n\n10.8.1 Benchmark Suites\nNucleotide Transformer introduced a widely used benchmark panel (Dalla-Torre et al. 2023), and later work, including HyenaDNA and Life-Code, also reports results on GenomicBenchmarks and related collections (Nguyen et al. 2023). Common traits of these suites include:\n\nMultiple task families:\n\nPromoter/enhancer classification.\nTF binding prediction.\nChromatin accessibility and histone marks.\nSplicing, TSS/TES prediction, or other sequence-label tasks.\n\nStandardized splits:\n\nTrain/validation/test partitions.\nConsistent evaluation metrics (AUROC, AUPRC, accuracy).\n\nBaseline comparisons:\n\nNon-pretrained CNNs and transformers.\nEarlier models like DeepSEA, ExPecto, and SpliceAI.\nPreviously published genomic LMs.\n\n\nThese benchmarks help separate true representational gains from gains due to dataset choice or training tricks.\n\n\n10.8.2 Data Leakage and Overfitting\nGenomic data pose unique leakage challenges:\n\nNearby windows: Overlapping or adjacent windows from the same locus can leak between train and test.\nReverse-complement duplicates: Genomic sequences and their reverse complements may appear in both splits.\nHomologous regions: Repeats, segmental duplications, and conserved elements across chromosomes or species can create hidden redundancy.\n\nTo mitigate this, researchers increasingly use:\n\nChromosome-level splits: Holding out entire chromosomes for testing.\nSpecies-level splits: Training on some species and testing on others.\nCell-type and tissue splits: Ensuring that specific biological contexts are unseen during training of downstream probes.\n\nEven with these precautions, interpreting benchmark gains requires caution: some tasks are easier than others, and improvements may reflect distributional quirks rather than truly deeper understanding of genomic function.\n\n\n10.8.3 Distribution Shift and Clinical Utility\nA model that performs well on curated benchmarks may still struggle in real-world scenarios:\n\nPopulation diversity: Training corpora may underrepresent certain ancestries, leading to biased variant scoring (Chapter 2).\nAssay heterogeneity: Experimental conditions, labs, and technologies differ from the curated datasets used in training.\nPhenotypic complexity: Many clinically relevant phenotypes involve long causal chains—from variant to molecular consequence to tissue-level effect to disease.\n\nThus, genomic LM evaluation increasingly includes:\n\nCross-population robustness.\nOut-of-distribution testing (new tissues, cell types, or species).\nEnd-to-end evaluations on clinically relevant endpoints (e.g., disease risk prediction, rare disease diagnosis), often in combination with traditional statistical genetics tools.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-glm.html#lessons-and-outlook",
    "href": "ch-p3-glm.html#lessons-and-outlook",
    "title": "10  DNA Foundation Models",
    "section": "10.9 Lessons and Outlook",
    "text": "10.9 Lessons and Outlook\nDNA language models bring the “foundation model” paradigm to the genome. Several themes emerge:\n\nRepresentation is central\nTokenization and context length (Chapter 8) are not superficial implementation details—they determine what patterns a model can see and how efficiently it can learn. Life-Code and BioToken show that biologically informed tokenization and annotations can serve as powerful inductive biases (Liu et al. 2025; Medvedev et al. 2025).\nScale and diversity matter\nNucleotide Transformer and HyenaDNA demonstrate that performance improves with both model size and training data diversity (Dalla-Torre et al. 2023; Nguyen et al. 2023). Including multiple species, populations, and genomic contexts yields more robust representations.\nLong-range context is biologically necessary\nMany regulatory phenomena operate at tens to hundreds of kilobases. Megabase-scale models like HyenaDNA show that we can finally begin to model these interactions at single-base resolution in a single forward pass.\nSelf-supervision and supervision are complementary\nSelf-supervised LMs excel at learning broad, reusable features, but they do not automatically solve every downstream problem. Specialized architectures and supervised objectives (e.g., Enformer and related models in Chapter 11) remain crucial for accurate quantitative prediction of complex genomic readouts.\nIntegration with other modalities is the next frontier\nModels like GROVER, Life-Code, and BioToken hint at a future where DNA LMs are one part of larger multi-modal genomic foundation models that integrate:\n\nSequence (DNA, RNA, protein).\nRegulatory profiles (chromatin, expression).\n3D genome organization.\nPopulation genetics, phenotypes, and clinical data.\n\n\nThis chapter has focused on sequence-centric DNA LMs and their immediate extensions. In Chapter 11, we turn to Enformer and related long-range sequence-to-function models that explicitly predict molecular readouts from sequence, closing the loop between self-supervised sequence understanding and supervised functional prediction.\n\n\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.” Nature Genetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025. “Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. “[GROVER] DNA Language Model GROVER Learns Sequence Context in the Human Genome.” Nature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. “DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>DNA Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html",
    "href": "ch-p3-hybrid.html",
    "title": "11  Long-range Hybrid Models",
    "section": "",
    "text": "11.1 Why Expression Needs Long-Range Models\nExPecto (Chapter 6) showed that gene expression can be predicted ab initio from sequence by combining a CNN-based chromatin model (Beluga) with a separate regression layer mapping chromatin features to expression across tissues (Zhou et al. 2018). This modular strategy worked surprisingly well, but it inherited two key limitations from its DeepSEA-style backbone (Chapter 5):\nAs genomic datasets grew (ENCODE, Roadmap, FANTOM, GTEx, and others; Chapter 4), it became clear that:\nPure CNN architectures can expand their receptive field using dilated convolutions and pooling, but doing so at single-nucleotide resolution quickly becomes parameter- and memory-intensive. On the other hand, classic transformer architectures can model long-range dependencies via attention, but their \\(O(L^2)\\) runtime and memory makes naïve application to 200 kb sequences infeasible (Chapter 10).\nHybrid architectures like Enformer and Borzoi emerged as a compromise:\nThis chapter focuses on these hybrid designs—particularly Enformer (Avsec et al. 2021) and Borzoi (Linder et al. 2025)—and how they changed what “sequence-to-expression” models can do.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html#why-expression-needs-long-range-models",
    "href": "ch-p3-hybrid.html#why-expression-needs-long-range-models",
    "title": "11  Long-range Hybrid Models",
    "section": "",
    "text": "Restricted context: A 40 kb input window captures proximal promoters and some nearby enhancers, but many regulatory interactions span 100 kb or more.\nTwo-stage learning: Chromatin prediction and expression prediction are trained separately, leaving no opportunity for the expression objective to shape the representation of sequence.\n\n\n\nEnhancers can regulate genes hundreds of kilobases away.\neQTLs often sit outside promoter windows traditionally used for expression models.\nChromatin conformation (loops, TADs) introduces non-local dependencies between DNA segments.\n\n\n\n\nUse convolutions to extract local motif features and progressively downsample the sequence into a manageable number of latent positions.\nApply self-attention over this compressed representation to capture long-range regulatory interactions across ~100–200 kb.\nPredict many signals at once (chromatin profiles, transcription start site activity, RNA-seq coverage), enabling multi-task learning and rich variant effect prediction.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html#problem-setting-sequence-to-expression-at-scale",
    "href": "ch-p3-hybrid.html#problem-setting-sequence-to-expression-at-scale",
    "title": "11  Long-range Hybrid Models",
    "section": "11.2 Problem Setting: Sequence-to-Expression at Scale",
    "text": "11.2 Problem Setting: Sequence-to-Expression at Scale\nThe models in this chapter tackle a demanding version of the classic problem:\n\nGiven a long DNA sequence window around a genomic locus, predict a rich set of regulatory and transcriptional readouts across many cell types.\n\n\n11.2.1 Inputs\n\nDNA sequence: One-hot encoded sequence:\n\nLength: typically ~200 kb centered on a candidate promoter or gene.\nAlphabet: A/C/G/T (N masked or handled by special channels).\n\nPositional indexing:\n\nThe model must know where promoter-proximal bases and distal elements are, relative to each other.\nPositional information is encoded via convolutional receptive fields and/or explicit positional embeddings for the attention layers.\n\n\n\n\n11.2.2 Outputs\nEnformer and Borzoi are both multi-task, multi-position sequence-to-signal models:\n\nMultiple assays:\n\nDNase/ATAC-seq (chromatin accessibility)\nHistone marks (e.g., H3K4me3, H3K27ac, etc.)\nCAGE or RNA-seq signals related to transcription and expression.\n\nMultiple cell types / conditions:\n\nHundreds of tracks, each representing a signal in a particular cell type or experimental context.\n\nMultiple positions along the window:\n\nPredictions are made at fixed strides across the input window (e.g., every 128 or 256 bp), yielding a coverage track rather than a single scalar.\n\n\n\n\n11.2.3 Loss Functions\nTypical objective:\n\nPer-track, per-position regression:\n\nOften a Poisson or negative binomial likelihood on read counts.\nSometimes log-transformed counts with a mean-squared error loss.\n\nMulti-task weighting:\n\nAll tracks contribute to the loss.\nSome models tune weights to prevent abundant assays (e.g., DNase) from dominating scarce but important ones (e.g., rare histone marks).\n\n\nThe learning problem is thus:\n\\[\nf_\\theta: \\text{DNA sequence (≈200 kb)} \\rightarrow \\text{[Tracks × Positions] continuous outputs}\n\\]\nwith \\(\\theta\\) shared across assays, cell types, and genomic loci.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html#enformer-cnn-attention-for-200-kb-context",
    "href": "ch-p3-hybrid.html#enformer-cnn-attention-for-200-kb-context",
    "title": "11  Long-range Hybrid Models",
    "section": "11.3 Enformer: CNN + Attention for 200 kb Context",
    "text": "11.3 Enformer: CNN + Attention for 200 kb Context\nEnformer (Avsec et al. 2021) is a landmark model that directly integrates long-range sequence context with cell-type-specific expression prediction, using a hybrid CNN–transformer architecture.\n\n11.3.1 Architectural Overview\nConceptually, Enformer has three stages:\n\nConvolutional stem:\nExtract local motifs and progressively downsample the sequence.\nTransformer trunk:\nApply self-attention to model long-range dependencies between downsampled positions.\nHeads for multi-task outputs:\nDecode the attended representation into assay- and cell-type-specific coverage tracks.\n\nA high-level architecture table is:\n\n\n\n\n\n\n\n\nStage\nFunction\nKey Characteristics\n\n\n\n\nCNN stem\nLocal motif extraction, downsampling\nResidual + dilated convs, pooling\n\n\nTransformer blocks\nLong-range dependency modeling\nMulti-head self-attention, MLPs\n\n\nOutput heads\nPredict assays across positions & cells\nTask-specific linear projections\n\n\n\n\n11.3.1.1 1. Convolutional Stem\nThe convolutional front-end:\n\nTakes ~200 kb one-hot sequence as input.\nApplies stacked conv–norm–nonlinearity–pooling layers.\nExpands receptive field while downsampling length by a large factor (e.g., 128–256×).\n\nThe resulting representation can be viewed as:\n\nA sequence of \\(L'\\) latent tokens (\\(L' \\ll L\\)), each summarizing a multi-kilobase region.\nEach token encodes local motif configurations and short-range regulatory patterns.\n\nThis step solves the “attention on raw nucleotides” problem by:\n\nReducing a 200,000 bp sequence into, say, ~1,000–2,000 tokens.\nAllowing attention to operate at a much lower effective resolution.\n\n\n\n11.3.1.2 2. Transformer Trunk\nEnformer then applies several transformer blocks over the compressed sequence:\n\nMulti-head self-attention:\n\nEvery downsampled position can attend to every other position.\nCaptures relationships between distant enhancers and promoters, or between multiple regulatory elements.\n\nFeed-forward networks (MLPs):\n\nNonlinear mixing of information at each position.\n\nResidual connections and normalization:\n\nStabilize training and enable deep stacks.\n\n\nIntuitively:\n\nConvolution layers answer:\n“What motifs and local patterns exist in this region?”\nAttention layers answer:\n“How do these regions interact across the 200 kb window to shape regulatory activity?”\n\n\n\n11.3.1.3 3. Multi-Task Output Heads\nAfter attention, Enformer:\n\nApplies task-specific heads to each position in the latent sequence.\nProduces coverage predictions for each assay × cell type combination.\n\nFor CAGE-based transcription start site (TSS) activity:\n\nThe model predicts coverage around TSS positions.\nGene-level expression metrics can be obtained by aggregating predictions at positions near annotated TSSs (e.g., summing or averaging log counts across a small window).\n\n\n\n\n11.3.2 Training Data and Objective\nEnformer is trained on a large collection of human and mouse regulatory datasets:\n\nHuman:\n\nDNase, histone ChIP-seq, and CAGE across many cell types.\n\nMouse:\n\nAnalogous assays used for cross-species learning.\n\n\nKey design choices:\n\nJoint human–mouse training:\n\nEncourages the model to learn regulatory principles conserved across mammals.\nEnables zero-shot transfer between species for some tasks.\n\nChromosome holdout:\n\nEntire chromosomes held out for evaluation to avoid overly optimistic performance via local sequence similarity.\n\n\nThe loss aggregates over:\n\nAll targets (tracks).\nAll positions in the output window.\nAll training loci.\n\n\n\n11.3.3 Enformer as a Variant Effect Predictor\nLike DeepSEA, Enformer can be used for in silico variant effect prediction:\n\nExtract a 200 kb window around a locus from the reference genome.\nRun Enformer to obtain predicted coverage tracks.\nIntroduce an alternative allele (e.g., SNP) into the window.\nRe-predict coverage and compute Δ-prediction:\n\\[\n\\Delta \\text{signal} = f_\\theta(\\text{alt sequence}) - f_\\theta(\\text{ref sequence})\n\\]\nAggregate Δ-predictions around TSSs to quantify predicted expression change for genes in each cell type.\n\nThis approach allows:\n\nFine-grained assessment of how a variant might alter promoter-proximal signals and distal enhancer contributions.\nIntegration into downstream tools (e.g., fine-mapping pipelines) that require variant-level scores.\n\n\n\n11.3.4 eQTL Validation via GTEx\nEnformer’s variant effect predictions were systematically evaluated using GTEx eQTL data (Chapter 4):\n\nFor each gene–tissue pair:\n\nKnown eQTLs (lead variants) and non-eQTL variants in LD were compared.\n\nSigned LD profile (SLDP) regression:\n\nCorrelates predicted expression effects with observed eQTL effect sizes, accounting for LD structure.\n\nFindings (Avsec et al. 2021):\n\nEnformer’s predictions showed stronger alignment with observed eQTLs than prior models like Basenji2 (a purely convolutional long-range model).\nImprovement was especially notable at distal regulatory variants, where long-range attention is crucial.\n\n\nIn practice, this means Enformer:\n\nCan prioritize variants likely to be causal eQTLs.\nProvides cell-type-specific effect predictions, which are critical for interpreting tissues with sparse experimental data.\n\n\n\n11.3.5 Interpretation and Mechanistic Insight\nWhile Enformer is a complex model, several interpretation strategies provide mechanistic insight:\n\nGradient-based attribution:\n\nCompute gradients of gene-level expression predictions with respect to input sequence.\nHighlight bases or motifs that drive the predicted expression of a gene in a specific cell type.\n\nIn silico mutagenesis:\n\nSystematically mutate bases to estimate their impact on a target gene or track.\nIdentify enhancers and key transcription factor binding sites controlling expression.\n\nPerturbation of attention:\n\nAnalyze which positions attend most strongly to a promoter, revealing candidate long-range enhancers.\n\n\nThese tools have been used to:\n\nMap promoter–enhancer interactions directly from sequence.\nSuggest causal regulatory elements for disease-associated variants.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html#borzoi-transcriptome-centric-hybrid-modeling",
    "href": "ch-p3-hybrid.html#borzoi-transcriptome-centric-hybrid-modeling",
    "title": "11  Long-range Hybrid Models",
    "section": "11.4 Borzoi: Transcriptome-Centric Hybrid Modeling",
    "text": "11.4 Borzoi: Transcriptome-Centric Hybrid Modeling\nEnformer is primarily trained on chromatin and CAGE profiles. Borzoi (Linder et al. 2025) extends the hybrid architecture paradigm to model the RNA transcriptome itself, with an emphasis on finer-grained transcriptional features.\n\n11.4.1 Motivation\nRNA-seq data carries richer information than a single expression scalar per gene:\n\nCoverage along exons and introns:\n\nReflects transcription initiation, elongation, and termination.\n\nSplice junction usage:\n\nReveals alternative splicing patterns (complementing Chapter 7’s SpliceAI).\n\nPolyadenylation and 3′ UTR usage:\n\nImpacts mRNA stability, localization, and translation.\n\n\nA general-purpose model that predicts base-level RNA-seq read coverage from DNA sequence could:\n\nProvide a unified framework for transcript-level variant effect prediction (transcription, splicing, polyadenylation).\nOffer mechanistic insight into how regulatory sequence features shape the full life cycle of transcripts.\n\n\n\n11.4.2 Architectural Highlights\nBorzoi builds on the Enformer-style backbone:\n\nConvolutional front-end:\n\nProcesses long DNA windows (on the order of ~100–200 kb).\nLearns local motifs and regulatory patterns at single-nucleotide or modestly downsampled resolution.\n\nHybrid long-range module:\n\nUses attention and/or long-range convolutions to integrate information across the entire context.\nExplicitly designed to capture relationships between promoters, internal exons, and distal elements.\n\nMulti-layer output heads:\n\nPredict RNA-seq coverage tracks across the window.\nOutput separate tracks for:\n\nSense vs antisense transcription.\nSplice junction signals.\nPolyA-related coverage around 3′ ends.\n\n\n\nLike Enformer, Borzoi is trained in a multi-task regime, but with a stronger emphasis on RNA-related readouts.\n\n\n11.4.3 From Chromatin Signals to RNA Readouts\nConceptually, Borzoi closes the loop:\n\nDeepSEA/Beluga/Enformer:\nSequence → chromatin + transcription start activity\nBorzoi:\nSequence → full transcriptome coverage\n\nThis supports several analyses:\n\nPromoter usage:\n\nDistinguish alternative promoter TSSs based on coverage patterns.\n\nAlternative splicing:\n\nPredict differential exon inclusion or skipping, complementing specialized models like SpliceAI.\n\n3′ UTR and polyA site choice:\n\nModel coverage drop-offs and polyA-linked patterns.\n\n\nVariant effect prediction follows similar steps as with Enformer:\n\nPredict transcriptome outputs for reference and alternate sequences.\nCompute Δ-coverage at exons, splice junctions, and 3′ ends.\nAggregate into variant-level scores for tasks like eQTL or sQTL prioritization.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html#what-hybrid-models-changed",
    "href": "ch-p3-hybrid.html#what-hybrid-models-changed",
    "title": "11  Long-range Hybrid Models",
    "section": "11.5 What Hybrid Models Changed",
    "text": "11.5 What Hybrid Models Changed\nHybrid CNN–transformer sequence models like Enformer and Borzoi introduced several conceptual advances over earlier architectures.\n\n11.5.1 1. Explicit Long-Range Modeling\nBy combining convolutional downsampling with attention over latent tokens, these models:\n\nAchieve hundreds of kilobases of effective context with manageable compute.\nAllow all positions in the compressed representation to interact, approximating many possible promoter–enhancer relationships.\n\nThis is crucial for:\n\nCapturing distal enhancers that sit far from genes.\nModeling complex regulatory architectures where multiple enhancers and silencers integrate to control expression.\n\n\n\n11.5.2 2. Unified Multi-Task Learning Across Modalities\nHybrid models jointly predict:\n\nChromatin accessibility.\nHistone marks.\nTranscriptional activity (CAGE, RNA-seq).\n\nThe result:\n\nShared representations that capture general regulatory logic.\nRegularization across assays and cell types, reducing overfitting to any single dataset.\nA pathway to transfer learning, where a single pretrained model can be adapted to downstream tasks.\n\n\n\n11.5.3 3. Improved Variant Effect Prediction for Expression\nCompared to earlier CNN-only models (DeepSEA, Beluga, ExPecto, Basenji2):\n\nEnformer demonstrated stronger eQTL concordance and better performance on expression-related benchmarks (Avsec et al. 2021).\nHybrid designs can identify distal causal variants more reliably, because their architecture naturally encodes long-range dependencies.\n\nBorzoi takes this further by providing detailed transcriptome-level readouts, enabling:\n\nCombined assessment of transcription, splicing, and polyadenylation for each variant.\nA richer mechanistic understanding of how sequence variation impacts the full RNA life cycle.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html#limitations-and-failure-modes",
    "href": "ch-p3-hybrid.html#limitations-and-failure-modes",
    "title": "11  Long-range Hybrid Models",
    "section": "11.6 Limitations and Failure Modes",
    "text": "11.6 Limitations and Failure Modes\nDespite their power, hybrid long-range models are not omniscient and introduce new challenges.\n\n11.6.1 Data and Label Limitations\n\nBiased training data:\n\nENCODE/Roadmap assays focus on specific cell types, conditions, and regions.\nGTEx eQTLs are enriched for certain ancestries (Chapter 2).\n\nMissing modalities:\n\nMany regulatory phenomena (e.g., RNA binding protein effects, 3D structure beyond contact frequency) are only partially captured by the available assays.\n\n\nAs a result, the models may:\n\nUnderperform in cell types or ancestries not well represented in the training data.\nMisinterpret patterns that are confounded by technical artifacts (batch effects, mapping biases).\n\n\n\n11.6.2 Sequence Context and Generalization\n\nEnformer and Borzoi are trained on fixed window sizes around annotated loci:\n\nBehavior outside those canonical windows may be less reliable.\n\nTraining focuses on reference genome context:\n\nLarge indels, structural variants, or rearrangements may be poorly modeled.\n\nThe models assume linear genomic context:\n\n3D chromatin architecture is only indirectly captured via sequence patterns correlated with looping; explicit Hi-C or Micro-C integration is limited.\n\n\n\n\n11.6.3 Interpretability and Trust\nAlthough attribution methods exist:\n\nAttention weights and gradient-based scores are not direct causal evidence.\nAttributions can be noisy and sensitive to how targets are aggregated.\nFor clinical use, predictions often require orthogonal validation, e.g., CRISPR perturbation or allele-specific expression assays.\n\nThese issues are part of the broader interpretability challenges discussed in later chapters on evaluation and confounders.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p3-hybrid.html#role-in-the-gfm-landscape",
    "href": "ch-p3-hybrid.html#role-in-the-gfm-landscape",
    "title": "11  Long-range Hybrid Models",
    "section": "11.7 Role in the GFM Landscape",
    "text": "11.7 Role in the GFM Landscape\nHybrid architectures like Enformer and Borzoi occupy an interesting middle ground between task-specific CNNs and general-purpose genomic foundation models:\n\nCompared to earlier CNN systems:\n\nThey model much longer context and support richer multi-modal outputs.\nThey offer significantly improved expression-related variant effect prediction.\n\nCompared to modern GFMs (Chapters 12–13):\n\nThey are specialized and supervised on particular assays, not trained with broad self-supervision on raw genomes.\nTheir architecture is hand-crafted for specific tasks (chromatin + expression), rather than serving as a universal pretraining backbone.\n\n\nIn practice, they serve as:\n\nHigh-performance baselines for variant effect prediction tasks, especially when expression or RNA readouts are primary endpoints.\nPretraining sources: Representations learned by Enformer-like trunks can be adapted for downstream tasks or combined with pretrained language models over DNA.\nDesign templates: Many newer architectures borrow the “conv stem + long-range module + multi-task heads” pattern, swapping attention for alternative long-range mechanisms (e.g., state space models, Hyena, Mamba; Chapter 12).\n\nAs the field moves toward large, multi-modal genomic foundation models that integrate sequence, chromatin, expression, and 3D structure, Enformer and Borzoi represent key waypoints—demonstrating that:\n\nLong-range context is essential for accurate expression prediction.\nHybrid architectures can make such context computationally tractable.\nMulti-task supervision across regulatory layers is an effective path from raw DNA to clinically relevant variant effect predictions.\n\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[ExPecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.",
    "crumbs": [
      "Part III: Transformers Models",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html",
    "href": "ch-p4-principles.html",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "",
    "text": "12.1 From Task-Specific Models to Genomic Foundation Models\nGenomic foundation models (GFMs) are the culmination of several threads developed across the earlier parts of this book: high-fidelity variant calling, regulatory sequence-to-function prediction, protein language models, and long-context transformers for DNA. They extend these ideas into models that are general-purpose, pretrained at scale, and reusable across a wide range of genomic and genetic tasks.\nThis chapter steps back from individual architectures to define what it means for a model to be a genomic foundation model, organizes the emerging ecosystem into a practical taxonomy, and distills design principles that will guide the rest of Part IV.\nThe earlier chapters traced a fairly linear progression:\nFoundation models build on these ingredients but change the contract:\nHyenaDNA is a canonical example: a genomic foundation model pretrained on the human reference genome with context lengths up to 1M tokens at single-nucleotide resolution using a Hyena-based long-range architecture. DNABERT-2, Nucleotide Transformer V2, Caduceus-Ph, GROVER and related models form a parallel family of transformer-style DNA FMs. A recent benchmark comparing these five models across diverse tasks (classification, gene expression prediction, variant effect quantification, TAD recognition) illustrates both the promise and the limitations of current DNA FMs (Manzo, Borkowski, and Ovcharenko 2025).\nAt a high level, we can view GFMs as extending the “pretrain → finetune” paradigm from natural language and protein modeling into genomics, but with domain-specific constraints (extreme context lengths, single-nucleotide sensitivity, strong mechanistic priors).",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#from-task-specific-models-to-genomic-foundation-models",
    "href": "ch-p4-principles.html#from-task-specific-models-to-genomic-foundation-models",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "",
    "text": "Hand-crafted scores and shallow models such as CADD and early pathogenicity predictors (Rentzsch et al. 2019; Schubach et al. 2024).\nTask-specific deep models such as DeepSEA, ExPecto, Sei, Enformer and SpliceAI, which learn regulatory or splicing effects directly from sequence (J. Zhou and Troyanskaya 2015; J. Zhou et al. 2018; Chen et al. 2022; Avsec et al. 2021; Jaganathan et al. 2019).\nSequence language models over proteins and DNA (ESM, DNABERT, Nucleotide Transformer, HyenaDNA, GROVER) that learn general sequence representations via self-supervision (Rives et al. 2021; Lin et al. 2022; Brandes et al. 2023; Ji et al. 2021; Dalla-Torre et al. 2023; Nguyen et al. 2023; Sanabria et al. 2024).\n\n\n\nThe primary “product” of a GFM is not a task-specific prediction head, but a reusable representation (and sometimes a general interface) that can be adapted to many downstream tasks with modest additional supervision.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#what-makes-a-model-a-genomic-foundation-model",
    "href": "ch-p4-principles.html#what-makes-a-model-a-genomic-foundation-model",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.2 What Makes a Model a Genomic Foundation Model?",
    "text": "12.2 What Makes a Model a Genomic Foundation Model?\nThe term “foundation model” is sometimes used loosely in the genomics literature. For practical purposes, it is useful to define working criteria that separate GFMs from ordinary deep models.\n\n12.2.1 Working definition\nA genomic foundation model is a pre-trained model that:\n\nLearns from large-scale genomic data with minimal task-specific supervision\n\nPretraining on entire genomes (or large portions) across species or populations.\nObjectives such as masked language modeling, next-token prediction, denoising, or multi-task sequence-to-function prediction.\n\nProduces general-purpose representations\n\nEmbeddings of sequences, variants, loci, or genes that are useful across many downstream tasks.\nRepresentations can be extracted and reused with light adapters or linear probes.\n\nIs designed for broad transfer\n\nSupports many downstream tasks without retraining the full model.\nTransfer across assays (e.g., from chromatin marks to gene expression), tissues, species, or variant types.\n\nScales along at least one dimension\n\nContext length (e.g., HyenaDNA’s million-token window).\nParameter count (e.g., ESM and Nucleotide Transformer families).\nData diversity (e.g., pan-genomic pretraining, cross-species corpora).\n\nExposes a relatively standardized interface\n\nA common API for embeddings, sequence scoring, and mask-based perturbation.\nOften distributed via model hubs (e.g., Hugging Face) with documented downstream recipes.\n\n\nMany excellent deep models for genomics (e.g., early DeepSEA or SpliceAI) fail one or more of these criteria: they were trained for a specific assay or task, use narrowly scoped inputs/outputs, and are not designed for broad reuse.\n\n\n12.2.2 GFMs vs “just big models”\nScale alone does not make a model a foundation model. A very large Enformer-like model trained solely on human chromatin tracks is powerful but still strongly bound to a specific prediction interface (e.g., sequence → fixed set of chromatin tracks). By contrast, a DNA LM like HyenaDNA or DNABERT-2 is explicitly trained to model raw sequence using a general objective, and is naturally repurposed as an embedding engine.\nThe distinction matters because it affects:\n\nEvaluation: GFMs must be assessed across families of tasks (e.g., TraitGym, ProteinGym) (Benegas, Eraslan, and Song 2025; Notin et al. 2023).\nDeployment: GFMs are infrastructure that many downstream teams can reuse; task-specific models are closer to “applications.”",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#taxonomy-of-genomic-foundation-models",
    "href": "ch-p4-principles.html#taxonomy-of-genomic-foundation-models",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.3 Taxonomy of Genomic Foundation Models",
    "text": "12.3 Taxonomy of Genomic Foundation Models\nWe will use a pragmatic taxonomy based on input modality and pretraining objective rather than architecture alone.\n\n12.3.1 DNA language models\nThese models treat DNA as a “language” and learn to predict masked or next tokens. Representative examples include:\n\nDNABERT / DNABERT-2: k-mer and nucleotide-level transformers trained with masked language modeling on large genomic corpora (Ji et al. 2021; Z. Zhou et al. 2024).\nNucleotide Transformer: large-scale transformer LMs trained across multiple species, with variants V1/V2 differing in context length and pretraining data (Dalla-Torre et al. 2023).\nHyenaDNA: a long-range genomic FM using Hyena operators (implicit convolutions) with sub-quadratic scaling, trained on human reference with up to 1M-token contexts and single-nucleotide vocabulary (Nguyen et al. 2023).\nGROVER: an autoregressive DNA LM that learns rich sequence context and shows strong performance on annotation and variant tasks (Sanabria et al. 2024).\n\nStrengths\n\nNatural fit for representation learning: the main output is a contextual embedding for each nucleotide or token.\nFlexible adaptation: any task that can be phrased as “score a sequence or variant” can be built on top.\nCompatible with in-context learning and soft prompting (see HyenaDNA) for some tasks.\n\nLimitations\n\nIndirect modeling of quantitative functional readouts (e.g., expression, epigenetic signal).\nDifficult to interpret mechanistically compared to sequence-to-function models that predict explicit assays.\n\n\n\n12.3.2 Regulatory sequence-to-function GFMs\nBuilding on DeepSEA, ExPecto, Sei, and Enformer (J. Zhou and Troyanskaya 2015; J. Zhou et al. 2018; Chen et al. 2022; Avsec et al. 2021), newer models aim to:\n\nPredict hundreds to thousands of chromatin marks, TF binding profiles, and accessibility tracks from raw sequence.\nOperate over longer context windows (100 kb or more).\nProvide variant effect scores by computing \\(\\Delta\\)-predictions between reference and alternative alleles.\n\nWhile some of these models were originally trained for specific assays, they approximate GFMs when:\n\nThe output space is sufficiently broad (e.g., a panel of assays spanning many cell types).\nTheir internal representations are reused for tasks beyond the original assay set, such as gene expression prediction, enhancer–promoter linking, or variant prioritization.\n\nEnformer is a prototypical example of a sequence-to-function model that has been widely reused as a feature extractor for downstream tasks, including gene expression prediction and fine-mapping of regulatory variants (Avsec et al. 2021).\n\n\n12.3.3 Variant-centric GFMs and trait models\nA third class of GFMs focuses not on raw sequence but on genetic variants as the fundamental unit. These models often:\n\nEmbed variants using contextual information from local sequence, gene structure, and external annotations.\nPredict variant pathogenicity, molecular consequences, or trait-level effect sizes.\n\nExamples in this space include:\n\nCADD and its deep-learning-enhanced successor models, which integrate annotations and sequence features for broad variant pathogenicity scoring (Rentzsch et al. 2019; Schubach et al. 2024).\nAlphaMissense, which repurposes ESM-style protein LMs to predict missense pathogenicity at scale (Cheng et al. 2023).\nDelphi, MIFM, and related models that couple GFMs with polygenic risk score (PRS) estimation for complex traits (Georgantas, Kutalik, and Richiardi 2024; Rakowski and Lippert 2025; Wu et al. 2024).\nEmerging variant representation learning datasets and benchmarks (e.g., GV-Rep) that explicitly probe how well GFMs represent genetic variants and clinical annotations.\n\nVariant-centric GFMs blur the line between feature extractors and trait models: their predictions can be plugged directly into PRS pipelines, risk stratification tools, or rare disease interpretation workflows.\n\n\n12.3.4 Multi-omic and cross-modal GFMs\nFinally, a growing set of models aim to natively integrate multiple modalities:\n\nDNA sequence, chromatin state, and gene expression.\nSequence and 3D genome structure (Hi-C, Micro-C).\nDNA with non-sequence modalities such as images or free text.\n\nRecent work (e.g., Omni-DNA) explores transformer-based auto-regressive models that jointly handle DNA and task-specific tokens, enabling multi-task learning over sequence, epigenetic marks, and even textual descriptions of function. These models move GFMs closer to a unified interface for genome biology, at the cost of more complex training objectives and data engineering.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#design-dimensions-of-genomic-foundation-models",
    "href": "ch-p4-principles.html#design-dimensions-of-genomic-foundation-models",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.4 Design Dimensions of Genomic Foundation Models",
    "text": "12.4 Design Dimensions of Genomic Foundation Models\nWhen designing or choosing a GFM, it is helpful to think in terms of several orthogonal design dimensions.\n\n12.4.1 Data: what does the model “see”?\nKey data decisions include:\n\nSpecies coverage\n\nHuman-only: focused on clinical and human genetics applications.\nCross-species: pretraining on dozens or hundreds of species (as in Nucleotide Transformer and many protein LMs) encourages discovery of conserved regulatory code and better out-of-domain generalization (Dalla-Torre et al. 2023; Rives et al. 2021).\n\nAssay diversity\n\nFor sequence-to-function GFMs: which epigenomic assays, cell types, and perturbation datasets are included (e.g., Cistrome-like collections (Zheng et al. 2019)).\nFor variant-centric GFMs: which clinical databases, experimental screens, and population cohorts are integrated.\n\nPopulation diversity\n\nInclusion of genomes from diverse ancestries is crucial to avoid embedding population-specific biases into GFMs and downstream risk scores.\nEarly deep PRS models such as Delphi and MIFM explicitly tackle ancestry-aware evaluation (Georgantas, Kutalik, and Richiardi 2024; Rakowski and Lippert 2025; Wu et al. 2024).\n\nContext length and sampling\n\nRandom slicing of long chromosomes into training windows (HyenaDNA).\nTargeted sampling around genes, enhancers, or known variants.\nWarm-up schedules that gradually increase context length to stabilize training.\n\n\n\n\n12.4.2 Architecture: how does the model process sequence?\nCommon architectural families include:\n\nTransformers\n\nEncoder-only (BERT-style; DNABERT, Nucleotide Transformer).\nDecoder-only (GPT-style; GROVER, some Omni-DNA models).\nEncoder–decoder hybrids for tasks requiring explicit outputs (e.g., sequence→text explanations).\n\nAttention-free long-range models\n\nHyena-based models (HyenaDNA): implicit convolutions with sub-quadratic complexity.\nState space models and related architectures that trade exact attention for scalable long-range interactions.\n\nDense-attention long-range transformers\n\nModels like Gene42 show that with careful engineering and context extension schedules, dense-attention transformers can also reach ~200 kb contexts at single-nucleotide resolution.\n\nHybrid architectures\n\nCNN + transformer stacks (e.g., local convolutions followed by global attention, as seen in some Enformer-like models (Avsec et al. 2021)).\nCross-attention between DNA and auxiliary modalities (e.g., chromatin, 3D contacts).\n\n\nArchitecture choices primarily determine:\n\nMaximum practical context length.\nMemory and compute requirements.\nEase of adaptation (e.g., decoder-only models are often easier to use for generative tasks, transformers easier for cross-modal fusion).\n\n\n\n12.4.3 Objectives: what does the model learn to predict?\nTypical pretraining objectives include:\n\nMasked token prediction\n\nRandomly mask nucleotides or k-mers and predict them given context (DNABERT, DNABERT-2, many transformers) (Ji et al. 2021; Z. Zhou et al. 2024).\nEncourages the model to capture local and medium-range dependencies.\n\nNext-token prediction\n\nAutoregressive LM objective (GROVER, HyenaDNA).\nNaturally aligns with generative tasks and in-context learning, and leverages techniques from large language models.\n\nDenoising and span corruptions\n\nReplace or permute spans of sequence and train the model to reconstruct them.\nEncourages robustness to small perturbations and focus on long-range structure.\n\nMulti-task sequence-to-function prediction\n\nPredict chromatin profiles, TF binding, accessibility, expression, etc., directly from sequence (DeepSEA, Enformer, Sei) (J. Zhou and Troyanskaya 2015; Avsec et al. 2021; Chen et al. 2022).\nFunctions as a powerful regularizer and a direct bridge between sequence patterns and molecular readouts.\n\nCross-modal objectives\n\nJointly predict sequence, epigenetic tracks, and textual/function labels (e.g., in Omni-DNA-like architectures).\nContrastive alignment between DNA slices and other modalities (e.g., 3D contacts, histone marks).\n\n\n\n\n12.4.4 Tokenization and representations\nTokenization is non-trivial for DNA:\n\nCharacter-level (single nucleotide): simplest and compatible with single-nucleotide resolution, used by HyenaDNA and many sequence-to-function models (Nguyen et al. 2023).\nk-mer tokenization (e.g., 3–6-mers) reduces sequence length and helps transformers reach longer effective contexts, at the cost of some resolution (Ji et al. 2021).\nLearned tokenization (e.g., BioToken-style approaches) which discover sub-sequence units optimized for downstream performance (Medvedev et al. 2025).\n\nInternally, GFMs typically produce:\n\nPer-position embeddings \\(h_i \\in \\mathbb{R}^d\\) for each nucleotide or token.\nPooled sequence embeddings (mean, CLS token, learned pooling) that summarize an entire region.\nVariant embeddings, constructed by contrasting reference vs alternative alleles, sometimes augmented with structural context.\n\nThe choice of pooling strategy can significantly influence downstream performance; benchmarking studies have found that simple mean pooling of per-token embeddings often outperforms more elaborate strategies across many tasks (Manzo, Borkowski, and Ovcharenko 2025).",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#evaluating-genomic-foundation-models",
    "href": "ch-p4-principles.html#evaluating-genomic-foundation-models",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.5 Evaluating Genomic Foundation Models",
    "text": "12.5 Evaluating Genomic Foundation Models\nBecause GFMs are meant to be foundations, evaluation must be broader than single-task metrics.\n\n12.5.1 Downstream task suites and benchmarks\nEmerging benchmark suites provide structured evaluations:\n\nProteinGym: variant effect prediction across many proteins for protein LMs (Notin et al. 2023).\nTraitGym: trait-level performance of regulatory and genomic models across complex trait prediction tasks (Benegas, Eraslan, and Song 2025).\nComparative evaluations of DNA LMs and regulatory models, such as the work by Manzo et al. comparing sequence models across regulatory genomics tasks (Manzo, Borkowski, and Ovcharenko 2025).\nDNA FM benchmarks that systematically compare models like DNABERT-2, Nucleotide Transformer V2, HyenaDNA, Caduceus-Ph, and GROVER across classification, variant effect, and TAD tasks.\nVariant-centric benchmarks like GV-Rep, probing GFMs’ ability to represent clinical variants and their contexts.\n\nA key lesson from these benchmarks is that no single model dominates all tasks: general-purpose DNA FMs often perform well but may lag specialized architectures for gene expression and QTL prediction, while excelling for variant prioritization and regulatory element annotation.\n\n\n12.5.2 Evaluation modes: zero-shot, linear probe, fine-tune\nGFMs can be evaluated in several regimes:\n\nZero-shot evaluation\n\nUse frozen embeddings with simple operations (similarity, clustering) or predefined scoring rules.\nExample: using HyenaDNA embeddings directly for in-context learning on simple motif tasks.\n\nLinear probes\n\nTrain shallow linear or logistic regression heads on top of frozen embeddings.\nProvides a quick measure of how easily information is linearly decodable from GFM representations.\n\nLight-weight adaptation\n\nLow-rank adaptation (LoRA), prompt tuning, or small MLP heads fine-tuned on specific tasks.\nBalances performance with computational cost and stability.\n\nFull-model finetuning\n\nFinetune all parameters for high-stakes tasks where maximal performance is critical and data is abundant.\nRisk of catastrophic forgetting or overfitting, especially when downstream data is limited.\n\n\nThe right regime depends on data size, computational budget, and the sensitivity of the application (e.g., rare disease diagnosis vs exploratory motif discovery).",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#using-gfms-in-practice",
    "href": "ch-p4-principles.html#using-gfms-in-practice",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.6 Using GFMs in Practice",
    "text": "12.6 Using GFMs in Practice\nFrom the vantage point of a working computational biologist, the most pressing questions are “Which model should I use?” and “How do I plug it into my pipeline?”\n\n12.6.1 Typical usage patterns\nCommon ways to use GFMs include:\n\nEmbedding-based pipelines\n\nExtract per-base or pooled embeddings for loci of interest.\nTrain simple downstream models (e.g., gradient-boosted trees, small neural nets) on these embeddings.\nEvaluate on held-out datasets or across cohorts.\n\nVariant effect scoring\n\nUse sequence-to-function GFMs (Enformer-like) to compute \\(\\Delta\\)-predictions between reference and alternate alleles.\nFeed variant-level scores into downstream calibration layers or PRS models (Avsec et al. 2021; Georgantas, Kutalik, and Richiardi 2024; Rakowski and Lippert 2025).\n\nFeature augmentation\n\nCombine GFM-derived features with classical annotations (conservation, CADD scores, functional genomics tracks) (Rentzsch et al. 2019; Schubach et al. 2024).\nParticularly useful for rare variant interpretation where each evidence source is sparse.\n\nCross-modal linking\n\nUse GFMs as common embedding spaces linking sequence with expression, imaging, or textual annotations (e.g., variant→phenotype descriptions).\n\n\n\n\n12.6.2 Choosing a model for your use case\nA simple decision guide:\n\nNeed long-range context (&gt;100 kb)?\n\nConsider models like HyenaDNA or long-context dense-attention models such as Gene42.\n\nFocus on regulatory variant interpretation near genes?\n\nStart with Enformer-like or DeepSEA-like GFMs and compare against DNA LMs working via embeddings (Avsec et al. 2021; J. Zhou and Troyanskaya 2015; Chen et al. 2022; Ji et al. 2021).\n\nTrait-level prediction with large cohorts?\n\nExplore PRS pipelines that incorporate GFM-based variant priors such as Delphi or MIFM (Georgantas, Kutalik, and Richiardi 2024; Rakowski and Lippert 2025; Wu et al. 2024).\n\nMethod development / benchmarking?\n\nUse standardized benchmarks (TraitGym, ProteinGym, GV-Rep, DNA FM suites) to ensure your comparisons are meaningful (Benegas, Eraslan, and Song 2025; Notin et al. 2023; Manzo, Borkowski, and Ovcharenko 2025).",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#safety-robustness-and-responsible-use",
    "href": "ch-p4-principles.html#safety-robustness-and-responsible-use",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.7 Safety, Robustness, and Responsible Use",
    "text": "12.7 Safety, Robustness, and Responsible Use\nAs GFMs become infrastructure for clinical and research pipelines, safety and robustness are not optional extras.\n\n12.7.1 Robustness and adversarial sensitivity\nRecent work such as SafeGenes highlights that genomic FMs (including ESM1b-like and other GFMs) can be surprisingly sensitive to adversarial perturbations—both at the input sequence level and through soft prompts in embedding space. Even when perturbations are hardly biologically plausible, they reveal:\n\nFragility of decision boundaries in high-dimensional representation space.\nPotential failure modes where small spurious changes strongly impact pathogenicity or variant effect predictions.\n\nThis suggests that:\n\nAdversarial testing should become part of GFM validation, especially for clinical use cases.\nRobust training (e.g., via data augmentation, adversarial objectives, or distributionally robust optimization) may be needed for high-stakes tasks.\n\n\n\n12.7.2 12.7.2 Bias, fairness, and ancestry\nGFMs trained predominantly on reference genomes or Euro-centric cohorts risk encoding biased priors:\n\nUnderestimation of risk in underrepresented ancestries.\nMisclassification of benign variants that are common in certain populations but rare in training data.\n\nDeep PRS and variant interpretation pipelines that incorporate GFMs should:\n\nPerform ancestry-stratified evaluation (Georgantas, Kutalik, and Richiardi 2024; Rakowski and Lippert 2025; Wu et al. 2024).\nConsider explicit debiasing (e.g., reweighting) and careful calibration.\n\n\n\n12.7.3 Data governance and privacy\nBecause GFMs are often trained on large collections of genomic sequences:\n\nData use agreements and privacy protections must be respected; some cohort-level datasets cannot be used for unrestricted pretraining.\nEven when training on reference genomes, leakage from labeled clinical datasets into training may complicate downstream evaluation.\n\nTo date, most published GFMs emphasize training on public reference genomes or synthetic benchmarks, but clinical deployment will require stronger guarantees.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#open-challenges-and-future-directions",
    "href": "ch-p4-principles.html#open-challenges-and-future-directions",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.8 Open Challenges and Future Directions",
    "text": "12.8 Open Challenges and Future Directions\nGenomic foundation models are still in their early days. Several open challenges stand out.\n\n12.8.1 Toward unified multi-omic GFMs\nCurrent GFMs are still fragmented:\n\nDNA-only LMs.\nSequence-to-function models tied to specific assays.\nVariant-centric pathogenicity models.\nProtein and RNA LMs.\n\nA major frontier is unified multi-omic GFMs that:\n\nJointly model DNA, RNA, protein, chromatin, and 3D genome structure.\nSupport cross-modal queries such as “given this variant, what is the likely impact on TF binding, chromatin accessibility, and gene expression in a given cell type?”\nProvide interpretable pathways connecting sequence variation to phenotypes.\n\nModels such as Omni-DNA are first steps in this direction, showing that multi-task, cross-modal training is feasible at scale.\n\n\n12.8.2 Integrating causal and mechanistic structure\nMost GFMs are trained with purely predictive objectives. Incorporating more causal structure could:\n\nImprove robustness to distribution shift (e.g., between cell types or interventions).\nEnable counterfactual reasoning (“what if we knock out this enhancer?”).\n\nPotential routes include:\n\nCausal representation learning on top of GFM embeddings.\nMechanistic constraints derived from gene regulatory networks or biochemical kinetics.\nJoint modeling of perturbation data (CRISPR screens, gene knockouts) with observational genomics.\n\n\n\n12.8.3 Efficient and accessible deployment\nEven if GFMs train on large clusters, their deployment should be feasible in typical research labs and clinical environments:\n\nDistillation into smaller student models.\nEfficient inference via sparsity, quantization, and hardware-aware architectures.\nTask-specific adapters that keep the frozen backbone small enough for on-premise use.\n\nThe long-range efficiency of architectures like HyenaDNA and the emergence of dense-attention models like Gene42 suggest multiple viable paths to deployable GFMs.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-principles.html#summary",
    "href": "ch-p4-principles.html#summary",
    "title": "12  Genomic FMs: Principles & Practice",
    "section": "12.9 Summary",
    "text": "12.9 Summary\nIn this chapter, we:\n\nDefined what it means for a model to be a genomic foundation model, emphasizing scale, generality, and reusability.\nProposed a practical taxonomy: DNA language models, sequence-to-function GFMs, variant-centric GFMs, and emerging multi-omic models.\nSurveyed core design dimensions: data, architecture, objectives, and tokenization.\nDiscussed evaluation regimes and benchmark suites that assess GFMs across diverse tasks.\nOutlined how practitioners can integrate GFMs into variant interpretation, regulatory genomics, and trait prediction pipelines.\nHighlighted emerging concerns around robustness, bias, and responsible deployment.\n\nThe remaining chapters of Part IV will dive deeper into specific application domains—clinical interpretation, population-scale trait modeling, and multi-omics integration—using the conceptual framework established here to organize a rapidly evolving ecosystem of genomic foundation models.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.” Nature Genetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, et al. 2022. “[ESM-2] Language Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction.” bioRxiv. https://doi.org/10.1101/2022.07.20.500902.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025. “Comparative Analysis of Deep Learning Models for Predicting Causative Regulatory Variants.” bioRxiv: The Preprint Server for Biology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. “ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design.” Advances in Neural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. “[ESM-1b] Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.” Proceedings of the National Academy of Sciences of the United States of America 118 (15): e2016239118. https://doi.org/10.1073/pnas.2016239118.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. “[GROVER] DNA Language Model GROVER Learns Sequence Context in the Human Genome.” Nature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nZheng, Rongbin, Changxin Wan, Shenglin Mei, Qian Qin, Qiu Wu, Hanfei Sun, Chen-Hao Chen, et al. 2019. “Cistrome Data Browser: Expanded Datasets and New Tools for Gene Regulatory Analysis.” Nucleic Acids Research 47 (D1): D729–35. https://doi.org/10.1093/nar/gky1094.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[ExPecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. “DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Genomic FMs: Principles & Practice</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html",
    "href": "ch-p4-vep.html",
    "title": "13  Variant Effect Prediction",
    "section": "",
    "text": "13.1 From Handcrafted Scores to Foundation Models\nVariant effect prediction (VEP) sits at the heart of modern genomics. Most variants discovered in clinical sequencing are rare and lack direct experimental evidence; yet clinicians still need to decide whether they’re benign, pathogenic, or somewhere in between. Earlier in this book we saw:\nThe frontier today is shaped by foundation models that combine:\nThis chapter surveys four landmark systems:\nTogether, they preview what “Genomic Foundation Models” look like when specialized for variant interpretation.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#from-handcrafted-scores-to-foundation-models",
    "href": "ch-p4-vep.html#from-handcrafted-scores-to-foundation-models",
    "title": "13  Variant Effect Prediction",
    "section": "",
    "text": "Conservation and heuristic scores (e.g., traditional tools like SIFT, PolyPhen, CADD), which combine evolutionary constraint and manually engineered features.\nSequence-to-function CNNs like DeepSEA and ExPecto (Chapters 5–6), which predict chromatin and expression to estimate regulatory effects.\nSpecialized architectures like SpliceAI (Chapter 7), which target specific mechanisms such as splicing.\nProtein language models (Chapter 9), which learn rich representations from large-scale protein sequences and can be adapted for missense VEP.\n\n\n\nMassive pretraining (proteome- or genome-scale),\nLong-range context (from kilobases to megabases),\nMultiple sources of information (sequence, structure, multi-species alignments, multi-omic outputs).\n\n\n\nAlphaMissense – proteome-wide missense pathogenicity predictions.\nGPN-MSA – a DNA language model over multi-species alignments for genome-wide VEP.\nEvo 2 – a generalist genomic language model spanning all domains of life.\nAlphaGenome – a unified, megabase-scale sequence-to-function model with state-of-the-art regulatory VEP.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#alphamissense-proteome-wide-missense-pathogenicity",
    "href": "ch-p4-vep.html#alphamissense-proteome-wide-missense-pathogenicity",
    "title": "13  Variant Effect Prediction",
    "section": "13.2 AlphaMissense: Proteome-Wide Missense Pathogenicity",
    "text": "13.2 AlphaMissense: Proteome-Wide Missense Pathogenicity\nAlphaMissense, developed by DeepMind, provides precomputed pathogenicity scores for ~71 million possible human missense variants, covering almost every single–amino acid change in the proteome.\n\n13.2.1 Inputs: Combining Sequence and Structure\nAlphaMissense builds on two pillars:\n\nProtein language modeling\n\nA transformer-based model is trained on massive multiple sequence alignments (MSAs), learning which amino acids tend to appear at each position across evolution.\n\nFrom this, the model infers how “surprising” a given amino acid substitution is in its evolutionary context.\n\nPredicted 3D structure from AlphaFold2\n\nStructural context (packing, secondary structure, local interactions) helps distinguish tolerated changes (e.g., on solvent-exposed loops) from disruptive ones (e.g., in tightly packed cores or active sites).\n\n\nFor each variant, AlphaMissense ingests:\n\nThe wild-type sequence,\nThe substitution position and amino-acid change,\nSequence context from the MSA,\nStructural environment derived from AlphaFold2.\n\nThese features are fed into a neural network that outputs a pathogenicity probability between 0 and 1.\n\n\n13.2.2 Training and Calibration\nAlphaMissense’s training is hybrid:\n\nSelf-supervised pretraining learns general sequence and structural representations from evolutionary data.\nSupervised calibration uses:\n\nClinVar and similar databases for labeled pathogenic/benign variants,\nPopulation frequencies (e.g., gnomAD) under the assumption that common variants are more likely benign.\n\n\nThe model’s raw scores are calibrated so that:\n\nScores near 0 behave like “likely benign,”\n\nScores near 1 behave like “likely pathogenic,”\n\nIntermediate scores capture uncertainty and ambiguous cases.\n\nIn practice, AlphaMissense adopts score cutoffs that approximately map to “likely benign,” “uncertain,” and “likely pathogenic” categories used in clinical interpretation frameworks.\n\n\n13.2.3 Performance and Clinical Utility\nAcross diverse benchmarks—ClinVar, curated expert panels, and multiplexed assays of variant effect (MAVEs)—AlphaMissense:\n\nAchieves state-of-the-art AUROC and AUPRC for missense VEP.\nGeneralizes across many genes, including those with little prior annotation.\nProduces scores that are more consistent with experimental functional readouts than many earlier predictors.\n\nAs a result, AlphaMissense scores have already been integrated into:\n\nClinical re-annotation of exomes,\n\nReclassification of variants of uncertain significance (VUS),\n\nGene-specific studies where high-throughput functional assays are impractical.\n\n\n\n13.2.4 Limitations and Caveats\nDespite its impressive performance, AlphaMissense has important limitations:\n\nMissense-only: It does not natively handle nonsense, frameshift, regulatory, or deep intronic variants.\nSingle-variant focus: It scores one substitution at a time, ignoring combinations of variants (compound heterozygosity, epistasis).\nDependent on training labels: Any biases in ClinVar or population data (e.g., ancestry representation) can propagate into scores.\nInterpretability: While attention maps and feature attributions can be examined, the reasoning for a particular score is often opaque.\n\nFor these reasons, guidelines recommend treating AlphaMissense as supporting evidence to be combined with segregation, functional data, and population frequencies—not as a standalone decision-maker.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#gpn-msa-genome-wide-variant-effect-prediction-from-msas",
    "href": "ch-p4-vep.html#gpn-msa-genome-wide-variant-effect-prediction-from-msas",
    "title": "13  Variant Effect Prediction",
    "section": "13.3 GPN-MSA: Genome-Wide Variant Effect Prediction from MSAs",
    "text": "13.3 GPN-MSA: Genome-Wide Variant Effect Prediction from MSAs\nWhile AlphaMissense focuses on proteins, GPN-MSA tackles the harder problem of genome-wide variant effect prediction in complex genomes such as human, directly at the DNA level.\n\n13.3.1 Alignment-Based DNA Language Model\nGPN-MSA extends earlier Genomic Pre-trained Network (GPN) models by operating on multi-species genome alignments:\n\nInput: a stack of aligned sequences from multiple species (e.g., human plus dozens of mammals).\nRepresentation: the model sees both:\n\nThe reference sequence (e.g., human), and\n\nAuxiliary features encoding how each aligned species matches, mismatches, or gaps at each base.\n\n\nThe model is trained with a masked language modeling (MLM) objective:\n\nRandomly mask nucleotides in the reference sequence,\nPredict the masked base given the surrounding context and the aligned sequences.\n\nThis encourages the model to learn evolutionary constraints: positions where substitutions are strongly disfavored across species get very confident predictions; unconstrained positions allow more flexibility.\n\n\n13.3.2 Variant Scoring Strategies\nGPN-MSA supports several ways to derive variant effect scores:\n\nLikelihood-based scoring: compare the model’s log-likelihood (or probability) of the reference vs. alternate allele at the variant position.\nEmbedding distance: compute embeddings for reference and alternate sequences and use their difference (e.g., Euclidean distance) as an effect magnitude.\nInfluence scores: quantify how much a variant perturbs the model’s outputs across the surrounding genomic context.\n\nBecause the model operates on whole-genome alignments, it can score:\n\nCoding and noncoding variants,\nRegulatory elements, introns, UTRs, and intergenic regions,\nVariants in regions with complex conservation patterns, where simple phyloP-like scores struggle.\n\n\n\n13.3.3 Benchmarking and Applications\nGPN-MSA demonstrates strong performance on:\n\nGenome-wide pathogenic vs. benign classification datasets,\nVariant sets from genome-wide association studies,\nFunctional readouts from high-throughput reporter assays.\n\nPractically, GPN-MSA is useful for:\n\nGenome-wide prefiltering: prioritizing candidate causal variants in regulatory regions.\nComplementing protein-focused tools: supplying information where AlphaMissense is blind (deep noncoding, intronic, intergenic).\n\nIts key limitation is dependency on high-quality multi-species alignments; coverage and quality drop in repetitive, structurally complex, or poorly aligned regions.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#evo-2-a-generalist-genomic-language-model",
    "href": "ch-p4-vep.html#evo-2-a-generalist-genomic-language-model",
    "title": "13  Variant Effect Prediction",
    "section": "13.4 Evo 2: A Generalist Genomic Language Model",
    "text": "13.4 Evo 2: A Generalist Genomic Language Model\nEvo 2 pushes the foundation-model paradigm to the extreme: it is a genome-scale language model trained across all domains of life—bacteria, archaea, eukaryotes, and phages—on &gt;9 trillion DNA tokens.\n\n13.4.1 Scale and Architecture\nKey features of Evo 2 include:\n\nAutoregressive training on DNA: predict the next base given the preceding context, analogous to next-token prediction in text LLMs.\nA StripedHyena 2 architecture, blending convolutional and attention mechanisms to support:\n\nContext windows up to 1 million base pairs,\n\nEfficient long-range modeling.\n\nMultiple model sizes (e.g., 7B and 40B parameters) with open-source weights, training code, and the OpenGenome2 dataset.\n\nEvo 2 is designed as a generalist: it is not trained specifically for VEP, but rather to model genomic sequences broadly.\n\n\n13.4.2 Zero-Shot Variant Effect Scoring\nRemarkably, Evo 2 can be used for zero-shot variant interpretation:\n\nFor a given locus, compute the model’s sequence likelihood (or log-probability) for the reference allele.\nThen compute the likelihood for the alternate allele (or sequence containing it).\nThe difference in likelihood provides a variant effect score—variants that strongly reduce probability are inferred to be more disruptive.\n\nIn benchmarks reported in the preprint and follow-up analyses:\n\nEvo 2 achieves competitive or state-of-the-art accuracy for pathogenic vs. benign classification across multiple variant types (coding and noncoding), even without variant-specific supervised training.\nA simple supervised classifier built on Evo 2 embeddings reaches state-of-the-art performance on tasks like BRCA1 VUS classification.\n\n\n\n13.4.3 Cross-Species Variant Interpretation\nBecause Evo 2 is trained across diverse species:\n\nIt naturally supports variant effect prediction in non-model organisms (e.g., livestock, crops).\nIt can help quantify mutation load, prioritize variants for breeding programs, and guide genome editing designs across species.\n\nHowever, its generality comes with trade-offs:\n\nDomain-specific models (like AlphaMissense for human missense or AlphaGenome for regulatory variants) may still outperform Evo 2 on certain human-centric tasks.\nCareful calibration and benchmarking are required before clinical use.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#alphagenome-unified-megabase-scale-regulatory-modeling",
    "href": "ch-p4-vep.html#alphagenome-unified-megabase-scale-regulatory-modeling",
    "title": "13  Variant Effect Prediction",
    "section": "13.5 AlphaGenome: Unified Megabase-Scale Regulatory Modeling",
    "text": "13.5 AlphaGenome: Unified Megabase-Scale Regulatory Modeling\nWhere Evo 2 is generalist and sequence-only, AlphaGenome is explicitly designed as a multimodal regulatory model of the human genome, with a focus on variant effect prediction across many functional readouts.\n\n13.5.1 Architecture: CNNs + Transformers over 1 Mbp\nAlphaGenome takes as input 1 megabase (1 Mb) of DNA sequence and produces predictions at single-base resolution for a large set of genomic “tracks,” including:\n\nChromatin accessibility and histone marks,\nTranscription factor binding,\nGene expression (e.g., CAGE-like signals),\n3D genome contacts,\nSplicing features (junctions and splice-site usage).\n\nArchitecturally:\n\nConvolutional layers detect local sequence motifs.\nTransformer blocks propagate information across the full megabase context.\nTask-specific heads output different experimental modalities across many tissues and cell types.\n\nThis design generalizes earlier models like Basenji/Enformer (for regulatory tracks) and SpliceAI (for splicing) into a single, unified model.\n\n\n13.5.2 Variant Effect Prediction Across Modalities\nGiven a reference sequence and a candidate variant, AlphaGenome scores variant effects by:\n\nPredicting genome-wide functional tracks for the reference sequence.\nPredicting the same tracks for the sequence bearing the variant.\nComparing predictions to obtain delta signals across:\n\nRegulatory elements (promoters, enhancers, insulators),\nSplicing patterns (gain/loss of splice junctions),\nGene expression levels,\n3D contact maps affecting enhancer–promoter communication.\n\n\nOn extensive benchmarks, AlphaGenome:\n\nAchieves state-of-the-art accuracy in predicting unseen functional genomics tracks.\nShows strong performance on diverse variant effect tasks (e.g., noncoding disease variants, splicing disruptions, regulatory MPRA data).\nProvides mechanistic hypotheses (which tracks/tissues are disrupted) rather than only a single scalar risk score.\n\nAn API makes AlphaGenome accessible to the research community, enabling large-scale variant scoring without local training infrastructure.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#comparing-design-choices-across-modern-vep-models",
    "href": "ch-p4-vep.html#comparing-design-choices-across-modern-vep-models",
    "title": "13  Variant Effect Prediction",
    "section": "13.6 Comparing Design Choices Across Modern VEP Models",
    "text": "13.6 Comparing Design Choices Across Modern VEP Models\nThe models in this chapter span different points in the design space:\n\n\n\n\n\n\n\n\n\n\n\nModel\nInput Modality\nContext Length\nPretraining Data\nVariant Types\nPrimary Outputs\n\n\n\n\nAlphaMissense\nProtein sequence + structure\nProtein-length\nMSAs + structural environment\nMissense only\nPathogenicity probability\n\n\nGPN-MSA\nMulti-species DNA alignments\nkb-scale windows\nWhole-genome MSAs (multiple species)\nCoding + noncoding\nLikelihood / embedding-based scores\n\n\nEvo 2\nRaw DNA sequence\nUp to ~1 Mb\nOpenGenome2 (all domains of life)\nAll variant types\nZero-shot likelihood-based scores\n\n\nAlphaGenome\nRaw DNA sequence\n1 Mb\nHuman genome + multi-omic tracks\nAll variant types\nMulti-omic tracks + delta effects\n\n\n\nKey contrasts:\n\nScope\n\nAlphaMissense is human-missense-specific, with deep clinical calibration.\n\nGPN-MSA and AlphaGenome are human-genome-centric, spanning coding and regulatory variants.\n\nEvo 2 is cross-species and general-purpose.\n\nContext and long-range effects\n\nAlphaMissense operates at protein scale.\n\nGPN-MSA uses modest windows centered on the variant.\n\nEvo 2 and AlphaGenome support megabase-scale context, capturing long-range regulatory interactions.\n\nOutputs\n\nAlphaMissense and GPN-MSA primarily output scalar scores.\n\nEvo 2 outputs likelihoods/embeddings that require task-specific postprocessing.\n\nAlphaGenome outputs rich functional profiles, enabling mechanistic hypotheses.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#practical-use-choosing-and-interpreting-modern-vep-tools",
    "href": "ch-p4-vep.html#practical-use-choosing-and-interpreting-modern-vep-tools",
    "title": "13  Variant Effect Prediction",
    "section": "13.7 Practical Use: Choosing and Interpreting Modern VEP Tools",
    "text": "13.7 Practical Use: Choosing and Interpreting Modern VEP Tools\nIn realistic workflows, these models are complementary rather than competing.\n\n13.7.1 Coding Missense Variants\nFor human missense variants:\n\nUse AlphaMissense as a high-coverage, clinically calibrated score.\nComplement with:\n\nProtein language model embeddings (Chapter 9) for gene- or domain-specific modeling,\nConservation and population data (e.g., GPN-MSA in coding regions, gnomAD frequencies),\nGene-level context (constraint metrics, disease association).\n\n\n\n\n13.7.2 Noncoding and Regulatory Variants\nFor regulatory variation (promoters, enhancers, introns, intergenic):\n\nUse AlphaGenome to obtain:\n\nTissue-specific changes in chromatin and expression,\nSplicing consequences (especially for intronic and exonic variants),\nPotential disruption of long-range enhancer–promoter interactions.\n\nUse GPN-MSA when:\n\nYou want a conservation-grounded score,\nHigh-quality multi-species alignments are available,\nYou’re scanning broad regions genome-wide.\n\n\n\n\n13.7.3 Cross-Species and Large-Scale Modeling\nFor non-human organisms, or when building general-purpose genomic tools:\n\nLeverage Evo 2 for:\n\nZero-shot variant scoring in poorly annotated species,\nDesigning or screening edits (e.g., CRISPR designs),\nServing as a feature extractor feeding downstream supervised models.\n\n\n\n\n13.7.4 Score Interpretation and Calibration\nRegardless of the model:\n\nTreat scores as probabilistic evidence, not binary labels.\nConsider:\n\nCalibration (does a score of 0.9 truly correspond to ~90% pathogenic variants?),\nDistribution of scores within a gene (outliers are more suspect),\nConsistency across tools (agreement between AlphaMissense, GPN-MSA, AlphaGenome, Evo 2, and simpler conservation metrics strengthens confidence).\n\n\nWhere possible, tie predictions back to:\n\nMechanistic hypotheses (splice site disruption, enhancer–promoter rewiring),\nExperimental follow-up (targeted assays, MPRA, CRISPR screens).",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-vep.html#open-challenges-and-future-directions",
    "href": "ch-p4-vep.html#open-challenges-and-future-directions",
    "title": "13  Variant Effect Prediction",
    "section": "13.8 Open Challenges and Future Directions",
    "text": "13.8 Open Challenges and Future Directions\nEven these state-of-the-art systems leave major gaps:\n\nAncestry and population bias\nTraining data and labels remain skewed toward certain ancestries, raising concerns about performance and calibration in underrepresented populations.\nComplex variant patterns\nMost models focus on single-base or single-amino-acid changes. Systematic handling of:\n\nHaplotypes,\n\nIndels and structural variants,\n\nEpistatic interactions across distant loci\nis still in its infancy.\n\nIntegrating multi-omics and longitudinal data\nAlphaGenome marks a step toward unified multi-omic prediction, but dynamic phenomena (developmental trajectories, environment, time-series responses) are only lightly modeled.\nInterpretability and clinical communication\nTranslating high-dimensional predictions into explanations that clinicians and patients can understand—and that map onto emerging guidelines for AI-assisted variant interpretation—remains a human-factor challenge.\nSafe deployment and continual learning\nAs more functional datasets and clinical labels accumulate, models will need continual updating without catastrophic forgetting, along with governance frameworks to track model versions and provenance.\n\nIn the next chapters, we will connect these VEP systems to broader issues in evaluation, bias, and multi-omics integration, positioning them within the broader landscape of Genomic Foundation Models. This chapter’s models illustrate how the building blocks from earlier chapters—NGS, functional genomics, CNNs, transformers, protein and DNA language models—coalesce into powerful, end-to-end systems for variant interpretation.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html",
    "href": "ch-p4-omics.html",
    "title": "14  Multi-omics and Systems Context",
    "section": "",
    "text": "14.1 Why Single-omics Models Are Not Enough\nModern genomic foundation models (GFMs) excel at learning from sequences, structures, or single-omic profiles in isolation. Yet most complex traits arise from systems-level interactions: genetic variants perturb molecular networks; networks span multiple omics layers; and these layers interact with environment, development, and clinical context. A model that sees only one layer rarely captures the full story.\nThis chapter surveys how deep learning extends beyond single-omics to integrate methylation, chromatin, expression, protein, and clinical data into unified representations. Within the book structure defined by the Quarto project, this is the final chapter of Part IV and serves as a bridge from model-centric architecture design to systems-level, clinically grounded applications.\nWe focus on several archetypal systems:\nTogether, these approaches illustrate emerging design patterns for systems-aware GFMs that move from single sequences to whole-patient representations.\nEarlier chapters emphasized how sequence-based models can predict variant effects from local DNA or protein context. These models already improve causal variant prioritization and polygenic risk scoring. However, they typically assume a narrow view of biology:\nReal diseases violate all three assumptions:\nChapter 2 highlighted the “missing heritability” and limited portability of traditional GWAS and linear PRS, motivating sequence-based deep learning. Here we take the next step: combining sequence-derived features with multi-omics and systems-level models that better reflect biological organization.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#why-single-omics-models-are-not-enough",
    "href": "ch-p4-omics.html#why-single-omics-models-are-not-enough",
    "title": "14  Multi-omics and Systems Context",
    "section": "",
    "text": "Single layer: A CNN or transformer may see only DNA sequence or only expression.\n\nAdditive effects: Many downstream uses still treat variant effects as additively summing across loci.\n\nStatic context: Models rarely account for dynamic state (cell type, developmental stage, environment).\n\n\n\nRegulation is multi-layered: genetic variants alter chromatin accessibility and DNA methylation, which modulate transcription, splicing, translation, and protein modification.\n\nEffects are context-dependent: the same variant can be benign in one tissue and pathogenic in another.\n\nRisk is combinatorial: epistasis and pathway-level perturbations play a significant role in many complex traits.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#foundations-of-multi-omics-integration",
    "href": "ch-p4-omics.html#foundations-of-multi-omics-integration",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.2 Foundations of Multi-omics Integration",
    "text": "14.2 Foundations of Multi-omics Integration\nMulti-omics data come in several flavors:\n\nBulk-level profiles (e.g., GWAS variants, bulk RNA-seq, bulk proteomics)\n\nSingle-cell modalities (scRNA-seq, scATAC-seq, multiome, spatial omics)\n\nEpigenetic readouts (DNA methylation, histone marks, chromatin conformation)\n\nClinical and environmental covariates (EHR, labs, lifestyle)\n\nIntegration strategies typically fall into three categories:\n\nEarly fusion (feature-level)\n\nConcatenate normalized features from multiple omics and feed them into a single model.\n\nStraightforward but sensitive to scaling, missing data, and modality imbalance.\n\nIntermediate fusion (shared latent space)\n\nLearn modality-specific encoders that map each omic into a common latent space.\n\nAlign latent spaces via reconstruction losses, contrastive terms, or graph constraints.\n\nThis is the dominant design in modern multi-omics deep learning.\n\nLate fusion (prediction-level)\n\nTrain separate models per modality; combine outputs via ensemble or meta-model.\n\nRobust to missing modalities but may underutilize cross-omic structure.\n\n\nModern frameworks like GLUE and multi-omics GNNs adopt intermediate fusion, often with graphs encoding known or inferred relationships (e.g., gene–peak, gene–TF, protein–protein, or sample similarity networks). The rest of this chapter traces how these design choices implement systems-level reasoning in practice.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#cpgpt-a-foundation-model-for-dna-methylation",
    "href": "ch-p4-omics.html#cpgpt-a-foundation-model-for-dna-methylation",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.3 CpGPT: A Foundation Model for DNA Methylation",
    "text": "14.3 CpGPT: A Foundation Model for DNA Methylation\n\n14.3.1 Motivation: Methylation as a Systems Hub\nDNA methylation sits at a crucial junction between genotype, environment, and phenotype:\n\nIt integrates genetic, developmental, and environmental influences.\n\nIt encodes cell type and cell state information.\n\nIt is predictive of aging, mortality, and disease risk.\n\nTraditional methylation models are task-specific (e.g., age clocks, mortality predictors). CpGPT reframes methylation as a foundation modeling problem, using large-scale pretraining to unlock downstream tasks.\n\n\n14.3.2 Architecture and Pretraining\nCpGPT (Cytosine-phosphate-Guanine Pretrained Transformer) is trained on large-scale collections of whole-genome and array-based methylation profiles. Conceptually, CpGPT treats methylomes as sequences or sets of CpG sites, and uses transformer-style self-attention to model:\n\nLocal CpG correlations (e.g., CpG islands)\n\nLong-range coordination across genomic regions\n\nGlobal sample-level variation (e.g., age, disease status)\n\nKey aspects:\n\nMasked modeling objectives: Learn to reconstruct held-out CpG values from context.\n\nMulti-task pretraining: Auxiliary tasks like array conversion or reference mapping encourage robust representations.\n\nSample embeddings: The [CLS]-like embedding for each sample acts as a compact, task-agnostic representation of its methylome.\n\n\n\n14.3.3 Zero-shot and Fine-tuned Tasks\nBecause CpGPT is trained on diverse cohorts, it exhibits zero-shot or few-shot generalization to new tasks:\n\nImputation and array conversion: Fill in missing CpGs or harmonize different methylation platforms.\n\nChronological age and mortality prediction: Yield clocks that match or exceed specialized models.\n\nSample classification: Distinguish tissues, disease states, or exposure profiles.\n\nIn a multi-omics context, CpGPT-derived embeddings can serve as:\n\nInputs to downstream predictors (e.g., risk scores, prognosis models).\n\nOne modality in a shared latent space (with expression, proteomics, etc.).\n\nA way to inject epigenetic state into otherwise sequence-centric GFMs.\n\nConceptually, CpGPT is an example of a single-omic foundation model that is designed to plug into multi-omics architectures.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#glue-graph-linked-unified-embedding-for-single-cell-multi-omics",
    "href": "ch-p4-omics.html#glue-graph-linked-unified-embedding-for-single-cell-multi-omics",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.4 GLUE: Graph-linked Unified Embedding for Single-cell Multi-omics",
    "text": "14.4 GLUE: Graph-linked Unified Embedding for Single-cell Multi-omics\n\n14.4.1 The Unpaired Single-cell Integration Problem\nSingle-cell experiments often profile different modalities in different cells—for instance:\n\nSome cells with scRNA-seq only\n\nOther cells with scATAC-seq only\n\nSometimes a small subset with both (multiome) or additional modalities (e.g., protein, methylation)\n\nThe central challenge: build a unified atlas that aligns these cells in a common space, recovers cell types and trajectories, and infers regulatory networks.\nGLUE (Graph-Linked Unified Embedding) addresses this by combining modality-specific encoders with a graph of biological prior knowledge linking features across omics.\n\n\n14.4.2 Architecture\nGLUE consists of three key components:\n\nModality-specific variational autoencoders (VAEs)\n\nEach omic (e.g., RNA, ATAC) has its own encoder–decoder pair.\n\nEncoders map cells to a low-dimensional latent embedding; decoders reconstruct modality-specific features.\n\nFeature graph and SCGLUE\n\nFeatures (genes, peaks, motifs) form a graph whose edges capture biological relationships: e.g., a peak linked to a gene’s promoter or enhancer, or TF binding motifs affecting genes.\n\nA graph neural network (GNN) learns feature embeddings consistent with this graph.\n\nAlignment objectives\n\nLoss terms encourage the cell latent spaces to align (so RNA-only and ATAC-only cells with similar biology end up near each other).\n\nThe feature embeddings are tied to the cell latents via generative decoders, enforcing consistency between data and prior graph.\n\n\nThe result is a unified embedding in which cells from multiple modalities can be jointly clustered, visualized, and used for downstream tasks.\n\n\n14.4.3 Applications\nThe GLUE framework has demonstrated:\n\nMulti-omics integration (RNA, ATAC, methylation or protein) at single-cell resolution.\n\nRegulatory network inference by linking chromatin features to gene expression through the feature graph.\n\nAtlas construction over large cohorts, correcting earlier annotation errors and unifying datasets across labs.\n\nFrom the perspective of GFMs, GLUE exemplifies graph-guided multi-modal pretraining: modality-specific encoders learn a shared latent space regularized by biological networks, enabling reuse across tasks and tissues.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#gnn-based-multi-omics-cancer-subtyping-mogcn-cgmega-and-beyond",
    "href": "ch-p4-omics.html#gnn-based-multi-omics-cancer-subtyping-mogcn-cgmega-and-beyond",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.5 GNN-based Multi-omics Cancer Subtyping: MoGCN, CGMega, and Beyond",
    "text": "14.5 GNN-based Multi-omics Cancer Subtyping: MoGCN, CGMega, and Beyond\nCancer is inherently multi-omic: driver mutations, copy number changes, epigenetic reprogramming, and transcriptional rewiring jointly define tumor subtypes. Multi-omics cancer subtyping models increasingly rely on graph neural networks to capture this complexity.\n\n14.5.1 MoGCN: Patient Graphs from Multi-omics\nMoGCN is a graph-convolutional framework for cancer subtype classification that integrates genomics, transcriptomics, and proteomics.\nDesign:\n\nEach patient is a node in a graph; edges encode similarity (e.g., based on expression or multi-omics features).\n\nFor each omic, a GCN learns modality-specific latent representations.\n\nThese representations are concatenated into a joint embedding per patient.\n\nA classifier operating on node embeddings predicts cancer subtypes (e.g., BRCA subtypes).\n\nBenefits:\n\nCaptures non-linear relationships between patients in a data-driven graph.\n\nNaturally integrates multiple omics via multi-view GCNs.\n\nEnables subtype discovery and interpretation via graph structure and learned embeddings.\n\n\n\n14.5.2 CGMega: Multi-omics Cancer Gene Modules\nWhere MoGCN focuses on patient-level graphs, CGMega operates on gene-level graphs:\n\nNodes represent genes; edges capture multi-omics relationships (expression, copy number, methylation, 3D genome contacts, etc.).\n\nA graph attention network learns cancer gene modules—subsets of genes that co-vary across omics and are associated with phenotypes.\n\nThis module-centric view aligns with systems biology: instead of single-gene markers, CGMega identifies network-level signatures that better reflect pathway dysregulation.\n\n\n14.5.3 Design Patterns and Alternatives\nA growing ecosystem of multi-omics subtyping methods uses related patterns:\n\nContrastive learning for multi-omics sample embeddings.\n\nGenerative models (e.g., GAN-based subtyping) that jointly model multiple omics for unsupervised clustering.\n\nTransformer-based hybrids that blend MLPs and transformer blocks for high-dimensional omics.\n\nCommon themes:\n\nModality-specific encoders with shared latent spaces\n\nGraphs capturing patient–patient or gene–gene relationships\n\nEmphasis on interpretability via clusters, modules, or attention over features\n\nThese cancer models illustrate how multi-omics integration naturally leads to graph-structured GFMs, where sequences, epigenetics, and expression are all nodes in a learned biological network.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#rare-variants-and-epistasis-in-systems-context",
    "href": "ch-p4-omics.html#rare-variants-and-epistasis-in-systems-context",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.6 Rare Variants and Epistasis in Systems Context",
    "text": "14.6 Rare Variants and Epistasis in Systems Context\nChapter 2 discussed how standard PRS methods often ignore rare variants and epistasis, despite their importance for individual-level risk and disease mechanism. Multi-omics and systems models offer a framework to incorporate these effects more effectively.\n\n14.6.1 DeepRVAT: Set-based Rare Variant Burden Modeling\nDeepRVAT (Deep Rare Variant Association Testing) learns gene-level impairment scores from rare variant annotations and genotypes using set neural networks.\nKey properties:\n\nTreats each gene’s rare variants as an unordered set.\n\nLearns a trait-agnostic gene impairment score that generalizes across traits.\n\nImproves both gene discovery and detection of high-risk individuals across many complex traits.\n\nConceptually, DeepRVAT bridges the gap between variant-level annotations (e.g., VEP, conservation, structure-based predictions) and gene-level burden, making it naturally compatible with sequence-based variant effect models introduced earlier in the book.\n\n\n14.6.2 NeEDL: Network-based Epistasis Detection\nNeEDL (Network-based Epistasis Detection via Local search) uses network medicine and quantum-inspired optimization to identify epistatic interactions among SNPs.\nCore ideas:\n\nBuild a network of SNPs and genes based on biological priors and GWAS signals.\n\nUse local search strategies to explore combinations of variants that jointly influence disease.\n\nPrioritize interpretable epistatic modules that map onto pathways and cellular processes.\n\nNeEDL does not yet operate as a full GFM, but it points toward systems-level combinatorial reasoning that future GFMs will need to support.\n\n\n14.6.3 G2PT: Hierarchical Genotype-to-Phenotype Transformers\nG2PT (Genotype-to-Phenotype Transformer) explicitly models hierarchical structure:\n\nVariant-level signals aggregate into genes.\n\nGenes aggregate into systems (e.g., pathways, tissues).\n\nSystems collectively determine phenotypes and polygenic risk.\n\nArchitecturally:\n\nUses transformer blocks to model interactions at each level.\n\nIncorporates prior knowledge (e.g., gene–pathway membership) to structure attention patterns.\n\nProvides explanations by attributing risk to specific variants, genes, and systems.\n\nG2PT can be viewed as an early example of a systems-aware GFM for genotype data, unifying additive and interaction effects within a single deep model.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#deep-learning-enhanced-polygenic-risk-and-fine-mapping",
    "href": "ch-p4-omics.html#deep-learning-enhanced-polygenic-risk-and-fine-mapping",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.7 Deep Learning-enhanced Polygenic Risk and Fine-mapping",
    "text": "14.7 Deep Learning-enhanced Polygenic Risk and Fine-mapping\nChapter 2 framed PRS as linear weighted sums of SNP effects. Deep learning extends this paradigm by:\n\nModeling non-linear interactions and context dependence\n\nIntegrating multi-omics features as priors or inputs\n\nSharing information across ancestries and cohorts\n\n\n14.7.1 Deep-learning PRS (e.g., Delphi-like frameworks)\nDeep-learning PRS frameworks learn complex functions of genotype and covariates, rather than relying on additive SNP weights.\nKey contributions:\n\nIncorporate non-genetic risk factors alongside genome-wide variants.\n\nLearn non-linear functions that can capture dominance, epistasis, and interactions with covariates.\n\nDemonstrate improved discrimination over traditional PRS across several traits.\n\nFrom a systems perspective, these models represent a move toward whole-patient risk modeling, albeit still primarily from genotype + covariates, without explicit multi-omics integration.\n\n\n14.7.2 MIFM and Multi-ancestry Fine-mapping\nMultiple-instance fine-mapping frameworks (MIFM-like methods) address a key bottleneck: lack of per-variant labels. Instead, we often know only that some variant(s) in a locus are causal. This is formulated as a multiple-instance learning problem:\n\nEach locus is a “bag” of variants.\n\nLoci with significant GWAS signals form positive bags; others form negative bags.\n\nA deep model learns to assign high scores to causal variants within positive bags.\n\nRelated methods in multi-ancestry contexts combine signals across cohorts and ancestries, leveraging divergent LD patterns to refine causal inference.\nConnections to earlier chapters:\n\nVariant effect predictors (Chapters 5–7, 13) can supply per-variant features.\n\nMulti-omics models (this chapter) provide functional priors (e.g., regulatory activity, methylation, chromatin accessibility).\n\nMIFM-type frameworks integrate these priors with GWAS evidence to produce more accurate, ancestry-aware fine-mapping.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#design-patterns-for-multi-omics-and-systems-gfms",
    "href": "ch-p4-omics.html#design-patterns-for-multi-omics-and-systems-gfms",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.8 Design Patterns for Multi-omics and Systems GFMs",
    "text": "14.8 Design Patterns for Multi-omics and Systems GFMs\nPulling these examples together, several design patterns emerge for systems-level GFMs:\n\nModality-specific encoders + shared latent space\n\nCpGPT, GLUE, and many multi-omics subtyping models use separate encoders for each omic, aligned in a common embedding space.\n\nThis design supports flexible inference with missing modalities and incremental addition of new data types.\n\nGraph-guided integration\n\nGLUE’s feature graph, CGMega’s gene modules, and NeEDL’s epistasis networks all use prior or learned graphs to structure learning.\n\nGNNs, graph transformers, and attention over graph edges are natural tools for encoding biological networks.\n\nHierarchical modeling\n\nG2PT formalizes the hierarchy from variants → genes → systems → phenotypes.\n\nSimilar hierarchies can be defined for omics layers: sequence → chromatin → methylation → expression → protein → clinical traits.\n\nSet- and bag-based learning\n\nDeepRVAT and MIFM treat variants or loci as sets/bags with permutation-invariant architectures.\n\nThis is crucial when sample sizes are large, labels are sparse, and order is biologically meaningless.\n\nFoundation pretraining + task-specific adaptation\n\nCpGPT is pretrained on massive methylation datasets and then adapted to tasks like aging clocks, mortality prediction, or disease classification.\n\nFuture models may pretrain jointly on sequence, chromatin, methylation, expression, and clinical data, then specialize for specific traits.\n\n\nThese patterns collectively point toward general-purpose systems GFMs that can ingest heterogeneous biological data and output risk predictions, mechanistic hypotheses, or treatment recommendations.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#practical-pitfalls-and-considerations",
    "href": "ch-p4-omics.html#practical-pitfalls-and-considerations",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.9 Practical Pitfalls and Considerations",
    "text": "14.9 Practical Pitfalls and Considerations\nDespite impressive progress, multi-omics and systems GFMs are especially vulnerable to confounding and overinterpretation—issues examined in depth in Chapter 14. Key challenges include:\n\nBatch effects and platform heterogeneity\n\nDifferent omics layers often come from different assays, labs, or time points.\n\nIntegration methods can inadvertently encode batch structure rather than biology if not properly corrected.\n\nSample size and missingness\n\nMulti-omics datasets are typically smaller than single-omic datasets.\n\nMany samples lack certain modalities, requiring robust handling of missing data.\n\nPopulation diversity and fairness\n\nAs highlighted for PRS, representation of diverse ancestries is essential.\n\nMulti-omics GFMs risk amplifying disparities if trained primarily on European-ancestry or high-resource cohorts.\n\nEvaluation complexity\n\nMulti-omics models can be evaluated at many levels: predictive performance, biological consistency, network plausibility, and clinical utility.\n\nOverfitting to proxy metrics (e.g., clustering quality) may not translate to actionable biology.\n\nInterpretability and causal inference\n\nAttention or feature importance scores are not guarantees of causal mechanism.\n\nIntegrating deep models with perturbation data (e.g., CRISPR screens) and robust causal frameworks remains an open frontier.\n\n\nCareful experimental design, thoughtful validation, and transparent reporting are therefore especially crucial for multi-omics GFMs.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-omics.html#outlook-toward-whole-patient-foundation-models",
    "href": "ch-p4-omics.html#outlook-toward-whole-patient-foundation-models",
    "title": "14  Multi-omics and Systems Context",
    "section": "14.10 Outlook: Toward Whole-patient Foundation Models",
    "text": "14.10 Outlook: Toward Whole-patient Foundation Models\nThe methods in this chapter sketch an endgame for genomic deep learning:\n\nGenome-wide variant and sequence representation via hybrid CNN/transformer/SSM architectures (Chapters 10–13).\n\nMulti-omics integration through graph-guided latent spaces (CpGPT, GLUE, MoGCN, CGMega).\n\nSystems-level reasoning about rare variants and epistasis (DeepRVAT, NeEDL, G2PT).\n\nClinically oriented risk modeling with deep PRS and fine-mapping (Delphi-like and MIFM-like frameworks).\n\nA future whole-patient foundation model might:\n\nJointly encode genotype, methylome, chromatin state, expression, proteomics, imaging, and EHR data.\n\nProvide unified representations across tissues, cell types, and time points.\n\nOffer calibrated, equitable predictions of disease risk and treatment response.\n\nSupport mechanistic queries like “which pathways mediate this variant’s effect in this tissue?” or “which interventions counteract this rare variant burden in this patient?”\n\nRealizing this vision will require advances in data sharing, privacy-preserving learning, scalable architecture design, and causal validation. But the methods surveyed here show that moving beyond single-omics is not just incremental—it fundamentally changes what kinds of questions genomic models can answer, bringing us closer to truly systems-level, clinically actionable genomics.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html",
    "href": "ch-p4-confound.html",
    "title": "15  Confounders in Model Training",
    "section": "",
    "text": "15.1 Why Confounders Are Ubiquitous in Genomic ML\nIn previous chapters, we treated model performance curves and ROC–AUC numbers as if they transparently reflected how well a model learns biology. In practice, genomic data is riddled with structure that makes it dangerously easy for models—especially large, overparameterized ones—to exploit shortcuts.\nPopulation structure, technical batch effects, benchmark leakage, and label noise can all inflate headline metrics while leaving real-world performance and clinical reliability largely unchanged. These issues are not unique to deep learning; they affect traditional statistics and GWAS as well. But the scale, flexibility, and opacity of modern genomic foundation models (GFMs) make them particularly susceptible.\nThis chapter surveys the main confounders that arise when training and evaluating genomic models, and outlines practical strategies to detect, mitigate, and transparently report them. We focus on five recurring themes:\nThroughout, the key message is simple: architecture advances are only as meaningful as the datasets and evaluation protocols that support them.\nA confounder is a variable that influences both the features (e.g., genotypes, readouts) and the labels (e.g., case/control status, functional effect), creating spurious associations. In genomics, confounders abound because:\nDeep models are powerful pattern detectors. If confounders produce consistent patterns that correlate with labels, models will happily learn those shortcuts instead of the causal biology we care about. The result is impressive performance on held-out data that share the same hidden structure, but brittle behavior as soon as we change ancestry, institution, assay, or time period.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#why-confounders-are-ubiquitous-in-genomic-ml",
    "href": "ch-p4-confound.html#why-confounders-are-ubiquitous-in-genomic-ml",
    "title": "15  Confounders in Model Training",
    "section": "",
    "text": "Data are observational, not randomized. Disease labels, population sampling, and technical pipelines are all determined by real-world constraints and historical biases.\n\nPopulation structure is strong and multi-layered. Ancestry, relatedness, and local adaptation affect allele frequencies throughout the genome.\n\nTechnical pipelines are complex. Each step—sample collection, library prep, sequencing, alignment, variant calling, QC—can introduce systematic differences between cohorts.\n\nLabels are noisy. Clinical databases (e.g., ClinVar) and high-throughput assays contain uncertain and sometimes incorrect annotations.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#ancestry-stratification-and-population-bias",
    "href": "ch-p4-confound.html#ancestry-stratification-and-population-bias",
    "title": "15  Confounders in Model Training",
    "section": "15.2 Ancestry Stratification and Population Bias",
    "text": "15.2 Ancestry Stratification and Population Bias\n\n15.2.1 How ancestry becomes a shortcut\nHuman genetic variation is structured by ancestry: allele frequencies and haplotype patterns differ across populations due to demographic history, drift, and selection. Disease prevalence, environmental exposures, and health-care access are also ancestry- and region-dependent.\nThis creates a classic confounding scenario:\n\nFeatures: Genotypes or sequence variants reflect ancestry.\n\nLabels: Case/control status, disease subtype, or even “pathogenic vs. benign” annotations can vary with ancestry.\n\nIf a case cohort is primarily of one ancestry and controls are primarily of another, a model can achieve high predictive performance by acting as an ancestry classifier rather than a disease predictor. The same issue arises for variant effect prediction: variants common in one ancestry but rare in another can be spuriously tagged as pathogenic or benign because of how databases were curated.\n\n\n15.2.2 Manifestations in genomic models\nSome common ways ancestry confounding shows up:\n\nCase/control imbalance across ancestries. For example, cases over-representing individuals of European ancestry, controls over-representing other groups.\n\nReference database bias. Variant annotations derived mostly from European-ancestry cohorts; “benign” often means “common in Europeans”.\n\nImplicit ancestry markers. Cryptic relatedness, shared haplotypes, and local LD patterns let models recover ancestry even when explicit labels are removed.\n\nFor high-capacity models such as transformer-based GFMs, even subtle ancestry differences are enough to support a shortcut.\n\n\n15.2.3 Detecting ancestry confounding\nPractical diagnostics include:\n\nPCA or UMAP of genotypes/embeddings. If cases and controls cluster by ancestry, that’s a red flag.\n\nStratified performance. Evaluate metrics separately within each ancestry group; large performance drops or reversals across groups suggest confounding.\n\nAncestry-only baselines. Fit a simple classifier on ancestry PCs or self-identified ancestry alone. If this baseline approaches your model’s performance, your model is likely exploiting similar information.\n\nPermutation tests within ancestry strata. Shuffling labels within ancestry groups should destroy performance for a truly disease-specific signal, but not for models relying on cross-ancestry differences.\n\n\n\n15.2.4 Mitigating ancestry bias\nMitigation is imperfect, but several strategies help:\n\nBalanced study design. Wherever possible, recruit cases and controls with similar ancestry distributions, or match controls to cases.\n\nWithin-ancestry evaluation. Report metrics for each ancestry separately; use training–validation splits that preserve within-group structure.\n\nCovariate adjustment. Include ancestry PCs, kinship matrices, or mixed-model random effects in simpler models; for deep models, condition on or adversarially remove ancestry signals from learned embeddings.\n\nMulti-ancestry training. Train on diverse populations rather than restricting to a single ancestry, and explicitly model ancestry as a domain variable.\n\nFairness-aware objectives. Introduce regularizers or constraints that penalize performance disparities across ancestry groups, especially in clinical deployment contexts.\n\nIn later chapters on PRS and multi-omics, careful ancestry handling will be essential for equitable risk prediction.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#benchmark-leakage-and-traintest-overlap",
    "href": "ch-p4-confound.html#benchmark-leakage-and-traintest-overlap",
    "title": "15  Confounders in Model Training",
    "section": "15.3 Benchmark Leakage and Train/Test Overlap",
    "text": "15.3 Benchmark Leakage and Train/Test Overlap\nEven with perfectly balanced ancestries, evaluation can be misleading if information “leaks” from training to test sets. Leakage is especially insidious in genomics because:\n\nThe genome is highly structured and redundant.\n\nPublic datasets and benchmarks are heavily reused.\n\nMany papers do not fully specify how splits were constructed.\n\n\n15.3.1 Forms of leakage\nCommon leakage patterns include:\n\nIndividual overlap. The same person (or close relative) appears in both train and test sets, directly or via related cohorts.\n\nVariant overlap. Exact variants, or near-identical ones at the same locus, appear in both splits; this can happen when different datasets are merged.\n\nLocus-level overlap. Variants in the same gene, regulatory element, or LD block are split between train and test. A model may learn locus-specific idiosyncrasies instead of general rules.\n\nDatabase reuse leakage. Benchmarks constructed from ClinVar, gnomAD, or other public databases but evaluated against an external set that partially overlaps those sources.\n\nTime-based leakage. Models trained on data that include later submissions of the same variants or patients that are used as “future” test examples.\n\nFor large models, even very small overlaps can inflate metrics, particularly when test sets are small.\n\n\n15.3.2 Safer splitting strategies\nTo reduce leakage:\n\nIndividual-level splits. Ensure that no individual (or closely related individuals, if kinship is known) appears in both train and test sets.\n\nLocus- or gene-level splits. For variant effect prediction, split at the gene, enhancer, or genomic region level so that test loci are unseen.\n\nChromosome-based splits. For genome-wide tasks, hold out entire chromosomes or chromosome arms. This is not perfect but greatly reduces local dependency leakage.\n\nTime-based splits. Train on data up to a cutoff date and test on later data, mimicking realistic deployment.\n\nTransparent data provenance. Track the origin of each sample and variant (e.g., database version, submission ID) to avoid accidental reuse.\n\n\n\n15.3.3 Evaluation design and reporting\nBeyond the split itself, evaluation design matters:\n\nReport both in-distribution performance (same cohort) and out-of-distribution performance (new cohorts, ancestries, or technical pipelines).\n\nWhenever possible, include cross-cohort benchmarks: train on one cohort, test on another with different recruitment or sequencing characteristics.\n\nShare code and detailed recipes for dataset construction so that others can reproduce and critique splitting choices.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#technical-artifacts-batch-effects-and-platform-differences",
    "href": "ch-p4-confound.html#technical-artifacts-batch-effects-and-platform-differences",
    "title": "15  Confounders in Model Training",
    "section": "15.4 Technical Artifacts: Batch Effects and Platform Differences",
    "text": "15.4 Technical Artifacts: Batch Effects and Platform Differences\nWhile ancestry and population structure reflect biological reality, batch effects are artifacts of the measurement process. In genomics, differences in:\n\nSample collection protocols\n\nLibrary preparation kits\n\nSequencing platforms and chemistry versions\n\nRead length, depth, and coverage\n\nAlignment and variant calling pipelines\n\ncan all introduce systematic shifts in feature distributions.\n\n15.4.1 How batch effects confound models\nTechnical batches often correlate with labels:\n\nA case cohort may be sequenced at one institution on one platform, while controls are sequenced elsewhere with different protocols.\n\nA longitudinal study might switch from one capture kit or sequencer to another halfway through, coinciding with changes in enrollment criteria.\n\nPublic datasets may aggregate studies with very different technical characteristics.\n\nIn such settings, a model can achieve high accuracy by recognizing batch signatures (e.g., patterns of missingness, depth, noise spectra) rather than bona fide biological signals.\n\n\n15.4.2 Diagnosing technical confounders\nCommon diagnostics include:\n\nEmbedding visualization by batch. Project learned embeddings or expression/coverage profiles via PCA or UMAP, then color points by batch, platform, or institution. Strong clustering by these variables suggests technical structure.\n\nBatch-only baselines. Train a classifier using only batch labels or simple technical covariates (e.g., read depth, platform indicators). High baseline performance is a warning sign.\n\nNegative controls. Evaluate models on samples where labels should be uncorrelated with batch (e.g., technical replicates, randomized subsets).\n\nReplicate consistency. Examine consistency of predictions across technical replicates processed in different batches.\n\n\n\n15.4.3 Mitigating batch effects\nMitigation is an active research area; common approaches include:\n\nCareful study design. Randomize cases and controls across batches whenever possible; avoid systematic alignment between batch and outcome.\n\nPreprocessing harmonization. Use standardized pipelines for alignment and variant calling; reprocess raw data when feasible to reduce inter-study differences.\n\nStatistical batch correction. Methods such as ComBat, Harmony, and related approaches can reduce batch effects in expression or chromatin data; similar ideas can be applied to embeddings from GFMs.\n\nDomain adaptation and adversarial training. Train representations that are predictive of labels while being invariant to batch or platform (e.g., via gradient reversal layers or distribution matching objectives).\n\nExplicit multi-domain modeling. Treat each batch or platform as a domain and learn domain-conditional parameters or mixture-of-experts models.\n\nEven with aggressive correction, residual batch structure typically remains; transparent reporting and robustness checks are essential.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#label-noise-and-ground-truth-uncertainty",
    "href": "ch-p4-confound.html#label-noise-and-ground-truth-uncertainty",
    "title": "15  Confounders in Model Training",
    "section": "15.5 Label Noise and Ground-Truth Uncertainty",
    "text": "15.5 Label Noise and Ground-Truth Uncertainty\nLarge-scale genomic models rely on labels from:\n\nClinical variant interpretation databases (e.g., pathogenic vs. benign)\n\nGWAS-derived case/control status\n\nHigh-throughput functional screens (e.g., MPRA, saturation mutagenesis, CRISPR screens)\n\nCurated “gold-standard” sets for VEP, splicing predictions, or PRS\n\nThese labels are not error-free. Sources of label noise include:\n\nConflicting annotations. ClinVar often contains variants with conflicting interpretations or uncertain significance; criteria for pathogenicity change over time.\n\nAscertainment bias. Variants labeled as “benign” may simply be common in some populations; variants labeled as “pathogenic” may be enriched in clinically ascertained cohorts.\n\nMeasurement noise in functional assays. High-throughput experiments have variable reproducibility across labs, conditions, and replicates. Thresholding continuous scores into discrete classes compounds the issue.\n\nPhenotyping noise. Clinical case/control labels may be inaccurate due to misdiagnosis, incomplete records, or heterogeneous disease definitions.\n\n\n15.5.1 Consequences for models\nLabel noise can:\n\nLimit achievable performance, especially for tasks with overlapping phenotype definitions.\n\nEncourage models to learn spurious proxies that correlate with annotation errors.\n\nBias calibration and decision thresholds, particularly in imbalanced settings.\n\nIn some scenarios, training on noisy labels still improves performance if noise is roughly symmetric or if the dataset is very large. However, for rare disease variants and high-stakes predictions, even small fractions of mislabeled examples can be problematic.\n\n\n15.5.2 Strategies for robust learning with noisy labels\nApproaches to deal with label noise include:\n\nCurated subsets. Restrict training and evaluation to high-confidence annotations (e.g., ClinVar “Pathogenic” and “Benign” with multiple submitters and no conflicts), even at the cost of reduced size.\n\nSoft labels and uncertainty modeling. Use probabilistic labels derived from inter-rater disagreement, confidence scores, or continuous assay measurements rather than hard 0/1 labels.\n\nRobust losses. Employ loss functions less sensitive to mislabeled points (e.g., label smoothing, margin-based losses, or methods that down-weight high-loss outliers).\n\nNoise-aware training. Explicitly model label noise (e.g., via a noise transition matrix or latent variable models) and jointly infer true labels.\n\nConsensus across modalities. Combine evidence from protein structure, evolutionary conservation, regulatory context, and clinical data; treat disagreements as signals of uncertainty.\n\nMechanistic interpretability can also help flag model predictions that disagree with known biology, potentially identifying mislabeled examples.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#cross-ancestry-prs-transferability-and-model-fairness",
    "href": "ch-p4-confound.html#cross-ancestry-prs-transferability-and-model-fairness",
    "title": "15  Confounders in Model Training",
    "section": "15.6 Cross-Ancestry PRS Transferability and Model Fairness",
    "text": "15.6 Cross-Ancestry PRS Transferability and Model Fairness\nPolygenic risk scores and other genome-wide predictors have gained traction as potential tools for early disease risk stratification. However, many PRS have been developed primarily in individuals of European ancestry, raising concerns about:\n\nReduced predictive accuracy in underrepresented ancestries.\n\nBiased calibration, where risk is systematically over- or under-estimated in certain groups.\n\nDownstream disparities if PRS-informed clinical decisions (e.g., screening recommendations) are applied uniformly.\n\n\n15.6.1 Why transferability fails\nReasons for poor cross-ancestry transfer include:\n\nAllele frequency differences. Effect estimates calibrated in one population may not generalize when allele frequencies change.\n\nLD pattern differences. Tagging SNPs used in PRS may capture causal variants in one ancestry but not another.\n\nGene–environment interaction. Environmental exposures and lifestyle factors that interact with genetic risk differ across populations.\n\nAscertainment and recruitment biases. Early GWAS datasets often oversampled certain ancestries, clinical populations, or socioeconomic strata.\n\nThese issues carry over to deep learning–based PRS and GFMs fine-tuned for disease prediction. Even if the underlying model is trained on diverse genomes in a self-supervised fashion, the supervised fine-tuning and evaluation data can reintroduce bias.\n\n\n15.6.2 Towards more equitable models\nApproaches to improve cross-ancestry performance and fairness include:\n\nMulti-ancestry GWAS and training data. Include diverse cohorts at the design stage rather than as an afterthought.\n\nAncestry-aware modeling. Condition effect sizes or model parameters on ancestry, or learn ancestry-invariant representations coupled with ancestry-specific calibration.\n\nTransfer learning and fine-tuning. Adapt models from ancestries with large datasets to those with smaller datasets using domain adaptation techniques.\n\nFairness metrics. Report group-wise calibration, sensitivity, specificity, and decision-curve analyses, not just overall AUC.\n\nStakeholder engagement. Work with clinicians, ethicists, and affected communities to decide when and how PRS should be used, and what constitutes acceptable performance gaps.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#from-cautionary-tales-to-best-practices",
    "href": "ch-p4-confound.html#from-cautionary-tales-to-best-practices",
    "title": "15  Confounders in Model Training",
    "section": "15.7 From Cautionary Tales to Best Practices",
    "text": "15.7 From Cautionary Tales to Best Practices\nModern genomic foundation models promise impressive capabilities: genome-scale variant effect prediction, cross-species transfer, multi-omics integration, and clinically actionable risk scores. Yet without rigorous attention to confounders, these capabilities can be overstated or misapplied.\nEmerging work on genomic evaluation frameworks emphasizes:\n\nData documentation. Detailed datasheets for datasets and benchmarks, including recruitment, ancestry composition, technical pipelines, and label provenance.\n\nRobust evaluation protocols. Cross-cohort, cross-ancestry, and time-split evaluations that stress-test models beyond their training distribution.\n\nConfounder-aware training. Explicit modeling of ancestry, batch, and label uncertainty, and the use of adversarial or domain-adaptation techniques.\n\nTransparent reporting. Clear communication of limitations, potential failure modes, and groups for whom the model has not been validated.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-confound.html#a-practical-checklist-for-confounder-resilient-genomic-modeling",
    "href": "ch-p4-confound.html#a-practical-checklist-for-confounder-resilient-genomic-modeling",
    "title": "15  Confounders in Model Training",
    "section": "15.8 A Practical Checklist for Confounder-Resilient Genomic Modeling",
    "text": "15.8 A Practical Checklist for Confounder-Resilient Genomic Modeling\nTo close, here is a concise checklist you can apply when designing, training, and evaluating genomic models:\n\nPopulation structure\n\nHave you quantified ancestry and relatedness (e.g., via PCs or kinship)?\n\nAre cases and controls balanced within ancestry groups?\n\nDo you report performance stratified by ancestry?\n\nData splits and leakage\n\nAre individuals, families, and closely related samples confined to a single split?\n\nDo you split at the locus, gene, or chromosome level where appropriate?\n\nHave you checked for overlap with external databases used in evaluation?\n\nBatch and platform effects\n\nAre technical variables (batch, platform, institution) correlated with labels?\n\nHave you visualized embeddings colored by batch?\n\nDo you use harmonization, batch correction, or domain adaptation as needed?\n\nLabel quality\n\nHow are labels defined, and what is their uncertainty?\n\nDo you filter to high-confidence subsets for primary evaluation?\n\nDo you employ robust training strategies to handle label noise?\n\nCross-group performance and fairness\n\nDo you report metrics for each ancestry and relevant subgroup?\n\nAre risk scores calibrated across groups, or is group-specific calibration required?\n\nHave you considered the ethical and clinical implications of residual performance gaps?\n\nReproducibility and transparency\n\nAre dataset construction and splitting procedures fully documented and shareable?\n\nAre code and evaluation pipelines available for independent verification?\n\n\nBy systematically addressing these points, we can ensure that the gains from modern architectures—transformers, SSMs, and GFMs—translate into trustworthy advances in genomic science and medicine, rather than brittle models that merely reflect quirks of our data and history.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html",
    "href": "ch-p4-interp.html",
    "title": "16  Interpretability & Mechanisms",
    "section": "",
    "text": "16.1 Why Interpretability Matters for Genomic Models\nDeep learning models in genomics increasingly operate as systems-level surrogates for biology: they predict chromatin features, gene expression, or variant effects directly from sequence. When such models drive mechanistic hypotheses or clinical decisions, how they make predictions becomes as important as how well they perform.\nInterpretability in this context serves at least four roles:\nThis chapter surveys the main interpretability tools developed for genomic models, from convolutional filters and saliency maps to global regulatory vocabularies and attention patterns in genomic language models (gLMs) and transformer-based regulatory models. Throughout, the emphasis is on mechanistic interpretability: moving from “what correlates with the prediction?” to “what regulatory hypothesis does the model imply?”",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#why-interpretability-matters-for-genomic-models",
    "href": "ch-p4-interp.html#why-interpretability-matters-for-genomic-models",
    "title": "16  Interpretability & Mechanisms",
    "section": "",
    "text": "Mechanistic insight\n\nExtract sequence motifs (putative TF binding sites), regulatory grammars, and long-range interaction patterns directly from trained models.\n\nTurn “black-box” predictions into candidate mechanisms that can be tested experimentally.\n\nModel debugging and confounder detection\n\nReveal when models rely on artifacts (e.g., GC content, mappability, batch-specific motifs) instead of bona fide regulatory signals.\n\nComplement Chapter 14’s focus on data and evaluation confounders by interrogating model internals.\n\nClinical and translational trust\n\nSupport variant interpretation workflows by explaining why specific rare or de novo variants are predicted to be damaging.\n\nProvide interpretable axes of variation (e.g., motif disruptions, regulatory “sequence classes”) that can be combined with orthogonal evidence.\n\nScientific communication\n\nCondense high-dimensional latent representations into human-readable abstractions—motifs, regulatory classes, or interaction graphs—that can be shared across labs and applications.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#interpreting-convolutional-filters-as-motifs",
    "href": "ch-p4-interp.html#interpreting-convolutional-filters-as-motifs",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.2 Interpreting Convolutional Filters as Motifs",
    "text": "16.2 Interpreting Convolutional Filters as Motifs\nConvolutional neural networks (CNNs) remain a workhorse for modeling cis-regulatory sequence (Chapters 5–7). In many of these models, first-layer convolutional filters act as motif detectors:\n\nA filter slides along the one-hot encoded sequence (Chapter 8).\n\nAt each position, it computes a dot product between its weights and the local sequence window.\n\nHigh activation indicates that the subsequence closely matches the filter’s preferred pattern.\n\n\n16.2.1 From Filters to Motif Logos\nA common workflow to interpret filters:\n\nCollect high-activation instances\n\nRun the trained model on a large sequence set (e.g., training data or genome tiles).\n\nFor each filter, record positions where its activation exceeds a threshold.\n\nExtract and align subsequences\n\nPull out fixed-length windows around those positions.\n\nAlign them and compute base frequencies at each position.\n\nBuild a position weight matrix (PWM)\n\nConvert base frequencies to log-odds scores relative to a background distribution.\n\nVisualize as a sequence logo.\n\nMatch to known motif databases\n\nCompare PWMs to JASPAR or HOCOMOCO TF motif libraries using similarity scores.\n\nAnnotate filters with candidate TF identities (“this filter resembles CTCF”).\n\n\nThis procedure has been applied to models like DeepSEA and its successors to demonstrate that early layers learn motifs for canonical TFs and chromatin-associated patterns, validating that models are discovering biologically meaningful sequence features rather than arbitrary patterns.\n\n\n16.2.2 Beyond First-Layer Filters\nDeeper convolutional layers aggregate lower-level motifs:\n\nCombinatorial motifs: Filters that respond to pairs or clusters of TF motifs.\n\nGrammar patterns: Distance or orientation constraints (e.g., “ETS motif ~10 bp upstream of GATA motif”).\n\nContextual preferences: Filters that fire only in particular GC contexts or nucleosome positioning patterns.\n\nHowever, directly interpreting deeper layers becomes challenging because receptive fields expand and nonlinearities accumulate. This motivates attribution-based approaches that connect predictions back to individual bases.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#attribution-methods-connecting-bases-to-predictions",
    "href": "ch-p4-interp.html#attribution-methods-connecting-bases-to-predictions",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.3 Attribution Methods: Connecting Bases to Predictions",
    "text": "16.3 Attribution Methods: Connecting Bases to Predictions\nAttribution methods assign an “importance score” to each input base (or k-mer), reflecting how much it contributes to a prediction for a specific task and sequence.\nLet ( f(x) ) be a model predicting some output (e.g., chromatin accessibility, gene expression, or variant effect) from sequence ( x ). Attribution methods estimate the contribution of each base ( x_i ) to ( f(x) ), often for a specific output neuron (e.g., a particular cell type).\n\n16.3.1 In Silico Mutagenesis (ISM)\nIn silico mutagenesis is conceptually straightforward and model-agnostic:\n\nFor each position ( i ) and base ( b ), create a mutated sequence ( x^{(i b)} ).\n\nCompute the change in prediction\n[ f_{i,b} = f(x^{(i b)}) - f(x). ]\nAggregate these changes (e.g., max across non-reference alleles) to obtain a per-base importance score.\n\nVariants:\n\nSingle-nucleotide ISM: Mutate each base individually; expensive but faithful.\n\nSaturation mutagenesis: Explore all possible oligos in a window to probe combinatorial effects and grammar.\n\nVariant-specific scoring: Evaluate ( f() - f() ) for a particular SNV or indel.\n\nStrengths:\n\nTrue “what-if” causal perturbations under the model.\n\nWorks for any differentiable or non-differentiable model (including ensembles and post-processed scores).\n\nLimitations:\n\nComputationally expensive: ( O(L ||) ) forward passes for sequence length ( L ) and alphabet size ( || ).\n\nCaptures local effects; may miss distributed interactions if not designed carefully.\n\n\n\n16.3.2 Gradient-Based Methods\nGradient-based methods approximate “how much would the prediction change if we nudged this base?” via backpropagation.\n\n16.3.2.1 Vanilla Gradient / Saliency\nCompute the gradient of the output with respect to the input:\n[ s_i = . ]\nWith one-hot encoding, this gradient can be interpreted as the sensitivity to changing the nucleotide at position ( i ). A common variant multiplies the gradient by the input (“gradient × input”).\nPros:\n\nRequires a single backward pass per sequence.\n\nEasy to implement and integrate into training workflows.\n\nCons:\n\nSusceptible to gradient saturation (zero gradients in regions where the model is already confident).\n\nNoisy saliency maps often require smoothing or aggregation across multiple noisy inputs.\n\n\n\n16.3.2.2 DeepLIFT\nDeepLIFT (Deep Learning Important FeaTures) compares neuron activations between an input and a reference (or baseline) sequence, distributing differences back to inputs using layer-wise rules rather than raw gradients. It aims to:\n\nAvoid gradient saturation.\n\nEnforce a consistency constraint: the sum of input contributions matches the difference in output between input and reference.\n\nDeepLIFT has been widely used for genomic models, particularly in conjunction with TF-MoDISco (next section), where its base-level importance scores serve as inputs for motif discovery.\n\n\n16.3.2.3 Integrated Gradients (IG)\nIntegrated Gradients compute the path integral of gradients along a linear interpolation from a reference ( x’ ) to the input ( x ):\n[ _i(x) = (x_i - x’i) {}^1 d. ]\nIn practice, this integral is approximated via a Riemann sum over discrete steps. IG satisfies desirable axioms (e.g., sensitivity, implementation invariance) and tends to be less noisy than raw gradients.\nKey design considerations for all gradient-based methods:\n\nChoice of reference:\n\nRandom genomic background, dinucleotide-shuffled sequence, or an “average” non-functional sequence.\n\nDifferent references emphasize different aspects of the signal.\n\nOutput selection:\n\nSingle-task models: directly attribute the scalar output.\n\nMulti-task models: choose a specific track (e.g., H3K27ac in one cell type) or aggregate across tasks.\n\nPost-processing:\n\nSmooth along the sequence (e.g., average in sliding windows).\n\nAggregate over channels or strands.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#from-attributions-to-motifs-tf-modisco",
    "href": "ch-p4-interp.html#from-attributions-to-motifs-tf-modisco",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.4 From Attributions to Motifs: TF-MoDISco",
    "text": "16.4 From Attributions to Motifs: TF-MoDISco\nAttribution maps highlight where the model focuses, but they do not automatically yield consistent motifs or regulatory grammars. TF-MoDISco (Transcription Factor Motif Discovery from Importance Scores) was developed to bridge this gap.\n\n16.4.1 Core Idea\nRather than performing motif discovery on raw sequences, TF-MoDISco operates on base-level importance scores:\n\nCompute importance scores\n\nUse DeepLIFT, ISM, IG, or similar methods on many sequences.\n\nObtain an importance score for each base and strand.\n\nExtract “seqlets”\n\nIdentify local windows where the total importance exceeds a threshold.\n\nTreat each window (seqlet) as a candidate motif instance.\n\nCluster seqlets\n\nCompare seqlets using similarity metrics that consider both sequence and importance scores.\n\nCluster into groups corresponding to putative motifs.\n\nBuild consolidated motifs\n\nAlign seqlets within each cluster.\n\nConstruct PWMs and importance-weighted logos.\n\nOptionally match to known TF motifs.\n\nReport motif instances and grammar\n\nMap motifs back onto the genome.\n\nAnalyze co-occurrence, spacing, and orientation rules.\n\n\nWhen applied to models like BPNet, TF-MoDISco has recovered known TF motifs, discovered novel variants, and revealed grammars (e.g., directional spacing constraints) that can be validated with synthetic reporter assays.\nIn the context of genomic foundation models, an analogous workflow can be applied:\n\nUse a GFM or transformer-based model to produce base-level attributions for a specific downstream task (e.g., chromatin accessibility).\n\nRun TF-MoDISco to extract a task-specific motif vocabulary.\n\nAnalyze how motif usage changes across cell types, conditions, or species.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#interpreting-attention-and-long-range-context",
    "href": "ch-p4-interp.html#interpreting-attention-and-long-range-context",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.5 Interpreting Attention and Long-Range Context",
    "text": "16.5 Interpreting Attention and Long-Range Context\nTransformer-based models (Chapters 8–11) use self-attention to mix information across long genomic contexts, enabling them to capture distal regulatory interactions and genomic organization. Interpretability here often centers on attention patterns and long-range attribution.\n\n16.5.1 Genomic Language Models and Operon Structure (gLM)\nGenomic language models (gLMs) treat genes or genomic tokens as a sequence and train transformers to predict masked tokens, analogous to protein or text LMs. Work on gLMs trained on millions of metagenomic scaffolds shows that these models learn non-trivial genomic structure:\n\nAttention heads mark operons and co-regulated modules\n\nCertain heads specialize in connecting genes that are part of the same operon or functional module.\n\nAttention maps reveal networks of co-regulated genes, often aligning with known operon boundaries.\n\nFunctional semantics and taxonomic signals\n\nLatent representations cluster by enzymatic function and gene ontology.\n\nAttention patterns can separate clades and capture clade-specific gene neighborhoods.\n\nMechanistic interpretation\n\nThese patterns suggest the model has inferred a “syntax” of gene neighborhoods: which genes tend to co-occur and in what order, conditioned on phylogenetic context.\n\n\nWhile attention is not universally a faithful explanation of model decisions, attention analysis in gLM reveals emergent mechanistic structure that is consistent with biological organization.\n\n\n16.5.2 Distal Regulatory Elements in Enformer-Like Models\nEnformer and related models predict chromatin features and gene expression from large genomic windows (e.g., 100 kb+) by combining convolutional layers with transformer blocks.\nKey interpretability questions:\n\nWhich distal enhancers drive the predicted expression at a given transcription start site (TSS)?\n\nHow do variants in distal elements propagate to gene-level outputs?\n\nInterpretability strategies include:\n\nGradient-based attributions over long windows\n\nCompute attributions of a gene’s expression output with respect to input bases across the entire window.\n\nVisualize importance tracks to highlight putative enhancers and silencers.\n\nAttention pattern analysis\n\nIdentify attention heads that consistently link distal positions to TSS regions.\n\nRelate high-attention edges to Hi-C contact maps or chromatin interaction data.\n\nIn silico perturbation of regulatory elements\n\nDelete or scramble candidate enhancers and recompute gene expression predictions.\n\nInsert synthetic motifs or enhance motif scores to gauge dose–response relationships.\n\n\nThese analyses can reveal candidate enhancer–promoter links and TF motifs that the model deems critical for gene regulation, helping translate raw attention weights and attributions into mechanistic hypotheses.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#global-regulatory-vocabularies-sei-sequence-classes",
    "href": "ch-p4-interp.html#global-regulatory-vocabularies-sei-sequence-classes",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.6 Global Regulatory Vocabularies: Sei Sequence Classes",
    "text": "16.6 Global Regulatory Vocabularies: Sei Sequence Classes\nMost motif-based interpretation operates at the local level. Sei takes a complementary global approach by learning a vocabulary of regulatory sequence classes that summarize a vast array of chromatin profiles.\n\n16.6.1 The Sei Framework\nSei trains a deep sequence model to predict tens of thousands of chromatin profiles (TF binding, histone marks, accessibility) across many cell types directly from DNA sequence. The key interpretability step is to compress these thousands of outputs into a few dozen “sequence classes”, each representing a characteristic regulatory activity pattern:\n\nPromoter-like classes (e.g., H3K4me3-rich, TSS-proximal).\n\nEnhancer-like classes (H3K27ac, H3K4me1).\n\nRepressive classes (H3K27me3, H3K9me3).\n\nCell-type- or lineage-specific modules (e.g., neuronal, immune).\n\nEach input sequence (or variant) is assigned a score for each sequence class, effectively mapping it to a point in a low-dimensional “regulatory activity space”.\n\n\n16.6.2 Interpretation and Applications\nA regulatory vocabulary like Sei’s supports several interpretability goals:\n\nIntermediate, human-interpretable features\n\nInstead of raw high-dimensional outputs, one can reason in terms of “promoter-like,” “B-cell enhancer,” or “polycomb-repressed” scores.\n\nVariant interpretation\n\nVariants can be summarized by their shifts in sequence-class scores, yielding concise descriptions like “increases neuronal enhancer activity while decreasing repressive marks.”\n\nTrait and disease enrichment\n\nGWAS loci can be enriched for specific sequence classes, revealing tissues and regulatory programs most relevant to disease.\n\n\nThis notion of a regulatory vocabulary parallels word embeddings or topics in NLP and provides a bridge between highly multivariate model outputs and mechanistically interpretable axes of variation.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#case-study-from-base-pair-attributions-to-regulatory-grammar",
    "href": "ch-p4-interp.html#case-study-from-base-pair-attributions-to-regulatory-grammar",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.7 Case Study: From Base-Pair Attributions to Regulatory Grammar",
    "text": "16.7 Case Study: From Base-Pair Attributions to Regulatory Grammar\nPutting the pieces together, a typical mechanistic interpretability pipeline for a CNN or transformer-based regulatory model might look like:\n\nTrain a predictive model\n\nFor example, predict chromatin accessibility or TF ChIP-seq tracks from sequence.\n\nCompute base-level attributions\n\nUse DeepLIFT or IG for positive predictions in a target cell type.\n\nDiscover motifs with TF-MoDISco\n\nExtract seqlets from high-attribution regions, cluster, and derive motifs.\n\nMatch motifs to known TFs and identify novel ones.\n\nInfer grammar from motif instances\n\nAnalyze motif co-occurrence, spacing, and orientation in high-scoring sequences.\n\nUse knock-in/knock-out in silico experiments to confirm dependencies (e.g., both motifs needed, order matters).\n\nRelate motifs to sequence classes or attention patterns\n\nMap motif-rich regions to Sei sequence classes or Enformer attributions.\n\nConnect local motif grammar to global regulatory context (e.g., distal enhancer–promoter linkages, cell-type specificity).\n\nValidate with experiments or external datasets\n\nCheck whether motif disruptions align with reporter assay effects or allelic imbalance.\n\nCompare inferred enhancer–promoter links to Hi-C or CRISPR perturbation screens.\n\n\nThis integrated approach moves beyond “pretty saliency maps” toward testable hypotheses about regulatory logic.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#evaluating-interpretations-faithfulness-vs-plausibility",
    "href": "ch-p4-interp.html#evaluating-interpretations-faithfulness-vs-plausibility",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.8 Evaluating Interpretations: Faithfulness vs Plausibility",
    "text": "16.8 Evaluating Interpretations: Faithfulness vs Plausibility\nNot all explanations are equally trustworthy. Effective interpretability work must grapple with the distinction between:\n\nPlausibility: Does the explanation “look” biological (e.g., known motifs, enhancer marks)?\n\nFaithfulness: Does the explanation accurately reflect the internal computation of the model?\n\nPotential pitfalls:\n\nAttention as explanation\n\nHigh attention weights need not correspond to large changes in output; they may reflect information routing rather than causal influence.\n\nCombining attention with attribution or perturbation analyses yields more reliable insights.\n\nAttribution noise and saturation\n\nGradient-based methods can produce noisy maps or miss important features in saturated regions.\n\nUse multiple methods (ISM, DeepLIFT, IG) and check for consistency.\n\nShortcut features\n\nModels may rely on dataset-specific artifacts (e.g., barcode k-mers, GC content) that produce clean motifs but are not mechanistically meaningful.\n\n\nRecommended practices:\n\nSanity checks\n\nRandomize model weights: attributions should degrade to noise.\n\nRandomize labels: derived motifs should disappear or lose predictive power.\n\nCounterfactual tests\n\nDelete or scramble high-attribution regions and confirm that predictions drop accordingly.\n\nInsert discovered motifs into neutral backgrounds to test gain-of-function effects.\n\nBenchmarking interpretability methods\n\nUse synthetic datasets with known ground-truth grammar.\n\nCompare methods on their ability to recover planted motifs and interactions.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#a-practical-interpretability-toolbox-for-genomic-foundation-models",
    "href": "ch-p4-interp.html#a-practical-interpretability-toolbox-for-genomic-foundation-models",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.9 A Practical Interpretability Toolbox for Genomic Foundation Models",
    "text": "16.9 A Practical Interpretability Toolbox for Genomic Foundation Models\nFor practitioners working with genomic foundation models (GFMs) and their fine-tuned derivatives, a practical toolbox might include:\n\nLocal effect estimation\n\nFor variant effect prediction: use ref/alt scoring and small-window ISM around variants.\n\nAggregate per-base attributions into per-variant or per-motif scores.\n\nMotif and grammar discovery\n\nCompute base-level attributions for high-confidence predictions.\n\nRun TF-MoDISco or similar algorithms to build a motif vocabulary.\n\nAnalyze motif grammars across tasks (e.g., multiple cell types or assays).\n\nGlobal context visualization\n\nFor transformer-based GFMs: inspect attention patterns to identify heads that track operons, gene neighborhoods, or enhancer–promoter loops.\n\nFor models like Enformer: combine long-range attributions with contact maps to hypothesize regulatory architectures.\n\nRegulatory vocabularies and embeddings\n\nUse frameworks like Sei to project sequences into a low-dimensional regulatory activity space.\n\nCluster variants, enhancers, or genomic regions by their sequence-class profiles to reveal shared regulatory programs.\n\nModel and dataset auditing\n\nUse interpretability tools to identify reliance on confounded or undesirable features.\n\nCross-reference with Chapter 14’s confounder taxonomy (ancestry stratification, batch effects) to design deconfounded training and evaluation.\n\nHuman-in-the-loop analysis\n\nIntegrate motif and sequence-class outputs into visualization tools (e.g., genome browsers with attribution tracks, motif tracks, and class scores).\n\nEnable domain experts to iteratively refine hypotheses.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p4-interp.html#outlook-from-explanations-to-mechanistic-models",
    "href": "ch-p4-interp.html#outlook-from-explanations-to-mechanistic-models",
    "title": "16  Interpretability & Mechanisms",
    "section": "16.10 Outlook: From Explanations to Mechanistic Models",
    "text": "16.10 Outlook: From Explanations to Mechanistic Models\nInterpretability in genomic deep learning is evolving from post hoc explanation toward model-assisted mechanistic discovery:\n\nFoundation models provide rich latent spaces and long-range context.\n\nAttribution and motif discovery tools translate those representations into candidate regulatory grammars.\n\nGlobal vocabularies like Sei’s sequence classes offer interpretable axes spanning thousands of assays.\n\nAttention analysis in genomic language models reveals emergent gene-level organization, hinting at scalable ways to capture systems-level biology.\n\nThe next frontier is to close the loop:\n\nUse insights from interpretability (motifs, grammars, sequence classes) to design better architectures and training objectives.\n\nFeed experimentally validated grammars back into models as inductive biases.\n\nDevelop evaluation frameworks where success is measured not only by predictive accuracy but also by mechanistic fidelity—how well model-derived hypotheses align with the causal structure of regulatory biology.\n\nIn this sense, interpretability is not just a diagnostic for black-box models. It is a central tool for turning genomic foundation models into engines of biological discovery, capable of bridging the gap between sequence-level predictions and the mechanistic understanding that underpins robust clinical translation.",
    "crumbs": [
      "Part IV: GFMs & Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html",
    "href": "ch-p5-clinical.html",
    "title": "17  Clinical Risk Prediction",
    "section": "",
    "text": "17.1 Problem Framing: What Is Clinical Risk Prediction?\nModern genomic foundation models (GFMs) give us increasingly rich representations of DNA, RNA, proteins, and multi-omic context (Parts II–IV). The natural next question is: how do we turn these representations into actionable predictions for individual patients?\nThis chapter focuses on clinical risk prediction and decision support—models that estimate the probability, timing, or trajectory of outcomes such as incident disease, progression, recurrence, or adverse drug reactions. We emphasize how GFMs and related deep models:\nWe end with case studies in cardiometabolic risk, oncology risk and recurrence, and pharmacogenomics / adverse drug reactions, illustrating how GFMs move from bench to bedside.\nClinical risk prediction is the task of mapping patient data—including genotypes, family history, clinical measurements, imaging, and environmental factors—to probabilistic statements about future outcomes. Concretely, a model might answer questions like:\nIn practice, these tasks fall into a few archetypes:\nGFMs enter these problems as feature generators: they transform raw genomic and multi-omic data into structured embeddings, variant effect scores, or region-level functional annotations. These representations then feed classic supervised learning tasks—classification, regression, and survival modeling—alongside clinical covariates.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#problem-framing-what-is-clinical-risk-prediction",
    "href": "ch-p5-clinical.html#problem-framing-what-is-clinical-risk-prediction",
    "title": "17  Clinical Risk Prediction",
    "section": "",
    "text": "What is this patient’s 10-year risk of coronary artery disease if treated with standard of care?\n\nGiven current tumor characteristics and therapy, what is the hazard of recurrence within 2 years?\n\nIf we start this medication, what is the probability of a severe adverse drug reaction (ADR) in the next 6 months?\n\n\n\nIndividual-level incident risk\n\nWill a currently disease-free individual develop disease within a specified time window (e.g., 10-year type 2 diabetes risk)?\n\n\nProgression and complication risk\n\nAmong individuals with an existing condition, who will develop complications (e.g., nephropathy in diabetes, heart failure after myocardial infarction)?\n\n\nPrognosis and survival\n\nTime-from-baseline to events such as death, recurrence, or transplant, often with censoring and competing risks.\n\n\nTreatment response and toxicity\n\nWill a patient benefit from therapy A vs B, and what is their risk of severe toxicity or ADR?",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#task-types-and-loss-functions",
    "href": "ch-p5-clinical.html#task-types-and-loss-functions",
    "title": "17  Clinical Risk Prediction",
    "section": "17.2 Task Types and Loss Functions",
    "text": "17.2 Task Types and Loss Functions\nAlthough GFMs provide sophisticated inputs, the prediction tasks themselves often re-use well-understood statistical frameworks.\n\n17.2.1 Binary and Multi-label Classification\nFor many screening or triage problems, risk prediction is posed as:\n\nWill outcome Y occur within horizon T?\n\nExamples include incident atrial fibrillation within 5 years, or hospitalization for heart failure in the next 12 months. Models output a risk score ( = P(Y=1 x) ), trained with cross-entropy or focal losses.\nExtensions:\n\nMulti-label classification: Predict multiple outcomes (e.g., myocardial infarction, stroke, heart failure) simultaneously; share a common representation but separate output heads.\n\nOrdinal endpoints: Disease stages or severity scores modeled with ordinal losses instead of strictly binary outcomes.\n\nGFMs contribute by providing richer genetic features than traditional hand-crafted burden scores or PRS (e.g., variant-level embeddings from Nucleotide Transformer, GPN, or regulatory LMs) (Dalla-Torre et al. 2023; Benegas, Batra, and Song 2023).\n\n\n17.2.2 Survival and Time-to-Event Modeling\nRisk is often more naturally expressed as time-to-event:\n\nTime from baseline to myocardial infarction or revascularization.\n\nTime from surgery to cancer recurrence.\n\nTime from first exposure to drug to severe toxicity.\n\nThese require models that handle censoring (patients lost to follow-up or event-free at study end). Approaches include:\n\nCox proportional hazards models with genomic and GFM-derived features as covariates.\n\nDeep survival models that use neural networks to parameterize hazard functions, survival curves, or discrete-time hazards.\n\nCompeting risks models for mutually exclusive outcomes (e.g., cancer-specific vs non-cancer mortality).\n\nGFMs naturally provide high-dimensional, possibly non-linear features; deep survival architectures can exploit these features while learning flexible hazard structures.\n\n\n17.2.3 Multi-task Risk and Shared Representations\nLarge health systems increasingly estimate risk for dozens of outcomes simultaneously (e.g., hospital readmission, multiple cardiovascular endpoints, medication-specific ADRs). This motivates multi-task frameworks:\n\nA shared encoder (combining EHR, genomic, and multi-omic encoders) produces a patient-level embedding.\n\nMultiple output heads estimate risks for different endpoints or time horizons.\n\nSuch models can exploit cross-task correlations and share statistical strength (e.g., overlapping genetic architectures between lipids, CAD, and stroke). Deep polygenic architectures like Delphi and G2PT already adopt multi-trait ideas for genomic risk representations (Georgantas, Kutalik, and Richiardi 2024; Lee et al. 2025).",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#from-prs-to-gfm-enabled-risk-scores",
    "href": "ch-p5-clinical.html#from-prs-to-gfm-enabled-risk-scores",
    "title": "17  Clinical Risk Prediction",
    "section": "17.3 From PRS to GFM-Enabled Risk Scores",
    "text": "17.3 From PRS to GFM-Enabled Risk Scores\nPolygenic risk scores (PRS) are a natural starting point for genomically informed clinical prediction.\n\n17.3.1 Classical PRS: Strengths and Limitations\nTraditional PRS typically:\n\nUse GWAS summary statistics to estimate per-variant weights.\n\nConstruct a score ( S = _j w_j g_j ), where ( g_j ) is genotype at variant ( j ) and ( w_j ) is its estimated effect size.\n\nPlug PRS into regression or survival models alongside clinical covariates (age, sex, BMI, labs).\n\nDespite many successes, classical PRS have well-known limitations:\n\nLimited modeling of epistasis and non-linearities: Additive models struggle with higher-order interactions and context-dependent effects.\n\nChallenge in integrating functional priors: Annotation-aware methods exist, but rarely leverage full GFMs.\n\nPortability gaps: Performance often drops in under-represented ancestries due to LD structure and GWAS ascertainment.\n\nThese limitations motivate deep learning-based PRS that better exploit structure in both genotype and functional annotation space.\n\n\n17.3.2 Deep Polygenic Risk: Delphi and G2PT\nRecent methods push beyond additive scores by using deep sequence and genotype models:\n\nDelphi: A deep-learning method for polygenic risk prediction that jointly models variant-level features and higher-order patterns across the genome (Georgantas, Kutalik, and Richiardi 2024).\n\nCan incorporate variant annotations and linkage structure more flexibly than linear PRS.\n\nSupports multi-phenotype prediction, effectively performing task-conditioned PRS.\n\nG2PT (Genotype-to-Phenotype Transformer): A transformer-based architecture that treats an individual’s genotype as a sequence of variant “tokens” and learns polygenic risk representations with attention-based context (Lee et al. 2025).\n\nNaturally captures epistatic interactions via attention, not just additive effects.\n\nEmphasizes interpretability by tying attention patterns back to loci and pathways.\n\n\nBoth systems can optionally use GFM-derived variant features (e.g., scores from sequence-level LMs such as Nucleotide Transformer, HyenaDNA, or GPN) (Dalla-Torre et al. 2023; Nguyen et al. 2023; Benegas, Batra, and Song 2023). In this view:\n\nA GFM maps variant and local sequence context to variant effect features (e.g., predicted impact on chromatin, expression, motifs).\n\nA polygenic risk model (Delphi, G2PT, or related) aggregates these features across the genome to produce a patient-level risk embedding.\n\nA clinical head uses this embedding plus EHR covariates to output risk for specific outcomes or time horizons.\n\n\n\n17.3.3 Fine-mapping and Causal Variants: MIFM\nPolygenic risk ultimately hinges on causal variants, not just associated markers. MIFM (Multiple Instance Fine-Mapping) exemplifies how deep sequence models can refine the link between variant effects and risk:\n\nMIFM uses a deep sequence model in a multiple-instance learning framework to identify causal regulatory variants within associated loci (Rakowski and Lippert 2025).\n\nBy modeling sets (bags) of variants per locus, it distinguishes causal variants from passengers in tight LD blocks.\n\nThe outputs—posterior probabilities or importance scores for candidate variants—can inform both mechanistic studies and more parsimonious, interpretable PRS.\n\nTogether, Delphi, G2PT, and MIFM illustrate a pattern that recurs throughout this chapter:\n\nUse GFMs and deep sequence models to transform raw genotype into rich, structured features, then plug those features into prediction and decision-support architectures that live closer to the clinic.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#beyond-genotype-fusing-gfms-with-ehr-and-multi-omics",
    "href": "ch-p5-clinical.html#beyond-genotype-fusing-gfms-with-ehr-and-multi-omics",
    "title": "17  Clinical Risk Prediction",
    "section": "17.4 Beyond Genotype: Fusing GFMs with EHR and Multi-omics",
    "text": "17.4 Beyond Genotype: Fusing GFMs with EHR and Multi-omics\nClinical risk prediction rarely depends on genetics alone. Real-world deployment typically requires fusing genomic features with EHR, imaging, and other omics, mirroring the multi-omics integration strategies from Chapter 16 (Cao and Gao 2022; Camillo et al. 2024; Clarke et al. 2024).\n\n17.4.1 Feature Sources\n\nGenomics and regulatory features\n\nZero-shot variant scores from DNA GFMs (e.g., Nucleotide Transformer, HyenaDNA, GPN, Grover) (Dalla-Torre et al. 2023; Nguyen et al. 2023; Benegas, Batra, and Song 2023).\n\nCoding variant scores from protein LMs (e.g., AlphaMissense-like systems; see earlier chapters).\n\nFine-mapped causal variant probabilities from MIFM or similar (Rakowski and Lippert 2025).\n\nMulti-omics and systems context\n\nCell-type–resolved epigenomic and transcriptomic embeddings from GLUE/SCGLUE and CpGPT (Cao and Gao 2022; Camillo et al. 2024).\n\nRare-variant burden and pathway-level representations from DeepRVAT and related models (Clarke et al. 2024).\n\nTumor-level representations from models such as SetQuence/SetOmic or GNN-based cancer subtypers (Jurenaite et al. 2024; X. Li et al. 2022; H. Li et al. 2024).\n\nClinical covariates and EHR\n\nDemographics, vitals, lab results, medication history.\n\nProblem lists, procedures, imaging-derived features.\n\nTime-varying trajectories of biomarkers (e.g., eGFR, HbA1c, tumor markers).\n\n\n\n\n17.4.2 Fusion Patterns\nArchitecturally, risk models usually adopt one of the fusion strategies echoed from Chapter 16:\n\nEarly fusion\n\nConcatenate GFM-derived genomic embeddings with static clinical covariates and feed into a single MLP or survival model.\n\nSimple but sensitive to scaling, missingness, and modality imbalance.\n\nIntermediate fusion\n\nSeparate encoders for genomics, EHR, and multi-omics produce modality-specific embeddings.\n\nA fusion layer (attention, cross-modal transformer, or graph-based integration) combines them into a patient embedding, which downstream heads use for risk prediction.\n\nLate fusion / ensembling\n\nIndependent models per modality (e.g., a PRS-only model, an EHR-only model).\n\nMeta-model or decision rule combines predictions (e.g., “treat if either PRS or EHR risk is high”).\n\n\nFrom a practical standpoint, intermediate fusion is often most attractive: it allows modularity (swap encoders as GFMs improve) while enabling cross-modal interactions.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#evaluation-discrimination-calibration-and-clinical-utility",
    "href": "ch-p5-clinical.html#evaluation-discrimination-calibration-and-clinical-utility",
    "title": "17  Clinical Risk Prediction",
    "section": "17.5 Evaluation: Discrimination, Calibration, and Clinical Utility",
    "text": "17.5 Evaluation: Discrimination, Calibration, and Clinical Utility\nHigh performance on test sets is not enough for clinical deployment. Risk models must be discriminative, well-calibrated, robust, and clinically useful.\n\n17.5.1 Discrimination\nDiscrimination measures how well the model ranks individuals by risk:\n\nAUROC (AUC) for binary endpoints.\n\nAUPRC when outcomes are rare (e.g., severe ADRs).\n\nC-index and time-dependent AUC for survival tasks.\n\nStrong discrimination is necessary but not sufficient; poorly calibrated models can still achieve high AUROC.\n\n\n17.5.2 Calibration and Risk Stratification\nCalibration asks whether predicted probabilities match observed frequencies:\n\nIf a group of patients is assigned ~20% risk of an event, do ~20% actually experience it?\n\nCalibration is assessed with calibration plots, Hosmer–Lemeshow tests, and Brier scores, often stratified by subgroups (e.g., ancestry, sex, age).\n\nFor PRS-informed models, calibration is especially important because:\n\nRaw PRS are often centered and scaled rather than calibrated; mapping PRS to absolute risk usually requires post-hoc models that incorporate baseline incidence and covariates.\n\nGFMs can shift score distributions as architectures evolve; recalibration may be required when swapping or updating encoders.\n\n\n\n17.5.3 Uncertainty Estimation and “When Not to Predict”\nIn high-stakes settings, models should know when they do not know. Common strategies include:\n\nEnsemble variance or Monte Carlo dropout as uncertainty proxies.\n\nConformal prediction to output risk intervals or prediction sets with guaranteed coverage.\n\nSelective prediction / abstention: allow models to abstain on cases where uncertainty is high or inputs are out-of-distribution (e.g., rare ancestries missing from training, novel tumor subtypes).\n\nFor GFM-based systems, uncertainty can be decomposed:\n\nGenomic uncertainty: confidence in variant effect predictions or fine-mapping (e.g., MIFM probabilities).\n\nClinical uncertainty: extrapolation to new care settings, practice patterns, or patient populations.\n\nCommunicating uncertainty transparently is a core part of decision support.\n\n\n17.5.4 Fairness, Bias, and Health Equity\nMany genomic and EHR datasets reflect historical and structural inequities. Risk models can amplify these biases if not carefully evaluated.\nKey considerations:\n\nAncestry and PRS portability: Classical PRS underperform in under-represented ancestries due to GWAS design; GFM-based methods such as Delphi and G2PT have the opportunity—but not the guarantee—to improve this by leveraging functional priors and cross-ancestry information (Georgantas, Kutalik, and Richiardi 2024; Lee et al. 2025).\n\nMeasurement and access bias: EHR-derived features may differ systematically across groups (e.g., who gets genotyped, which labs are ordered).\n\nGroup-wise calibration: Evaluate calibration and discrimination separately by ancestry, sex, socio-economic proxies, and care site.\n\nFairness metrics and constraints: When necessary, enforce group-level constraints (e.g., equalized odds) or design affirmative models targeting historically disadvantaged groups.\n\nEquity is not an afterthought; for GFMs, it should inform what data to pretrain on, which benchmarks to report, and how to deploy models in practice.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#prospective-validation-trials-and-regulation",
    "href": "ch-p5-clinical.html#prospective-validation-trials-and-regulation",
    "title": "17  Clinical Risk Prediction",
    "section": "17.6 Prospective Validation, Trials, and Regulation",
    "text": "17.6 Prospective Validation, Trials, and Regulation\nRetrospective AUCs are not enough to justify clinical use. Clinical risk models typically require:\n\nProspective validation: Evaluate model performance in a temporally held-out cohort, ideally in multiple health systems with different population structures and practice patterns.\n\nImpact studies: Measure whether using the model actually changes clinician behavior and improves outcomes (e.g., better statin targeting, fewer ADRs, reduced unnecessary imaging).\n\nRandomized or pragmatic trials when models materially influence treatment decisions, to guard against hidden confounding in observational evaluations.\n\nRegulatory landscapes (e.g., device approvals, software-as-a-medical-device frameworks) increasingly recognize learning systems and continuous updates. GFMs complicate this further:\n\nA “fixed” risk model may rely on a GFM backbone that improves over time; updates may change risk rankings and calibration.\n\nRegulatory strategies include locked models with explicit versions, change control plans, or adaptive approvals for constrained forms of continual learning.\n\nRegardless of the framework, clear documentation of data provenance, GFM versions, training procedures, and validation results is essential.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#monitoring-drift-and-continual-learning",
    "href": "ch-p5-clinical.html#monitoring-drift-and-continual-learning",
    "title": "17  Clinical Risk Prediction",
    "section": "17.7 Monitoring, Drift, and Continual Learning",
    "text": "17.7 Monitoring, Drift, and Continual Learning\nOnce deployed, GFMs and downstream risk models operate in non-stationary environments:\n\nClinical practice patterns change (new treatments, guidelines).\n\nPatient populations drift (e.g., new screening programs).\n\nLab assays and sequencing pipelines evolve.\n\nMonitoring should track:\n\nInput distributions (e.g., genotype frequencies, EHR feature patterns).\n\nOutput distributions (risk score histograms, fraction of patients above decision thresholds).\n\nPerformance over time (calibration, discrimination), often via rolling windows or periodic audits.\n\nWhen drift is detected:\n\nRecalibration may suffice (e.g., refitting a calibration layer to current data).\n\nPartial retraining of heads or fusion layers can adapt to new environments while keeping GFM weights fixed.\n\nFull continual learning—including updating GFM backbones—requires careful safeguards to avoid catastrophic forgetting and maintain regulatory compliance.\n\nDesign patterns from Chapter 16’s systems models (e.g., modular encoders, robust interfaces between GFMs and clinical layers) are crucial for maintainable, updatable decision support.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#case-studies",
    "href": "ch-p5-clinical.html#case-studies",
    "title": "17  Clinical Risk Prediction",
    "section": "17.8 Case Studies",
    "text": "17.8 Case Studies\nTo make these ideas concrete, we outline three stylized case studies that build on models and concepts from earlier chapters.\n\n17.8.1 Cardiometabolic Risk Stratification\nGoal: Identify individuals at high risk of major adverse cardiovascular events (MACE)—e.g., myocardial infarction, stroke, cardiovascular death—over a 10-year horizon.\nInputs:\n\nGenotype: Biobank-scale genotyping or WGS data.\n\nGFM features: Variant effect scores from DNA GFMs (Nucleotide Transformer, HyenaDNA, GPN) (Dalla-Torre et al. 2023; Nguyen et al. 2023; Benegas, Batra, and Song 2023).\n\nPolygenic model: Delphi or G2PT to produce a polygenic risk embedding for cardiometabolic traits (Georgantas, Kutalik, and Richiardi 2024; Lee et al. 2025).\n\nClinical data: Age, sex, BMI, blood pressure, lipids, smoking, diabetes status, medications (e.g., statins, antihypertensives).\n\nModel design:\n\nUse a DNA GFM to compute variant-level annotations (e.g., predicted enhancer disruption in cardiomyocyte or hepatocyte contexts).\n\nFeed annotations and genotypes into Delphi or G2PT to obtain a patient-level genomics embedding tuned for cardiometabolic outcomes.\n\nFuse the genomics embedding with EHR covariates via an intermediate fusion network (e.g., MLP or transformer over structured features).\n\nTrain the model to predict 10-year MACE risk using survival or discrete-time hazard losses.\n\nClinical use:\n\nStratify patients into risk categories (e.g., low, intermediate, high) that inform statin initiation, PCSK9 inhibitor consideration, or intensive lifestyle intervention.\n\nProvide individual-level explanations: highlight variants and pathways (via G2PT attention or Delphi variant contributions) that most contributed to risk—bridging Chapters 9 and 15.\n\nEvaluate equity: ensure performance and calibration hold across ancestries and care sites.\n\n\n\n17.8.2 Oncology: Risk and Recurrence Prediction\nGoal: Predict recurrence risk and treatment benefit for patients with solid tumors after surgery or first-line therapy.\nInputs:\n\nSomatic landscapes from whole-exome or whole-genome tumor sequencing.\n\nTumor representations from deep set or transformer architectures such as SetQuence/SetOmic (Jurenaite et al. 2024).\n\nMulti-omics: tumor expression, methylation, and chromatin accessible from integrated frameworks (GLUE, CpGPT) (Cao and Gao 2022; Camillo et al. 2024).\n\nGNN-based subtyping: embeddings or cluster assignments from cancer subtyping models like MoGCN and CGMega (X. Li et al. 2022; H. Li et al. 2024).\n\nClinical features: stage, grade, performance status, treatment regimen.\n\nModel design:\n\nEncode somatic mutation sets with SetQuence/SetOmic to obtain tumor-variant embeddings (Jurenaite et al. 2024).\n\nIntegrate transcriptomic and epigenomic profiles via GLUE-like latent spaces and CpGPT methylation embeddings (Cao and Gao 2022; Camillo et al. 2024).\n\nCombine these with GNN-based subtype embeddings (MoGCN/CGMega) to capture tumor–microenvironment and histopathological context (X. Li et al. 2022; H. Li et al. 2024).\n\nFuse tumor-level representations with clinical features in a time-to-recurrence model (e.g., flexible deep survival network).\n\nClinical use:\n\nProvide risk estimates that guide adjuvant therapy decisions (e.g., intensifying chemotherapy or adding targeted agents for high-risk patients).\n\nSuggest candidate biomarkers or pathways for trial stratification, based on GFM-derived importance scores and attention maps.\n\nMonitor drift as treatment standards evolve; update models to reflect new targeted therapies and immune checkpoint inhibitors.\n\n\n\n17.8.3 Pharmacogenomics and Adverse Drug Reaction Risk\nGoal: Predict which patients are at high risk of severe ADRs (e.g., myopathy on statins, severe cutaneous reactions to certain drugs, cardiotoxicity of oncology agents).\nInputs:\n\nGermline variation in pharmacogenes (e.g., CYP family, HLA alleles) and broader genome.\n\nVariant effect scores from both DNA and protein LMs for coding and regulatory variants in drug metabolism and immune genes (see Chapters 2–3, 9–10).\n\nClinical context: co-medications, comorbidities, organ function (liver, kidney), prior adverse reactions.\n\nModel design:\n\nUse GFMs to derive mechanistically meaningful features for variants in pharmacogenes (e.g., predicted impact on protein stability, binding, or gene regulation).\n\nAggregate these features across loci into a pharmacogenomic risk embedding, possibly using a G2PT-style transformer restricted to relevant genes (Lee et al. 2025).\n\nCombine this with EHR data in a multi-task classification model that predicts ADR risk for multiple drugs or drug classes.\n\nClinical use:\n\nFlag patients at high risk before initiating therapy, prompting genotype-guided drug choice or dose adjustment.\n\nGenerate reports that tie risk back to specific variants and pharmacogenes, aligned with existing clinical pharmacogenomics guidelines.\n\nEvaluate performance across ancestries to avoid exacerbating disparities in access to safe and effective therapy.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-clinical.html#practical-design-patterns-and-outlook",
    "href": "ch-p5-clinical.html#practical-design-patterns-and-outlook",
    "title": "17  Clinical Risk Prediction",
    "section": "17.9 Practical Design Patterns and Outlook",
    "text": "17.9 Practical Design Patterns and Outlook\nAcross these examples, several design patterns for GFM-enabled clinical prediction recur:\n\nTreat GFMs as modular feature extractors:\n\nKeep a clear separation between foundation encoders and clinical prediction heads, easing updates and regulatory management.\n\nEmbrace multi-modal fusion:\n\nCombine genotype, multi-omics, and EHR, taking advantage of architectures discussed in Chapters 10 and 16 (Dalla-Torre et al. 2023; Cao and Gao 2022).\n\nPrioritize calibration, uncertainty, and fairness as first-class citizens, not post-hoc add-ons.\nBridge interpretability and mechanism:\n\nUse tools from Chapter 15 to connect individual risk predictions to variants, regions, and pathways, enabling mechanistic hypotheses and clinician trust.\n\nDesign for continual learning and monitoring:\n\nAssume that clinical practice and data distributions will change; build pipelines that can adapt responsibly.\n\n\nIn the broader story of this book, clinical risk prediction and decision support represent a key translation layer: they connect the representational gains of genomic foundation models to the realities of patient care. The next chapters will extend these ideas to other application domains (e.g., rare disease diagnosis, discovery of pathogenic variants, and drug/biotech innovation), further exploring how GFMs reshape translational genomics.\n\n\n\n\nBenegas, Gonzalo, Sanjit Singh Batra, and Yun S. Song. 2023. “[GPN] DNA Language Models Are Powerful Predictors of Genome-Wide Variant Effects.” Proceedings of the National Academy of Sciences 120 (44): e2311219120. https://doi.org/10.1073/pnas.2311219120.\n\n\nCamillo, Lucas Paulo de Lima, Raghav Sehgal, Jenel Armstrong, Albert T. Higgins-Chen, Steve Horvath, and Bo Wang. 2024. “CpGPT: A Foundation Model for DNA Methylation.” bioRxiv. https://doi.org/10.1101/2024.10.24.619766.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus Wahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024. “[DeepRVAT] Integration of Variant Annotations Using Deep Set Networks Boosts Rare Variant Association Testing.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nJurenaite, Neringa, Daniel León-Periñán, Veronika Donath, Sunna Torge, and René Jäkel. 2024. “SetQuence & SetOmic: Deep Set Transformers for Whole Genome and Exome Tumour Analysis.” BioSystems 235 (January): 105095. https://doi.org/10.1016/j.biosystems.2023.105095.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam, Amit R. Majithia, and Trey Ideker. 2025. “[G2PT] A Genotype-Phenotype Transformer to Assess and Explain Polygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai, et al. 2024. “CGMega: Explainable Graph Neural Network Framework with Attention Mechanisms for Cancer Gene Module Dissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and Yunping Zhu. 2022. “MoGCN: A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Analysis.” Frontiers in Genetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html",
    "href": "ch-p5-variants.html",
    "title": "18  Pathogenic Variant Discovery",
    "section": "",
    "text": "18.1 From Variant Effect Prediction to Prioritization\nClinical genetics ultimately cares about specific variants and genes: which changes in a patient’s genome plausibly explain their phenotype, and which loci are compelling targets for follow-up in the lab. The previous chapters focused on foundation models for variant effect prediction (Chapter 13), multi-omics integration (Chapter 16), and clinical risk prediction (Chapter 17). This chapter shifts the emphasis from prediction to discovery workflows.\nThe central question is:\nWe will treat “pathogenic” broadly—covering both Mendelian variants with large effects and complex trait variants that modulate risk more subtly. GFMs appear at multiple stages of these pipelines:\nWe will walk through these roles from locus-level variant ranking, to Mendelian disease diagnostics, to graph-based gene prioritization, and finally to closed-loop “hypothesis factory” workflows that blend GFMs with systematic perturbation experiments.\nChapter 13 surveyed state-of-the-art variant effect prediction (VEP) systems. Models such as AlphaMissense, GPN-MSA, Evo 2, and AlphaGenome assign each variant a score reflecting predicted impact on protein function, regulatory activity, or multi-omic phenotypes Cheng et al. (2023) Benegas et al. (2024) Brixi et al. (2025) Z. Avsec, Latysheva, and Cheng (2025). In isolation, these scores are powerful but not yet a full prioritization pipeline.\nIn practice, discovery workflows require several additional steps:\nIn other words, GFMs provide high-resolution local perturbation scores, but the art of discovery is in wiring those scores into larger decision frameworks.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html#from-variant-effect-prediction-to-prioritization",
    "href": "ch-p5-variants.html#from-variant-effect-prediction-to-prioritization",
    "title": "18  Pathogenic Variant Discovery",
    "section": "",
    "text": "Contextualizing the score\nA raw VEP score has different implications depending on:\n\nVariant class (missense, splice, promoter, enhancer, UTR, intronic).\n\nGene context (constraint, tissue-specific expression, pathway membership).\n\nClinical or experimental question (dominant Mendelian disease, recessive disease, modifier of complex trait).\n\nFor example, a moderately damaging missense variant in a highly constrained gene expressed in the relevant tissue may be more compelling than a strongly damaging variant in a gene with no supporting biology.\nAggregation from variants to loci and genes\nDiscovery problems often operate at locus or gene level, requiring some aggregation of variant scores. Common strategies include:\n\nMax or top-k pooling – Focus on the worst predicted variant per gene or locus.\n\nBurden-style aggregation – Sum or average the predicted impact of all rare variants in a gene, possibly weighted by allele frequency and predicted effect.\n\nMechanism-aware aggregation – Separate coding vs regulatory, or promoter vs distal enhancer contributions, using tissue-specific scores from models like Enformer or AlphaGenome Ž. Avsec et al. (2021) Z. Avsec, Latysheva, and Cheng (2025).\n\nCombining VEP with orthogonal evidence\nVEP is rarely used alone. Modern pipelines combine:\n\nPopulation data – Allele frequency and constraint (pLI, LOEUF, missense and LoF intolerance).\n\nClinical databases – ClinVar classifications, disease-gene catalogs (OMIM, HGMD).\n\nFunctional annotations – Chromatin state, conservation (PhyloP, PhastCons), known regulatory elements.\n\nPathway and network context – Membership in pathways enriched for the trait, or centrality in relevant biological networks.\n\nGFMs enter as feature providers in this stack, often replacing or augmenting hand-crafted features.\nCalibration and interpretability\nFor prioritization, ranking may matter more than perfectly calibrated probabilities, but interpretable risk categories are crucial in clinical and experimental settings. This pushes towards:\n\nScore thresholds with empirical positive predictive value (PPV) estimates.\n\nQualitative explanations (e.g., “strong disruption of a conserved splice donor in a haploinsufficient gene”).\n\nVisualizations of attention maps, saliency, or motif-level contributions (Chapter 15).",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html#integrating-vep-with-gwas-fine-mapping-and-burden-tests",
    "href": "ch-p5-variants.html#integrating-vep-with-gwas-fine-mapping-and-burden-tests",
    "title": "18  Pathogenic Variant Discovery",
    "section": "18.2 Integrating VEP with GWAS, Fine-Mapping, and Burden Tests",
    "text": "18.2 Integrating VEP with GWAS, Fine-Mapping, and Burden Tests\nGenome-wide association studies (GWAS) identify statistical associations between variants and traits. However, GWAS hits are often:\n\nNoncoding – Located in enhancers or other regulatory elements.\n\nIn linkage disequilibrium (LD) – Dozens of variants in a region share similar association statistics.\n\nMechanistically opaque – Even the top GWAS SNP may not be truly causal.\n\n\n18.2.1 VEP as a prior for fine-mapping\nFine-mapping methods aim to assign each variant in a locus a posterior probability of causality, usually by combining LD patterns, effect-size estimates, and sometimes functional annotations Wu et al. (2024). GFMs naturally provide functional priors:\n\nRegulatory sequence models such as Enformer and AlphaGenome predict how a variant perturbs gene expression or chromatin landscapes Ž. Avsec et al. (2021) Z. Avsec, Latysheva, and Cheng (2025).\n\nGenome-scale LMs like GPN-MSA and Evo 2 estimate the likelihood or impact of nucleotide substitutions in their genomic context Benegas et al. (2024) Brixi et al. (2025).\n\nSpecialized models like TREDNet and MIFM directly target causal variant prediction at GWAS loci Hudaiberdiev et al. (2023) Rakowski and Lippert (2025).\n\nFrom a Bayesian perspective, these models provide a functional prior ( _j ) for each variant ( j ) in the locus. Fine-mapping frameworks can then:\n\nUpweight variants predicted to have large regulatory or coding effects.\n\nDownweight variants with benign or neutral predictions.\n\nSupport multi-variant configurations, where multiple causal variants exist at the same locus.\n\nRecent benchmarks like TraitGym systematically evaluate how well various genomic LMs and VEP models serve as fine-mapping priors across traits and tissues Benegas, Eraslan, and Song (2025).\n\n\n18.2.2 Rare variant association and DeepRVAT-style models\nFor rare variants, single-variant tests have limited power. Instead, gene- or region-based burden tests aggregate rare variants across individuals to detect association. Here, VEP plays two key roles:\n\nVariant weighting and filtering\nClassical burden tests often restrict to “damaging” variants using simple filters (e.g., predicted LoF, CADD &gt; threshold). GFMs provide richer filters and weights, enabling:\n\nFine-grained distinctions among missense variants (e.g., using AlphaMissense scores Cheng et al. (2023)).\n\nInclusion of regulatory variants predicted to modulate gene expression.\n\nContinuous weights reflecting predicted effect size, rather than binary include/exclude decisions.\n\nEnd-to-end deep set models\nDeepRVAT exemplifies a newer paradigm: instead of hand-engineered burden summaries, a deep set network ingests per-variant features (including GFM-derived VEP scores) and learns to aggregate them into a gene-level risk signal Clarke et al. (2024). This approach:\n\nSupports heterogeneous variant classes within a gene.\n\nLearns flexible aggregation functions (e.g., non-additive interactions) while preserving permutation invariance.\n\nAccommodates multiple phenotypes and covariates within a single model.\n\n\nAs more cohorts with whole-exome or whole-genome sequencing become available, these GFM-enhanced burden frameworks blur the line between GWAS and rare variant analysis, providing a continuum of variant discovery tools.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html#mendelian-disease-gene-and-variant-discovery",
    "href": "ch-p5-variants.html#mendelian-disease-gene-and-variant-discovery",
    "title": "18  Pathogenic Variant Discovery",
    "section": "18.3 Mendelian Disease Gene and Variant Discovery",
    "text": "18.3 Mendelian Disease Gene and Variant Discovery\nIn Mendelian disease genetics, the questions tend to be more concrete: Which variant explains this patient’s phenotype? Which gene is implicated? WES/WGS of trios and families produces thousands of variants per individual. The standard pipeline includes:\n\nQuality control and filtering\n\nRemove low-quality calls and technical artifacts.\n\nFilter by allele frequency (e.g., &lt;0.1% in population databases), inheritance mode (de novo, recessive, X-linked), and variant type (LoF, missense, splice, structural).\n\nGene-centric ranking\n\nAggregate candidate variants per gene, using constraint metrics and known disease-gene catalogs.\n\nIntegrate phenotype similarity (e.g., HPO-based matching between patient and known gene syndromes).\n\nManual curation\n\nExpert review of gene function, expression patterns, animal models, and literature.\n\nAssessment of segregation in the family, de novo status, and evidence of pathogenic mechanism.\n\n\n\n18.3.1 GFMs in Mendelian variant prioritization\nGFMs reshape several stages of this process:\n\nRicher coding impact scores\nAlphaMissense provides proteome-wide missense pathogenicity estimates with continuous scores that often outperform traditional tools Cheng et al. (2023). Coding-aware foundation models (cdsFM and related systems) further capture codon-level context and co-evolutionary patterns Naghipourfar et al. (2024).\nRegulatory and splice prediction\nGenome-wide models like GPN-MSA, Evo 2, and AlphaGenome estimate the effect of noncoding and splice-proximal variants, filling a gap for Mendelian variants outside exons Benegas et al. (2024) Brixi et al. (2025) Z. Avsec, Latysheva, and Cheng (2025).\nCombined variant–gene scoring\nFor each gene, we can aggregate:\n\nMax or weighted VEP score across all candidate variants.\n\nSeparate tallies for LoF, missense, regulatory, and splice variants.\n\nGene-level features (constraint, expression, pathways) and phenotype similarity.\n\nA simple model might compute a composite gene score as a learned function of these features, trained on cohorts with labeled diagnoses.\n\n\n\n18.3.2 Rare disease association at scale\nBeyond single-family diagnostics, large consortia collect rare disease cohorts where the goal is to discover new gene–disease associations. DeepRVAT-style models provide one blueprint:\n\nRepresent each individual as a set of rare variants with multi-dimensional VEP features (from GFMs and traditional tools).\n\nUse deep set networks to map from per-variant features to individual-level phenotype predictions or gene-level association signals Clarke et al. (2024).\n\nIncorporate multi-omics context (e.g., tissue-specific expression, chromatin accessibility from GLUE-like models) as additional features Cao and Gao (2022).\n\nThis pushes Mendelian discovery closer to the foundation model paradigm: instead of hand-designed burden statistics, we train flexible architectures that learn how to combine variant-level representations into gene- and phenotype-level insights.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html#graph-based-prioritization-of-disease-genes",
    "href": "ch-p5-variants.html#graph-based-prioritization-of-disease-genes",
    "title": "18  Pathogenic Variant Discovery",
    "section": "18.4 Graph-Based Prioritization of Disease Genes",
    "text": "18.4 Graph-Based Prioritization of Disease Genes\nMany discovery problems are inherently network-structured. Genes interact through pathways, protein–protein interaction (PPI) networks, co-expression modules, regulatory networks, and knowledge graphs. GNNs offer a natural way to fuse:\n\nNode features from GFMs (e.g., aggregated VEP scores, expression profiles).\n\nGraph structure capturing biological relationships.\n\nLabels such as disease associations, essentiality, or cancer driver status.\n\n\n18.4.1 Multi-omics and cancer gene modules\nGLUE (and SCGLUE) frame multi-omics integration as a graph-linked embedding problem, connecting cells and features across modalities Cao and Gao (2022). Inspired by this, GNN frameworks like MoGCN and CGMega build:\n\nGene-level graphs combining expression, methylation, copy number, and other omics layers X. Li et al. (2022) H. Li et al. (2024).\n\nAttention mechanisms to highlight important neighbors and pathways in cancer gene modules.\n\nPredictive models for cancer subtypes, driver genes, and prognostic signatures.\n\nGFMs can enhance these systems by supplying:\n\nVariant-aware gene features (e.g., aggregated predicted impact of observed somatic mutations).\n\nRegulatory context via sequence-based predictions of expression and chromatin (Enformer, Borzoi, AlphaGenome) Ž. Avsec et al. (2021) Linder et al. (2025) Z. Avsec, Latysheva, and Cheng (2025).\n\n\n\n18.4.2 Knowledge graphs and essential gene prediction\nKnowledge graphs like PrimeKG aggregate heterogeneous biomedical entities—genes, diseases, drugs, pathways, and phenotypes—into a unified relational structure Chandak, Huang, and Zitnik (2023). GNNs on such graphs can be trained to:\n\nPrioritize disease genes based on graph proximity to known genes.\n\nSuggest drug repurposing candidates by connecting genetic evidence to drug targets.\n\nDiscover modules linked to therapeutic response or adverse effects.\n\nBingo provides a related example, combining a large language model (LLM) with GNNs to predict essential genes from protein-level data Ma et al. (2023). In principle, the node features in such systems could incorporate:\n\nGene-level embeddings derived from protein LMs (Chapter 9).\n\nAggregated variant effect embeddings from genomic LMs (Chapter 10 and 13).\n\nMulti-omic signatures from GLUE-like integrative models Cao and Gao (2022).\n\nTogether, these approaches illustrate a broader trend: GFMs rarely act alone. Instead, they supply dense, information-rich features to graph-based models that reason over the network context where disease mechanisms actually play out.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html#experimental-follow-up-and-closed-loop-refinement",
    "href": "ch-p5-variants.html#experimental-follow-up-and-closed-loop-refinement",
    "title": "18  Pathogenic Variant Discovery",
    "section": "18.5 Experimental Follow-Up and Closed-Loop Refinement",
    "text": "18.5 Experimental Follow-Up and Closed-Loop Refinement\nComputational prioritization is only half of discovery. Ultimately, we need experimental validation: does perturbing a candidate variant or gene alter the relevant molecular or cellular phenotype?\n\n18.5.1 Designing CRISPR and MPRA experiments with GFMs\nHigh-throughput perturbation assays such as:\n\nMassively parallel reporter assays (MPRAs) targeting many regulatory variants.\n\nCRISPR tiling and base editing screens across enhancers, promoters, and coding regions.\n\nPerturb-seq linking genetic perturbations to single-cell transcriptomes.\n\nare expensive and capacity-limited. GFMs help prioritize and design these experiments:\n\nSequence-to-expression models like Enformer and Borzoi can identify regions and variants with large predicted regulatory effects, guiding where to tile and which alleles to test Ž. Avsec et al. (2021) Linder et al. (2025).\n\nGenome-scale generative models like Evo 2 can propose counterfactual edits that maximize predicted effect, enabling focused exploration of regulatory landscapes Brixi et al. (2025).\n\nVariant effect models can suggest multiplexed libraries that systematically probe key motifs, splice sites, or codon usage patterns.\n\nInstead of brute-force tiling every base pair, we can use GFMs to bias the library toward informative perturbations, effectively turning them into experiment design engines.\n\n\n18.5.2 Using functional data to retrain and recalibrate models\nThe feedback loop goes in the other direction as well. Functional genomics screens produce rich labeled datasets:\n\nMPRA readouts of allele-specific regulatory activity.\n\nCRISPR screen scores for gene essentiality or drug sensitivity.\n\nSingle-cell perturbation responses across cell states.\n\nThese can be used to:\n\nRefine model heads for specific tasks (e.g., fine-tune a GFM to predict MPRA outcomes in a particular cell type).\n\nCalibrate scores so that predicted effect magnitudes align with measured changes.\n\nDiscover failure modes, such as motifs or chromatin contexts where current models systematically mispredict.\n\nSome recent systems explicitly design closed-loop pipelines, where model predictions drive experiments, which then feed back to improve the model and inform the next round of design Benegas, Eraslan, and Song (2025) Rakowski and Lippert (2025). In the limit, we approach a semi-automated “hypothesis factory”:\n\nStart from GWAS, rare variant, or tumor sequencing data.\n\nUse GFMs plus graphs to prioritize candidate variants and genes.\n\nDesign perturbation experiments guided by model predictions.\n\nUpdate the models with new functional data.\n\nIterate, progressively sharpening our understanding of the underlying mechanisms.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html#case-studies-and-practical-considerations",
    "href": "ch-p5-variants.html#case-studies-and-practical-considerations",
    "title": "18  Pathogenic Variant Discovery",
    "section": "18.6 Case Studies and Practical Considerations",
    "text": "18.6 Case Studies and Practical Considerations\nTo ground these ideas, consider two representative application areas.\n\n18.6.1 Rare disease diagnosis pipelines leveraging VEP scores\nModern rare disease centers increasingly adopt GFM-enhanced diagnostic workflows:\n\nVariant filtering and annotation\n\nStandard QC and frequency filters.\n\nAnnotation with GFM-based VEP scores (coding, regulatory, splice), constraint, and ClinVar evidence.\n\nGene-ranking model\n\nPer-gene aggregation of variant scores and features.\n\nA trained model that predicts the likelihood of each gene being causal, based on retrospective cohorts with known diagnoses.\n\nPhenotype integration\n\nHPO-based similarity to known gene syndromes.\n\nNetwork-based propagation of phenotype associations using knowledge graphs like PrimeKG Chandak, Huang, and Zitnik (2023).\n\nExpert review\n\nGeneticists and clinicians inspect the top-ranked genes and variants, cross-checking against patient phenotypes, family segregation, and literature.\n\n\nCompared to traditional pipelines, the GFM-enhanced version tends to:\n\nSurface non-obvious candidates, such as noncoding or splice variants with strong predicted functional effects.\n\nProvide more nuanced prioritization among multiple missense variants in the same gene.\n\nOffer richer mechanistic hypotheses to guide follow-up experiments.\n\n\n\n18.6.2 Cancer driver mutation discovery (coding and noncoding)\nIn cancer genomics, the goal is to distinguish driver mutations from a large background of passenger mutations. GFMs and graph-based models contribute at multiple levels:\n\nVariant-level scoring\n\nUse coding VEP (e.g., AlphaMissense, cdsFM-like models) for missense drivers Cheng et al. (2023) Naghipourfar et al. (2024).\n\nUse regulatory sequence models (Enformer, AlphaGenome, TREDNet) to evaluate noncoding mutations in promoters and enhancers Ž. Avsec et al. (2021) Z. Avsec, Latysheva, and Cheng (2025) Hudaiberdiev et al. (2023).\n\nGene- and module-level aggregation\n\nAggregate somatic variants per gene, weighted by predicted functional impact.\n\nApply GNNs such as MoGCN and CGMega to identify driver gene modules that are recurrently perturbed across patients X. Li et al. (2022) H. Li et al. (2024).\n\nUse set-based models (akin to DeepRVAT) to relate patient-specific variant sets to tumor subtypes or outcomes Clarke et al. (2024).\n\nFunctional follow-up\n\nDesign focused CRISPR tiling screens around candidate regulatory elements, prioritized by GFMs.\n\nValidate predicted driver genes in cell line or organoid models, integrating transcriptional responses with multi-omic readouts (Chapter 16).\n\n\nThese pipelines exemplify multi-scale integration: GFMs for variant-level effects, GNNs for network-level reasoning, and high-throughput perturbations for experimental validation.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-variants.html#outlook-towards-end-to-end-discovery-systems",
    "href": "ch-p5-variants.html#outlook-towards-end-to-end-discovery-systems",
    "title": "18  Pathogenic Variant Discovery",
    "section": "18.7 Outlook: Towards End-to-End Discovery Systems",
    "text": "18.7 Outlook: Towards End-to-End Discovery Systems\nBiomedical discovery of pathogenic variants is moving from manual, hypothesis-driven workflows toward data- and model-driven pipelines where GFMs act as a central substrate:\n\nThey turn raw sequence variation into rich, context-aware variant embeddings.\n\nThey provide priors and features for fine-mapping, rare variant association, and gene prioritization.\n\nThey guide the design of targeted perturbation experiments, which in turn provide new data to refine the models.\n\nAt the same time, several challenges remain:\n\nRobustness and generalization across ancestries, tissues, and disease cohorts.\n\nCalibration and interpretability suitable for clinical and experimental decision-making.\n\nEvaluation frameworks (like TraitGym) that fairly compare models and reveal domain gaps Benegas, Eraslan, and Song (2025).\n\nEthical and regulatory considerations around automated variant classification and gene discovery in sensitive contexts.\n\nIn the next chapter, we zoom out to the broader drug discovery and biotech landscape (Chapter 19), where many of these discovery building blocks are embedded in industrial-scale pipelines that span from genetic association to target validation, biomarker discovery, and eventually clinical translation.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. “[Evo 2] Genome Modeling and Design Across All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nChandak, Payal, Kexin Huang, and Marinka Zitnik. 2023. “[PrimeKG] Building a Knowledge Graph to Enable Precision Medicine.” Scientific Data 10 (1): 67. https://doi.org/10.1038/s41597-023-01960-3.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus Wahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024. “[DeepRVAT] Integration of Variant Annotations Using Deep Set Networks Boosts Rare Variant Association Testing.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nHudaiberdiev, Sanjarbek, D. Leland Taylor, Wei Song, Narisu Narisu, Redwan M. Bhuiyan, Henry J. Taylor, Xuming Tang, et al. 2023. “[TREDNet] Modeling Islet Enhancers Using Deep Learning Identifies Candidate Causal Variants at Loci Associated with T2D and Glycemic Traits.” Proceedings of the National Academy of Sciences 120 (35): e2206612120. https://doi.org/10.1073/pnas.2206612120.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai, et al. 2024. “CGMega: Explainable Graph Neural Network Framework with Attention Mechanisms for Cancer Gene Module Dissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and Yunping Zhu. 2022. “MoGCN: A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Analysis.” Frontiers in Genetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nMa, Jiani, Jiangning Song, Neil D. Young, Bill C. H. Chang, Pasi K. Korhonen, Tulio L. Campos, Hui Liu, and Robin B. Gasser. 2023. “’Bingo’-a Large Language Model- and Graph Neural Network-Based Workflow for the Prediction of Essential Genes from Protein Data.” Briefings in Bioinformatics 25 (1): bbad472. https://doi.org/10.1093/bib/bbad472.\n\n\nNaghipourfar, Mohsen, Siyu Chen, Mathew K. Howard, Christian B. Macdonald, Ali Saberi, Timo Hagen, Mohammad R. K. Mofrad, Willow Coyote-Maestas, and Hani Goodarzi. 2024. “[cdsFM - EnCodon/DeCodon] A Suite of Foundation Models Captures the Contextual Interplay Between Codons.” bioRxiv. https://doi.org/10.1101/2024.10.10.617568.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "ch-p5-drugs.html",
    "href": "ch-p5-drugs.html",
    "title": "19  Drug Discovery & Biotech",
    "section": "",
    "text": "19.1 Where Genomics Touches the Drug Discovery Pipeline\nGenomic foundation models (GFMs) are built to turn raw sequence and multi-omic data into reusable biological representations and fine-grained predictions (Chapter 12). In previous chapters you saw how these models improve variant effect prediction (Chapters 10, 11, 13), long-range regulatory modeling (Chapters 8, 11, 12), and disease genetics workflows (Chapters 14–16).\nThis chapter zooms out to ask a more translational question:\nRather than walking step-by-step through a single therapeutic program, this chapter offers a compact, high-level map of where GFMs are already useful—or plausibly soon will be. The focus is on three broad roles:\nThroughout, the aim is not to promise “end-to-end AI drug discovery,” but to show pragmatic ways that genomic foundation models can reduce risk, prioritize hypotheses, and make experiments more informative, especially when coupled to high-quality human data.\nThe canonical small-molecule or biologics pipeline is often summarized as:\nGenomics most directly enters at three points:\nOther AI-for-drug-discovery efforts focus on molecular design, docking, or protein structure; those are largely beyond the scope of this book. Here we stay close to the DNA- and RNA-centric capabilities you’ve seen earlier: variant effect prediction, regulatory modeling, and multi-omics integration.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "ch-p5-drugs.html#where-genomics-touches-the-drug-discovery-pipeline",
    "href": "ch-p5-drugs.html#where-genomics-touches-the-drug-discovery-pipeline",
    "title": "19  Drug Discovery & Biotech",
    "section": "",
    "text": "Target identification and validation\n\nHit finding and lead optimization\n\nPreclinical characterization (safety, PK/PD, tox)\n\nClinical trials (Phase I–III) and post-marketing\n\n\n\nEarly-stage target discovery and validation\n\nHuman genetic associations (GWAS, rare-variant burden, somatic mutation landscapes) point to potential targets.\n\nVariant-level effect predictions and gene-level constraint metrics help de-prioritize potentially unsafe or non-causal signals.\n\nBiomarker discovery and patient stratification\n\nGenetic risk scores, regulatory embeddings, and multi-omic signatures define patient subgroups and endpoints for trials.\n\nEmbeddings from GFMs make it easier to find molecularly coherent patient strata beyond traditional clinical labels.\n\nMechanism-of-action (MoA) and resistance\n\nFunctional genomics screens and perturbation assays help dissect how a compound perturbs cellular networks.\n\nGFMs can predict which perturbations matter and suggest follow-up experiments.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "ch-p5-drugs.html#target-discovery-and-genetic-validation",
    "href": "ch-p5-drugs.html#target-discovery-and-genetic-validation",
    "title": "19  Drug Discovery & Biotech",
    "section": "19.2 Target Discovery and Genetic Validation",
    "text": "19.2 Target Discovery and Genetic Validation\nHuman genetics provides some of the strongest evidence that modulating a particular target can safely change disease risk. GFMs don’t replace classical statistical genetics, but they provide richer priors and more mechanistic features for identifying and validating targets.\n\n19.2.1 From variant-level scores to gene-level targets\nVariant effect prediction (VEP) models provide a natural starting point. Earlier chapters introduced:\n\nGenome-wide deleteriousness scores such as CADD, which integrate diverse annotations and—more recently—deep and foundation-model features (Rentzsch et al. 2019; Schubach et al. 2024).\nProtein-centric VEP GFMs, including AlphaMissense, GPN-MSA, and AlphaGenome, which combine protein language models, structure, and long-range context to score coding variants (Cheng et al. 2023; Benegas, Albors, et al. 2024; Z. Avsec, Latysheva, and Cheng 2025; Brandes et al. 2023).\nSequence-to-function models such as Enformer and long-context DNA LMs (e.g., Nucleic Transformer, HyenaDNA), which predict regulatory outputs from large genomic windows (Ž. Avsec et al. 2021; He et al. 2023; Nguyen et al. 2023; Trop et al. 2024).\n\nDrug target teams rarely care about individual variants per se; they care about genes and pathways. The key move is therefore to aggregate variant-level information into gene-level evidence:\n\nCoding variant aggregation\n\nSummarize missense and predicted loss-of-function (pLoF) variants in each gene using VEP scores.\n\nPartition variants by predicted functional category (e.g. likely loss-of-function vs. benign missense) and by allele frequency.\n\nDerive gene-level metrics such as “burden of predicted damaging variants in cases vs controls.”\n\nNoncoding and regulatory evidence\n\nAggregate variant effect predictions on enhancers, promoters, and splice sites that link (via chromatin interaction maps or models like Enformer) to a candidate gene (Ž. Avsec et al. 2021; He et al. 2023).\n\nUse long-range GFMs to connect distal regulatory elements to target loci across 100 kb–1 Mb.\n\nConstraint and intolerance\n\nCombine VEP-informed burden with gene constraint measures (as used implicitly in CADD and downstream tools) to identify genes that are highly intolerant to damaging variation (Rentzsch et al. 2019; Schubach et al. 2024).\n\nExtremely constrained genes may be risky targets (essentiality/toxicity), while “dose-sensitive” but not lethal genes may present more attractive opportunities.\n\n\nFrom a GFM perspective, the core idea is to treat gene-level evidence as an aggregation problem over high-dimensional variant embeddings. Instead of manually defining a handful of summary statistics, teams can feed variant embeddings or predicted functional profiles into downstream models that learn which patterns matter most for disease.\n\n\n19.2.2 Linking genetic evidence to target safety and efficacy\nClassical human genetics has established several now-standard heuristics for target selection:\n\n“Human knockout” individuals (carrying biallelic LoF variants) provide a natural experiment on what happens when a gene is effectively inactivated.\n\nProtective variants that reduce disease risk suggest directionality of effect (e.g. partial inhibition of a protein is beneficial rather than harmful).\n\nPleiotropy—associations with many unrelated traits—may signal safety liabilities.\n\nGFMs reinforce and extend these ideas by:\n\nImproving causal variant identification\n\nFine-mapping methods and multiple-instance models like MIFM can distinguish truly causal regulatory variants from correlated passengers (Wu et al. 2024; Rakowski and Lippert 2025).\n\nCombining these with regulatory GFMs tightens the map from GWAS locus → variant → target gene.\n\nRefining effect direction and magnitude\n\nVEP scores from protein and regulatory GFMs can approximate effect sizes (e.g. how “severe” a missense change is, or how strongly a regulatory variant alters expression) (Cheng et al. 2023; Benegas, Albors, et al. 2024; Z. Avsec, Latysheva, and Cheng 2025).\n\nThis can help differentiate subtle modulators from catastrophic LoF.\n\nHighlighting mechanism-enriched loci\n\nGFMs provide multi-task predictions (chromatin marks, TF binding, expression, splicing) that make it easier to interpret how a risk locus affects biology (Ž. Avsec et al. 2021; Benegas, Ye, et al. 2024).\n\n\nIn practice, a target discovery workflow might:\n\nStart from GWAS summary statistics or rare variant analyses.\n\nApply fine-mapping (e.g. MIFM) to identify candidate causal variants (Wu et al. 2024; Rakowski and Lippert 2025).\n\nScore candidate variants with VEP GFMs (both protein and regulatory).\n\nMap variants to genes using long-range regulatory models (Enformer, Nucleic Transformer, HyenaDNA) (Ž. Avsec et al. 2021; He et al. 2023; Nguyen et al. 2023).\n\nAggregate signals into gene-level “genetic support” scores, incorporating constraint and pleiotropy information.\n\nThe result is a ranked list of candidate targets with structured evidence that can be compared across diseases and programs.\n\n\n19.2.3 Evolving from hand-curated to model-centric target triage\nHistorically, target triage relied heavily on manual curation:\n\nExperts would review GWAS hits, literature, and pathway diagrams.\n\nLimited quantitative information was available for most genes, especially in non-classical pathways.\n\nGFMs shift this towards a model-centric, continuously updated view:\n\nNew data (e.g. biobank sequencing, single-cell atlases) can be fed through trained GFMs to update variant and gene evidence.\n\nThe same underlying model suite can support many disease programs, enabling consistent cross-portfolio comparisons.\n\nBenchmark frameworks like TraitGym emphasize standardized evaluation of genotype-phenotype modeling, helping teams choose appropriate model stacks for a given trait (Benegas, Eraslan, and Song 2025).\n\nThe limiting factor becomes less “do we have an annotation?” and more “can we interpret the model’s representation and connect it to biological plausibility and druggability?”—a theme echoed in Chapters 13 and 15.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "ch-p5-drugs.html#functional-genomics-screens-in-drug-discovery",
    "href": "ch-p5-drugs.html#functional-genomics-screens-in-drug-discovery",
    "title": "19  Drug Discovery & Biotech",
    "section": "19.3 Functional Genomics Screens in Drug Discovery",
    "text": "19.3 Functional Genomics Screens in Drug Discovery\nWhile human genetics offers observational evidence, drug discovery also relies heavily on perturbation experiments:\n\nCRISPR knockout/knockdown/activation screens.\n\nBase-editing or saturation mutagenesis around key domains.\n\nMPRA and massively parallel promoter/enhancer assays.\n\nPerturb-seq and other high-throughput transcriptomic readouts.\n\nGenomic foundation models are well positioned to both design and interpret such screens.\n\n19.3.1 Designing smarter perturbation libraries\nTraditional pooled screens often rely on simple design rules (e.g. one sgRNA per exon, or tiling a region at fixed spacing). GFMs enable more information-dense designs:\n\nSequence-to-function priors\n\nModels like DeepSEA, Enformer, and related CNN/transformer architectures predict which bases are most functionally critical for regulatory outputs (Zhou and Troyanskaya 2015; Ž. Avsec et al. 2021; Benegas, Ye, et al. 2024).\n\nLibrary design can focus perturbations on high-sensitivity sites—predicted TF motifs, splice junctions, or enhancer “hotspots.”\n\nVariant prioritization for saturation mutagenesis\n\nProtein and DNA GFMs can prioritize substitutions expected to span a wide range of predicted fitness, enabling better estimation of quantitative genotype–phenotype maps (Cheng et al. 2023; Marquet et al. 2024).\n\nThis is especially useful for deep mutational scanning near active sites or in regulatory domains.\n\nOff-target and safety considerations\n\nSequence models can help filter sgRNA designs with high predicted off-target binding, or prioritize guide positions that minimize unintended regulatory disruption.\n\n\nThe overarching idea is to maximize the information gained per experimental budget by letting GFMs suggest where to perturb in sequence space.\n\n\n19.3.2 Interpreting screen readouts with GFMs\nOnce a screen has been run, GFMs can assist in several ways:\n\nEmbedding perturbations and outcomes\n\nEncode each perturbed sequence (e.g. enhancer variant, gene knockout) using a DNA or protein GFM, and represent each experimental condition as the combination of its embedding and observed phenotype (e.g. expression profile).\n\nThis enables manifold learning over perturbations, in which clusters correspond to shared mechanism-of-action.\n\nMapping hits back to pathways\n\nCombine GFMs with graph-based models over protein–protein interaction networks and regulatory networks to identify enriched pathways (Gao et al. 2023; Yuan and Duren 2025).\n\nLearned embeddings help propagate signal to weakly observed genes or variants.\n\nClosing the loop with model retraining\n\nUse screen outcomes as labeled examples to fine-tune sequence-to-function models in the relevant cell type or context.\n\nThis “lab-in-the-loop” refinement turns generic GFMs into highly tuned models for the cell system of interest.\n\n\nFor example, an MPRA that assays thousands of enhancer variants can yield sequence–activity pairs that dramatically improve expression-prediction GFMs in that locus or tissue. Conversely, model predictions can suggest follow-up experiments (additional variants, cell types, or perturbation strengths) that would be maximally informative given previous data.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "ch-p5-drugs.html#biomarker-discovery-patient-stratification-and-trial-design",
    "href": "ch-p5-drugs.html#biomarker-discovery-patient-stratification-and-trial-design",
    "title": "19  Drug Discovery & Biotech",
    "section": "19.4 Biomarker Discovery, Patient Stratification, and Trial Design",
    "text": "19.4 Biomarker Discovery, Patient Stratification, and Trial Design\nEven when a target is well validated, many programs fail in late-stage trials because the right patients, endpoints, or biomarkers were not selected. GFMs, combined with large cohorts, offer new tools for defining and validating biomarkers.\n\n19.4.1 From polygenic risk scores to GFM-informed biomarkers\nClassical polygenic risk scores (PRS) summarize the additive effect of many common variants on disease risk. Deep learning methods such as Delphi extend this idea by learning non-linear genotype–phenotype mappings directly from genome-wide data (Georgantas, Kutalik, and Richiardi 2024).\nGFMs can enhance these approaches by:\n\nProviding richer genetic features\n\nInstead of raw genotypes, models can use VEP-derived scores, variant embeddings, or gene-level features produced by GFMs.\n\nThis can capture non-additive effects, regulatory architecture, and variant-level biology in a more compact representation.\n\nTransferring knowledge across traits and ancestries\n\nFoundation models trained across diverse genomes (e.g. Nucleotide Transformer, GENA-LM, HyenaDNA) provide features that may generalize more robustly across populations than trait-specific models (Dalla-Torre et al. 2023; Fishman et al. 2025; Nguyen et al. 2023).\n\nFine-mapping–aware approaches like MIFM further reduce dependence on linkage disequilibrium patterns (Wu et al. 2024; Rakowski and Lippert 2025).\n\nDistinguishing risk and progression\n\nBy integrating regulatory and expression predictions, risk models can differentiate genetic influences on disease onset vs progression, enabling more targeted enrichment strategies.\n\n\nIn trial design, such models can be used to:\n\nEnrich for high-risk individuals (in prevention trials).\n\nDefine genetic subtypes that may respond differently to the same mechanism.\n\nConstruct composite biomarkers that mix genetics with conventional clinical features.\n\n\n\n19.4.2 Multi-omic and single-cell biomarker discovery\nBeyond DNA variation, drug development increasingly leverages multi-omic and single-cell readouts:\n\nWhole-genome/exome tumor sequencing combined with expression, methylation, and copy-number profiling.\n\nSingle-cell multiome datasets (RNA + ATAC) that characterize cell-state landscapes in disease (Jurenaite et al. 2024; Yuan and Duren 2025).\n\nMicrobiome sequencing for host–microbe interplay and response to therapy (Yan et al. 2025).\n\nGFMs and related architectures can help here in several ways:\n\nSet-based and graph-based encoders\n\nModels like SetQuence/SetOmic treat heterogeneous genomic features for each tumor as a set, using deep set transformers to extract predictive representations (Jurenaite et al. 2024).\n\nGRN inference models such as LINGER leverage atlas-scale multiome data to infer regulatory networks that can serve as biomarkers of pathway activity (Yuan and Duren 2025).\n\nMulti-scale integration\n\nDNA and RNA GFMs can be combined with graph neural networks over gene and protein networks to build end-to-end predictors that map from genotype + cell state to clinical endpoints (Gao et al. 2023; Benegas, Ye, et al. 2024).\n\nEmbeddings from protein LMs (e.g. ESM-2-based variant models) provide additional structure for coding variants (Brandes et al. 2023; Marquet et al. 2024).\n\nBiomarker discovery workflows\n\nUse GFMs to generate rich embeddings for patients (e.g. from tumor genomes, germline variation, or multi-omic profiles).\n\nCluster or perform supervised learning to identify molecular subgroups with differential prognosis or treatment response.\n\nValidate candidate biomarkers on held-out cohorts or external datasets before deploying them in a trial.\n\n\nThe key shift is that biomarkers are no longer limited to a handful of hand-picked variants or expression markers: they become functions over high-dimensional genomic and multi-omic embeddings, learned in a data-driven way yet grounded in biological priors from GFMs.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "ch-p5-drugs.html#biotech-workflows-and-infrastructure-for-gfms",
    "href": "ch-p5-drugs.html#biotech-workflows-and-infrastructure-for-gfms",
    "title": "19  Drug Discovery & Biotech",
    "section": "19.5 Biotech Workflows and Infrastructure for GFMs",
    "text": "19.5 Biotech Workflows and Infrastructure for GFMs\nFor pharma and biotech organizations, the primary challenge is not “can we train a big model?” so much as “how do we integrate GFMs into existing data platforms, governance, and decision-making?”\n\n19.5.1 GFMs as shared infrastructure\nIn a mature organization, GFMs should be treated as shared infrastructure, not ad hoc scripts:\n\nModel catalog\n\nDNA LMs (e.g. Nucleic Transformer, HyenaDNA, GENA-LM) (He et al. 2023; Nguyen et al. 2023; Fishman et al. 2025).\n\nSequence-to-function models (e.g. Enformer, Genomic Interpreter) (Ž. Avsec et al. 2021; Li et al. 2023).\n\nVariant effect predictors (AlphaMissense, GPN-MSA, AlphaGenome, CADD v1.7) (Rentzsch et al. 2019; Schubach et al. 2024; Cheng et al. 2023; Benegas, Albors, et al. 2024; Z. Avsec, Latysheva, and Cheng 2025).\n\nFeature services\n\nCentralized APIs that take as input variants, genomic intervals, or genes and return embeddings, predicted functional profiles, or risk features.\n\nLogging and versioning so that analyses can be reproduced even as models and data evolve.\n\nData governance\n\nClear separation between models trained on public data vs. sensitive internal cohorts.\n\nGuardrails around where internal data can be used for fine-tuning and how resulting models can be shared.\n\n\nEmbedding GFMs in this way allows multiple teams—target ID, biomarker discovery, clinical genetics—to reuse the same core representations rather than each building bespoke models.\n\n\n19.5.2 Build vs buy vs fine-tune\nOrganizations face three strategic options:\n\nUse external GFMs “as-is”\n\nPros: Low up-front cost; benefits from community benchmarking (e.g. TraitGym for genotype–phenotype modeling (Benegas, Eraslan, and Song 2025)).\n\nCons: May not capture organization-specific populations, assays, or traits.\n\nFine-tune open-source GFMs on internal data\n\nPros: Retains powerful general representations while adapting to local distribution.\n\nCons: Requires careful privacy controls and computational investment.\n\nTrain bespoke internal GFMs\n\nPros: Maximum control; can align pretraining exactly with available data and target use cases.\n\nCons: Expensive, complex MLOps; risk of overfitting to narrow datasets if not complemented by broader pretraining.\n\n\nIn practice, many groups adopt a hybrid strategy:\n\nStart with public GFMs for early exploration and non-sensitive tasks.\n\nGradually fine-tune on internal biobank or trial data when added value is clear.\n\nMaintain lightweight model-serving infrastructure for latency-sensitive applications (e.g. clinical decision support) and heavier offline systems for large-scale research workloads.\n\n\n\n19.5.3 IP, collaboration, and regulatory considerations\nGFMs also raise new questions around:\n\nIntellectual property\n\nModels trained on proprietary data can be valuable IP assets but are hard to patent directly.\n\nDownstream discoveries (targets, biomarkers) derived from GFMs must be carefully documented for freedom-to-operate.\n\nData sharing and federated approaches\n\nJoint training or evaluation across institutions may require federated learning or model-to-data paradigms, especially for patient-level data.\n\nRegulatory expectations\n\nFor biomarkers used in pivotal trials, regulators will expect transparent documentation of model training, validation, and performance across subgroups.\n\nChapters 14 and 15 highlight confounding and interpretability challenges that become even more acute when models inform trial inclusion or primary endpoints.\n\n\nOverall, leveraging GFMs in biotech is as much an organizational and regulatory engineering problem as a technical one.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "ch-p5-drugs.html#forward-look-toward-lab-in-the-loop-gfms",
    "href": "ch-p5-drugs.html#forward-look-toward-lab-in-the-loop-gfms",
    "title": "19  Drug Discovery & Biotech",
    "section": "19.6 Forward Look: Toward Lab-in-the-Loop GFMs",
    "text": "19.6 Forward Look: Toward Lab-in-the-Loop GFMs\nA recurring theme across this book is moving from static models to closed loops that integrate:\n\nFoundational representation learning on large unlabeled datasets (genomes, multi-omics).\n\nTask-specific supervision (disease status, expression, variant effects).\n\nExperimental feedback from perturbation assays, functional screens, and clinical trials.\n\nIn the drug discovery context, this suggests an evolution toward lab-in-the-loop GFMs:\n\nHypothesis generation\n\nGFMs identify promising targets, variants, and regulatory regions.\n\nGraph and set-based models suggest network-level interventions (Jurenaite et al. 2024; Gao et al. 2023; Yuan and Duren 2025).\n\nExperiment design\n\nModels propose perturbation libraries (CRISPR, MPRA) that maximize expected information gain.\n\nSafety and off-target predictions help filter risky designs.\n\nEvidence integration and model refinement\n\nScreen results feed back into GFMs, improving their local accuracy in disease-relevant regions of sequence space.\n\nClinical trial outcomes update biomarker models and risk predictors for future trials.\n\nPortfolio-level decision support\n\nGenetic and functional evidence from GFMs is combined with classical pharmacology to prioritize or deprioritize programs.\n\nUncertainty estimates and model critique (Chapter 15) help avoid over-confidence in purely model-driven recommendations.\n\n\nRealizing this vision will require:\n\nBetter calibration and uncertainty quantification in GFMs.\n\nStronger causal reasoning to distinguish correlation from intervention-worthiness.\n\nCareful ethical and equity considerations, especially when models influence who gets access to trials or targeted therapies (Chapter 14).\n\nYet even in the near term, GFMs already offer tangible value in de-risking targets, enriching cohorts, and interpreting complex functional data. When combined with rigorous experimental design and domain expertise, they can act not as oracle decision-makers, but as force multipliers for human scientists and clinicians.\n\nIn summary, this chapter has sketched how genomic foundation models extend beyond academic benchmarks into practical levers for drug discovery and biotech:\n\nTurning variant and regulatory predictions into target discovery and validation pipelines.\n\nDesigning and interpreting functional genomics screens that probe mechanism and vulnerability.\n\nBuilding richer biomarkers and patient stratification schemes for trials.\n\nEmbedding GFMs into industrial data platforms and MLOps.\n\nSubsequent chapters in Part V can zoom into specific application domains—clinical risk prediction (Chapter 17) and pathogenic variant discovery (Chapter 18)—using the conceptual toolkit laid out here.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nBenegas, Gonzalo, Chengzhong Ye, Carlos Albors, Jianan Canal Li, and Yun S. Song. 2024. “Genomic Language Models: Opportunities and Challenges.” arXiv. https://doi.org/10.48550/arXiv.2407.11435.\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.” Nature Genetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nFishman, Veniamin, Yuri Kuratov, Aleksei Shmelev, Maxim Petrov, Dmitry Penzar, Denis Shepelin, Nikolay Chekanov, Olga Kardymon, and Mikhail Burtsev. 2025. “GENA-LM: A Family of Open-Source Foundational DNA Language Models for Long Sequences.” Nucleic Acids Research 53 (2): gkae1310. https://doi.org/10.1093/nar/gkae1310.\n\n\nGao, Ziqi, Chenran Jiang, Jiawen Zhang, Xiaosen Jiang, Lanqing Li, Peilin Zhao, Huanming Yang, Yong Huang, and Jia Li. 2023. “[HIGH-PPI] Hierarchical Graph Learning for Protein–Protein Interaction.” Nature Communications 14 (1): 1093. https://doi.org/10.1038/s41467-023-36736-1.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nHe, Shujun, Baizhen Gao, Rushant Sabnis, and Qing Sun. 2023. “Nucleic Transformer: Classifying DNA Sequences with Self-Attention and Convolutions.” ACS Synthetic Biology 12 (11): 3205–14. https://doi.org/10.1021/acssynbio.3c00154.\n\n\nJurenaite, Neringa, Daniel León-Periñán, Veronika Donath, Sunna Torge, and René Jäkel. 2024. “SetQuence & SetOmic: Deep Set Transformers for Whole Genome and Exome Tumour Analysis.” BioSystems 235 (January): 105095. https://doi.org/10.1016/j.biosystems.2023.105095.\n\n\nLi, Zehui, Akashaditya Das, William A. V. Beardall, Yiren Zhao, and Guy-Bart Stan. 2023. “Genomic Interpreter: A Hierarchical Genomic Deep Neural Network with 1D Shifted Window Transformer.” arXiv. https://doi.org/10.48550/arXiv.2306.05143.\n\n\nMarquet, Céline, Julius Schlensok, Marina Abakarova, Burkhard Rost, and Elodie Laine. 2024. “[VespaG] Expert-Guided Protein Language Models Enable Accurate and Blazingly Fast Fitness Prediction.” Bioinformatics 40 (11): btae621. https://doi.org/10.1093/bioinformatics/btae621.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nTrop, Evan, Yair Schiff, Edgar Mariano Marroquin, Chia Hsiang Kao, Aaron Gokaslan, McKinley Polen, Mingyi Shao, et al. 2024. “The Genomics Long-Range Benchmark: Advancing DNA Language Models,” October. https://openreview.net/forum?id=8O9HLDrmtq.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nYan, Binghao, Yunbi Nam, Lingyao Li, Rebecca A. Deek, Hongzhe Li, and Siyuan Ma. 2025. “Recent Advances in Deep Learning and Language Models for Studying the Microbiome.” Frontiers in Genetics 15 (January). https://doi.org/10.3389/fgene.2024.1494474.\n\n\nYuan, Qiuyue, and Zhana Duren. 2025. “[LINGER] Inferring Gene Regulatory Networks from Single-Cell Multiome Data Using Atlas-Scale External Data.” Nature Biotechnology 43 (2): 247–57. https://doi.org/10.1038/s41587-024-02182-7.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Avsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A.\nGrabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet\nKohli, and David R. Kelley. 2021. “[Enformer]\nEffective Gene Expression Prediction from Sequence by\nIntegrating Long-Range Interactions.” Nature Methods 18\n(October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025.\n“AlphaGenome: AI for Better\nUnderstanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S.\nSong. 2024. “GPN-MSA: An Alignment-Based\nDNA Language Model for Genome-Wide Variant Effect\nPrediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBenegas, Gonzalo, Sanjit Singh Batra, and Yun S. Song. 2023.\n“[GPN] DNA Language Models Are Powerful\nPredictors of Genome-Wide Variant Effects.” Proceedings of\nthe National Academy of Sciences 120 (44): e2311219120. https://doi.org/10.1073/pnas.2311219120.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025.\n“[TraitGym] Benchmarking\nDNA Sequence Models for\nCausal Regulatory Variant\nPrediction in Human\nGenetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nBenegas, Gonzalo, Chengzhong Ye, Carlos Albors, Jianan Canal Li, and Yun\nS. Song. 2024. “Genomic Language Models:\nOpportunities and Challenges.” arXiv.\nhttps://doi.org/10.48550/arXiv.2407.11435.\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and\nVasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant\nEffects with a Deep Protein Language Model.” Nature\nGenetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg\nBrockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025.\n“[Evo 2] Genome Modeling and Design\nAcross All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nCamillo, Lucas Paulo de Lima, Raghav Sehgal, Jenel Armstrong, Albert T.\nHiggins-Chen, Steve Horvath, and Bo Wang. 2024.\n“CpGPT: A Foundation Model\nfor DNA Methylation.” bioRxiv. https://doi.org/10.1101/2024.10.24.619766.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE]\nMulti-Omics Single-Cell Data Integration and Regulatory\nInference with Graph-Linked Embedding.” Nature\nBiotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nChandak, Payal, Kexin Huang, and Marinka Zitnik. 2023.\n“[PrimeKG] Building a Knowledge Graph to\nEnable Precision Medicine.” Scientific Data 10 (1): 67.\nhttps://doi.org/10.1038/s41597-023-01960-3.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou.\n2022. “[DeepSEA Sei] A\nSequence-Based Global Map of Regulatory Activity for Deciphering Human\nGenetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė,\nTaylor Applebaum, Alexander Pritzel, et al. 2023.\n“[AlphaMissense] Accurate Proteome-Wide\nMissense Variant Effect Prediction with\nAlphaMissense.” Science 381 (6664):\neadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus\nWahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024.\n“[DeepRVAT] Integration of Variant\nAnnotations Using Deep Set Networks Boosts Rare Variant Association\nTesting.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nCornman, Andre, Jacob West-Roberts, Antonio Pedro Camargo, Simon Roux,\nMartin Beracochea, Milot Mirdita, Sergey Ovchinnikov, and Yunha Hwang.\n2024. “[gLM2] The\nOMG Dataset: An Open\nMetaGenomic Corpus for Mixed-Modality Genomic Language\nModeling.” bioRxiv. https://doi.org/10.1101/2024.08.14.607850.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez\nCarranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago,\net al. 2023. “Nucleotide Transformer: Building and\nEvaluating Robust Foundation Models for Human Genomics.”\nNature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nFishman, Veniamin, Yuri Kuratov, Aleksei Shmelev, Maxim Petrov, Dmitry\nPenzar, Denis Shepelin, Nikolay Chekanov, Olga Kardymon, and Mikhail\nBurtsev. 2025. “GENA-LM: A Family of\nOpen-Source Foundational DNA Language Models for Long\nSequences.” Nucleic Acids Research 53 (2): gkae1310. https://doi.org/10.1093/nar/gkae1310.\n\n\nGao, Ziqi, Chenran Jiang, Jiawen Zhang, Xiaosen Jiang, Lanqing Li,\nPeilin Zhao, Huanming Yang, Yong Huang, and Jia Li. 2023.\n“[HIGH-PPI] Hierarchical\nGraph Learning for Protein–Protein Interaction.” Nature\nCommunications 14 (1): 1093. https://doi.org/10.1038/s41467-023-36736-1.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024.\n“Delphi: A Deep-Learning\nMethod for Polygenic Risk\nPrediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nHe, Shujun, Baizhen Gao, Rushant Sabnis, and Qing Sun. 2023.\n“Nucleic Transformer: Classifying\nDNA Sequences with\nSelf-Attention and\nConvolutions.” ACS Synthetic Biology 12\n(11): 3205–14. https://doi.org/10.1021/acssynbio.3c00154.\n\n\nHudaiberdiev, Sanjarbek, D. Leland Taylor, Wei Song, Narisu Narisu,\nRedwan M. Bhuiyan, Henry J. Taylor, Xuming Tang, et al. 2023.\n“[TREDNet] Modeling Islet Enhancers\nUsing Deep Learning Identifies Candidate Causal Variants at Loci\nAssociated with T2D and Glycemic Traits.”\nProceedings of the National Academy of Sciences 120 (35):\ne2206612120. https://doi.org/10.1073/pnas.2206612120.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F.\nMcRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A.\nKosmicki, et al. 2019. “[SpliceAI]\nPredicting Splicing from Primary\nSequence with Deep\nLearning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021.\n“DNABERT: Pre-Trained Bidirectional\nEncoder Representations from\nTransformers Model for DNA-Language in\nGenome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nJurenaite, Neringa, Daniel León-Periñán, Veronika Donath, Sunna Torge,\nand René Jäkel. 2024. “SetQuence &\nSetOmic: Deep Set Transformers for Whole\nGenome and Exome Tumour Analysis.” BioSystems 235\n(January): 105095. https://doi.org/10.1016/j.biosystems.2023.105095.\n\n\nKagda, Meenakshi S., Bonita Lam, Casey Litton, Corinn Small, Cricket A.\nSloan, Emma Spragins, Forrest Tanaka, et al. 2025. “Data\nNavigation on the ENCODE Portal.” Nature\nCommunications 16 (1): 9592. https://doi.org/10.1038/s41467-025-64343-9.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam,\nAmit R. Majithia, and Trey Ideker. 2025. “[G2PT]\nA Genotype-Phenotype Transformer to Assess and Explain\nPolygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai,\net al. 2024. “CGMega: Explainable Graph Neural\nNetwork Framework with Attention Mechanisms for Cancer Gene Module\nDissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and\nYunping Zhu. 2022. “MoGCN: A\nMulti-Omics Integration\nMethod Based on Graph\nConvolutional Network for Cancer\nSubtype Analysis.” Frontiers in\nGenetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nLi, Zehui, Akashaditya Das, William A. V. Beardall, Yiren Zhao, and\nGuy-Bart Stan. 2023. “Genomic Interpreter:\nA Hierarchical Genomic\nDeep Neural Network with\n1D Shifted Window\nTransformer.” arXiv. https://doi.org/10.48550/arXiv.2306.05143.\n\n\nLin, Yi-Lin, Pi-Chuan Chang, Ching Hsu, Miao-Zi Hung, Yin-Hsiu Chien,\nWuh-Liang Hwu, FeiPei Lai, and Ni-Chung Lee. 2022.\n“[DeepVariant] Comparison of\nGATK and DeepVariant by Trio\nSequencing.” Scientific Reports 12 (1): 1809. https://doi.org/10.1038/s41598-022-05833-4.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting\nLu, Allan dos Santos Costa, et al. 2022. “[ESM-2]\nLanguage Models of Protein Sequences at the Scale of\nEvolution Enable Accurate Structure Prediction.” bioRxiv. https://doi.org/10.1101/2022.07.20.500902.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and\nDavid R. Kelley. 2025. “[Borzoi]\nPredicting RNA-Seq Coverage from\nDNA Sequence as a Unifying Model of Gene\nRegulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang,\nYucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025.\n“Life-Code: Central Dogma\nModeling with Multi-Omics\nSequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nMa, Jiani, Jiangning Song, Neil D. Young, Bill C. H. Chang, Pasi K.\nKorhonen, Tulio L. Campos, Hui Liu, and Robin B. Gasser. 2023.\n“’Bingo’-a Large Language Model- and Graph Neural\nNetwork-Based Workflow for the Prediction of Essential Genes from\nProtein Data.” Briefings in Bioinformatics 25 (1):\nbbad472. https://doi.org/10.1093/bib/bbad472.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025.\n“Comparative Analysis of Deep\nLearning Models for Predicting\nCausative Regulatory\nVariants.” bioRxiv: The Preprint Server for\nBiology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nMarquet, Céline, Julius Schlensok, Marina Abakarova, Burkhard Rost, and\nElodie Laine. 2024. “[VespaG]\nExpert-Guided Protein Language Models Enable Accurate and\nBlazingly Fast Fitness Prediction.” Bioinformatics 40\n(11): btae621. https://doi.org/10.1093/bioinformatics/btae621.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill\nVishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel,\nRonnie Rajan, and Shadab Khan. 2025. “BioToken and\nBioFM – Biologically-Informed\nTokenization Enables Accurate and\nEfficient Genomic Foundation\nModels.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNaghipourfar, Mohsen, Siyu Chen, Mathew K. Howard, Christian B.\nMacdonald, Ali Saberi, Timo Hagen, Mohammad R. K. Mofrad, Willow\nCoyote-Maestas, and Hani Goodarzi. 2024. “[cdsFM - EnCodon/DeCodon]\nA Suite of Foundation\nModels Captures the Contextual\nInterplay Between Codons.”\nbioRxiv. https://doi.org/10.1101/2024.10.10.617568.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum\nBirch-Sykes, Michael Wornow, Aman Patel, et al. 2023.\n“HyenaDNA: Long-Range\nGenomic Sequence Modeling at\nSingle Nucleotide\nResolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk,\nSteffanie Paul, Han Spinner, Nathan Rollins, et al. 2023.\n“ProteinGym: Large-Scale\nBenchmarks for Protein Fitness\nPrediction and Design.” Advances in\nNeural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nPoplin, Ryan, Pi-Chuan Chang, David Alexander, Scott Schwartz, Thomas\nColthurst, Alexander Ku, Dan Newburger, et al. 2018.\n“[DeepVariant] A Universal\nSNP and Small-Indel Variant Caller Using Deep Neural\nNetworks.” Nature Biotechnology 36 (10): 983–87. https://doi.org/10.1038/nbt.4235.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025.\n“[MIFM] Multiple Instance Fine-Mapping:\nPredicting Causal Regulatory Variants with a Deep Sequence\nModel.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and\nMartin Kircher. 2019. “CADD: Predicting the\nDeleteriousness of Variants Throughout the Human Genome.”\nNucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin,\nJason Liu, Demi Guo, et al. 2021. “[ESM-1b]\nBiological Structure and Function Emerge from Scaling\nUnsupervised Learning to 250 Million Protein Sequences.”\nProceedings of the National Academy of Sciences of the United States\nof America 118 (15): e2016239118. https://doi.org/10.1073/pnas.2016239118.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch.\n2024. “[GROVER] DNA Language Model\nGROVER Learns Sequence Context in the Human Genome.”\nNature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nSchiff, Yair, Chia-Hsiang Kao, Aaron Gokaslan, Tri Dao, Albert Gu, and\nVolodymyr Kuleshov. 2024. “Caduceus:\nBi-Directional Equivariant\nLong-Range DNA\nSequence Modeling.” arXiv. https://doi.org/10.48550/arXiv.2403.03234.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and\nMartin Kircher. 2024. “CADD V1.7: Using Protein\nLanguage Models, Regulatory CNNs and Other Nucleotide-Level\nScores to Improve Genome-Wide Variant Predictions.” Nucleic\nAcids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nTrop, Evan, Yair Schiff, Edgar Mariano Marroquin, Chia Hsiang Kao, Aaron\nGokaslan, McKinley Polen, Mingyi Shao, et al. 2024. “The\nGenomics Long-Range\nBenchmark: Advancing DNA\nLanguage Models,” October. https://openreview.net/forum?id=8O9HLDrmtq.\n\n\nVishniakov, Kirill, Karthik Viswanathan, Aleksandr Medvedev,\nPraveenkumar Kanithi, Marco AF Pimentel, and Shadab Khan. 2024.\n“Genomic Foundationless Models:\nPretraining Does Not\nPromise Performance,” October. https://openreview.net/forum?id=kDZKEtDnT1.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray,\nPeter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping\nImproves Identification of Causal Variants.” Research\nSquare, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nYan, Binghao, Yunbi Nam, Lingyao Li, Rebecca A. Deek, Hongzhe Li, and\nSiyuan Ma. 2025. “Recent Advances in Deep Learning and Language\nModels for Studying the Microbiome.” Frontiers in\nGenetics 15 (January). https://doi.org/10.3389/fgene.2024.1494474.\n\n\nYuan, Qiuyue, and Zhana Duren. 2025. “[LINGER]\nInferring Gene Regulatory Networks from Single-Cell\nMultiome Data Using Atlas-Scale External Data.” Nature\nBiotechnology 43 (2): 247–57. https://doi.org/10.1038/s41587-024-02182-7.\n\n\nZhang, Qiang, Keyang Ding, Tianwen Lyv, Xinda Wang, Qingyu Yin, Yiwen\nZhang, Jing Yu, et al. 2024. “Scientific Large\nLanguage Models: A\nSurvey on Biological &\nChemical Domains.” arXiv. https://doi.org/10.48550/arXiv.2401.14656.\n\n\nZheng, Rongbin, Changxin Wan, Shenglin Mei, Qian Qin, Qiu Wu, Hanfei\nSun, Chen-Hao Chen, et al. 2019. “Cistrome Data\nBrowser: Expanded Datasets and New Tools for Gene\nRegulatory Analysis.” Nucleic Acids Research 47 (D1):\nD729–35. https://doi.org/10.1093/nar/gky1094.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K.\nWong, and Olga G. Troyanskaya. 2018. “[ExPecto]\nDeep Learning Sequence-Based Ab Initio Prediction of\nVariant Effects on Expression and Disease Risk.” Nature\nGenetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA]\nPredicting Effects of Noncoding Variants with Deep\nLearning–Based Sequence Model.” Nature Methods 12 (10):\n931–34. https://doi.org/10.1038/nmeth.3547.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and\nHan Liu. 2024. “DNABERT-2: Efficient\nFoundation Model and Benchmark\nFor Multi-Species\nGenome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.\n\n\nZvyagin, Maxim, Alexander Brace, Kyle Hippe, Yuntian Deng, Bin Zhang,\nCindy Orozco Bohorquez, Austin Clyde, et al. 2022.\n“GenSLMs: Genome-Scale Language Models\nReveal SARS-CoV-2 Evolutionary\nDynamics.” bioRxiv. https://doi.org/10.1101/2022.10.10.511571.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "app-dl.html",
    "href": "app-dl.html",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "",
    "text": "A.1 From Linear Models to Deep Networks\nThis appendix gives a compact introduction to deep learning for readers who are comfortable with genomics but less familiar with modern neural networks. The goal is not to replace a full machine learning textbook, but to provide enough background to make the models in Chapters 5–19 feel intuitive rather than magical.\nWe focus on:\nWhere possible, we connect directly to the genomic case studies in the main text (DeepSEA, ExPecto, SpliceAI, Enformer, genomic language models, and GFMs).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#from-linear-models-to-deep-networks",
    "href": "app-dl.html#from-linear-models-to-deep-networks",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "",
    "text": "A.1.1 Models as Functions\nAt its core, a predictive model is just a function:\n\\[\nf_\\theta: x \\mapsto \\hat{y}\n\\tag{A.1}\\]\nwhere:\n\n\\(x\\) is an input (e.g., a one-hot encoded DNA sequence, variant-level features, or a patient feature vector).\n\n\\(\\hat{y}\\) is a prediction (e.g., probability of a histone mark, gene expression level, disease risk).\n\n\\(\\theta\\) are the parameters (weights) of the model.\n\nIn classical genomics workflows, \\(f_\\theta\\) might be:\n\nLogistic regression (for case–control status)\n\nLinear regression (for quantitative traits)\n\nRandom forests or gradient boosting (for variant pathogenicity scores)\n\nDeep learning keeps the same basic structure but allows \\(f_\\theta\\) to be a much more flexible, high-capacity function built by composing many simple operations.\n\n\nA.1.2 Linear Models vs Neural Networks\nA simple linear model for classification looks like:\n\\[\n\\hat{y} = \\sigma(w^\\top x + b),\n\\]\nwhere \\(w\\) and \\(b\\) are parameters and \\(\\sigma(\\cdot)\\) is a squashing nonlinearity (e.g., the logistic function). The model draws a single separating hyperplane in feature space.\nA neural network generalizes this by stacking multiple linear transformations with nonlinear activation functions:\n\\[\n\\begin{aligned}\nh_1 &= \\phi(W_1 x + b_1) \\\\\nh_2 &= \\phi(W_2 h_1 + b_2) \\\\\n&\\vdots \\\\\n\\hat{y} &= g(W_L h_{L-1} + b_L)\n\\end{aligned}\n\\]\nwhere:\n\nEach \\(W_\\ell, b_\\ell\\) is a layer’s weight matrix and bias.\n\n\\(\\phi(\\cdot)\\) is a nonlinear activation (e.g., ReLU).\n\n\\(g(\\cdot)\\) is a final activation (e.g., sigmoid for probabilities, identity for regression).\n\nThe key idea:\n\nBy composing many simple nonlinear transformations, deep networks can approximate very complex functions.\n\nIn Chapters 5–7, DeepSEA, ExPecto, and SpliceAI implement exactly this pattern, but with convolutional layers (Section 4) tailored to 1D DNA sequence instead of dense matrix multiplications (Zhou and Troyanskaya 2015; Zhou et al. 2018; Jaganathan et al. 2019).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#training-deep-models",
    "href": "app-dl.html#training-deep-models",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.2 Training Deep Models",
    "text": "A.2 Training Deep Models\n\nA.2.1 Data, Labels, and Loss Functions\nTo train a model, we need:\n\nA dataset of examples \\(\\{(x_i, y_i)\\}_{i=1}^N\\)\n\nA model \\(f_\\theta\\)\n\nA loss function \\(L(\\hat{y}, y)\\) that measures how wrong a prediction is\n\nCommon loss functions:\n\nBinary cross-entropy (for yes/no labels, e.g., “is this ChIP–seq peak present?”):\n\\[\nL(\\hat{p}, y) = -\\big(y \\log \\hat{p} + (1-y)\\log(1-\\hat{p})\\big)\n\\]\nMulticlass cross-entropy (for one-of-K labels)\n\nMean squared error (MSE) (for continuous outputs, e.g., gene expression)\n\nThe training objective is to find \\(\\theta\\) that minimizes the average loss:\n\\[\n\\mathcal{L}(\\theta) = \\frac{1}{N}\\sum_{i=1}^N L\\big(f_\\theta(x_i), y_i\\big).\n\\]\n\n\nA.2.2 2.2 Gradient-Based Optimization\nDeep networks may have millions to billions of parameters. We can’t search over all possibilities, but we can follow the gradient of the loss with respect to \\(\\theta\\):\n\nGradient descent updates: \\[\n\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta \\mathcal{L}(\\theta),\n\\] where \\(\\eta\\) is the learning rate.\n\nIn practice, we use:\n\nMini-batch stochastic gradient descent (SGD): Compute gradients on small batches of examples (e.g., 128 sequences at a time) for efficiency and better generalization.\nAdaptive optimizers like Adam, which adjust learning rates per parameter.\n\nYou never compute gradients by hand; modern frameworks (PyTorch, JAX, TensorFlow) use automatic differentiation to efficiently compute \\(\\nabla_\\theta \\mathcal{L}\\) even for very complex architectures.\n\n\nA.2.3 Backpropagation in One Sentence\nBackpropagation is just the chain rule of calculus applied efficiently through the layers of a network. It propagates “blame” from the output back to each weight, telling us how changing that weight would change the loss.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#generalization-overfitting-and-evaluation",
    "href": "app-dl.html#generalization-overfitting-and-evaluation",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.3 Generalization, Overfitting, and Evaluation",
    "text": "A.3 Generalization, Overfitting, and Evaluation\n\nA.3.1 Train / Validation / Test Splits\nDeep networks can memorize training data if we’re not careful. To evaluate generalization, we typically split data into:\n\nTraining set – used to fit parameters\n\nValidation set – used to tune hyperparameters (learning rate, depth, etc.) and perform early stopping\n\nTest set – held out until the end to estimate performance on new data\n\nIn genomics, how we split matters as much as how much data we have:\n\nSplitting by locus or chromosome (to test cross-locus generalization)\n\nSplitting by individual or cohort (to avoid leakage between related samples)\n\nSplitting by species or ancestry when evaluating transfer\n\nThese issues are developed in more depth in the evaluation and confounding chapters (Chapters 12 and 14).\n\n\nA.3.2 Overfitting and Regularization\nSigns of overfitting:\n\nTraining loss keeps decreasing, but validation loss starts increasing.\n\nMetrics like AUROC or AUPRC plateau or drop on validation data even as they improve on training data.\n\nCommon regularization techniques:\n\nWeight decay / L2 regularization – penalize large weights.\n\nDropout – randomly zero out activations during training.\n\nEarly stopping – stop training when validation performance stops improving.\n\nData augmentation – generate more training examples by transforming inputs, e.g.:\n\nReverse-complement augmentation for DNA sequences (treat sequence and its reverse complement as equivalent).\n\nWindow jittering: randomly shifting the sequence window around a target site.\n\n\n\n\nA.3.3 Basic Metrics\nYou’ll encounter metrics such as:\n\nAUROC (Area Under the ROC Curve) – how well the model ranks positives above negatives.\n\nAUPRC (Area Under the Precision–Recall Curve) – more informative when positives are rare.\n\nCalibration metrics (e.g., Brier score) and reliability diagrams – especially for clinical risk prediction (Chapter 17).\n\nThe model and application chapters provide details about which metrics are appropriate for which tasks.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#convolutional-networks-for-genomic-sequences",
    "href": "app-dl.html#convolutional-networks-for-genomic-sequences",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.4 Convolutional Networks for Genomic Sequences",
    "text": "A.4 Convolutional Networks for Genomic Sequences\nConvolutional neural networks (CNNs) are the workhorse architecture in early genomic deep learning models like DeepSEA, ExPecto, and SpliceAI (Zhou and Troyanskaya 2015; Zhou et al. 2018; Jaganathan et al. 2019).\n\nA.4.1 1D Convolutions as Motif Detectors\nFor a 1D DNA sequence encoded as a matrix \\(X \\in \\mathbb{R}^{L \\times 4}\\) (length \\(L\\), 4 nucleotides), a convolutional layer applies a set of filters (kernels) of width \\(k\\):\n\nEach filter is a small matrix \\(K \\in \\mathbb{R}^{k \\times 4}\\).\n\nAt each position, the filter computes a dot product between \\(K\\) and the corresponding \\(k\\)-length chunk of \\(X\\).\n\nSliding the filter along the sequence creates an activation map that is high wherever the motif encoded by \\(K\\) is present.\n\nIntuitively:\n\nA 1D convolutional filter learns to recognize sequence motifs (e.g., transcription factor binding sites) directly from data.\n\n\n\nA.4.2 Stacking Layers and Receptive Fields\nDeeper convolutional layers allow the model to “see” longer-range patterns:\n\nFirst layer: short motifs (e.g., 8–15 bp).\n\nHigher layers: combinations of motifs, motif spacing, and local regulatory grammar.\n\nPooling layers (e.g., max pooling) reduce spatial resolution while aggregating features, increasing the receptive field.\n\nIn DeepSEA, stacked convolutions and pooling allow the model to use hundreds of base pairs of context around a locus to predict chromatin state (Zhou and Troyanskaya 2015). ExPecto extends this idea by mapping sequence to tissue-specific expression predictions (Zhou et al. 2018). SpliceAI uses very deep dilated convolutions to reach ~10 kb of context for splicing (Jaganathan et al. 2019).\n\n\nA.4.3 Multi-Task Learning\nEarly sequence-to-function CNNs are almost always multi-task:\n\nA single input sequence is used to predict many outputs simultaneously (e.g., hundreds of TF ChIP–seq peaks, histone marks, DNase hypersensitivity tracks).\n\nShared convolutional layers learn common features, while the final layer has many output units (one per task).\n\nBenefits:\n\nEfficient use of data and compute\n\nBetter regularization: related tasks constrain each other\n\nNatural interface for variant effect prediction: you can see how a mutation affects many functional readouts at once",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#beyond-cnns-recurrent-networks-briefly",
    "href": "app-dl.html#beyond-cnns-recurrent-networks-briefly",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.5 Beyond CNNs: Recurrent Networks (Briefly)",
    "text": "A.5 Beyond CNNs: Recurrent Networks (Briefly)\nBefore Transformers dominated sequence modeling, recurrent neural networks (RNNs)—especially LSTMs and GRUs—were the default architecture for language and time series.\nConceptually:\n\nAn RNN processes a sequence one position at a time.\n\nIt maintains a hidden state that is updated as it moves along the sequence.\n\nIn principle, it can capture arbitrarily long-range dependencies.\n\nIn practice, for genomic sequences:\n\nVery long-range dependencies (tens to hundreds of kilobases) are difficult to learn with standard RNNs.\n\nTraining can be slow and unstable on very long sequences.\n\nCNNs and attention-based models have largely displaced RNNs in genomic applications.\n\nYou may still see RNNs in some multi-modal or temporal settings (e.g., modeling longitudinal clinical data), but they are not central to this book’s architectures.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#transformers-and-self-attention",
    "href": "app-dl.html#transformers-and-self-attention",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.6 Transformers and Self-Attention",
    "text": "A.6 Transformers and Self-Attention\nTransformers, introduced in natural language processing, have become the dominant architecture for sequence modeling. In this book, they underpin protein language models, DNA language models (DNABERT and successors), and long-range models like Enformer (Ji et al. 2021; Avsec et al. 2021).\n\nA.6.1 The Idea of Self-Attention\nIn a self-attention layer, each position in a sequence can directly “look at” and combine information from every other position.\nFor an input sequence represented as vectors \\(\\{x_1, \\dots, x_L\\}\\):\n\nEach position is mapped to query (\\(q_i\\)), key (\\(k_i\\)), and value (\\(v_i\\)) vectors via learned linear projections.\n\nThe attention weight from position \\(i\\) to position \\(j\\) is:\n\\[\n\\alpha_{ij} \\propto \\exp\\left(\\frac{q_i^\\top k_j}{\\sqrt{d}}\\right),\n\\]\nfollowed by normalization so that \\(\\sum_j \\alpha_{ij} = 1\\).\nThe new representation of position \\(i\\) is a weighted sum of all value vectors:\n\\[\nz_i = \\sum_{j=1}^L \\alpha_{ij} v_j.\n\\]\n\nKey properties:\n\nContent-based: Interactions are determined by similarity of representations, not just distance.\n\nGlobal context: Each position can, in principle, attend to any other position.\n\nPermutation-aware via positional encodings: Additional information (sinusoidal or learned) encodes position so the model knows order.\n\n\n\nA.6.2 Multi-Head Attention and Transformer Blocks\nReal Transformer layers use multi-head attention:\n\nThe model runs self-attention in parallel with multiple sets of \\((Q,K,V)\\) projections (heads).\n\nDifferent heads can specialize in different patterns (e.g., local motif combinations, long-range enhancer–promoter contacts).\n\nA typical Transformer block has:\n\nMulti-head self-attention\n\nAdd & layer normalization\n\nPosition-wise feed-forward network\n\nAnother add & layer normalization\n\nStacking many blocks yields a deep Transformer.\n\n\nA.6.3 Computational Cost and Long-Range Genomics\nNaive self-attention has \\(O(L^2)\\) cost in sequence length \\(L\\). For genomic sequences, where we might want 100 kb–1 Mb contexts, this is expensive.\nLong-range genomic models like Enformer and HyenaDNA address this with:\n\nHybrid designs (CNNs + attention) to reduce sequence length before applying global attention (Avsec et al. 2021).\n\nStructured state space models (SSMs) and related architectures that scale more gracefully with length (Nguyen et al. 2023).\n\nThese details are treated in depth in the long-range modeling chapters; here it suffices to know that Transformers give flexible global context at the cost of higher computational complexity.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#self-supervised-learning-and-pretraining",
    "href": "app-dl.html#self-supervised-learning-and-pretraining",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.7 Self-Supervised Learning and Pretraining",
    "text": "A.7 Self-Supervised Learning and Pretraining\nA central theme of this book is pretraining: training a large model once on a broad, unlabeled or weakly-labeled task, then re-using it for many downstream problems.\n\nA.7.1 Supervised vs Self-Supervised\n\nSupervised learning: Each input \\(x\\) comes with a label \\(y\\). Examples:\n\nPredicting chromatin marks from sequence (DeepSEA).\n\nPredicting splice junctions (SpliceAI).\n\nPredicting disease risk from features (Chapter 17).\n\nSelf-supervised learning: The model learns from raw input data without explicit labels, using some pretext task constructed from the data itself. Examples:\n\nMasked token prediction (BERT-style): hide some nucleotides and train the model to predict them from surrounding context.\n\nNext-token prediction (GPT-style): predict the next base given previous ones.\n\nDenoising or reconstruction tasks.\n\n\nIn genomics, self-supervised models treat DNA sequences as a language and learn from the vast amount of genomic sequence without needing curated labels.\n\n\nA.7.2 Masked Language Modeling on DNA\nDNABERT applied BERT-style masked language modeling to DNA sequences tokenized as overlapping k-mers (Ji et al. 2021). The model:\n\nReads sequences as k-mer tokens.\n\nRandomly masks a subset of tokens.\n\nLearns to predict the masked tokens given surrounding context.\n\nBenefits:\n\nUses essentially unlimited unlabeled genomic data.\n\nLearns rich representations that can be fine-tuned for tasks like promoter prediction, splice site detection, and variant effect prediction.\n\nChapter 10 generalizes this story to broader DNA foundation models, including alternative tokenization schemes and architectures.\n\n\nA.7.3 Pretraining, Fine-Tuning, and Probing\nAfter pretraining, we can use a model in several ways:\n\nFine-tuning: Initialize with pretrained weights, then continue training on a specific downstream task with task-specific labels.\n\nLinear probing: Freeze the pretrained model, extract embeddings, and train a simple linear classifier on top.\n\nPrompting / adapters: Add small task-specific modules (adapters) while keeping most of the model fixed.\n\nThese patterns reappear across protein LMs, DNA LMs, variant effect models, and GFMs in Chapters 9–16.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#foundations-for-evaluation-and-reliability",
    "href": "app-dl.html#foundations-for-evaluation-and-reliability",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.8 Foundations for Evaluation and Reliability",
    "text": "A.8 Foundations for Evaluation and Reliability\nWhile the main book has dedicated chapters for evaluation (Chapter 12), confounding (Chapter 14), and clinical metrics (Chapter 17), it’s useful to have a few basic concepts in mind.\n\nA.8.1 Distribution Shift\nA model is trained under some data distribution (e.g., certain assays, cohorts, ancestries) and then deployed under another (e.g., a different hospital system or population). When these differ, we have distribution shift, which can degrade performance.\nTypical genomic shifts include:\n\nNew sequencing technologies or lab protocols\n\nNew ancestries or populations\n\nNew tissues, diseases, or phenotypes\n\n\n\nA.8.2 Data Leakage\nData leakage occurs when information from the test set “leaks” into training (e.g., through overlapping loci or related individuals), leading to overly optimistic estimates of performance. Chapters 12 and 14 discuss strategies for leak-resistant splits in detail.\n\n\nA.8.3 Calibration and Uncertainty\nFor many applications, especially in the clinic, we care not just about whether the model is correct, but whether its probabilities are well calibrated and whether we know when the model is uncertain. Calibration and uncertainty quantification are covered in Chapter 17; here, the main takeaway is that perfect AUROC does not imply perfect clinical utility.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#a-minimal-recipe-for-a-genomic-deep-learning-project",
    "href": "app-dl.html#a-minimal-recipe-for-a-genomic-deep-learning-project",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.9 A Minimal Recipe for a Genomic Deep Learning Project",
    "text": "A.9 A Minimal Recipe for a Genomic Deep Learning Project\nTo make the abstractions more concrete, here is a lightweight “recipe” that roughly mirrors what the case-study chapters do.\n\nDefine the prediction problem\n\nInput: e.g., 1 kb sequence around a variant, or patient-level features.\n\nOutput: e.g., presence of a chromatin mark, change in expression, disease risk.\n\nChoose an input representation\n\nOne-hot encoding or tokenization scheme for sequences (see Chapter 8).\n\nEncodings for variants, genes, or patients (e.g., aggregate from per-variant features).\n\nPick a model family\n\nCNN for local sequence-to-function (Chapters 5–7).\n\nTransformer or SSM for long-range or language model-style tasks (Chapters 8–11).\n\nPretrained GFM + small task-specific head (Chapters 12–16).\n\nSpecify the loss and metrics\n\nCross-entropy for binary classification, MSE for regression, etc.\n\nMetrics like AUROC, AUPRC, correlation, calibration.\n\nSet up data splits and evaluation\n\nDecide whether to split by locus, individual, cohort, or species.\n\nHold out a test set and use validation data to tune hyperparameters.\n\nTrain with regularization and monitoring\n\nUse an optimizer (SGD or Adam-like) with a learning rate schedule.\n\nApply regularization (dropout, weight decay, augmentation).\n\nMonitor training and validation curves for overfitting.\n\nInspect and stress-test\n\nCheck performance across subgroups (e.g., ancestries, assays, cohorts).\n\nUse interpretability tools (Chapter 15) to see what patterns the model is using.\n\nRun robustness checks and ablations.\n\nIterate\n\nAdjust architecture, add more data, refine labels, or incorporate pretrained backbones.\n\nMove from model-centric tuning to system-level considerations (data quality, deployment environment, feedback loops).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  },
  {
    "objectID": "app-dl.html#how-this-primer-connects-to-the-rest-of-the-book",
    "href": "app-dl.html#how-this-primer-connects-to-the-rest-of-the-book",
    "title": "Appendix A — Deep Learning Primer for Genomics",
    "section": "A.10 How This Primer Connects to the Rest of the Book",
    "text": "A.10 How This Primer Connects to the Rest of the Book\nThis appendix gives you the minimum vocabulary to navigate the rest of the text:\n\nChapters 5–7 show how CNNs on one-hot sequence learn regulatory code, expression, and splicing.\n\nChapters 8–11 extend these ideas to richer sequence representations, Transformers, and long-range sequence models.\n\nChapters 12–16 frame these models as genomic foundation models, introduce evaluation, interpretability, and multi-omics.\n\nChapters 17–19 show how these ingredients are assembled into clinical, discovery, and biotech applications.\n\nYou don’t need to internalize every detail here. The goal is simply that when you see terms like “convolution,” “attention,” “pretraining,” or “fine-tuning” in the main chapters, they feel like familiar tools rather than mysterious jargon.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[ExPecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer for Genomics</span>"
    ]
  }
]