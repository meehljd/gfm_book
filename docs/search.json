[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genomic Foundation Models",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Ma et al. (2023) for additional discussion of literate programming.\n\n\n\n\nMa, Jiani, Jiangning Song, Neil D. Young, Bill C. H. Chang, Pasi K. Korhonen, Tulio L. Campos, Hui Liu, and Robin B. Gasser. 2023. “’Bingo’-a Large Language Model- and Graph Neural Network-Based Workflow for the Prediction of Essential Genes from Protein Data.” Briefings in Bioinformatics 25 (1): bbad472. https://doi.org/10.1093/bib/bbad472.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Summary"
    ]
  },
  {
    "objectID": "ch01.html",
    "href": "ch01.html",
    "title": "1  Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling",
    "section": "",
    "text": "1.1 The Challenge of NGS Data\nNext-generation sequencing has revolutionized genomics by enabling the rapid generation of billions of short sequence reads from an individual’s genome. However, these reads are inherently error-prone, with error rates ranging from approximately 0.1% to 10% depending on the platform and chemistry (Poplin et al. 2018). The errors arise from a complex process that depends on properties of the sequencing instrument, preceding data processing tools, and the genome sequence itself.\nTraditional variant calling methods like the Genome Analysis Toolkit (GATK) rely on a combination of hand-crafted statistical models to distinguish true genetic variants from sequencing artifacts:\nWhile these techniques achieve high accuracy on the Illumina platform, generalizing them to other sequencing technologies (e.g., Ion Torrent, PacBio) has proven difficult due to the need to manually retune or extend the statistical models for each platform’s unique error profile (Poplin et al. 2018).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch02.html",
    "href": "ch02.html",
    "title": "2  Polygenic Risk Scores and GWAS Foundations",
    "section": "",
    "text": "2.1 The GWAS Paradigm\nGenome-wide association studies (GWAS) have transformed our understanding of the genetic architecture of complex traits and diseases. By testing millions of common genetic variants across large populations, GWAS identify single nucleotide polymorphisms (SNPs) statistically associated with phenotypes of interest. The NHGRI-EBI GWAS Catalog now contains tens of thousands of robust associations across hundreds of traits.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Polygenic Risk Scores and GWAS Foundations</span>"
    ]
  },
  {
    "objectID": "ch03.html",
    "href": "ch03.html",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "",
    "text": "3.1 The Variant Prioritization Challenge\nThe human genome harbors millions of genetic variants, the vast majority of which have unknown functional consequences. While Chapter 1 addressed distinguishing true variants from sequencing artifacts and Chapter 2 examined statistical association with phenotypes, a complementary challenge remains: predicting which variants are likely deleterious across the entire genome, including both coding and non-coding regions.\nTraditional approaches to variant prioritization suffer from critical limitations:\nCombined Annotation-Dependent Depletion (CADD) addresses these limitations through a fundamentally different approach: rather than training directly on known pathogenic variants, CADD learns to distinguish variants that survived evolutionary selection from those that did not (rentzsch_cadd_2019?).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch04.html",
    "href": "ch04.html",
    "title": "4  Foundational Functional Genomics Data",
    "section": "",
    "text": "4.1 The Data Landscape for Genomic Deep Learning\nThe preceding chapters established methods for identifying genetic variants (Chapter 1), associating them with phenotypes (Chapter 2), and scoring their likely deleteriousness (Chapter 3). These approaches and the deep learning models that follow depend on large-scale public data resources spanning chromatin profiling, population genetics, clinical variant databases, expression atlases, biobanks, and experimental benchmarks.\nThis chapter surveys the foundational data resources that underpin modern genomic machine learning. These datasets serve multiple roles: training targets for supervised models, validation benchmarks for variant effect prediction, and population references for interpreting rare variants.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch05.html",
    "href": "ch05.html",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "",
    "text": "5.1 The Noncoding Variant Challenge\nThe vast majority of disease-associated variants identified by GWAS lie in noncoding regions of the genome. Yet in 2015, the field lacked systematic methods to predict how these variants affect gene regulation. Existing approaches relied on overlap with known annotations—if a variant fell within a ChIP-seq peak or DNase hypersensitive site, it might be flagged as potentially functional. But this strategy offered no mechanism for predicting the direction or magnitude of effect, and it could not score variants in regions lacking experimental coverage.\nDeepSEA, introduced by Zhou and Troyanskaya in 2015, fundamentally changed this paradigm by learning to predict chromatin features directly from DNA sequence (zhou_deepsea_2015?). Rather than asking “does this variant overlap a known regulatory element?”, DeepSEA asks “what regulatory activities does this sequence encode, and how would a mutation change them?”",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch06.html",
    "href": "ch06.html",
    "title": "6  Predicting Transcriptional Effects (ExPecto)",
    "section": "",
    "text": "Modular framework: epigenomic CNN → spatial transformation → tissue-specific expression\n2,002 profiles, 40kb context Ab initio disease variant prioritization Key refs: (zhou_expecto_2018?)",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Predicting Transcriptional Effects (ExPecto)</span>"
    ]
  },
  {
    "objectID": "ch07.html",
    "href": "ch07.html",
    "title": "7  Specialized Prediction – Splicing (SpliceAI)",
    "section": "",
    "text": "Ultra-deep residual CNN, 10kb context\nCryptic splice prediction\n9-11% of pathogenic mutations are splice-altering\nKey refs: Jaganathan et al. (2019)\n\n\n\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Specialized Prediction – Splicing (SpliceAI)</span>"
    ]
  },
  {
    "objectID": "ch08.html",
    "href": "ch08.html",
    "title": "8  Sequence Representation and Tokenization",
    "section": "",
    "text": "One-hot vs learned embeddings\nk-mer (DNABERT), BPE, codon-aware (Life-Code)\nSingle-nucleotide (HyenaDNA) vs compression trade-offs\nContext length evolution: 512 → 100kb → 1M bp\nKey refs: (ji_dnabert_2021?), Liu et al. (2025), Medvedev et al. (2025)\n\n\n\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025. “Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.",
    "crumbs": [
      "Part III: The Age of Transformers and Long-Range Context (Hybrid Era)",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sequence Representation and Tokenization</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Avsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A.\nGrabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet\nKohli, and David R. Kelley. 2021. “[Enformer]\nEffective Gene Expression Prediction from Sequence by\nIntegrating Long-Range Interactions.” Nature Methods 18\n(October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025.\n“AlphaGenome: AI for Better\nUnderstanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S.\nSong. 2024. “GPN-MSA: An Alignment-Based\nDNA Language Model for Genome-Wide Variant Effect\nPrediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025.\n“[TraitGym] Benchmarking\nDNA Sequence Models for\nCausal Regulatory Variant\nPrediction in Human\nGenetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE]\nMulti-Omics Single-Cell Data Integration and Regulatory\nInference with Graph-Linked Embedding.” Nature\nBiotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou.\n2022. “[DeepSEA Sei] A\nSequence-Based Global Map of Regulatory Activity for Deciphering Human\nGenetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė,\nTaylor Applebaum, Alexander Pritzel, et al. 2023.\n“[AlphaMissense] Accurate Proteome-Wide\nMissense Variant Effect Prediction with\nAlphaMissense.” Science 381 (6664):\neadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez\nCarranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago,\net al. 2023. “Nucleotide Transformer: Building and\nEvaluating Robust Foundation Models for Human Genomics.”\nNature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nFishman, Veniamin, Yuri Kuratov, Aleksei Shmelev, Maxim Petrov, Dmitry\nPenzar, Denis Shepelin, Nikolay Chekanov, Olga Kardymon, and Mikhail\nBurtsev. 2025. “GENA-LM: A Family of\nOpen-Source Foundational DNA Language Models for Long\nSequences.” Nucleic Acids Research 53 (2): gkae1310. https://doi.org/10.1093/nar/gkae1310.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024.\n“Delphi: A Deep-Learning\nMethod for Polygenic Risk\nPrediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nHwang, Yunha, Andre L. Cornman, Elizabeth H. Kellogg, Sergey\nOvchinnikov, and Peter R. Girguis. 2024. “[gLM] Genomic Language Model Predicts\nProtein Co-Regulation and Function.” Nature\nCommunications 15 (1): 2880. https://doi.org/10.1038/s41467-024-46947-9.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F.\nMcRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A.\nKosmicki, et al. 2019. “[SpliceAI]\nPredicting Splicing from Primary\nSequence with Deep\nLearning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nKarollus, Alexander, Johannes Hingerl, Dennis Gankin, Martin\nGrosshauser, Kristian Klemon, and Julien Gagneur. 2024.\n“Species-Aware DNA Language Models Capture Regulatory\nElements and Their Evolution.” Genome Biology 25 (1):\n83. https://doi.org/10.1186/s13059-024-03221-x.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam,\nAmit R. Majithia, and Trey Ideker. 2025. “[G2PT]\nA Genotype-Phenotype Transformer to Assess and Explain\nPolygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.\n\n\nLin, Yi-Lin, Pi-Chuan Chang, Ching Hsu, Miao-Zi Hung, Yin-Hsiu Chien,\nWuh-Liang Hwu, FeiPei Lai, and Ni-Chung Lee. 2022.\n“[DeepVariant] Comparison of\nGATK and DeepVariant by Trio\nSequencing.” Scientific Reports 12 (1): 1809. https://doi.org/10.1038/s41598-022-05833-4.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and\nDavid R. Kelley. 2025. “[Borzoi]\nPredicting RNA-Seq Coverage from\nDNA Sequence as a Unifying Model of Gene\nRegulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang,\nYucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025.\n“Life-Code: Central Dogma\nModeling with Multi-Omics\nSequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nMa, Jiani, Jiangning Song, Neil D. Young, Bill C. H. Chang, Pasi K.\nKorhonen, Tulio L. Campos, Hui Liu, and Robin B. Gasser. 2023.\n“’Bingo’-a Large Language Model- and Graph Neural\nNetwork-Based Workflow for the Prediction of Essential Genes from\nProtein Data.” Briefings in Bioinformatics 25 (1):\nbbad472. https://doi.org/10.1093/bib/bbad472.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025.\n“Comparative Analysis of Deep\nLearning Models for Predicting\nCausative Regulatory\nVariants.” bioRxiv: The Preprint Server for\nBiology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill\nVishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel,\nRonnie Rajan, and Shadab Khan. 2025. “BioToken and\nBioFM – Biologically-Informed\nTokenization Enables Accurate and\nEfficient Genomic Foundation\nModels.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum\nBirch-Sykes, Michael Wornow, Aman Patel, et al. 2023.\n“HyenaDNA: Long-Range\nGenomic Sequence Modeling at\nSingle Nucleotide\nResolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nPoplin, Ryan, Pi-Chuan Chang, David Alexander, Scott Schwartz, Thomas\nColthurst, Alexander Ku, Dan Newburger, et al. 2018.\n“[DeepVariant] A Universal\nSNP and Small-Indel Variant Caller Using Deep Neural\nNetworks.” Nature Biotechnology 36 (10): 983–87. https://doi.org/10.1038/nbt.4235.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025.\n“[MIFM] Multiple Instance Fine-Mapping:\nPredicting Causal Regulatory Variants with a Deep Sequence\nModel.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nSchiff, Yair, Chia-Hsiang Kao, Aaron Gokaslan, Tri Dao, Albert Gu, and\nVolodymyr Kuleshov. 2024. “Caduceus:\nBi-Directional Equivariant\nLong-Range DNA\nSequence Modeling.” arXiv. https://doi.org/10.48550/arXiv.2403.03234.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and\nMartin Kircher. 2024. “CADD V1.7: Using Protein\nLanguage Models, Regulatory CNNs and Other Nucleotide-Level\nScores to Improve Genome-Wide Variant Predictions.” Nucleic\nAcids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nVishniakov, Kirill, Karthik Viswanathan, Aleksandr Medvedev,\nPraveenkumar Kanithi, Marco AF Pimentel, and Shadab Khan. 2024.\n“Genomic Foundationless Models:\nPretraining Does Not\nPromise Performance,” October. https://openreview.net/forum?id=kDZKEtDnT1.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray,\nPeter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping\nImproves Identification of Causal Variants.” Research\nSquare, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K.\nWong, and Olga G. Troyanskaya. 2018. “[DeepSEA\nBeluga] Deep Learning Sequence-Based Ab Initio\nPrediction of Variant Effects on Expression and Disease Risk.”\nNature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "ch02.html#the-need-for-universal-scoring",
    "href": "ch02.html#the-need-for-universal-scoring",
    "title": "2  Establishing Genome-Wide Deleteriousness Scores",
    "section": "",
    "text": "Genetic variant interpretation, crucial for personalized medicine, requires estimating the functional impact of variations throughout the human genome.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch02.html#combined-annotation-dependent-depletion-cadd",
    "href": "ch02.html#combined-annotation-dependent-depletion-cadd",
    "title": "2  Establishing Genome-Wide Deleteriousness Scores",
    "section": "2.2 Combined Annotation-Dependent Depletion (CADD)",
    "text": "2.2 Combined Annotation-Dependent Depletion (CADD)\n\nPrinciple:\n\nCADD is a machine-learning–based scoring system (logistic regression model).\nIntegrates hundreds of genomic annotations to assign a single deleteriousness score to SNVs and short InDels.\n\nTraining Objective:\n\nLearns to contrast a set of “proxy-neutral” variants (those observed in humans, assumed harmless) against a set of “proxy-deleterious” variants (simulated variants that have not been filtered by selection).\n\nEvolution (CADD v1.7):\n\nRecent iterations integrate features derived from advanced models, including:\n\nProtein language model scores (Meta ESM-1v).\nRegulatory variant effect predictions from sequence-based CNNs.\n\nDemonstrates the flexible and modular nature of the CADD framework.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "ch03.html#data-sources",
    "href": "ch03.html#data-sources",
    "title": "3  Foundational Functional Genomics Data",
    "section": "",
    "text": "The ENCODE and Roadmap Epigenomics projects are fundamental public data resources providing annotations for functional regulatory elements, such as:\n\nHistone marks (HMs)\nTranscription factor binding sites (TFBSs)\nDNA accessibility (DNase I hypersensitive sites)",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch03.html#role-in-model-training",
    "href": "ch03.html#role-in-model-training",
    "title": "3  Foundational Functional Genomics Data",
    "section": "3.2 Role in Model Training",
    "text": "3.2 Role in Model Training\n\nThese data serve as the crucial molecular phenotype targets used to train supervised Sequence-to-Function models (like DeepSEA and its successors) that interpret non-coding sequence variation.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch09.html",
    "href": "ch09.html",
    "title": "9  Protein Language Models — The First Biological LMs",
    "section": "",
    "text": "Evolutionary sequences as natural language\nESM/ESM-2, ProtTrans, ESM-1v (variant effects)\nESMFold (structure prediction)\nTransfer to genomics: CADD v1.7, AlphaMissense\nKey refs: (rives_esm_2021?), (lin_esmfold_2023?), Cheng et al. (2023)\n\n\n\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.",
    "crumbs": [
      "Part III: The Age of Transformers and Long-Range Context (Hybrid Era)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Protein Language Models — The First Biological LMs</span>"
    ]
  },
  {
    "objectID": "ch10.html",
    "href": "ch10.html",
    "title": "10  Genomic Language Models and Self-Supervised Pretraining",
    "section": "",
    "text": "DNABERT, Nucleotide Transformer, GENA-LM\nSpecies-aware models (GPN, SpeciesLM)\nPretraining objectives: MLM, next-token, span corruption\nKey refs: Dalla-Torre et al. (2023), Fishman et al. (2025), (benegas_gpn_2024?), Karollus et al. (2024)\n\n\n\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nFishman, Veniamin, Yuri Kuratov, Aleksei Shmelev, Maxim Petrov, Dmitry Penzar, Denis Shepelin, Nikolay Chekanov, Olga Kardymon, and Mikhail Burtsev. 2025. “GENA-LM: A Family of Open-Source Foundational DNA Language Models for Long Sequences.” Nucleic Acids Research 53 (2): gkae1310. https://doi.org/10.1093/nar/gkae1310.\n\n\nKarollus, Alexander, Johannes Hingerl, Dennis Gankin, Martin Grosshauser, Kristian Klemon, and Julien Gagneur. 2024. “Species-Aware DNA Language Models Capture Regulatory Elements and Their Evolution.” Genome Biology 25 (1): 83. https://doi.org/10.1186/s13059-024-03221-x.",
    "crumbs": [
      "Part III: The Age of Transformers and Long-Range Context (Hybrid Era)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Genomic Language Models and Self-Supervised Pretraining</span>"
    ]
  },
  {
    "objectID": "ch11.html",
    "href": "ch11.html",
    "title": "11  Hybrid Architectures for Long-Range Expression Prediction",
    "section": "",
    "text": "Enformer: CNN + attention, 100kb context, eQTL validation Borzoi: RNA-seq coverage, multi-layer VEP (transcription, splicing, polyadenylation) Key refs: Avsec et al. (2021), Linder et al. (2025)\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.",
    "crumbs": [
      "Part III: The Age of Transformers and Long-Range Context (Hybrid Era)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Hybrid Architectures for Long-Range Expression Prediction</span>"
    ]
  },
  {
    "objectID": "ch11.html#epigenomic-foundation-models-cpgpt",
    "href": "ch11.html#epigenomic-foundation-models-cpgpt",
    "title": "11  Integrating Multi-omics and Systems Context",
    "section": "",
    "text": "CpGPT (Cytosine-phosphate-Guanine Pretrained Transformer):\n\nSpecialized foundation model for DNA methylation.\nLeverages embeddings from nucleotide LMs (like NTv2) and positional context.\nTrained on the massive CpGCorpus dataset (&gt;150,000 samples).\nAchieves SOTA performance in clinically relevant tasks:\n\nMortality risk assessment.\nCancer classification.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch11.html#graph-neural-networks-gnns-for-subtyping",
    "href": "ch11.html#graph-neural-networks-gnns-for-subtyping",
    "title": "11  Integrating Multi-omics and Systems Context",
    "section": "11.2 Graph Neural Networks (GNNs) for Subtyping",
    "text": "11.2 Graph Neural Networks (GNNs) for Subtyping\n\nGNNs are powerful for modeling non-linear biological relationships and integrating heterogeneous data.\n\nExamples:\n\nMoGCN (Multi-Omics Graph Convolutional Network):\n\nDesigned for interpretable cancer subtype analysis.\nUses GCN to extract significant features from multi-omics data for clinical diagnosis.\n\nCGMega:\n\nExplainable GNN framework using graph attention.\nIntegrates multi-omics data:\n\nGenomics\nEpigenomics\n3D genome architecture\nProtein–protein interactions (PPIs)\n\nIdentifies influential cancer gene modules.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch10.html#the-quadratic-bottleneck",
    "href": "ch10.html#the-quadratic-bottleneck",
    "title": "10  Scaling Sequence Context Beyond Attention",
    "section": "",
    "text": "Standard Transformer attention scales quadratically (O(L²)) with sequence length (L).\nLimits input context to around 4k tokens, which is insufficient for long-range genomic regulation.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Scaling Sequence Context Beyond Attention</span>"
    ]
  },
  {
    "objectID": "ch10.html#alternatives-ssms-and-hyena",
    "href": "ch10.html#alternatives-ssms-and-hyena",
    "title": "10  Scaling Sequence Context Beyond Attention",
    "section": "10.2 Alternatives (SSMs and Hyena)",
    "text": "10.2 Alternatives (SSMs and Hyena)\n\nNew architectures leverage:\n\nState Space Models (SSMs)\nHierarchical convolutions\n\nAchieve quasi-linear scaling, enabling contexts up to 1 million nucleotides.\n\nExamples:\n\nHyenaDNA:\n\nDecoder-only model optimized for runtime scalability.\nHandles ultra-long genomic sequences.\n\nCaduceus (MambaDNA):\n\nBuilt on the Mamba SSM block.\nDesigned explicitly for genomics, incorporating:\n\nBi-directionality.\nReverse Complement (RC) equivariance.\n\nOutperforms 10× larger Transformer models on long-range VEP tasks.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Scaling Sequence Context Beyond Attention</span>"
    ]
  },
  {
    "objectID": "ch09.html#genomic-language-models-leveraging-evolution-gpn-msa-evo-2",
    "href": "ch09.html#genomic-language-models-leveraging-evolution-gpn-msa-evo-2",
    "title": "9  State-of-the-Art in VEP – Missense, Multi-Modality, and Conservation",
    "section": "9.2 Genomic Language Models Leveraging Evolution (GPN-MSA, Evo 2)",
    "text": "9.2 Genomic Language Models Leveraging Evolution (GPN-MSA, Evo 2)\n\nGPN-MSA:\n\nIntegrates a Multiple Sequence Alignment (MSA) across diverse vertebrate species into a Transformer architecture.\nEvolutionary information enables it to outperform:\n\nTraditional CADD.\nFunctional models like Enformer / SpliceAI in genome-wide deleteriousness prediction (coding and non-coding variants).\n\n\nEvo 2:\n\nGenome-scale language model.\nStrong zero-shot performance across various mutation types:\n\nCoding, non-coding, non-SNV, splice-associated.\n\nSet a new SOTA for BRCA1 non-coding SNVs.\nPerformed strongly on splice variant prediction using SpliceVarDB.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>State-of-the-Art in VEP – Missense, Multi-Modality, and Conservation</span>"
    ]
  },
  {
    "objectID": "ch09.html#alphagenome-avsec-et-al.-2025",
    "href": "ch09.html#alphagenome-avsec-et-al.-2025",
    "title": "9  State-of-the-Art in VEP – Missense, Multi-Modality, and Conservation",
    "section": "9.3 AlphaGenome (Avsec et al., 2025)",
    "text": "9.3 AlphaGenome (Avsec et al., 2025)\n\nUnification and Scale:\n\nDeep learning system designed to unify predictions across thousands of tracks:\n\nGene expression\nSplicing\nChromatin accessibility\n3D contact maps\n\nUses a massive 1 Mb input sequence at base-pair resolution.\n\nSOTA Performance:\n\nMatches or exceeds specialized external models on 24 out of 26 VEP evaluations.\nExcels in multi-faceted splicing prediction:\n\nSplice site probability\nUsage",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>State-of-the-Art in VEP – Missense, Multi-Modality, and Conservation</span>"
    ]
  },
  {
    "objectID": "ch09.html#alphamissense-cheng-et-al.-2023",
    "href": "ch09.html#alphamissense-cheng-et-al.-2023",
    "title": "9  State-of-the-Art in VEP – Missense, Multi-Modality, and Conservation",
    "section": "",
    "text": "Method:\n\nRepresents the SOTA for missense VEP.\nLeverages unsupervised protein language modeling.\nIncorporates structural context derived from the AlphaFold system.\nFine-tuned on weak labels from population frequency data (avoiding human-curated annotation bias).\n\nCoverage:\n\nProvides predictions for all possible single amino acid substitutions in the human proteome.\nConfidently classifies:\n\n32% as likely pathogenic.\n57% as likely benign.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>State-of-the-Art in VEP – Missense, Multi-Modality, and Conservation</span>"
    ]
  },
  {
    "objectID": "ch08.html#borzoi-linder-et-al.-2025",
    "href": "ch08.html#borzoi-linder-et-al.-2025",
    "title": "8  Integrating Long-Range Interactions for Expression Prediction",
    "section": "8.2 Borzoi (Linder et al., 2025)",
    "text": "8.2 Borzoi (Linder et al., 2025)\n\nUnifying Regulatory Layers:\n\nBased on the Enformer architecture.\nTrained to predict cell-type–specific and tissue-specific RNA-seq coverage directly from DNA sequence.\n\nMultilayer Scoring:\n\nBy predicting coverage, Borzoi allows variant effects to be scored across multiple regulatory layers:\n\nTranscription\nSplicing\nPolyadenylation\n\nOften outperforms state-of-the-art specialized models trained on individual functions.\nBorzoi-derived variant scores, combined with CADD scores, show equal power in discriminating between common benign variants and rare singletons in regulatory elements.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Integrating Long-Range Interactions for Expression Prediction</span>"
    ]
  },
  {
    "objectID": "ch08.html#enformer-avsec-et-al.-2021",
    "href": "ch08.html#enformer-avsec-et-al.-2021",
    "title": "8  Integrating Long-Range Interactions for Expression Prediction",
    "section": "",
    "text": "Architecture:\n\nHybrid CNN–Transformer model.\nExtends receptive field up to 100 kb (vs. 20 kb for predecessors like ExPecto).\nUses attention layers to refine predictions by gathering information from distal elements like enhancers.\n\nClinical Relevance:\n\nLarger context size is crucial because distal elements drive tissue-specific gene expression.\nSignificantly improved accuracy of non-coding Variant Effect Prediction (VEP) on eQTL data.\nEnables signed prediction of mutation effects (activating vs. repressive).",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Integrating Long-Range Interactions for Expression Prediction</span>"
    ]
  },
  {
    "objectID": "ch07.html#genomic-language-models-glms",
    "href": "ch07.html#genomic-language-models-glms",
    "title": "7  Architectural Shift to Attention and Foundation Models",
    "section": "7.2 Genomic Language Models (gLMs)",
    "text": "7.2 Genomic Language Models (gLMs)\n\nApply the principles of language models (like BERT, using the Masked Language Modeling objective) to DNA sequences.\nPre-trained on massive amounts of unlabeled data to learn complex features and dependencies.\n\nExamples:\n\nDNABERT\n\nOne of the earliest examples, applying BERT with k-mer tokenization to the human genome.\n\nNucleotide Transformer (NT)\n\nA family of encoder-only transformer foundation models (up to 2.5B parameters).\n\nPretrained on diverse human and multispecies genomes.\n\nEmbeddings and derived scores have been used to prioritize functional variants such as eQTLs and meQTLs.",
    "crumbs": [
      "Part III: The Age of Transformers and Long-Range Context (Hybrid Era)",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Architectural Shift to Attention and Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch07.html#the-transformer-core",
    "href": "ch07.html#the-transformer-core",
    "title": "7  Architectural Shift to Attention and Foundation Models",
    "section": "",
    "text": "Transformer architecture (from NLP) uses self-attention to capture long-range dependencies efficiently.\nContrasts with the local receptive fields of traditional CNNs.",
    "crumbs": [
      "Part III: The Age of Transformers and Long-Range Context (Hybrid Era)",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Architectural Shift to Attention and Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch11.html#interpreting-rare-and-complex-variants",
    "href": "ch11.html#interpreting-rare-and-complex-variants",
    "title": "11  Integrating Multi-omics and Systems Context",
    "section": "11.3 Interpreting Rare and Complex Variants",
    "text": "11.3 Interpreting Rare and Complex Variants\n\nDeepRVAT (Deep Rare Variant Association Testing):\n\nUses a deep set network to learn a single, trait-agnostic gene impairment score from dozens of rare variant annotations.\nScore is efficient and generalizable across traits.\nFacilitates refinement of Polygenic Risk Scores (PRS) by accounting for rare variant effects.\n\nNeEDL (Epistasis):\n\nUses network medicine to inform selection of higher-order interactions (Epistatic Interactions, EIs) between multiple SNPs.\nGoes beyond pair-wise limits.\nAddresses the polygenic nature of most heritable diseases.\n\nG2PT (Genotype-Phenotype Transformer):\n\nGraph transformer designed for transparent genotype-to-phenotype translation.\nIncorporates hierarchical biological knowledge.\nEnables analysis of nonlinear gene-by-gene epistatic interactions underlying polygenic risk prediction.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch04.html#the-deepsea-methodology-zhou-troyanskaya-2015",
    "href": "ch04.html#the-deepsea-methodology-zhou-troyanskaya-2015",
    "title": "4  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "",
    "text": "Introduced the fundamental application of deep convolutional neural networks (CNNs) to predict the functional effects of non-coding variants directly from sequence input.",
    "crumbs": [
      "Part II: Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch04.html#training-scale",
    "href": "ch04.html#training-scale",
    "title": "4  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "4.2 Training Scale",
    "text": "4.2 Training Scale\n\nTrained to predict a large number of chromatin profiles (e.g., 919 tracks).",
    "crumbs": [
      "Part II: Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch04.html#significance",
    "href": "ch04.html#significance",
    "title": "4  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "4.3 Significance",
    "text": "4.3 Significance\n\nEstablished the viability of using CNNs to implicitly learn the underlying regulatory code or “syntax” of the genome by recognizing local sequence patterns and motifs.",
    "crumbs": [
      "Part II: Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch05.html#extending-deepsea-expecto-zhou-et-al.-2018",
    "href": "ch05.html#extending-deepsea-expecto-zhou-et-al.-2018",
    "title": "5  Predicting Transcriptional Effects (ExPecto)",
    "section": "",
    "text": "ExPecto is a modular framework built on a refined DeepSEA architecture.\nDesigned to predict the tissue-specific transcriptional effects of mutations ab initio (from sequence only), without having trained on any variant information.",
    "crumbs": [
      "Part II: Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicting Transcriptional Effects (ExPecto)</span>"
    ]
  },
  {
    "objectID": "ch05.html#architecture-components",
    "href": "ch05.html#architecture-components",
    "title": "5  Predicting Transcriptional Effects (ExPecto)",
    "section": "5.2 Architecture Components",
    "text": "5.2 Architecture Components\n\nEpigenomic Effects Model\n\nA deep CNN predicts probabilities for 2,002 histone mark, TF, and DNA accessibility profiles across over 200 tissues/cell types.\n\nSpatial Feature Transformation\n\nSummarizes the predicted epigenomic information across a 40 kb region.\n\nTissue-Specific Prediction\n\nRegularized linear models use the transformed features to predict Pol II–transcribed gene expression in 218 tissues/cell types.",
    "crumbs": [
      "Part II: Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicting Transcriptional Effects (ExPecto)</span>"
    ]
  },
  {
    "objectID": "ch06.html#the-importance-of-splicing",
    "href": "ch06.html#the-importance-of-splicing",
    "title": "6  Specialized Prediction – Splicing (SpliceAI)",
    "section": "",
    "text": "Aberrant splicing is a major cause of genetic disorders.\nSpecialized tools are necessary to interpret variants affecting this process.",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Specialized Prediction – Splicing (SpliceAI)</span>"
    ]
  },
  {
    "objectID": "ch06.html#spliceai-jaganathan-et-al.-2019",
    "href": "ch06.html#spliceai-jaganathan-et-al.-2019",
    "title": "6  Specialized Prediction – Splicing (SpliceAI)",
    "section": "6.2 SpliceAI (Jaganathan et al., 2019)",
    "text": "6.2 SpliceAI (Jaganathan et al., 2019)\n\nUses an ultra-deep residual neural network architecture.\nPredicts splice junctions based on a large flanking context sequence (up to 10,000 nucleotides).",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Specialized Prediction – Splicing (SpliceAI)</span>"
    ]
  },
  {
    "objectID": "ch06.html#clinical-impact",
    "href": "ch06.html#clinical-impact",
    "title": "6  Specialized Prediction – Splicing (SpliceAI)",
    "section": "6.3 Clinical Impact",
    "text": "6.3 Clinical Impact\n\nAccurately predicts noncoding cryptic splice mutations.\nApprox. 9%–11% of pathogenic mutations in patients with rare genetic disorders are caused by this class of variation.\nThe network is trained only on reference sequences; predicting variant effects by comparing reference and alternate sequences (Δ score) is a robust test of its splicing determinant modeling ability.",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Specialized Prediction – Splicing (SpliceAI)</span>"
    ]
  },
  {
    "objectID": "ch05.html#clinical-utility",
    "href": "ch05.html#clinical-utility",
    "title": "5  Predicting Transcriptional Effects (ExPecto)",
    "section": "5.3 Clinical Utility",
    "text": "5.3 Clinical Utility\n\nProvides an end-to-end computational framework for in silico prediction of disease-associated regulatory variation.\nDemonstrates potential for interpreting clinically-relevant mutations, including those missed by traditional quantitative genetics.",
    "crumbs": [
      "Part II: Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicting Transcriptional Effects (ExPecto)</span>"
    ]
  },
  {
    "objectID": "ch01.html#the-challenge-of-ngs-data",
    "href": "ch01.html#the-challenge-of-ngs-data",
    "title": "1  Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling",
    "section": "",
    "text": "Logistic regression to model base errors\nHidden Markov models to compute read likelihoods\nNaive Bayes classification to identify variants\nGaussian mixture models with hand-crafted features to filter likely false positives",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch01.html#deepvariant-deep-learning-for-variant-calling-poplin-et-al.-2018",
    "href": "ch01.html#deepvariant-deep-learning-for-variant-calling-poplin-et-al.-2018",
    "title": "1  Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling",
    "section": "1.2 DeepVariant: Deep Learning for Variant Calling (Poplin et al., 2018)",
    "text": "1.2 DeepVariant: Deep Learning for Variant Calling (Poplin et al., 2018)\n\nConcept: DeepVariant replaces the assortment of statistical modeling components with a single deep learning model.\nArchitecture:\n\nUses a deep Convolutional Neural Network (CNN), such as the Inception architecture.\nProcesses read pileups encoded as images around candidate variants.\nThe CNN learns complex dependencies among reads, approximating the true but unknown interdependent likelihood function.\n\nClinical Impact:\n\nDeepVariant demonstrated higher accuracy than state-of-the-art tools like GATK.\nIn clinical Whole-Exome Sequencing (WES) trio analysis, DeepVariant yielded a significantly lower Mendelian error rate and shorter execution time compared to GATK HaplotypeCaller, suggesting proportionally more true positive calls.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch07.html#test-genomic-language-models-glms",
    "href": "ch07.html#test-genomic-language-models-glms",
    "title": "7  Architectural Shift to Attention and Foundation Models",
    "section": "7.2 TEST Genomic Language Models (gLMs)",
    "text": "7.2 TEST Genomic Language Models (gLMs)\n\nApply the principles of language models (like BERT, using the Masked Language Modeling objective) to DNA sequences.\nPre-trained on massive amounts of unlabeled data to learn complex features and dependencies.\n\nExamples:\n\nDNABERT\n\nOne of the earliest examples, applying BERT with k-mer tokenization to the human genome.\n\nNucleotide Transformer (NT)\n\nA family of encoder-only transformer foundation models (up to 2.5B parameters).\n\nPretrained on diverse human and multispecies genomes.\n\nEmbeddings and derived scores have been used to prioritize functional variants such as eQTLs and meQTLs.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Architectural Shift to Attention and Foundation Models</span>"
    ]
  },
  {
    "objectID": "ch12.html",
    "href": "ch12.html",
    "title": "12  Scaling Sequence Context Beyond Attention",
    "section": "",
    "text": "Quadratic bottleneck of attention (O(L²))\nSSMs, Hyena, quasi-linear scaling\nHyenaDNA: decoder-only, 1M bp context\nCaduceus/MambaDNA: bidirectional, RC-equivariant\nKey refs: Nguyen et al. (2023), Schiff et al. (2024)\n\n\n\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nSchiff, Yair, Chia-Hsiang Kao, Aaron Gokaslan, Tri Dao, Albert Gu, and Volodymyr Kuleshov. 2024. “Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling.” arXiv. https://doi.org/10.48550/arXiv.2403.03234.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Scaling Sequence Context Beyond Attention</span>"
    ]
  },
  {
    "objectID": "ch12.html#epigenomic-foundation-models-cpgpt",
    "href": "ch12.html#epigenomic-foundation-models-cpgpt",
    "title": "12  Integrating Multi-omics and Systems Context",
    "section": "",
    "text": "CpGPT (Cytosine-phosphate-Guanine Pretrained Transformer):\n\nSpecialized foundation model for DNA methylation.\nLeverages embeddings from nucleotide LMs (like NTv2) and positional context.\nTrained on the massive CpGCorpus dataset (&gt;150,000 samples).\nAchieves SOTA performance in clinically relevant tasks:\n\nMortality risk assessment.\nCancer classification.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch12.html#graph-neural-networks-gnns-for-subtyping",
    "href": "ch12.html#graph-neural-networks-gnns-for-subtyping",
    "title": "12  Integrating Multi-omics and Systems Context",
    "section": "12.2 Graph Neural Networks (GNNs) for Subtyping",
    "text": "12.2 Graph Neural Networks (GNNs) for Subtyping\n\nGNNs are powerful for modeling non-linear biological relationships and integrating heterogeneous data.\n\nExamples:\n\nMoGCN (Multi-Omics Graph Convolutional Network):\n\nDesigned for interpretable cancer subtype analysis.\nUses GCN to extract significant features from multi-omics data for clinical diagnosis.\n\nCGMega:\n\nExplainable GNN framework using graph attention.\nIntegrates multi-omics data:\n\nGenomics\nEpigenomics\n3D genome architecture\nProtein–protein interactions (PPIs)\n\nIdentifies influential cancer gene modules.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch12.html#interpreting-rare-and-complex-variants",
    "href": "ch12.html#interpreting-rare-and-complex-variants",
    "title": "12  Integrating Multi-omics and Systems Context",
    "section": "12.3 Interpreting Rare and Complex Variants",
    "text": "12.3 Interpreting Rare and Complex Variants\n\nDeepRVAT (Deep Rare Variant Association Testing):\n\nUses a deep set network to learn a single, trait-agnostic gene impairment score from dozens of rare variant annotations.\nScore is efficient and generalizable across traits.\nFacilitates refinement of Polygenic Risk Scores (PRS) by accounting for rare variant effects.\n\nNeEDL (Epistasis):\n\nUses network medicine to inform selection of higher-order interactions (Epistatic Interactions, EIs) between multiple SNPs.\nGoes beyond pair-wise limits.\nAddresses the polygenic nature of most heritable diseases.\n\nG2PT (Genotype-Phenotype Transformer):\n\nGraph transformer designed for transparent genotype-to-phenotype translation.\nIncorporates hierarchical biological knowledge.\nEnables analysis of nonlinear gene-by-gene epistatic interactions underlying polygenic risk prediction.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch13.html",
    "href": "ch13.html",
    "title": "13  State-of-the-Art Variant Effect Prediction",
    "section": "",
    "text": "AlphaMissense: PLM + structure, proteome-wide missense GPN-MSA: MSA + transformer, genome-wide VEP Evo2: genome-scale LM, zero-shot across variant types AlphaGenome: unified multi-track, 1Mb context Key refs: Cheng et al. (2023), Benegas et al. (2024), Avsec, Latysheva, and Cheng (2025)\n\n\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>State-of-the-Art Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "ch13.html#epigenomic-foundation-models-cpgpt",
    "href": "ch13.html#epigenomic-foundation-models-cpgpt",
    "title": "13  Integrating Multi-omics and Systems Context",
    "section": "",
    "text": "CpGPT (Cytosine-phosphate-Guanine Pretrained Transformer):\n\nSpecialized foundation model for DNA methylation.\nLeverages embeddings from nucleotide LMs (like NTv2) and positional context.\nTrained on the massive CpGCorpus dataset (&gt;150,000 samples).\nAchieves SOTA performance in clinically relevant tasks:\n\nMortality risk assessment.\nCancer classification.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch13.html#graph-neural-networks-gnns-for-subtyping",
    "href": "ch13.html#graph-neural-networks-gnns-for-subtyping",
    "title": "13  Integrating Multi-omics and Systems Context",
    "section": "13.2 Graph Neural Networks (GNNs) for Subtyping",
    "text": "13.2 Graph Neural Networks (GNNs) for Subtyping\n\nGNNs are powerful for modeling non-linear biological relationships and integrating heterogeneous data.\n\nExamples:\n\nMoGCN (Multi-Omics Graph Convolutional Network):\n\nDesigned for interpretable cancer subtype analysis.\nUses GCN to extract significant features from multi-omics data for clinical diagnosis.\n\nCGMega:\n\nExplainable GNN framework using graph attention.\nIntegrates multi-omics data:\n\nGenomics\nEpigenomics\n3D genome architecture\nProtein–protein interactions (PPIs)\n\nIdentifies influential cancer gene modules.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch13.html#interpreting-rare-and-complex-variants",
    "href": "ch13.html#interpreting-rare-and-complex-variants",
    "title": "13  Integrating Multi-omics and Systems Context",
    "section": "13.3 Interpreting Rare and Complex Variants",
    "text": "13.3 Interpreting Rare and Complex Variants\n\nDeepRVAT (Deep Rare Variant Association Testing):\n\nUses a deep set network to learn a single, trait-agnostic gene impairment score from dozens of rare variant annotations.\nScore is efficient and generalizable across traits.\nFacilitates refinement of Polygenic Risk Scores (PRS) by accounting for rare variant effects.\n\nNeEDL (Epistasis):\n\nUses network medicine to inform selection of higher-order interactions (Epistatic Interactions, EIs) between multiple SNPs.\nGoes beyond pair-wise limits.\nAddresses the polygenic nature of most heritable diseases.\n\nG2PT (Genotype-Phenotype Transformer):\n\nGraph transformer designed for transparent genotype-to-phenotype translation.\nIncorporates hierarchical biological knowledge.\nEnables analysis of nonlinear gene-by-gene epistatic interactions underlying polygenic risk prediction.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch14.html",
    "href": "ch14.html",
    "title": "14  Confounders in Genomic Model Training and Evaluation",
    "section": "",
    "text": "Ancestry stratification and population bias\nBenchmark leakage (train/test overlap)\nTechnical artifacts: batch effects, platform differences\nLabel noise (ClinVar uncertainty)\nCross-ancestry PRS transferability\nKey refs: Rakowski and Lippert (2025), Vishniakov et al. (2024)\n\n\n\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nVishniakov, Kirill, Karthik Viswanathan, Aleksandr Medvedev, Praveenkumar Kanithi, Marco AF Pimentel, and Shadab Khan. 2024. “Genomic Foundationless Models: Pretraining Does Not Promise Performance,” October. https://openreview.net/forum?id=kDZKEtDnT1.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Confounders in Genomic Model Training and Evaluation</span>"
    ]
  },
  {
    "objectID": "ch14.html#epigenomic-foundation-models-cpgpt",
    "href": "ch14.html#epigenomic-foundation-models-cpgpt",
    "title": "14  Integrating Multi-omics and Systems Context",
    "section": "",
    "text": "CpGPT (Cytosine-phosphate-Guanine Pretrained Transformer):\n\nSpecialized foundation model for DNA methylation.\nLeverages embeddings from nucleotide LMs (like NTv2) and positional context.\nTrained on the massive CpGCorpus dataset (&gt;150,000 samples).\nAchieves SOTA performance in clinically relevant tasks:\n\nMortality risk assessment.\nCancer classification.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch14.html#graph-neural-networks-gnns-for-subtyping",
    "href": "ch14.html#graph-neural-networks-gnns-for-subtyping",
    "title": "14  Integrating Multi-omics and Systems Context",
    "section": "14.2 Graph Neural Networks (GNNs) for Subtyping",
    "text": "14.2 Graph Neural Networks (GNNs) for Subtyping\n\nGNNs are powerful for modeling non-linear biological relationships and integrating heterogeneous data.\n\nExamples:\n\nMoGCN (Multi-Omics Graph Convolutional Network):\n\nDesigned for interpretable cancer subtype analysis.\nUses GCN to extract significant features from multi-omics data for clinical diagnosis.\n\nCGMega:\n\nExplainable GNN framework using graph attention.\nIntegrates multi-omics data:\n\nGenomics\nEpigenomics\n3D genome architecture\nProtein–protein interactions (PPIs)\n\nIdentifies influential cancer gene modules.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch14.html#interpreting-rare-and-complex-variants",
    "href": "ch14.html#interpreting-rare-and-complex-variants",
    "title": "14  Integrating Multi-omics and Systems Context",
    "section": "14.3 Interpreting Rare and Complex Variants",
    "text": "14.3 Interpreting Rare and Complex Variants\n\nDeepRVAT (Deep Rare Variant Association Testing):\n\nUses a deep set network to learn a single, trait-agnostic gene impairment score from dozens of rare variant annotations.\nScore is efficient and generalizable across traits.\nFacilitates refinement of Polygenic Risk Scores (PRS) by accounting for rare variant effects.\n\nNeEDL (Epistasis):\n\nUses network medicine to inform selection of higher-order interactions (Epistatic Interactions, EIs) between multiple SNPs.\nGoes beyond pair-wise limits.\nAddresses the polygenic nature of most heritable diseases.\n\nG2PT (Genotype-Phenotype Transformer):\n\nGraph transformer designed for transparent genotype-to-phenotype translation.\nIncorporates hierarchical biological knowledge.\nEnables analysis of nonlinear gene-by-gene epistatic interactions underlying polygenic risk prediction.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch15.html",
    "href": "ch15.html",
    "title": "15  Interpretability and Mechanistic Insights",
    "section": "",
    "text": "Conv filter visualization, motif extraction\nAttribution: ISM, DeepLIFT, integrated gradients\nAttention patterns: gLM operons, Enformer distal elements\nSei sequence classes as regulatory vocabulary\nTF-MoDISco for de novo motif discovery\nKey refs: (zhou_sei_2022?), Hwang et al. (2024)\n\n\n\n\n\nHwang, Yunha, Andre L. Cornman, Elizabeth H. Kellogg, Sergey Ovchinnikov, and Peter R. Girguis. 2024. “[gLM] Genomic Language Model Predicts Protein Co-Regulation and Function.” Nature Communications 15 (1): 2880. https://doi.org/10.1038/s41467-024-46947-9.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Interpretability and Mechanistic Insights</span>"
    ]
  },
  {
    "objectID": "ch15.html#epigenomic-foundation-models-cpgpt",
    "href": "ch15.html#epigenomic-foundation-models-cpgpt",
    "title": "15  Integrating Multi-omics and Systems Context",
    "section": "",
    "text": "CpGPT (Cytosine-phosphate-Guanine Pretrained Transformer):\n\nSpecialized foundation model for DNA methylation.\nLeverages embeddings from nucleotide LMs (like NTv2) and positional context.\nTrained on the massive CpGCorpus dataset (&gt;150,000 samples).\nAchieves SOTA performance in clinically relevant tasks:\n\nMortality risk assessment.\nCancer classification.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch15.html#graph-neural-networks-gnns-for-subtyping",
    "href": "ch15.html#graph-neural-networks-gnns-for-subtyping",
    "title": "15  Integrating Multi-omics and Systems Context",
    "section": "15.2 Graph Neural Networks (GNNs) for Subtyping",
    "text": "15.2 Graph Neural Networks (GNNs) for Subtyping\n\nGNNs are powerful for modeling non-linear biological relationships and integrating heterogeneous data.\n\nExamples:\n\nMoGCN (Multi-Omics Graph Convolutional Network):\n\nDesigned for interpretable cancer subtype analysis.\nUses GCN to extract significant features from multi-omics data for clinical diagnosis.\n\nCGMega:\n\nExplainable GNN framework using graph attention.\nIntegrates multi-omics data:\n\nGenomics\nEpigenomics\n3D genome architecture\nProtein–protein interactions (PPIs)\n\nIdentifies influential cancer gene modules.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch15.html#interpreting-rare-and-complex-variants",
    "href": "ch15.html#interpreting-rare-and-complex-variants",
    "title": "15  Integrating Multi-omics and Systems Context",
    "section": "15.3 Interpreting Rare and Complex Variants",
    "text": "15.3 Interpreting Rare and Complex Variants\n\nDeepRVAT (Deep Rare Variant Association Testing):\n\nUses a deep set network to learn a single, trait-agnostic gene impairment score from dozens of rare variant annotations.\nScore is efficient and generalizable across traits.\nFacilitates refinement of Polygenic Risk Scores (PRS) by accounting for rare variant effects.\n\nNeEDL (Epistasis):\n\nUses network medicine to inform selection of higher-order interactions (Epistatic Interactions, EIs) between multiple SNPs.\nGoes beyond pair-wise limits.\nAddresses the polygenic nature of most heritable diseases.\n\nG2PT (Genotype-Phenotype Transformer):\n\nGraph transformer designed for transparent genotype-to-phenotype translation.\nIncorporates hierarchical biological knowledge.\nEnables analysis of nonlinear gene-by-gene epistatic interactions underlying polygenic risk prediction.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch16.html",
    "href": "ch16.html",
    "title": "16  Integrating Multi-omics and Systems Context",
    "section": "",
    "text": "CpGPT (DNA methylation FM)\nGLUE (multi-omics integration)\nGNNs: MoGCN, CGMega (cancer subtyping)\nRare variants: DeepRVAT\nEpistasis: NeEDL, G2PT\nDL-enhanced PRS: Delphi, MIFM\nKey refs: Cao and Gao (2022), Lee et al. (2025), Georgantas, Kutalik, and Richiardi (2024)\n\n\n\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam, Amit R. Majithia, and Trey Ideker. 2025. “[G2PT] A Genotype-Phenotype Transformer to Assess and Explain Polygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch16.html#epigenomic-foundation-models-cpgpt",
    "href": "ch16.html#epigenomic-foundation-models-cpgpt",
    "title": "16  Integrating Multi-omics and Systems Context",
    "section": "",
    "text": "CpGPT (Cytosine-phosphate-Guanine Pretrained Transformer):\n\nSpecialized foundation model for DNA methylation.\nLeverages embeddings from nucleotide LMs (like NTv2) and positional context.\nTrained on the massive CpGCorpus dataset (&gt;150,000 samples).\nAchieves SOTA performance in clinically relevant tasks:\n\nMortality risk assessment.\nCancer classification.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch16.html#graph-neural-networks-gnns-for-subtyping",
    "href": "ch16.html#graph-neural-networks-gnns-for-subtyping",
    "title": "16  Integrating Multi-omics and Systems Context",
    "section": "16.2 Graph Neural Networks (GNNs) for Subtyping",
    "text": "16.2 Graph Neural Networks (GNNs) for Subtyping\n\nGNNs are powerful for modeling non-linear biological relationships and integrating heterogeneous data.\n\nExamples:\n\nMoGCN (Multi-Omics Graph Convolutional Network):\n\nDesigned for interpretable cancer subtype analysis.\nUses GCN to extract significant features from multi-omics data for clinical diagnosis.\n\nCGMega:\n\nExplainable GNN framework using graph attention.\nIntegrates multi-omics data:\n\nGenomics\nEpigenomics\n3D genome architecture\nProtein–protein interactions (PPIs)\n\nIdentifies influential cancer gene modules.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch16.html#interpreting-rare-and-complex-variants",
    "href": "ch16.html#interpreting-rare-and-complex-variants",
    "title": "16  Integrating Multi-omics and Systems Context",
    "section": "16.3 Interpreting Rare and Complex Variants",
    "text": "16.3 Interpreting Rare and Complex Variants\n\nDeepRVAT (Deep Rare Variant Association Testing):\n\nUses a deep set network to learn a single, trait-agnostic gene impairment score from dozens of rare variant annotations.\nScore is efficient and generalizable across traits.\nFacilitates refinement of Polygenic Risk Scores (PRS) by accounting for rare variant effects.\n\nNeEDL (Epistasis):\n\nUses network medicine to inform selection of higher-order interactions (Epistatic Interactions, EIs) between multiple SNPs.\nGoes beyond pair-wise limits.\nAddresses the polygenic nature of most heritable diseases.\n\nG2PT (Genotype-Phenotype Transformer):\n\nGraph transformer designed for transparent genotype-to-phenotype translation.\nIncorporates hierarchical biological knowledge.\nEnables analysis of nonlinear gene-by-gene epistatic interactions underlying polygenic risk prediction.",
    "crumbs": [
      "Part IV: Modern Frontiers – GFMs, Specialized Systems, and Multi-omics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Integrating Multi-omics and Systems Context</span>"
    ]
  },
  {
    "objectID": "ch01.html#deepvariant-deep-learning-for-variant-calling",
    "href": "ch01.html#deepvariant-deep-learning-for-variant-calling",
    "title": "1  Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling",
    "section": "1.2 DeepVariant: Deep Learning for Variant Calling",
    "text": "1.2 DeepVariant: Deep Learning for Variant Calling\nDeepVariant (Poplin et al. 2018) replaces the assortment of statistical modeling components with a single deep convolutional neural network (CNN), demonstrating that deep learning can learn to call genetic variants more accurately than state-of-the-art methods without specialized knowledge about genomics or sequencing.\n\n1.2.1 Architecture\nDeepVariant uses a three-stage pipeline:\n\nCandidate Generation: Standard algorithmic preprocessing identifies candidate SNPs and indels with high sensitivity but low specificity.\nPileup Image Encoding: Read alignments around each candidate variant are encoded as multi-channel images (pileup images), capturing:\n\nReference sequence\nRead bases and quality scores\nMapping quality\nStrand orientation\n\nCNN Classification: An Inception-architecture CNN processes each pileup image and emits probabilities for each of the three diploid genotypes (homozygous reference, heterozygous, homozygous alternate).\n\n\n\n1.2.2 Learning Complex Dependencies\nA key limitation of traditional variant callers like GATK is their assumption that read errors are independent. Though this has long been recognized as invalid, the true likelihood function that models multiple reads simultaneously is unknown. Deep neural networks are universal function approximators, enabling DeepVariant to learn an approximation to this complex, interdependent likelihood function directly from data (Poplin et al. 2018).\n\n\n1.2.3 Cross-Technology Generalization\nDeepVariant demonstrates remarkable generalization across sequencing technologies. When retrained on platform-specific data, the model achieves high positive predictive values (PPVs) across diverse technologies:\n\n\n\nTechnology\nInitial PPV\nFinal PPV\nNotes\n\n\n\n\nIllumina WGS\n96.5%\n99.9%\nStandard short-read\n\n\nPacBio WGS\n22.1%\n97.3%\nHigh indel error rate\n\n\nSOLiD WGS\n14.3%\n99.0%\nColor-space artifacts\n\n\nIon Ampliseq\n8.1%\n99.7%\nExome, amplification artifacts\n\n\n\nThe model even generalizes across species—a model trained on human data achieved high accuracy (F1 = 98.29%) when applied to mouse sequencing data, outperforming training on mouse data alone (Poplin et al. 2018).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch01.html#clinical-validation",
    "href": "ch01.html#clinical-validation",
    "title": "1  Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling",
    "section": "1.3 Clinical Validation",
    "text": "1.3 Clinical Validation\nIn a clinical comparison using whole-exome sequencing (WES) trio analysis of 80 families, DeepVariant demonstrated superior performance over GATK HaplotypeCaller (Lin et al. 2022):\n\n\n\nMetric\nDeepVariant\nGATK\np-value\n\n\n\n\nMendelian error rate\n3.09 ± 0.83%\n5.25 ± 0.91%\n&lt; 0.001\n\n\nTi/Tv ratio\n2.38 ± 0.02\n2.04 ± 0.07\n&lt; 0.001\n\n\nExecution time (trio)\n~1.5 hours\n~2.5 hours\n0.046\n\n\n\nThe higher transition-to-transversion (Ti/Tv) ratio achieved by DeepVariant suggests proportionally more true positive calls, as biological SNVs exhibit a characteristic Ti/Tv ratio near 2.1 for exomes. The lower Mendelian error rate—variants in a child that violate expected inheritance patterns—provides direct evidence of improved accuracy in real clinical samples.\nBoth pipelines detected nearly identical sets of disease-causing variants (62 vs. 61 of 63 total), with DeepVariant detecting one additional variant missed by GATK due to low coverage (Lin et al. 2022).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch01.html#significance-for-genomic-deep-learning",
    "href": "ch01.html#significance-for-genomic-deep-learning",
    "title": "1  Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling",
    "section": "1.4 Significance for Genomic Deep Learning",
    "text": "1.4 Significance for Genomic Deep Learning\nDeepVariant established several paradigms that recur throughout this book:\n\nImage-based encoding: Representing genomic data as images enables the application of powerful computer vision architectures.\nEnd-to-end learning: Replacing hand-crafted feature engineering with learned representations from raw data.\nTransfer learning: Models trained on data-rich settings (human genomes with ground truth) can generalize to data-poor settings (non-model organisms).\nTechnology agnosticism: A single architecture can adapt to diverse sequencing platforms through retraining, rather than requiring platform-specific statistical models.\n\nThese principles—learning from data rather than encoding expert knowledge, and generalizing across contexts—form the foundation of the deep learning approaches to genomic interpretation covered in subsequent chapters.\n\n\n\n\nLin, Yi-Lin, Pi-Chuan Chang, Ching Hsu, Miao-Zi Hung, Yin-Hsiu Chien, Wuh-Liang Hwu, FeiPei Lai, and Ni-Chung Lee. 2022. “[DeepVariant] Comparison of GATK and DeepVariant by Trio Sequencing.” Scientific Reports 12 (1): 1809. https://doi.org/10.1038/s41598-022-05833-4.\n\n\nPoplin, Ryan, Pi-Chuan Chang, David Alexander, Scott Schwartz, Thomas Colthurst, Alexander Ku, Dan Newburger, et al. 2018. “[DeepVariant] A Universal SNP and Small-Indel Variant Caller Using Deep Neural Networks.” Nature Biotechnology 36 (10): 983–87. https://doi.org/10.1038/nbt.4235.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Next-Generation Sequencing (NGS) and High-Fidelity Variant Calling</span>"
    ]
  },
  {
    "objectID": "ch02.html#the-gwas-paradigm",
    "href": "ch02.html#the-gwas-paradigm",
    "title": "2  Polygenic Risk Scores and GWAS Foundations",
    "section": "",
    "text": "2.1.1 Key Concepts\nEffect sizes and summary statistics: For each tested variant, GWAS produces summary statistics including:\n\nEffect size (β): The estimated change in phenotype per copy of the effect allele\nStandard error: Uncertainty in the effect estimate\nP-value: Statistical significance of the association\nAllele frequency: Population prevalence of the variant\n\nMost GWAS-identified variants have small individual effects—typically explaining less than 1% of phenotypic variance each—reflecting the highly polygenic nature of complex traits.\nLinkage disequilibrium (LD): Variants that are physically close on a chromosome tend to be inherited together, creating correlations in genotype data. This LD structure means that GWAS signals often implicate blocks of correlated variants rather than pinpointing causal variants directly. LD patterns vary substantially across populations due to different demographic histories, creating challenges for cross-ancestry analyses.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Polygenic Risk Scores and GWAS Foundations</span>"
    ]
  },
  {
    "objectID": "ch02.html#the-fine-mapping-challenge",
    "href": "ch02.html#the-fine-mapping-challenge",
    "title": "2  Polygenic Risk Scores and GWAS Foundations",
    "section": "2.2 The Fine-Mapping Challenge",
    "text": "2.2 The Fine-Mapping Challenge\nA central challenge in post-GWAS analysis is distinguishing causal variants from those merely correlated with causal variants through LD. Fine-mapping methods attempt to resolve this by computing posterior inclusion probabilities (PIPs) for each variant being causal.\nStatistical fine-mapping approaches like SuSiE identify credible sets of variants likely to contain the causal variant (Avsec et al. 2021). For 48 well-powered traits in the UK Biobank, genome-wide fine-mapping identified causal variants collectively explaining 17% of SNP-based heritability, though reaching 50% would require approximately 2 million samples on average (Wu et al. 2024).\nThe majority of GWAS-identified variants are spuriously correlated with the phenotype through LD rather than being truly causal. Fine-mapping—predicting which variants are causal—is crucial for downstream tasks including uncovering biological mechanisms and constructing robust polygenic risk scores (Rakowski and Lippert 2025).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Polygenic Risk Scores and GWAS Foundations</span>"
    ]
  },
  {
    "objectID": "ch02.html#constructing-polygenic-risk-scores",
    "href": "ch02.html#constructing-polygenic-risk-scores",
    "title": "2  Polygenic Risk Scores and GWAS Foundations",
    "section": "2.3 Constructing Polygenic Risk Scores",
    "text": "2.3 Constructing Polygenic Risk Scores\nPolygenic risk scores (PRS) aggregate the effects of many genetic variants into a single measure of an individual’s genetic predisposition to a trait or disease.\n\n2.3.1 Traditional PRS Methods\nClumping and thresholding (C+T): The simplest approach:\n\nSelect variants below a p-value threshold\n“Clump” correlated variants, keeping only the most significant per LD block\nSum effect sizes weighted by genotype dosage\n\nLDpred and Bayesian methods: More sophisticated approaches model the joint distribution of effect sizes while accounting for LD structure, typically improving prediction accuracy over C+T methods.\nLinear assumptions: Most PRS methods assume that variant effects:\n\nScale linearly with allele count (additive model)\nAre constant across individuals\nCombine additively across the genome\n\nWhile computationally convenient, these assumptions increase error, particularly for individuals from underrepresented populations (Georgantas, Kutalik, and Richiardi 2024).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Polygenic Risk Scores and GWAS Foundations</span>"
    ]
  },
  {
    "objectID": "ch02.html#heritability-and-its-partitioning",
    "href": "ch02.html#heritability-and-its-partitioning",
    "title": "2  Polygenic Risk Scores and GWAS Foundations",
    "section": "2.4 Heritability and Its Partitioning",
    "text": "2.4 Heritability and Its Partitioning\nSNP-based heritability (\\(h^2_{SNP}\\)) estimates the proportion of phenotypic variance explained by all measured common variants. This is typically lower than family-based heritability estimates, a phenomenon termed “missing heritability.”\nLD Score Regression (LDSR) enables partitioning of heritability using only GWAS summary statistics. By correlating test statistics with LD scores, LDSR can estimate:\n\nTotal SNP heritability\nHeritability enrichment in functional annotations\nGenetic correlations between traits\n\nAnalysis of UK Biobank GWAS revealed that heritability partitions distinctly across regulatory sequence classes, with tissue-specific enhancers explaining substantial heritability for relevant traits—for example, monocyte/macrophage enhancers for monocyte count, and brain enhancers for cognitive traits (zhou_sei_2022?).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Polygenic Risk Scores and GWAS Foundations</span>"
    ]
  },
  {
    "objectID": "ch02.html#limitations-of-current-approaches",
    "href": "ch02.html#limitations-of-current-approaches",
    "title": "2  Polygenic Risk Scores and GWAS Foundations",
    "section": "2.5 Limitations of Current Approaches",
    "text": "2.5 Limitations of Current Approaches\n\n2.5.1 Ancestry Bias\nThe vast majority of GWAS have been conducted in populations of European ancestry. This creates systematic problems:\n\nReduced prediction accuracy: PRS derived from European GWAS perform substantially worse in non-European populations due to differences in LD structure and allele frequencies\nHealth disparities: Clinical deployment of ancestry-biased PRS could exacerbate existing health inequities\nMissed variants: Causal variants common in non-European populations but rare in Europeans may be missed entirely\n\n\n\n2.5.2 Missing Heritability\nSNP-based heritability estimates typically capture only 20-50% of family-based heritability, attributed to:\n\nRare variants: GWAS are underpowered to detect rare variant associations\nStructural variants: Most arrays and imputation panels miss copy number variants and other structural variation\nGene-gene interactions (epistasis): Standard additive models ignore non-linear interactions\nGene-environment interactions: Effects that depend on environmental context\n\n\n\n2.5.3 Mechanistic Opacity\nGWAS associations rarely identify causal genes or mechanisms directly:\n\nMost significant variants lie in non-coding regions\nThe nearest gene is often not the causal gene\nRegulatory effects may act over large genomic distances",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Polygenic Risk Scores and GWAS Foundations</span>"
    ]
  },
  {
    "objectID": "ch02.html#the-promise-of-deep-learning",
    "href": "ch02.html#the-promise-of-deep-learning",
    "title": "2  Polygenic Risk Scores and GWAS Foundations",
    "section": "2.6 The Promise of Deep Learning",
    "text": "2.6 The Promise of Deep Learning\nThese limitations motivate the deep learning approaches covered in subsequent chapters. Sequence-based models can:\n\nPredict variant effects ab initio: Models like ExPecto and Enformer predict functional consequences from sequence alone, enabling prioritization of likely causal variants within LD blocks (zhou_expecto_2018?; Avsec et al. 2021)\nImprove fine-mapping: Functional predictions can be integrated with statistical fine-mapping to improve causal variant identification. Hybrid CNN-transformer models like Borzoi show superior performance in identifying causal SNPs within LD blocks (Manzo, Borkowski, and Ovcharenko 2025)\nEnable cross-ancestry transfer: By learning functional effects from sequence rather than population-specific LD patterns, sequence models may generalize better across ancestries. Variants prioritized by sequence-based models construct PRS that transfer better to non-European target populations (Rakowski and Lippert 2025)\nCapture non-linear effects: Deep learning architectures can model complex, non-linear relationships between genotype and phenotype. Methods like Delphi relax linear assumptions to produce more predictive PRS, with relative improvements of 11-35% in variance explained across traits (Georgantas, Kutalik, and Richiardi 2024)\nIncorporate rare variants: Approaches like DeepRVAT learn gene impairment scores from rare variant annotations, facilitating refinement of PRS by accounting for rare variant effects that standard GWAS miss.\n\nThe chapters that follow trace the development of these capabilities, from early CNN-based regulatory prediction through modern transformer architectures that integrate long-range genomic context.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025. “Comparative Analysis of Deep Learning Models for Predicting Causative Regulatory Variants.” bioRxiv: The Preprint Server for Biology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Polygenic Risk Scores and GWAS Foundations</span>"
    ]
  },
  {
    "objectID": "ch03.html#the-variant-prioritization-challenge",
    "href": "ch03.html#the-variant-prioritization-challenge",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "",
    "text": "Single-feature scores: Most methods exploit a single information type (e.g., conservation) and cannot integrate diverse signals\nRestricted scope: Many tools focus exclusively on missense variants or specific genomic contexts\nTraining set bias: Supervised methods trained on ClinVar or HGMD pathogenic variants inherit biases toward well-studied genes and variant types",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch03.html#the-evolutionary-proxy-training-strategy",
    "href": "ch03.html#the-evolutionary-proxy-training-strategy",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "3.2 The Evolutionary Proxy Training Strategy",
    "text": "3.2 The Evolutionary Proxy Training Strategy\nCADD’s innovation lies in its training data construction. Rather than relying on curated pathogenic/benign labels—which are sparse, biased, and incomplete—CADD exploits evolutionary history as a proxy for deleteriousness.\n\n3.2.1 Proxy-Neutral Variants\nThe proxy-neutral training set consists of approximately 15 million SNVs and 1.8 million indels that are:\n\nHuman-derived: Present in modern humans but absent in the inferred human-ape ancestor genome\nFixed or nearly fixed: Allele frequency of 95–100% in human populations\n\nThese variants have persisted through millions of years of purifying selection since the human-chimpanzee divergence. By virtue of reaching fixation, they are overwhelmingly neutral or at most weakly deleterious—strong deleterious effects would have been purged by natural selection.\n\n\n3.2.2 Proxy-Deleterious Variants\nThe proxy-deleterious set is generated through simulation, matching the sequence composition, substitution frequencies, and local mutation rate patterns of the proxy-neutral variants. These simulated “de novo” variants are free from selective pressure—they represent the full spectrum of possible mutations, including those that would be deleterious in a real genome.\nWhile many simulated variants are indeed neutral, an unknown but substantial fraction would be harmful if they occurred in an individual. The key insight is that the relative enrichment of deleterious variants differs systematically between the two sets: proxy-neutral variants are depleted for deleterious alleles, while proxy-deleterious variants contain a representative sample.\n\n\n3.2.3 Training Objective\nA machine learning classifier trained to distinguish proxy-neutral from proxy-deleterious variants effectively learns which annotation features characterize variants likely to be “observed” (survived selection) versus “simulated” (potentially deleterious). Higher CADD scores indicate variants more similar to the simulated set—and thus more likely to have functional consequences.\nThis approach provides several advantages over pathogenicity-based training:\n\n\n\nAspect\nCADD Approach\nPathogenicity Training\n\n\n\n\nTraining set size\n~30 million variants\nThousands of variants\n\n\nGenome coverage\nAll regions equally\nBiased toward coding\n\n\nGene bias\nMinimal\nConcentrated in disease genes\n\n\nVariant type bias\nMinimal\nBiased toward missense",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch03.html#integration-of-diverse-annotations",
    "href": "ch03.html#integration-of-diverse-annotations",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "3.3 Integration of Diverse Annotations",
    "text": "3.3 Integration of Diverse Annotations\nCADD’s strength derives from integrating more than 60 distinct genomic annotations into a unified framework. These annotations span multiple categories:\n\n3.3.1 Gene Model Annotations\nEnsembl Variant Effect Predictor (VEP) provides consequence predictions including:\n\nTranscript location (exon, intron, UTR, intergenic)\nProtein-coding effects (synonymous, missense, nonsense, frameshift)\nDistance to splice sites and transcript features\nAmino acid properties for missense variants\n\n\n\n3.3.2 Conservation and Constraint\nMultiple evolutionary conservation scores capture selective pressure across different timescales:\n\nPhyloP: Position-specific conservation across 46 vertebrate species\nPhastCons: Probability of negative selection estimated from multiple alignments\nGERP++: Rejected substitution scores indicating purifying selection\nGerpN/GerpS: Neutral evolution and constrained element scores\n\n\n\n3.3.3 Epigenetic and Regulatory Activity\nData from ENCODE and NIH Roadmap Epigenomics provide chromatin state information:\n\nDNase I hypersensitivity\nHistone modifications (H3K4me1, H3K4me3, H3K27ac, etc.)\nTranscription factor binding sites\nChromatin accessibility across cell types\n\n\n\n3.3.4 Additional Features\n\nCpG dinucleotide context and mutation rates\nSequence properties (GC content, repeat regions)\nPopulation genetics metrics (allele frequency distributions)\nProtein domain annotations",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch03.html#model-architecture-and-scoring",
    "href": "ch03.html#model-architecture-and-scoring",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "3.4 Model Architecture and Scoring",
    "text": "3.4 Model Architecture and Scoring\n\n3.4.1 Machine Learning Framework\nCADD v1.0 employed a support vector machine (SVM) with a linear kernel. Subsequent versions transitioned to logistic regression, which provides:\n\nFaster training and inference\nInterpretable feature weights\nEfficient handling of crossed features\n\nTo capture non-linear relationships between annotations, CADD creates crossed feature annotations—for example, combining conservation scores with consequence labels to allow the model to weight conservation differently for missense versus synonymous variants.\n\n\n3.4.2 PHRED-Scaled Scores\nRaw CADD scores are difficult to interpret across genomic contexts. To enable meaningful comparisons, CADD transforms raw scores into PHRED-like scaled scores based on genome-wide rank:\n\\[\\text{CADD}_\\text{PHRED} = -10 \\cdot \\log_{10}\\left(\\frac{\\text{rank}}{N}\\right)\\]\nwhere \\(N\\) ≈ 9 billion represents all possible single nucleotide substitutions in the reference genome. A CADD score of 10 indicates the variant is in the top 10% most deleterious; a score of 20 indicates the top 1%; a score of 30 indicates the top 0.1%.\nThis scaling provides intuitive interpretation: CADD 15–20 typically indicates likely functional variants, while CADD &gt; 30 suggests strong deleteriousness.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch03.html#cadd-v1.7-integration-of-deep-learning-predictions",
    "href": "ch03.html#cadd-v1.7-integration-of-deep-learning-predictions",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "3.5 CADD v1.7: Integration of Deep Learning Predictions",
    "text": "3.5 CADD v1.7: Integration of Deep Learning Predictions\nThe most recent CADD release (v1.7) demonstrates how the annotation integration framework can incorporate predictions from deep learning models (Schubach et al. 2024). This represents a bridge between traditional annotation-based approaches and the sequence-to-function models covered in subsequent chapters.\n\n3.5.1 Protein Language Model Features\nCADD v1.7 incorporates scores from Meta ESM-1v, a protein language model trained on millions of protein sequences. ESM-1v provides:\n\nPer-residue fitness predictions based on evolutionary plausibility\nImproved missense variant prioritization\nContext-aware amino acid substitution scoring\n\nThese features substantially improve CADD’s performance on coding variants, particularly for missense mutations in conserved protein regions.\n\n\n3.5.2 Regulatory CNN Predictions\nFor non-coding variants, CADD v1.7 integrates predictions from a custom convolutional neural network trained on regions of open chromatin. This model:\n\nPredicts regulatory activity from DNA sequence\nProvides variant effect scores for regulatory elements\nCaptures sequence patterns associated with transcription factor binding\n\n\n\n3.5.3 Extended Conservation Scores\nThe Zoonomia project’s alignment of &gt;240 mammalian genomes provides deeper evolutionary context through:\n\nBroader phylogenetic sampling\nImproved resolution of constrained elements\nBetter detection of lineage-specific selection\n\n\n\n3.5.4 Performance Improvements\nEvaluation on multiple benchmarks demonstrates consistent gains:\n\n\n\nBenchmark\nCADD v1.6\nCADD v1.7\nImprovement\n\n\n\n\nClinVar pathogenic vs. common\n0.94\n0.95\n+1%\n\n\nDeep mutational scanning (31 datasets)\n0.78\n0.81\n+3%\n\n\nRegulatory saturation mutagenesis\n0.68\n0.72\n+4%\n\n\n\nThe regulatory variant improvements are particularly notable, as this has historically been CADD’s weakest domain.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch03.html#benchmarking-against-alternative-approaches",
    "href": "ch03.html#benchmarking-against-alternative-approaches",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "3.6 Benchmarking Against Alternative Approaches",
    "text": "3.6 Benchmarking Against Alternative Approaches\nCADD’s genome-wide applicability allows direct comparison with specialized scores:\n\n3.6.1 Coding Variants\nFor missense variant classification separating ClinVar pathogenic from high-frequency ExAC variants, CADD performs comparably to dedicated tools like PolyPhen-2 and PROVEAN while maintaining broader applicability. The integration of ESM-1v features in v1.7 further improves coding variant prediction.\n\n\n3.6.2 Non-coding Variants\nCADD demonstrates strong performance on regulatory variants, though recent benchmarks suggest functional-genomics-supervised models like Enformer and Borzoi may perform better for certain variant classes. Interestingly, alignment-based models including CADD and GPN-MSA compare favorably for Mendelian and complex disease traits, while expression-predicting models excel for complex non-disease traits (Benegas, Eraslan, and Song 2025).\n\n\n3.6.3 Population Frequency Correlation\nA key validation of CADD’s evolutionary proxy approach is the strong inverse correlation between CADD scores and population allele frequency. Higher-scoring variants are systematically rarer in population databases like gnomAD, consistent with purifying selection removing deleterious alleles—the same principle underlying the training strategy.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch03.html#significance-for-genomic-deep-learning",
    "href": "ch03.html#significance-for-genomic-deep-learning",
    "title": "3  Establishing Genome-Wide Deleteriousness Scores (CADD)",
    "section": "3.7 Significance for Genomic Deep Learning",
    "text": "3.7 Significance for Genomic Deep Learning\nCADD established several important paradigms that inform the deep learning approaches covered in subsequent chapters:\n\nAnnotation integration: The principle of combining multiple information sources into unified predictions extends naturally to multi-headed neural network architectures that jointly predict diverse genomic features.\nEvolutionary training signals: Using evolutionary conservation as a proxy for function—rather than curated pathogenicity labels—avoids biases and provides genome-wide coverage. This approach reappears in protein language models and genomic foundation models.\nGenome-wide applicability: CADD demonstrated that a single framework could score any variant anywhere in the genome, setting expectations for the comprehensive coverage that sequence-to-function models now achieve.\nContinuous improvement through feature addition: The progression from CADD v1.0 to v1.7 shows how deep learning predictions can be incorporated as features into existing frameworks, providing a practical integration path.\n\nThe chapters that follow trace how deep learning models moved from providing features to CADD-like integrators toward directly predicting variant effects from DNA sequence—learning the regulatory grammar that explains why evolutionary conservation patterns emerge.\n\n\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Establishing Genome-Wide Deleteriousness Scores (CADD)</span>"
    ]
  },
  {
    "objectID": "ch04.html#the-encode-project",
    "href": "ch04.html#the-encode-project",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.2 The ENCODE Project",
    "text": "4.2 The ENCODE Project\nThe Encyclopedia of DNA Elements (ENCODE) project, launched in 2003, aimed to identify all functional elements in the human genome. Through three phases of increasingly comprehensive profiling, ENCODE has produced:\n\nPhase 1 (2003–2007): Pilot project covering 1% of the genome across multiple cell types\nPhase 2 (2007–2012): Genome-wide coverage across 147 cell types\nPhase 3 (2012–present): Expanded cell type coverage, mouse genome integration, and improved assay resolution\n\nThe most recent ENCODE release provides an integrated encyclopedia of DNA elements across human and mouse genomes, including chromatin accessibility, histone modifications, transcription factor binding, and gene expression across hundreds of biosamples (encode_project_consortium_expanded_2020?).\n\n4.2.1 Key ENCODE Data Types\n\n\n\n\n\n\n\n\n\nAssay\nTarget\nResolution\nTypical Coverage\n\n\n\n\nDNase-seq\nOpen chromatin\n~50 bp\n684 human datasets\n\n\nChIP-seq (TF)\nTF binding sites\n~100–200 bp\n2,131 human datasets\n\n\nChIP-seq (histone)\nHistone modifications\n~200 bp\n1,860 human datasets\n\n\nCAGE\nTranscription start sites\nSingle nucleotide\n638 human datasets",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#the-roadmap-epigenomics-project",
    "href": "ch04.html#the-roadmap-epigenomics-project",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.3 The Roadmap Epigenomics Project",
    "text": "4.3 The Roadmap Epigenomics Project\nComplementing ENCODE, the NIH Roadmap Epigenomics Mapping Consortium focused on systematically mapping epigenomic landscapes across primary human tissues and cell types. The project produced reference epigenomes for 111 primary human tissues and cell types, with comprehensive profiling of:\n\nHistone modifications (H3K4me1, H3K4me3, H3K27ac, H3K27me3, H3K36me3, H3K9me3)\nDNA methylation\nRNA expression\nChromatin accessibility\n\nRoadmap Epigenomics data are particularly valuable because they include primary tissues—not just immortalized cell lines—providing more physiologically relevant regulatory maps (kundaje_integrative_2015?).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#histone-modifications-as-regulatory-signatures",
    "href": "ch04.html#histone-modifications-as-regulatory-signatures",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.4 Histone Modifications as Regulatory Signatures",
    "text": "4.4 Histone Modifications as Regulatory Signatures\nHistones are proteins around which DNA wraps to form nucleosomes. Chemical modifications to histone tails serve as signals that influence chromatin structure and gene regulation. Different modifications mark distinct functional states:\n\n4.4.1 Active Marks\nH3K4me3 (trimethylation of histone H3 lysine 4): The hallmark of active promoters. Found at transcription start sites of actively transcribed genes across virtually all cell types. The Sei framework identifies a distinct “P” (promoter) sequence class enriched in H3K4me3 across all cell types examined (zhou_sei_2022?).\nH3K4me1 (monomethylation of H3K4): Marks enhancers. Present at both active and poised enhancers, H3K4me1 alone indicates enhancer potential without necessarily reflecting current activity.\nH3K27ac (acetylation of H3K27): Distinguishes active from poised enhancers. The combination of H3K4me1 and H3K27ac marks actively engaged enhancers driving gene expression in the current cellular state.\nH3K36me3 (trimethylation of H3K36): Associated with transcriptional elongation. Found in gene bodies of actively transcribed genes, marking regions where RNA polymerase II is productively elongating.\n\n\n4.4.2 Repressive Marks\nH3K27me3 (trimethylation of H3K27): Deposited by Polycomb repressive complex 2 (PRC2). Marks facultatively repressed genes—those silenced in particular cell types but potentially active in others. Tissue-specific enhancers often display H3K27me3 in cell types where they are inactive.\nH3K9me3 (trimethylation of H3K9): Associated with constitutive heterochromatin. Marks permanently silenced regions including centromeres, telomeres, and repetitive elements.\n\n\n4.4.3 Combinatorial Patterns\nRegulatory elements are characterized by combinations of marks rather than individual modifications:\n\n\n\n\n\n\n\n\nElement Type\nKey Marks\nFunction\n\n\n\n\nActive promoter\nH3K4me3, H3K27ac\nTranscription initiation\n\n\nActive enhancer\nH3K4me1, H3K27ac\nDistal gene activation\n\n\nPoised enhancer\nH3K4me1, H3K27me3\nDevelopmentally regulated\n\n\nBivalent domain\nH3K4me3, H3K27me3\nPluripotency, developmental genes\n\n\nHeterochromatin\nH3K9me3\nConstitutive silencing\n\n\n\nThe Sei model captures these patterns through sequence class definitions: enhancer classes (E1–E12) show tissue-specific enrichment in H3K4me1 and H3K27ac, with repressive H3K27me3 appearing in inactive cell types. Polycomb classes (PC1–PC4) are enriched in H3K27me3, while heterochromatin classes (HET1–HET6) are marked by H3K9me3 (zhou_sei_2022?).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#transcription-factor-binding-sites",
    "href": "ch04.html#transcription-factor-binding-sites",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.5 Transcription Factor Binding Sites",
    "text": "4.5 Transcription Factor Binding Sites\nTranscription factors (TFs) are proteins that bind specific DNA sequences to activate or repress gene expression. ChIP-seq (chromatin immunoprecipitation followed by sequencing) identifies genome-wide binding locations for individual TFs.\n\n4.5.1 Scale of TF Profiling\nThe Cistrome Project systematically processes publicly available ChIP-seq data, contributing nearly 20,000 TF binding profiles to current databases. Combined with ENCODE, these resources provide:\n\nBinding sites for ~1,000 distinct DNA-binding proteins\nCoverage across &gt;1,300 cell lines and tissues\nBoth sequence-specific TFs (e.g., CTCF, p53) and general cofactors\n\n\n\n4.5.2 Cell Type-Specific Binding\nTF binding is highly cell type-specific. The same TF can occupy different genomic locations in different cell types, driven by:\n\nCell type-specific chromatin accessibility\nCooperative binding with cell type-specific partner TFs\nCompetition with other factors for overlapping sites\n\nFor example, the Sei framework identifies TF-specific sequence classes: FOXA1 binding sequences (TF3) are enriched in prostate and liver cells, while PU.1/SPI1 binding (E7) marks monocyte and macrophage enhancers (zhou_sei_2022?).\n\n\n4.5.3 CTCF and Chromatin Architecture\nCTCF (CCCTC-binding factor) plays a special role in genome organization. Unlike most TFs, CTCF binds at relatively consistent locations across cell types and functions primarily as an architectural protein:\n\nDemarcates topologically associating domains (TADs)\nBlocks enhancer-promoter communication across boundaries\nRecruits cohesin complex for chromatin looping\n\nSequence models like Enformer learn CTCF’s role in limiting information flow between genomic compartments, using CTCF motifs at TAD boundaries when making expression predictions (Avsec et al. 2021).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#dna-accessibility",
    "href": "ch04.html#dna-accessibility",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.6 DNA Accessibility",
    "text": "4.6 DNA Accessibility\nDNA accessibility assays identify regions where chromatin is “open”—depleted of nucleosomes and accessible to DNA-binding proteins. These regions correspond to active regulatory elements.\n\n4.6.1 DNase-seq\nDNase I hypersensitive sites (DHSs) mark regions of open chromatin. The enzyme DNase I preferentially cleaves accessible DNA, and sequencing the cleavage products maps accessible regions genome-wide.\nThe DNase hypersensitive site vocabulary defined by Meuleman et al. provides a comprehensive catalog of regulatory elements indexed by cell type specificity. This resource is frequently used to annotate sequence model predictions and validate learned regulatory patterns.\n\n\n4.6.2 ATAC-seq\nAssay for Transposase-Accessible Chromatin (ATAC-seq) provides similar information to DNase-seq with simpler experimental protocols. A hyperactive transposase inserts sequencing adapters preferentially into accessible regions.\nModern sequence-to-function models typically train on both DNase-seq and ATAC-seq datasets. Enformer, for example, includes 684 DNase-seq and ATAC-seq tracks among its 5,313 human genomic targets (Avsec et al. 2021).\n\n\n4.6.3 Accessibility and Regulatory Grammar\nDNA accessibility is both a cause and consequence of TF binding:\n\nPioneer factors can bind nucleosomal DNA and establish accessibility\nEstablished accessible regions permit binding by non-pioneer TFs\nSustained TF binding maintains accessibility\n\nThis creates a chicken-and-egg relationship that sequence models must implicitly resolve: they must predict which sequences will be accessible (and therefore functional) without knowing which TFs are expressed in a given cell type.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#expression-data-cage-and-rna-seq",
    "href": "ch04.html#expression-data-cage-and-rna-seq",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.7 Expression Data: CAGE and RNA-seq",
    "text": "4.7 Expression Data: CAGE and RNA-seq\nWhile chromatin marks and TF binding indicate regulatory potential, expression data provides ground truth for regulatory activity.\n\n4.7.1 CAGE (Cap Analysis of Gene Expression)\nCAGE sequences the 5’ ends of capped transcripts, precisely mapping transcription start sites (TSSs) at single-nucleotide resolution. The FANTOM consortium’s CAGE atlas provides promoter-level expression across hundreds of human and mouse samples.\nCAGE data serve as direct training targets for expression-predicting models. Enformer predicts 638 CAGE tracks, allowing evaluation of predicted transcription start site activity across diverse cell types (Avsec et al. 2021).\n\n\n4.7.2 RNA-seq\nRNA sequencing quantifies transcript abundance genome-wide. GTEx (Genotype-Tissue Expression) provides RNA-seq across 54 human tissues, enabling:\n\nValidation of expression predictions against tissue-specific profiles\neQTL discovery linking genetic variants to expression changes\nCross-tissue comparisons of regulatory variant effects\n\nBorzoi extends beyond CAGE to predict full RNA-seq coverage, capturing not just transcription initiation but also splicing and polyadenylation patterns.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#from-data-to-training-targets",
    "href": "ch04.html#from-data-to-training-targets",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.8 From Data to Training Targets",
    "text": "4.8 From Data to Training Targets\n\n4.8.1 The Supervised Learning Framework\nThe functional genomics data described above enable a supervised learning approach to regulatory sequence modeling:\n\nInput: DNA sequence (typically one-hot encoded)\nOutput: Predicted probability or quantitative level for each chromatin profile\nTraining: Minimize prediction error against experimentally measured profiles\n\nThis framework transforms the biological question “what determines regulatory activity?” into a machine learning problem: learn a function \\(f: \\text{sequence} \\rightarrow \\text{chromatin profiles}\\).\n\n\n4.8.2 Scale of Modern Training Sets\nThe scale of available training data has grown dramatically:\n\n\n\nModel\nYear\nChromatin Targets\nCell Types\n\n\n\n\nDeepSEA\n2015\n919\n~125\n\n\nExPecto\n2018\n2,002\n&gt;200\n\n\nSei\n2022\n21,907\n&gt;1,300\n\n\nEnformer\n2021\n5,313\n~400\n\n\n\nThe Sei model predicts 21,907 chromatin profiles—9,471 TF binding, 10,064 histone modification, and 2,372 chromatin accessibility profiles—representing the broadest coverage to date (zhou_sei_2022?).\n\n\n4.8.3 From Profiles to Sequence Classes\nRaw chromatin profiles are numerous and partially redundant. The Sei framework introduces “sequence classes” that summarize regulatory activities across all predicted profiles:\n\n40 sequence classes covering &gt;97.4% of the genome\nCategories include: Promoter (P), Enhancer (E1–E12), CTCF, Polycomb (PC), Heterochromatin (HET), Transcription (TN)\nEach class defined by characteristic histone mark and TF enrichment patterns\n\nThis vocabulary enables interpretable summarization of sequence regulatory activities and variant effects.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#data-quality-and-limitations",
    "href": "ch04.html#data-quality-and-limitations",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.9 Data Quality and Limitations",
    "text": "4.9 Data Quality and Limitations\n\n4.9.1 Technical Considerations\nFunctional genomics data contain technical artifacts that affect model training:\n\nBatch effects: Systematic differences between experiments\nAntibody specificity: ChIP-seq quality depends on antibody performance\nPeak calling thresholds: Binary peak calls from continuous signals involve arbitrary cutoffs\nCell line artifacts: Immortalized lines may not reflect primary tissue biology\n\n\n\n4.9.2 Biological Limitations\n\nMissing cell types: Many disease-relevant cell types lack comprehensive profiling\nSteady-state measurements: Most data capture equilibrium states, missing dynamic responses\nContext dependence: Regulatory activity depends on cellular context not captured by sequence alone\n\n\n\n4.9.3 Implications for Model Development\nThese limitations shape how sequence models are trained and evaluated:\n\nModels typically predict binary peak calls rather than quantitative signal levels\nCross-cell-type generalization remains challenging\nValidation requires orthogonal experimental approaches (e.g., MPRA, CRISPR screens)",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#setting-the-stage-for-deep-learning",
    "href": "ch04.html#setting-the-stage-for-deep-learning",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.10 Setting the Stage for Deep Learning",
    "text": "4.10 Setting the Stage for Deep Learning\nThe data resources described in this chapter—ENCODE, Roadmap Epigenomics, Cistrome, GTEx, and FANTOM—provide the foundation for the sequence-to-function deep learning models covered in Part II. Key enabling factors include:\n\nScale: Thousands of genome-wide profiles provide sufficient training data for deep networks\nDiversity: Multiple cell types enable learning of cell type-specific regulatory patterns\nResolution: Base-pair resolution profiles allow single-nucleotide effect predictions\nStandardization: Consistent processing enables cross-study integration\n\nThe chapters that follow trace how deep convolutional networks first learned to predict these chromatin profiles from sequence (DeepSEA, Chapter 5), then connected chromatin predictions to gene expression (ExPecto, Chapter 6), and eventually integrated long-range regulatory interactions through attention mechanisms (Enformer, Chapter 11).\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#chromatin-profiling-encode-and-roadmap-epigenomics",
    "href": "ch04.html#chromatin-profiling-encode-and-roadmap-epigenomics",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.2 Chromatin Profiling: ENCODE and Roadmap Epigenomics",
    "text": "4.2 Chromatin Profiling: ENCODE and Roadmap Epigenomics\nThe ENCODE (Encyclopedia of DNA Elements) and Roadmap Epigenomics consortia generated genome-wide profiles of regulatory activity across hundreds of cell types, providing both biological insight and training data for sequence-to-function models.\n\n4.2.1 Data Types and Scale\n\n\n\n\n\n\n\n\n\nAssay\nTarget\nENCODE Coverage\nRoadmap Coverage\n\n\n\n\nDNase-seq / ATAC-seq\nOpen chromatin\n684 datasets\n53 samples\n\n\nChIP-seq (TF)\nTranscription factor binding\n2,131 datasets\n—\n\n\nChIP-seq (histone)\nHistone modifications\n1,860 datasets\n127 samples\n\n\nCAGE\nTranscription start sites\n638 datasets\n—\n\n\n\nThe Cistrome Project systematically reprocesses public ChIP-seq data, contributing ~20,000 profiles that supplement ENCODE (zheng_cistrome_2019?). Combined, these resources enable models like Sei to predict 21,907 chromatin targets across &gt;1,300 cell types (zhou_sei_2022?).\n\n\n4.2.2 Key Histone Modifications\nHistone modifications mark distinct regulatory states:\n\nH3K4me3: Active promoters\nH3K4me1 + H3K27ac: Active enhancers\nH3K4me1 + H3K27me3: Poised/bivalent enhancers\nH3K27me3: Polycomb-repressed regions\nH3K9me3: Constitutive heterochromatin\n\nThese combinatorial patterns define the training targets for models including DeepSEA, ExPecto, and Enformer (Chapters 5, 6, and 11).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#population-genetics-resources",
    "href": "ch04.html#population-genetics-resources",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.3 Population Genetics Resources",
    "text": "4.3 Population Genetics Resources\n\n4.3.1 gnomAD\nThe Genome Aggregation Database (gnomAD) aggregates exome and genome sequencing data from large-scale projects, providing allele frequencies and constraint metrics essential for variant interpretation.\nCurrent scale: gnomAD v4 includes &gt;800,000 exomes and &gt;76,000 genomes spanning diverse global populations.\nKey applications for deep learning:\n\nAllele frequency filtering: Rare variants (AF &lt; 0.01%) are enriched for functional effects; common variants have largely survived purifying selection\nConstraint metrics: pLI (probability of loss-of-function intolerance) and LOEUF (loss-of-function observed/expected upper bound fraction) quantify selective pressure on genes\nTraining signal: CADD’s evolutionary proxy approach uses allele frequency distributions to validate that predicted deleterious variants are depleted from the population (rentzsch_cadd_2019?)\n\n\n\n4.3.2 1000 Genomes Project\nThe 1000 Genomes Project catalogued genetic variation across 26 populations, providing:\n\nReference panel for genotype imputation\nLD structure for fine-mapping and PRS construction\nBenchmarking variants for sequence models (e.g., Sei variant effect analyses use 1000 Genomes SNPs) (zhou_sei_2022?)",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#clinical-variant-databases",
    "href": "ch04.html#clinical-variant-databases",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.4 Clinical Variant Databases",
    "text": "4.4 Clinical Variant Databases\n\n4.4.1 ClinVar\nClinVar is the primary public archive for clinically interpreted genetic variants, aggregating submissions from clinical laboratories, research groups, and expert panels.\nContent: &gt;2.5 million variant submissions covering pathogenic, likely pathogenic, benign, likely benign, and variants of uncertain significance (VUS).\nRole in model development:\n\nBenchmarking: ClinVar pathogenic/benign classifications provide standard evaluation sets for variant effect predictors. CADD v1.7 reports ~1% improvement on ClinVar variants compared to previous versions (Schubach et al. 2024).\nTraining labels: Some supervised approaches use ClinVar annotations as training targets, though this risks circularity if evaluated on the same database.\n\nLimitations: Ascertainment bias toward well-studied genes; classification criteria vary across submitters; benign variants are underrepresented relative to pathogenic.\n\n\n4.4.2 HGMD\nThe Human Gene Mutation Database provides curated disease-causing mutations, though access requires subscription. HGMD’s “regulatory” category has been used to benchmark non-coding variant effect predictions (zhou_sei_2022?).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#expression-resources",
    "href": "ch04.html#expression-resources",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.5 Expression Resources",
    "text": "4.5 Expression Resources\n\n4.5.1 GTEx\nThe Genotype-Tissue Expression (GTEx) project provides RNA-seq expression profiles and eQTL maps across 54 human tissues from ~1,000 donors.\nKey applications:\n\neQTL validation: Signed linkage disequilibrium profile (SLDP) regression tests whether model-predicted variant effects correlate with measured expression changes. Enformer showed improved SLDP Z-scores relative to Basenji2 across GTEx tissues (Avsec et al. 2021).\nTissue-specific expression: Enhancer sequence class scores correlate with tissue-specific gene expression in corresponding tissues (zhou_sei_2022?).\nCross-ancestry analysis: GTEx’s population diversity enables evaluation of model generalization.\n\n\n\n4.5.2 FANTOM\nThe FANTOM consortium’s CAGE atlas maps transcription start sites at single-nucleotide resolution across hundreds of human and mouse samples. CAGE data serve as direct training targets for expression-predicting models—Enformer predicts 638 CAGE tracks, enabling TSS-level activity predictions (Avsec et al. 2021).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#biobank-resources",
    "href": "ch04.html#biobank-resources",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.6 Biobank Resources",
    "text": "4.6 Biobank Resources\nLarge-scale biobanks linking genomic data to electronic health records and phenotypic measurements are transforming genetic research. These resources enable GWAS discovery, PRS development, and validation of variant effect predictions at population scale.\n\n4.6.1 UK Biobank\nThe UK Biobank enrolled ~500,000 participants aged 40–69 from across the United Kingdom, with comprehensive phenotyping and genomic data.\nData available:\n\nGenotyping array data (all participants)\nWhole exome sequencing (~470,000 participants)\nWhole genome sequencing (~500,000 participants)\nElectronic health records, imaging, and extensive phenotypic measurements\n\nApplications: UK Biobank GWAS summary statistics are used for heritability partitioning by sequence classes, revealing trait-specific regulatory architectures (zhou_sei_2022?). Genome-wide fine-mapping of 48 UK Biobank traits identified causal variants explaining 17% of SNP-based heritability (Wu et al. 2024).\n\n\n4.6.2 All of Us Research Program\nThe NIH All of Us Research Program aims to enroll one million diverse US participants, with explicit emphasis on historically underrepresented populations.\nCurrent scale: &gt;245,000 whole genome sequences, with ~45% from participants identifying with underrepresented racial or ethnic groups. The dataset includes &gt;1 billion genetic variants, including &gt;275 million previously unreported variants.\nUnique features:\n\nDiversity: 77% of participants are from communities historically underrepresented in biomedical research\nLongitudinal EHR: Linked electronic health records with median 10+ years of data for many participants\nMulti-modal data: Surveys, physical measurements, Fitbit wearable data, and genomics\nRapid access: Researcher Workbench enables data access with median 29 hours from registration\n\nAll of Us addresses a critical gap: over 90% of participants in prior large genomics studies were of European descent, limiting generalizability of findings and perpetuating health disparities.\n\n\n4.6.3 Mayo Clinic Tapestry\nThe Tapestry study represents Mayo Clinic’s largest genomics initiative, combining clinical exome sequencing with longitudinal EHR linkage.\nScale: &gt;98,000 enrolled participants with Exome+ sequencing (whole exome plus ~300,000 informative non-coding SNPs).\nClinical integration: Unlike research-only biobanks, Tapestry returns actionable results directly to participants and their providers:\n\n1.9% of participants carry pathogenic/likely pathogenic variants in CDC Tier 1 genes\nResults for BRCA1/2 (hereditary breast/ovarian cancer), Lynch syndrome genes, and familial hypercholesterolemia genes are entered into EHRs\n\nResearch access: &gt;62,000 participants’ exome data are available for research, with 82 approved investigator requests delivering &gt;1.1 million datasets.\n\n\n4.6.4 Comparative Summary\n\n\n\nBiobank\nParticipants\nSequencing\nDiversity\nEHR Linked\n\n\n\n\nUK Biobank\n~500,000\nWGS + WES\nPrimarily European\nYes\n\n\nAll of Us\n&gt;245,000 WGS\nWGS\n45% underrepresented\nYes\n\n\nMayo Tapestry\n~98,000\nExome+\n~11% underrepresented\nYes",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#experimental-benchmarks",
    "href": "ch04.html#experimental-benchmarks",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.7 Experimental Benchmarks",
    "text": "4.7 Experimental Benchmarks\n\n4.7.1 Deep Mutational Scanning\nDeep mutational scanning (DMS) experiments systematically measure the functional effects of thousands of variants in a single assay, providing gold-standard labels for benchmarking variant effect predictors.\nProteinGym: A comprehensive benchmark aggregating DMS data across 217 assays covering diverse proteins. CADD v1.7 reports ~3% improvement on DMS datasets with integration of ESM-1v protein language model scores (Schubach et al. 2024).\nMaveDB: The Multiplexed Assays of Variant Effect Database archives functional scores from MAVE experiments, enabling standardized model evaluation.\nCAGI: The Critical Assessment of Genome Interpretation organizes blinded prediction challenges using experimental data, including saturation mutagenesis of regulatory elements.\n\n\n4.7.2 TraitGym\nTraitGym provides curated regulatory variant benchmarks for evaluating causal variant prediction across Mendelian and complex traits (Benegas, Eraslan, and Song 2025).\nDataset composition:\n\n113 Mendelian traits with known or high-confidence causal regulatory variants\n83 complex traits with fine-mapped candidate causal variants\nCarefully constructed control variants matched for genomic context\n\nKey findings: Alignment-based models (CADD, GPN-MSA) perform favorably for Mendelian and complex disease traits, while functional-genomics-supervised models (Enformer, Borzoi) excel for complex non-disease traits. This suggests complementary information captured by evolutionary constraint versus molecular phenotype prediction.\nTraitGym addresses a critical gap: the field has lacked consistently curated datasets with accurate labels for non-coding variants, making comprehensive benchmarking difficult.\n\n\n4.7.3 Massively Parallel Reporter Assays\nMPRAs test thousands of regulatory sequences in parallel, measuring their ability to drive reporter gene expression. MPRA data from saturation mutagenesis experiments serve as benchmarks for regulatory variant effect prediction—CADD v1.7 shows ~4% improvement on regulatory saturation mutagenesis data (Schubach et al. 2024).",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#data-quality-considerations",
    "href": "ch04.html#data-quality-considerations",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.8 Data Quality Considerations",
    "text": "4.8 Data Quality Considerations\n\n4.8.1 Technical Artifacts\nFunctional genomics data contain systematic biases affecting model training:\n\nBatch effects: Technical variation between experiments\nAntibody specificity: ChIP-seq quality depends on antibody performance\nPeak calling thresholds: Binary calls from continuous signals involve arbitrary cutoffs\nCell line artifacts: Immortalized lines may not reflect primary tissue biology\n\n\n\n4.8.2 Ascertainment Bias\nClinical databases and biobanks exhibit ascertainment biases:\n\nClinVar is enriched for variants in well-studied disease genes\nBiobanks may oversample certain demographics or health-seeking populations\nBenign variants are systematically underrepresented in clinical databases\n\n\n\n4.8.3 Population Structure\nAncestry-specific allele frequencies and LD patterns affect model generalization:\n\nPRS developed in European populations transfer poorly to other ancestries\nRare variant interpretation depends on population-matched frequency data\nInitiatives like All of Us explicitly address historical underrepresentation",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch04.html#from-data-to-models",
    "href": "ch04.html#from-data-to-models",
    "title": "4  Foundational Functional Genomics Data",
    "section": "4.9 From Data to Models",
    "text": "4.9 From Data to Models\nThe resources described in this chapter enable the supervised learning framework underlying sequence-to-function models:\n\nChromatin profiles (ENCODE, Roadmap) → Training targets for predicting regulatory activity from sequence\nPopulation genetics (gnomAD, 1000 Genomes) → Evolutionary signal for constraint-based scoring\nClinical databases (ClinVar) → Benchmarking pathogenic variant detection\nExpression data (GTEx, FANTOM) → Validation of predicted expression effects\nBiobanks (UK Biobank, All of Us, Tapestry) → GWAS discovery and phenotype prediction\nExperimental benchmarks (DMS, TraitGym, MPRA) → Ground-truth functional measurements\n\nThe chapters that follow trace how deep learning models leverage these resources: CNNs learning to predict chromatin profiles (DeepSEA, Chapter 5), connecting predictions to expression (ExPecto, Chapter 6), and integrating long-range interactions (Enformer, Chapter 11).\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.",
    "crumbs": [
      "Part I: Foundations of Genomic Data and Pre-DL Interpretation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundational Functional Genomics Data</span>"
    ]
  },
  {
    "objectID": "ch05.html#the-core-innovation-learning-regulatory-code-from-sequence",
    "href": "ch05.html#the-core-innovation-learning-regulatory-code-from-sequence",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "5.2 The Core Innovation: Learning Regulatory Code from Sequence",
    "text": "5.2 The Core Innovation: Learning Regulatory Code from Sequence\nDeepSEA’s central insight was that deep convolutional networks could learn the sequence patterns underlying regulatory activity without explicit feature engineering. Previous methods like gapped k-mer SVMs (gkm-SVM) required defining sequence features a priori—specifying which k-mers to count and how to weight them. DeepSEA instead learned relevant sequence features automatically from data.\n\n5.2.1 Architecture\nThe original DeepSEA architecture comprised:\n\nInput layer: 1000 bp DNA sequence, one-hot encoded (4 channels × 1000 positions)\nThree convolutional layers: Each followed by ReLU activation and max pooling, learning increasingly abstract sequence features\nFully connected layer: Integrating learned features across the sequence\nOutput layer: 919 sigmoid outputs predicting chromatin profile probabilities\n\nThe convolutional layers function analogously to motif scanners, but with crucial differences: they learn motifs from data rather than requiring predefined position weight matrices, and deeper layers can learn combinations of motifs (regulatory “grammar”) rather than just individual binding sites.\n\n\n5.2.2 Training Data\nDeepSEA was trained on 919 chromatin profiles from ENCODE and Roadmap Epigenomics:\n\n\n\nProfile Type\nCount\nExamples\n\n\n\n\nTranscription factor binding\n690\nCTCF, p53, GATA1\n\n\nHistone modifications\n104\nH3K4me3, H3K27ac\n\n\nDNase I hypersensitivity\n125\nOpen chromatin across cell types\n\n\n\nFor each 1000 bp sequence, the model predicts the probability that the central 200 bp region exhibits each chromatin feature. Training used sequences from the human genome with chromosome 8 held out for testing.\n\n\n5.2.3 Multi-Task Learning\nA key architectural decision was predicting all 919 features simultaneously rather than training separate models. This multi-task learning approach offers several advantages:\n\nShared representations: Early convolutional layers learn general sequence features (e.g., GC content, common motifs) useful across tasks\nRegularization: Jointly predicting correlated features prevents overfitting to any single task\nEfficiency: One model serves all prediction tasks",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch05.html#predicting-variant-effects",
    "href": "ch05.html#predicting-variant-effects",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "5.3 Predicting Variant Effects",
    "text": "5.3 Predicting Variant Effects\nDeepSEA enables variant effect prediction through a straightforward procedure: predict chromatin profiles for both reference and alternative allele sequences, then compute the difference. This produces a 919-dimensional vector describing how the variant is predicted to alter regulatory activity across all profiled features.\n\n5.3.1 Single-Nucleotide Sensitivity\nThe model achieves single-nucleotide sensitivity—changing one base can substantially alter predictions. This was validated using allelic imbalance data from digital genomic footprinting. For 57,407 variants showing allele-specific DNase I sensitivity across 35 cell types, DeepSEA predictions correlated strongly with the experimentally observed allelic bias.\n\n\n5.3.2 In Silico Saturation Mutagenesis\nBy systematically predicting effects of all possible single-nucleotide substitutions within a sequence, DeepSEA enables “in silico saturation mutagenesis” (ISM). This computational experiment reveals which positions are most critical for regulatory function—equivalent to a CRISPR tiling screen, but performed entirely computationally.\nISM analysis of regulatory elements reveals sequence positions where mutations would most strongly perturb function, often corresponding to transcription factor binding motifs learned by the model.",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch05.html#functional-variant-prioritization",
    "href": "ch05.html#functional-variant-prioritization",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "5.4 Functional Variant Prioritization",
    "text": "5.4 Functional Variant Prioritization\nBeyond predicting chromatin effects, DeepSEA introduced a framework for prioritizing likely functional variants among large sets of candidates.\n\n5.4.1 eQTL Prioritization\nExpression quantitative trait loci (eQTLs) represent variants associated with gene expression changes. However, most eQTL signals reflect linkage disequilibrium rather than causal variants. DeepSEA demonstrated improved ability to distinguish true eQTLs from nearby non-causal variants compared to overlap-based methods.\n\n\n5.4.2 GWAS Variant Prioritization\nSimilarly, for GWAS-identified disease associations, DeepSEA helped prioritize which variants in LD blocks were most likely causal. The model outperformed contemporary methods including GWAVA (which was trained on known regulatory mutations) on held-out benchmarks.\n\n\n5.4.3 Comparison to Prior Methods\nDeepSEA’s performance advantage over gkm-SVM was particularly notable for transcription factor binding prediction:\n\nDeep CNN achieved higher AUC for nearly all transcription factors\ngkm-SVM showed no improvement with increased context sequence length\nDeepSEA performance improved substantially with context (200 bp → 500 bp → 1000 bp)\n\nThis demonstrated that the deep learning architecture could exploit longer-range sequence context that simpler models could not capture.",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch05.html#evolution-of-the-deepsea-framework",
    "href": "ch05.html#evolution-of-the-deepsea-framework",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "5.5 Evolution of the DeepSEA Framework",
    "text": "5.5 Evolution of the DeepSEA Framework\nThe original DeepSEA established the sequence-to-chromatin prediction paradigm. Subsequent work from the same group expanded and refined this approach.\n\n5.5.1 DeepSEA Beluga (2018)\nExPecto, published in 2018, included an updated chromatin prediction model nicknamed “Beluga” (Zhou et al. 2018). Key improvements included:\n\nExpanded prediction targets: 2,002 chromatin profiles (up from 919)\nDeeper architecture: Additional convolutional layers with residual connections\nLarger context: 2000 bp input sequences\nIntegration with expression prediction: Chromatin predictions serve as intermediate features for tissue-specific expression prediction (Chapter 6)\n\n\n\n5.5.2 Sei (2022)\nSei represents the current state of the DeepSEA lineage, predicting 21,907 chromatin profiles—a 24-fold expansion over the original (Chen et al. 2022). Architectural innovations include:\n\nDual linear/nonlinear paths: Parallel convolution blocks, one with activation functions and one without, allowing the model to learn both complex nonlinear patterns and simpler linear relationships\nDilated convolutions: Expanding receptive field without reducing spatial resolution\nSpatial basis functions: Memory-efficient integration of information across positions\n\nSei improved over Beluga by 19% on average (measured by AUROC/(1-AUROC)) on the 2,002 profiles predicted by both models.\n\n\n\nModel\nYear\nChromatin Targets\nInput Length\nArchitecture\n\n\n\n\nDeepSEA\n2015\n919\n1000 bp\n3 conv + FC\n\n\nBeluga\n2018\n2,002\n2000 bp\nDeep residual CNN\n\n\nSei\n2022\n21,907\n4000 bp\nDual-path + dilated conv",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch05.html#what-deepsea-learns",
    "href": "ch05.html#what-deepsea-learns",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "5.6 What DeepSEA Learns",
    "text": "5.6 What DeepSEA Learns\n\n5.6.1 Motif Discovery\nAnalysis of DeepSEA’s convolutional filters reveals learned sequence patterns corresponding to known transcription factor binding motifs. First-layer filters often match canonical motifs from databases like JASPAR, while deeper layers capture more complex patterns including motif combinations.\n\n\n5.6.2 Regulatory Grammar\nBeyond individual motifs, DeepSEA implicitly learns aspects of regulatory “grammar”—the rules governing how motifs combine to produce regulatory activity. This includes:\n\nMotif spacing: Some TF pairs require specific distances between binding sites\nMotif orientation: Directionality of certain motifs affects function\nCombinatorial logic: Multiple weak motifs can synergize, or compete through overlapping sites\n\nHowever, the original DeepSEA architecture’s limited receptive field (due to pooling operations) constrained its ability to learn long-range dependencies. This limitation motivated later architectures with expanded context windows (Enformer, Chapter 11).",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch05.html#limitations-and-considerations",
    "href": "ch05.html#limitations-and-considerations",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "5.7 Limitations and Considerations",
    "text": "5.7 Limitations and Considerations\n\n5.7.1 Cell Type Specificity\nDeepSEA predicts chromatin profiles for specific cell types included in training, but the same sequence may have different regulatory activity in cell types not represented. The model cannot predict activity in novel cell types without relevant training data.\n\n\n5.7.2 Context Independence\nThe model treats each input sequence independently, without considering:\n\n3D chromatin structure (which brings distant sequences into proximity)\nCurrent transcriptional state (which affects chromatin accessibility)\nOther variants in the same individual (epistasis)\n\n\n\n5.7.3 Quantitative Accuracy\nWhile DeepSEA accurately predicts binary presence/absence of chromatin features, quantitative predictions of signal strength are less reliable. Later models like Basenji addressed this by predicting continuous coverage rather than binary peaks.",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  },
  {
    "objectID": "ch05.html#significance-for-the-field",
    "href": "ch05.html#significance-for-the-field",
    "title": "5  DeepSEA and Ab Initio Regulatory Prediction",
    "section": "5.8 Significance for the Field",
    "text": "5.8 Significance for the Field\nDeepSEA established several paradigms that shaped subsequent genomic deep learning:\n\nSequence-in, function-out: Learning regulatory activity directly from sequence without hand-engineered features\nMulti-task chromatin prediction: Jointly modeling many related tasks improves both performance and efficiency\nVariant effect prediction via comparison: Score variants by comparing predictions for reference and alternative alleles\nAb initio prediction: Make predictions for any sequence, including novel mutations never observed in training data\n\nThe approach demonstrated that deep learning could extract biologically meaningful patterns from raw sequence data at scale. This opened the door to increasingly sophisticated sequence-to-function models—predicting not just chromatin state, but gene expression (ExPecto, Chapter 6), splicing (SpliceAI, Chapter 7), and eventually long-range regulatory interactions (Enformer, Chapter 11).\nDeepSEA’s public web server (http://deepsea.princeton.edu/) and code release also established a model for making genomic deep learning tools accessible to the broader research community—a practice that has become standard in the field.\n\n\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[DeepSEA Beluga] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.",
    "crumbs": [
      "Part II: Pioneering Sequence-to-Function Deep Learning (CNN Era)",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>DeepSEA and Ab Initio Regulatory Prediction</span>"
    ]
  }
]