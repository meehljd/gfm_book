[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genomic Foundation Models",
    "section": "",
    "text": "Introduction\nWe can now sequence a human genome for a few hundred dollars and store millions of genomes in a single biobank. What we cannot yet do, reliably, is tell you what most of those variants mean. The gap between sequencing capacity and interpretive capacity defines the central problem of modern genomics. It is exactly the gap that genomic foundation models aim to close.\nMeanwhile, deep learning has transformed how we represent language, proteins, and now DNA itself. Large models trained on broad sequence data can now be adapted to tasks ranging from variant interpretation to clinical risk prediction, all without retraining from scratch for each new problem.\nThis book is about that intersection: genomic foundation models (GFMs) - large, reusable models trained on genomic and related data that can be adapted to many downstream tasks. Rather than offering a general introduction to genomics or machine learning, the goal is narrower and more opinionated:\nThe chapters that follow connect classic genomics pipelines, early deep regulatory models, sequence language models, and multi-omic GFMs into a single narrative arc.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#why-genomic-foundation-models",
    "href": "index.html#why-genomic-foundation-models",
    "title": "Genomic Foundation Models",
    "section": "Why Genomic Foundation Models?",
    "text": "Why Genomic Foundation Models?\nTraditional genomic modeling has usually been task-specific:\n\nA variant caller tuned to distinguish sequencing errors from true variants.\n\nA supervised CNN trained to predict a fixed set of chromatin marks.\n\nA risk score fit for one trait, in one ancestry group, in one health system.\n\nThese models can work very well in the setting they were designed for, but they often do not transfer gracefully to new assays, tissues, ancestries, or institutions.\nThe foundation model paradigm takes a different view:\n\nScale\nTrain large models on massive, heterogeneous datasets, across assays, tissues, species, and cohorts, so they learn reusable structure.\nSelf-supervision\nUse objectives such as masked-token prediction, next-token modeling, or contrastive learning that do not require manual labels, allowing us to exploit unlabeled genomes, perturbation screens, and population variation.\nReusability\nTreat the model as a backbone: for new tasks, we probe, adapt, or fine-tune the same representation instead of training a new model from scratch.\n\nIn genomics, this paradigm is still evolving and far from settled. Some tasks benefit dramatically from pretraining; others barely move beyond strong classical baselines. This book leans into that tension and asking when foundation models actually help, and when simpler approaches suffice (Bommasani et al. 2022; Guo et al. 2025).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#recurring-themes",
    "href": "index.html#recurring-themes",
    "title": "Genomic Foundation Models",
    "section": "Recurring Themes",
    "text": "Recurring Themes\nSeveral threads run through the book; individual chapters can be read as different views of the same underlying questions.\n\nData and Architecture Co-evolve\nWe will see how:\n\nEarly deleteriousness scores built on hand-engineered features and shallow models.\n\nCNNs enabled direct learning of regulatory “motifs” and local grammar from raw sequence.\n\nTransformers and other long-context models opened the door to capturing broader regulatory neighborhoods and chromatin structure.\n\nGFMs push toward representations that span multiple assays, tissues, and even organisms.\n\nAt each stage, the interesting question is not “Is this model fancier?” but “How does the available data constrain what the model can sensibly learn?”\n\n\nContext Length and Genomic Geometry\nMany genomic phenomena are intrinsically non-local: enhancers regulating distant genes, looping interactions, polygenic effects spread across the genome. The book returns repeatedly to “how far” a model can see, how it represents long-range dependencies, and what is gained (and lost) as context windows and architectures scale.\n\n\nPrediction Versus Design\nMost current models are used as predictors: given sequence and context, what happens? But the same models can be embedded in design and closed-loop workflows, from variant prioritization to sequence or library design. We will explore how foundation models change the boundary between analysis and experimental planning, and what new failure modes emerge in the process.\n\n\nFrom Benchmarks to Decisions\nBenchmark scores are seductive and easy to compare. Real biological and clinical decisions are messy, multi-objective, and often constrained by data drift, bias, and poorly specified endpoints. A recurring theme is the gap between “state-of-the-art AUC” and actual impact—and how careful evaluation, confounder analysis, and calibration can narrow that gap.\n\n\nInterpretability and Mechanism\nFinally, we return often to interpretability, not as optional decoration, but as a design constraint. We will ask when saliency maps, motif extraction, or more mechanistic analyses genuinely deepen understanding, and when they simply provide a veneer of comfort over confounded or brittle models.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-the-book-is-organized",
    "href": "index.html#how-the-book-is-organized",
    "title": "Genomic Foundation Models",
    "section": "How the Book Is Organized",
    "text": "How the Book Is Organized\nThe book is organized into six parts plus three short appendices. Each part can be read on its own, but they are designed to build on one another.\n\nPart I — Data & Pre-DL Methods\nPart I lays the genomic and statistical foundation that later models rest on.\n\nChapter 1  Sequencing: From Reads to Variants introduces next-generation sequencing, alignment, and variant calling, highlighting sources of error and the evolution from hand-crafted pipelines to learned variant callers.\nChapter 2  The Genomic Data Landscape surveys the core data resources that underlie most modern work: reference genomes, population variation catalogs, clinical variant databases, and functional genomics consortia. It also discusses how they are used as training targets and evaluation benchmarks.\nChapter 3  GWAS & Polygenic Scores reviews genome-wide association studies, linkage disequilibrium, fine-mapping, and polygenic scores, emphasizing what these “variant-to-trait” associations do and do not tell us.\nChapter 4  Deleteriousness Scores covers conservation-based and machine learning-based variant effect predictors such as CADD, including their feature sets, label construction, and issues like circularity and dataset bias.\n\nTogether, Part I answers: What data and pre-deep-learning tools form the backdrop that any genomic foundation model must respect, integrate with, or improve upon?\n\n\n\nPart II — CNN Seq-to-Function Models\nPart II turns to the first wave of deep sequence-to-function models, largely built on convolutional neural networks.\n\nChapter DeepSEA: Regulatory Prediction from Sequence presents CNN-based models that predict chromatin accessibility, histone marks, and related regulatory annotations directly from DNA sequence, and explores what they learn about motifs and regulatory grammar.\nChapter ExPecto: From Chromatin to Expression extends from chromatin to gene expression, showing how models combine sequence, regulatory features, and context to predict expression levels and perturbation effects.\nChapter SpliceAI: Splicing Prediction focuses on deep models of pre-mRNA splicing and splice-site choice, and how these models can be used to interpret variant effects on splicing in both research and clinical contexts.\n\n\n\n\nPart III — Transformer Models\nPart III introduces transformer-based and related architectures for representing biological sequence.\n\nChapter 5  Sequence Representation & Tokens examines how we turn genomic and protein sequences into model-compatible tokens, including k-mers, byte-pair encodings, and other schemes, and how these choices shape downstream models.\nChapter 13  Protein Language Models describes large protein language models trained on sequence databases, their emergent structure and function representations, and applications to variant effect prediction and protein design.\nChapter 11  DNA and Genomic Models surveys DNA language models and other genomic foundation backbones, including their training corpora, objectives, evaluation suites, and limitations.\nChapter 14  Long-range Hybrid Models covers hybrid CNN/transformer and related architectures designed to handle long genomic contexts, such as models that predict regulatory readouts over tens to hundreds of kilobases.\n\n\n\n\nPart IV — GFMs & Multi-omics\nPart IV is the conceptual core of the book, focusing explicitly on genomic foundation models and their multi-omic extensions.\n\nChapter 7  Genomic Foundation Models: Concepts & Taxonomy provides a working definition and taxonomy of genomic FMs, design dimensions (architecture, context length, conditioning), and practical guidance for using pretrained backbones in downstream tasks…\nChapter 20  Variant Effect Prediction recasts variant effect prediction in the foundation-model era, spanning protein and DNA-based approaches, and discusses calibration, uncertainty, and integration into existing pipelines.\nChapter 15  Single-Cell & Epigenomic Models covers foundation models for epigenomic and single-cell data, from methylation transformers and chromatin contact predictors to single-cell language models and cross-modal alignment methods.\nChapter 17  Multi-Omics & Systems Biology broadens the view from isolated sequences to multi-omic and systems-level representations, including models that integrate genomic, transcriptomic, proteomic, and phenotype data.\n\n\n\n\nPart V — Reliability & Interpretation\nPart V pulls out cross-cutting issues that apply to essentially every model in the book.\n\nChapter 19  Evaluation of Models develops a unified framework for evaluating models across molecular, variant-level, trait-level, and clinical tasks, and discusses data splitting, metric choice, and the link between benchmarks and real-world decisions.\nChapter 21  Confounders in Model Training details sources of confounding and data leakage, from batch effects and ancestry structure to label bias and covariate shift, and offers practical strategies for detection and mitigation.\nChapter 22  Interpretability & Mechanisms explores interpretability tools from classical motif discovery and attribution methods to emerging mechanistic approaches, and asks when these tools genuinely reveal biological mechanisms.\n\n\n\n\nPart VI — Applications\nPart VI moves from methods to end-to-end workflows in research and clinical practice.\n\nChapter 23  Clinical Risk Prediction discusses risk prediction tasks that combine genomic features (including outputs from GFMs) with clinical and environmental data, focusing on discrimination, calibration, fairness, and deployment in health systems.\nChapter 24  Pathogenic Variant Discovery examines how models fit into rare disease and cancer workflows, including variant prioritization pipelines, integration with family and tumor-normal data, and lab-in-the-loop validation.\nChapter 25  Drug Discovery & Biotech looks at how GFMs intersect with target discovery, functional genomics screens, biomarker development, and biotech/industry workflows, including build-vs-buy and organizational considerations.\n\n\n\n\nAppendices\nThe appendices provide background and pointers:\n\nAppendix A — Deep Learning Primer is a compact introduction to neural networks, CNNs, transformers, training, and evaluation, aimed at genomics-first readers who want enough ML background to engage with the main chapters. :contentReferenceoaicite:2\nAppendix C — Referenced Models is a comprehensive list of models used through the book.\nAppendix D — Additional Resources is a curated set textbooks, courses, software, and papers for deeper dives into genomics, statistical genetics, and deep learning.\nAppendix E — Glossary is a glossary of key terms.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#a-moving-target",
    "href": "index.html#a-moving-target",
    "title": "Genomic Foundation Models",
    "section": "A Moving Target",
    "text": "A Moving Target\nGenomic foundation models are a moving target: architectures, datasets, and evaluation suites are evolving quickly. This book is not intended as a frozen survey of “the state of the art,” but as a framework for reasoning about new models as they appear.\nIf it succeeds, you should finish able to:\n\nPlace a new model in the landscape of data, architecture, objective, and application.\n\nDesign analyses and experiments that use GFMs as components—features, priors, or simulators—without overclaiming what they can do.\n\nRecognize common pitfalls in training, evaluation, and deployment, especially in clinical and translational settings.\n\nDecide where foundation models are genuinely useful, and where simpler methods or classical baselines are sufficient.\n\nThe next chapter now turns to the foundations: how we get from raw reads to variants, and from variants to the datasets and benchmarks on which all of these models depend.\n\n\n\n\nBommasani, Rishi, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, et al. 2022. “On the Opportunities and Risks of Foundation Models.” arXiv. https://doi.org/10.48550/arXiv.2108.07258.\n\n\nGuo, Fei, Renchu Guan, Yaohang Li, Qi Liu, Xiaowo Wang, Can Yang, and Jianxin Wang. 2025. “Foundation Models in Bioinformatics.” National Science Review 12 (4): nwaf028. https://doi.org/10.1093/nsr/nwaf028.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "Why I Wrote This Book\nWorking on genomic foundation models means context-switching constantly: debugging data artifacts one week, reproducing a transformer-based variant effect predictor the next, and arguing about clinical patient cohorts the week after. The knowledge required is scattered across textbooks, methods papers, and tribal folklore - genomics on one shelf, deep learning on another, clinical deployment in someone else’s head entirely.\nThis book is my attempt to put those pieces in one place: to connect the mature, statistically grounded tradition of human genetics with the rapidly changing ecosystem of deep learning and foundation models, and to make that transition legible for people who live in one corner of the triangle and are trying to get oriented to the others.\nI wrote it first for myself and my collaborators: as a way to organize wiki pages, markdown files, and half-finished slide decks into something coherent. Over time it became clear that turning those notes into a book might be useful to others navigating the same landscape.\nWhat I wanted, but could not find, was a conceptual throughline:\nThis book is my best attempt at answering those questions in a way that is historically grounded, technically honest, and practically oriented.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#why-i-wrote-this-book",
    "href": "preface.html#why-i-wrote-this-book",
    "title": "Preface",
    "section": "",
    "text": "How do we get from reads to variants in a way that a deep model can trust?\nHow should we think about polygenic scores, fine-mapping, and functional assays in the era of foundation models?\nWhen we say a model “understands” regulatory grammar or protein function, what does that actually mean?\nAnd what does it take to move from a promising preprint to a tool that can support decisions about real patients?",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#how-this-book-came-together",
    "href": "preface.html#how-this-book-came-together",
    "title": "Preface",
    "section": "How This Book Came Together",
    "text": "How This Book Came Together\nThe structure of the book reflects the way these ideas evolved in my own work.\nEarly sections grew out of teaching and mentoring conversations: explaining next-generation sequencing, variant calling, and pre-deep-learning interpretation methods to new team members who were strong in statistics or ML but new to genomics (and vice versa).\nThe middle sections emerged from a series of “journal club + experiments” cycles, where we:\n\nread papers on sequence-to-function CNNs, protein language models, and genomic transformers,\ntried to reproduce key results or adapt them to key datasets,\nand documented the pain points—data formats, training instabilities, evaluation pitfalls, which never quite fit into a methods section.\n\nThe later parts were shaped by collaborations around clinical prediction, variant interpretation pipelines, and larger multi-omic models. Many of the examples and caveats come directly from these projects: places where a model that looked excellent on paper behaved in surprising ways when exposed to real-world data, or where simple baselines outperformed much fancier architectures once confounding and distribution shift were handled correctly.\nBecause of that origin, the book has a particular bias: it is written from the perspective of someone who spends much of their time trying to get models to work in messy, high-stakes settings. You will see this in the emphasis on data quality, evaluation, and clinical translation.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#how-to-read-this-book",
    "href": "preface.html#how-to-read-this-book",
    "title": "Preface",
    "section": "How to Read This Book",
    "text": "How to Read This Book\nThis is not a genomics textbook, a complete review of every DNA or protein model, or a deep-learning-from-scratch course. Instead, it is meant to be:\n\na roadmap to the main kinds of data, models, and objectives that matter for genomic foundation models today\na bridge between classical statistical genetics and modern representation learning\na practical guide to the kinds of failure modes and design choices that matter in real applications.\n\nYou do not need to read the book cover-to-cover in order.\n\nIf your background is in genomics or statistical genetics, you may want to skim the early deep-learning motivations and focus more on the sections that introduce convolutional models, transformers, and self-supervision, then move on to evaluation and applications.\nIf you come from machine learning, it may be more helpful to start with the genomic data and pre-deep-learning methods, then dive into the sequence-to-function and transformer-based chapters with an eye toward how the data and objectives differ from text or images.\nIf you are a clinician or translational researcher, you might care most about the reliability, confounding, and clinical deployment discussions, dipping back into the modeling parts as needed to interpret results or communicate with technical collaborators.\n\nThe book is organized into six parts:\n\nPart I introduces genomic data and pre-deep-learning interpretation methods, from sequencing and variant calling to early pathogenicity scores and polygenic models.\nPart II focuses on supervised sequence-to-function models, with an emphasis on convolutional architectures, regulatory prediction, and splicing.\nPart III turns to transformer-based models and self-supervision, covering protein and DNA language models and hybrid architectures that combine CNNs and transformers.\nPart IV discusses what makes a model a foundation model in genomics, including multi-omic architectures, variant effect modeling, and emergent capabilities.\nPart V examines reliability, evaluation, confounding, and interpretability—how we know whether a model is learning what we think it is, and how to detect when it is not.\nPart VI looks at applications: clinical and risk prediction, variant interpretation workflows, and early steps toward drug discovery and biotech use cases.\n\nWithin each part, the goal is not to catalogue every paper, but to highlight representative examples and the design principles they illustrate. References are there to give you starting points, not to serve as a comprehensive literature review.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#what-this-book-assumes-and-what-it-does-not",
    "href": "preface.html#what-this-book-assumes-and-what-it-does-not",
    "title": "Preface",
    "section": "What This Book Assumes (and What It Does Not)",
    "text": "What This Book Assumes (and What It Does Not)\nThe book assumes:\n\nbasic familiarity with probability and statistics (regression, hypothesis testing, effect sizes),\ncore genomics concepts (genes, variants, linkage disequilibrium, GWAS at a high level),\nand some exposure to machine learning ideas (training versus test data, overfitting, loss functions).\n\nIt does not assume that you have implemented deep learning models yourself, or that you are fluent in every area. When a chapter leans heavily on a particular background (for example, causal inference or modern self-supervised learning), it will either provide a brief refresher or point you to an appendix or external resource.\nIf you are missing some of this background, that is fine. The intent is for you to be able to read actively: to pause, look up side topics, and then return to the main arc without feeling lost.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#a-note-on-scope-and-opinions",
    "href": "preface.html#a-note-on-scope-and-opinions",
    "title": "Preface",
    "section": "A Note on Scope and Opinions",
    "text": "A Note on Scope and Opinions\nGenomic foundation models are evolving quickly. Any snapshot is, by definition, incomplete and slightly out of date.\nRather than chasing every new architecture or benchmark, the book focuses on durable ideas:\n\nhow different data types fit together,\nwhat kinds of objectives encourage useful representations,\nhow evaluation can fail in genomics-specific ways,\nand where deep models complement (rather than replace) classical approaches.\n\nInevitably, there are judgment calls about which papers, methods, and perspectives to emphasize. Those choices reflect my own experiences and biases. They are not an official position of any institution I work with, and they will certainly differ from other reasonable views in the field.\nYou should treat the book as one opinionated map of the landscape, not the landscape itself.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#acknowledgements",
    "href": "preface.html#acknowledgements",
    "title": "Preface",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis book exists because of many generous people who shared their time, ideas, and encouragement.\nFirst, I owe a deep debt of gratitude to my colleagues in the Mayo Clinic GenAI and broader data science community. The day-to-day conversations, whiteboard sessions, and “what went wrong here?” post-mortems with this group shaped much of the perspective and many of the examples in the chapters.\nI am especially grateful to the principal investigators and clinicians whose questions kept the focus on real patients and real decisions:\nDr. Shant Ayanian, Dr. Elena Myasoedova, and Dr. Alexander Ryu.\nTo leadership at Mayo Clinic who supported the time, computing resources, and institutional patience needed for both the models and this book:\nDr. Matthew Callstrom, Dr. Panos Korfiatis, and Matt Redlon.\nTo my data science and machine learning engineering colleagues, whose work and feedback directly shaped many of the workflows and case studies:\nBridget Toomey, Carl Molnar, Zach Jensen, and Marc Blasi.\nI am also grateful for the architectural creativity, hardware insight, and willingness to experiment from our collaborators at Cerebras:\nNatalia Vassilieva, Jason Wolfe, Omid Shams Solari, Vinay Pondenkandath, Bhargav Kanakiya, and Faisal Al-khateeb.\nAnd to our collaborators at GoodFire, whose partnership helped push these ideas toward interpretable and deployable systems:\nDaniel Balsam, Nicholas Wang, Michael Pearce, and Mark Bissell.\nI would also like to thank my former colleagues at LGC for foundational work and conversations around protein language models and large-scale representation learning:\nPrasad Siddavatam and Robin Butler.\nBeyond these named groups, I owe a broader debt to the geneticists, molecular biologists, statisticians, clinicians, and engineers whose work this book draws on. The field moves forward because people share code, publish honest benchmarks, and insist that models be connected back to biologically meaningful questions. Thank you for setting that standard.\nFinally, I am grateful to my wife, Alyssa, and our two kids for their patience with the evenings and weekends this book consumed. You gave me the space to finish it and the reasons to step away from it.\nIf this book helps you connect a new model to a real biological question, design a more robust evaluation, or communicate more clearly across disciplinary boundaries then it will have done its job.\n— Josh Meehl",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "p1--foundations.html",
    "href": "p1--foundations.html",
    "title": "Part I: Foundations",
    "section": "",
    "text": "Before deep learning can predict variant effects, model regulatory grammars, or guide clinical decisions, it must contend with the raw materials of modern genomics: sequences, variants, and the biological and statistical frameworks used to interpret them. Part I establishes this foundation, surveying the technologies, datasets, and pre-deep-learning methods that any genomic foundation model must respect, integrate with, or improve upon.\nThe chapters that follow trace a natural arc from data generation to interpretation. 1  Sequencing: From Reads to Variants introduces next-generation sequencing and variant calling, the processes that transform biological samples into the VCF files of single-nucleotide variants and indels that serve as inputs to nearly all downstream analysis. Understanding these technologies reveals both their remarkable power and their systematic blind spots, from reference bias to missing structural variants, limitations that propagate into every model trained on their outputs.\n2  The Genomic Data Landscape surveys the public resources that underpin modern computational genomics: reference genomes, population variation catalogs like gnomAD, functional genomics consortia such as ENCODE and Roadmap Epigenomics, and biobank-scale cohorts including the UK Biobank and GTEx. These resources serve simultaneously as training data, evaluation benchmarks, and sources of prior biological knowledge. Their coverage and biases shape what models can learn and what questions remain out of reach.\nFrom individual variants, 3  GWAS & Polygenic Scores moves to the statistical machinery of genome-wide association studies and polygenic scores. GWAS identify variant-trait associations across populations, while polygenic scores aggregate thousands of small effects into genome-wide predictors of complex traits. These methods define the classical approach to connecting genotype with phenotype, providing both baselines against which deep models are measured and conceptual frameworks that inform their design.\nFinally, 4  Deleteriousness Scores examines pre-deep-learning variant effect prediction through the lens of CADD, the Combined Annotation Dependent Depletion framework. CADD represents a mature approach to variant prioritization through careful feature engineering, combining conservation, regulatory annotations, and population constraints into a single deleteriousness score. Its strengths and limitations, including subtle circularities with clinical databases, motivate the learned representations that subsequent chapters develop.\nTogether, these four chapters answer a foundational question: what data and methods form the backdrop against which genomic foundation models are built, trained, and evaluated? The models that follow do not emerge in a vacuum. They inherit the biases of sequencing technologies, learn from consortia-scale functional annotations, compete against GWAS-derived baselines, and face evaluation on benchmarks shaped by decades of prior computational and clinical work. Understanding this landscape is prerequisite to understanding what foundation models can and cannot accomplish.",
    "crumbs": [
      "Part I: Foundations"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html",
    "href": "p1-ch01-ngs.html",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "",
    "text": "1.1 The Challenge of NGS Data\nNext-generation sequencing (NGS) has transformed genomics by making it routine to generate tens to hundreds of gigabases of DNA sequence from a single individual (Goodwin, McPherson, and McCombie 2016). Modern instruments produce short reads, typically 100 to 300 base pairs of paired-end Illumina sequence, at very high throughput but with non-trivial error profiles including substitutions, context-specific errors, and base quality uncertainties. Long-read technologies from Pacific Biosciences and Oxford Nanopore further expand the space of observable variation to include complex structural variants and some segmental duplications (Wenger et al. 2019; Dabernig-Heinz et al. 2024).\nFrom the perspective of this book, the central problem is: how do we turn raw reads into a reliable list of genomic variants? The answer is a multi-stage pipeline involving alignment, local assembly, genotype likelihoods, joint calling, phasing, and imputation. Every downstream model in this book, including polygenic scores, regulatory sequence models, variant effect predictors, and clinical risk models, assumes that this upstream pipeline has already run and that its output represents ground truth.\nTurning raw reads into reliable variants is therefore not simply a matter of comparing strings. Variant calling pipelines must disentangle sequencing errors (instrument noise, PCR artifacts), alignment artifacts (mis-mapping in repeats, paralogous regions, pseudogenes), and genuine biological variation (germline variants, somatic mutations, mosaicism). Historically, this was addressed by complex, modular pipelines combining probabilistic models and hand-crafted heuristics (Nielsen et al. 2011). Deep learning now plays an important role in simplifying and improving parts of this stack, but understanding the classical pipeline remains essential.\nThis chapter focuses on germline variant calling in human WES and WGS data. Somatic variant calling in cancer and RNA-seq-specific variant calling share many parallels but require additional considerations that fall largely outside the scope of Part I.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#the-challenge-of-ngs-data",
    "href": "p1-ch01-ngs.html#the-challenge-of-ngs-data",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "",
    "text": "Warning\n\n\n\nVisual TODO: Overview schematic of an NGS variant-calling workflow, from DNA sample → library prep → sequencer (short vs. long read) → FASTQ → alignment → duplicate marking → BQSR → variant calling → filtering → VCF.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#targeting-strategies-panels-exomes-and-genomes",
    "href": "p1-ch01-ngs.html#targeting-strategies-panels-exomes-and-genomes",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.2 Targeting Strategies: Panels, Exomes, and Genomes",
    "text": "1.2 Targeting Strategies: Panels, Exomes, and Genomes\nNGS is not a single technology; it is deployed in different targeting strategies, each with distinct trade-offs in coverage, cost, and bias. We begin with these strategies before examining pipelines and models.\n\n1.2.1 Targeted and Panel Sequencing\nTargeted gene panels capture tens to hundreds of genes selected for a specific clinical indication, such as cardiomyopathy, hereditary cancer, or epilepsy. By restricting the target to a small number of loci, panels achieve very deep coverage (often exceeding 500×) at modest cost, enabling sensitive detection of rare variants and some mosaicism. Panels are widely used in clinical genetics for focused, high-yield diagnostic tests.\nThe narrow scope of panels is their main limitation for deep learning and population-scale analysis. Panels miss novel disease genes outside their target, are not easily repurposed for new traits, and often have heterogeneous content across laboratories. For large-scale genomic foundation models, panel data are more useful as richly phenotyped “anchors” than as primary training material: they provide clean labels but sparse genomic coverage.\n\n\n1.2.2 Whole-Exome Sequencing\nWhole-exome sequencing (WES) enriches coding exons and some splice-adjacent regions across the genome. Exome capture uses hybridization probes to pull down targeted regions, followed by short-read sequencing. Typical coverage ranges from 80 to 150× for exonic targets, though capture efficiency varies across GC content and repetitive exons. WES covers approximately 1 to 2 percent of the genome but concentrates on protein-coding sequence, where variant interpretation is currently most mature.\nWES has been especially successful for Mendelian disease gene discovery and early biobank-scale efforts, including the exome subsets of gnomAD and many hospital-based cohorts (Karczewski et al. 2020). However, capture-based approaches introduce nonuniform coverage, GC- and sequence-content biases, and batch effects tied to reagent lots and panel designs. Certain exons, especially those that are GC-rich, highly repetitive, or very long, may have systematically low coverage, which propagates into missingness and uncertainty for downstream models.\n\n\n1.2.3 Whole-Genome Sequencing\nWhole-genome sequencing (WGS) samples nearly all bases in the genome, including coding and noncoding regions. Typical coverage is 30 to 60× across the genome, with more uniform depth than WES. Because there is no capture step, WGS produces fewer batch-specific artifacts and enables detection of noncoding variants, structural variants, and copy-number changes along with SNVs and indels.\nWGS is increasingly favored for new large cohorts and rare disease studies. The data are reusable for many downstream analyses (GWAS, PGS, rare variant burden tests), and the simplified pipeline eliminates the need to track changing capture designs. WGS supports more complete variant catalogs for the models discussed in later chapters and is the primary data type for many of the biobanks and population resources that underpin modern genomic deep learning (Bycroft et al. 2018; Karczewski et al. 2020). Throughout this text, when we refer to “whole-genome models,” we implicitly assume access to WGS-based variant calls, even when actual training sets combine WES and WGS data.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Comparative table or radar plot for panels, WES, WGS (and possibly long-read WGS) summarizing target size, typical coverage depth, per-sample cost, ability to detect rare variants, and suitability for large-cohort foundation model training.\n\n\n\n\n1.2.4 Long-Read Sequencing Technologies\nWhile short-read Illumina sequencing dominates population-scale studies, long-read technologies are increasingly important for resolving complex genomic regions and structural variation.\nPacific Biosciences (PacBio) HiFi produces reads of 10 to 25 kilobases with per-base accuracy exceeding 99.9% through circular consensus sequencing (Wenger et al. 2019). Oxford Nanopore Technologies (ONT) instruments generate reads from a few kilobases up to megabases in length, with rapidly improving raw accuracy and unique capabilities such as portable sequencers, field diagnostics, and direct RNA sequencing (Dabernig-Heinz et al. 2024). Long reads can span repetitive elements, resolve haplotypes across tens to hundreds of kilobases, and directly characterize structural variants and complex indels. They played a central role in the telomere-to-telomere (T2T) assembly of a complete human genome and in emerging human pangenome references (Nurk et al. 2022; Liao et al. 2023).\nLong reads transform variant calling in several ways. They provide improved mappability, traversing low-complexity and repetitive regions that are essentially invisible to short reads. They enable robust structural variant detection, with callers such as PEPPER-Margin-DeepVariant (Shafin et al. 2021), Clair3 (Zheng et al. 2022), Sniffles2 (Smolka et al. 2024), pbsv (“PacificBiosciences/Pbsv” 2025), and cuteSV (Jiang et al. 2020) exploiting read-length and alignment patterns to detect insertions, deletions, inversions, and duplications. Single molecules spanning multiple heterozygous sites provide direct phasing information for haplotype resolution. Long reads also inform graph-based references and pangenomes that better represent population diversity (Liao et al. 2023).\nThis chapter focuses on short-read pipelines, which remain the workhorse for large human cohorts. However, the models in later chapters must accommodate variants discovered by either technology and must be evaluated on composite callsets that integrate short- and long-read information.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#classical-variant-calling-pipelines",
    "href": "p1-ch01-ngs.html#classical-variant-calling-pipelines",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.3 Classical Variant Calling Pipelines",
    "text": "1.3 Classical Variant Calling Pipelines\nWhile every institution implements its own details, a classical short-read pipeline has several common stages.\nThe process begins with base calling and demultiplexing, where instrument software converts fluorescent images to base calls and quality scores, and reads are demultiplexed by barcode into sample-specific FASTQ files.\nNext comes read alignment, in which short reads are aligned to a reference genome (such as GRCh38 or T2T-CHM13) using seed-and-extend mappers such as BWA-MEM or minimap2 (Li 2013, 2018). Aligners must cope with mismatches, small indels, and repetitive sequence, often producing multiple candidate alignments with associated scores.\nPost-alignment processing follows, including marking or removing PCR duplicates, base quality score recalibration (BQSR) to model systematic quality score errors, and local realignment around indels in older pipelines (DePristo et al. 2011; Van der Auwera et al. 2018). These steps aim to correct systematic errors in base qualities and improve alignment around small insertion-deletion events.\nPer-sample variant calling then takes place, where tools like GATK HaplotypeCaller assemble local haplotypes, compute genotype likelihoods at candidate sites, and output per-sample gVCFs that encode both variant calls and “reference blocks” with estimated confidence (DePristo et al. 2011).\nFinally, for cohort variant calling, joint genotyping and cohort-level filtering combine gVCFs across many samples to produce a multi-sample VCF. Joint genotyping ensures that all samples are evaluated at the same sites, and filtering strategies (hard filters, VQSR, or ML-based filters) select high-confidence variants based on multiple quality axes rather than independent thresholds.\nThese steps are encoded in pipelines like GATK Best Practices and similar frameworks implemented by large sequencing centers (Van der Auwera et al. 2018). The key point is that each step uses hand-designed summary features and mechanistic models chosen by experts, not learned end-to-end.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Block diagram of a short-read variant calling pipeline, with each step (alignment, duplicate marking, BQSR, per-sample calling, joint genotyping, filtering) shown as a box and data formats (FASTQ, BAM/CRAM, gVCF, VCF) annotated along the arrows.\n\n\n\n1.3.1 Sample-Level Quality Control and Cohort Curation\nBefore any downstream analysis or training of deep models, variant callsets must pass through sample-level quality control (QC). Sex checks compare reported sex to X/Y coverage and heterozygosity to detect sex mismatches or sex chromosome aneuploidy. Contamination and mixture analysis estimates contamination levels from allelic balance or dedicated tools and excludes heavily contaminated samples. Relatedness and duplicate detection identifies unexpected relatives or duplicate sequencing of the same individual. Ancestry inference estimates genetic ancestry using PCA or clustering, which is crucial both for scientific questions and for controlling confounding in later analyses.\nThese QC steps determine which samples enter training sets, how models are stratified by ancestry, and which samples may be excluded due to technical artifacts. Throughout the book, when we refer to “a callset,” we implicitly assume that a careful QC process like this has already been applied.\n\n\n1.3.2 Probabilistic Framework\nAt the core of GATK’s HaplotypeCaller and similar tools is a Bayesian genotype likelihood model. At a given site, the posterior probability of a genotype \\(G\\) (for example, 0/0, 0/1, or 1/1) given the read data \\(D\\) is:\n\\[\nP(G \\mid D) \\propto P(G) \\prod_{r \\in \\text{reads}} P(r \\mid G),\n\\]\nwhere \\(P(G)\\) is a prior over genotypes (often assuming Hardy-Weinberg equilibrium with a specified allele frequency) and \\(P(r \\mid G)\\) is the likelihood of observing read \\(r\\) given genotype \\(G\\). Computing this likelihood is non-trivial: GATK uses a pair hidden Markov model (pair-HMM) to marginalize over possible alignments between the read and candidate haplotypes, incorporating base quality scores to weight the contribution of each base (DePristo et al. 2011; Li 2014).\nThis formulation assumes conditional independence of reads given the genotype, an assumption known to be violated in practice. Systematic sequencing errors, read pair correlations, and library-level artifacts create dependencies among reads. Classical pipelines try to correct for these effects through BQSR and ad hoc filters, whereas deep learning-based callers can learn these dependencies implicitly. DeepVariant’s CNN, by contrast, sees all reads in a pileup simultaneously and can learn to model these dependencies directly.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Small schematic showing reads aligned at a single site, illustrating how each read contributes to the likelihood term in the Bayesian genotype model (e.g., three reads supporting the alternate allele with different base qualities).\n\n\nThe per-read likelihoods are aggregated into genotype likelihoods, which are then combined with priors to yield genotype posterior probabilities. These posteriors become the genotype quality (GQ) scores that downstream analyses often treat as truth.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#haplotype-phasing",
    "href": "p1-ch01-ngs.html#haplotype-phasing",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.4 Haplotype Phasing",
    "text": "1.4 Haplotype Phasing\nDiploid organisms carry two copies of each autosomal chromosome, one inherited from each parent. A standard VCF encodes genotypes at each site but does not specify which alleles reside together on the same physical chromosome. Haplotype phasing resolves this ambiguity by assigning each allele to a specific haplotype, transforming unphased genotypes such as 0/1 into phased genotypes like 0|1 or 1|0.\n\n1.4.1 Why Phasing Matters\nPhased haplotypes are essential for multiple applications. For interpreting compound heterozygosity, determining whether two rare variants in a gene are on the same or different chromosomes can distinguish benign from pathogenic combinations. In recessive disease, two deleterious variants in the same gene cause disease only if they are on different haplotypes (in trans); unphased calls cannot distinguish cis from trans configurations. For cis-trans regulatory effects, assigning regulatory variants and target gene variants to the same haplotype enables haplotype-specific expression and methylation analyses. For population genetics and LD structure, most statistical genetics methods assume a haplotype model of linkage disequilibrium, which requires well-phased data to estimate recombination and selection. Reference panels used for genotype imputation are stored as phased haplotypes, and accurate phasing improves imputation quality.\nIn the context of deep learning, phasing determines whether we feed models unordered genotypes or more structured, haplotype-resolved representations, which can change both model design and performance.\n\n\n1.4.2 Phasing Methods\nPhasing can be achieved through several approaches. Read-backed phasing uses sequencing reads that span multiple heterozygous sites to assign alleles to haplotypes. Short reads phase over tens to hundreds of base pairs, while long reads extend this to tens of kilobases or more.\nStatistical or population-based phasing tools such as SHAPEIT, Eagle, and Beagle use haplotype reference panels and linkage disequilibrium to infer phase over much longer distances (O’Connell et al. 2014; Loh et al. 2016; Browning et al. 2021). These methods excel in common variation but struggle with rare variants that lack informative LD.\nPedigree-based phasing becomes possible when parent-offspring trios or larger pedigrees are available. Mendelian inheritance rules can resolve phase with high confidence, especially when combined with population-based methods.\nLong-read and linked-read technologies provide direct observations of long-range haplotypes by sequencing long molecules or barcoded fragments spanning many heterozygous sites (Wenger et al. 2019; Shafin et al. 2021).\nModern pipelines often combine these approaches: statistical phasing anchored by a large reference panel, augmented by read-backed evidence where available, and refined by trio data when present. The result is a phased VCF where each heterozygous genotype is annotated with haplotype structure that downstream analyses can exploit.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Table or multi-panel cartoon comparing phasing strategies: axes for input data (short reads, long reads, trios, population reference), typical genomic span per phased block, and typical use cases (imputation, rare disease, population genetics).\n\n\n\n\n1.4.3 Imputation and Genotype Refinement\nPhasing is closely tied to genotype imputation and genotype refinement, which use phased reference panels to improve and extend variant calls.\nIn genotype imputation, a cohort with incomplete or noisy genotype data (for example, genotyped on an array or sequenced at low coverage) is matched against a reference panel of densely phased haplotypes. Statistical models infer missing genotypes and refine uncertain calls by leveraging LD patterns and shared haplotype segments (Browning et al. 2021). Two related processes are often distinguished. Within-panel boosting improves genotype quality at already-typed sites, especially in low-coverage WGS or WES, by pooling information across haplotypes and samples. Imputation of untyped variants infers genotypes at variants not directly observed in the study cohort but present in the reference panel, dramatically increasing the density of the callset.\nFor downstream deep learning, imputation has several important consequences. It increases the number of variants available as input “tokens” for genotype-based models. It changes the distribution of genotype uncertainty, often producing well-calibrated genotype probabilities that can be exploited by probabilistic models. It ties model performance to the composition and ancestry of the reference panel: imputation errors are larger when target individuals are underrepresented in the panel, reinforcing the themes of bias and confounding addressed in Chapter 21.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Cartoon showing how genotype imputation and boosting fill in missing genotypes and refine uncertain calls using a reference panel of phased haplotypes, with before/after views of a sparse vs. dense genotype matrix.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#sources-of-error-and-uncertainty",
    "href": "p1-ch01-ngs.html#sources-of-error-and-uncertainty",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.5 Sources of Error and Uncertainty",
    "text": "1.5 Sources of Error and Uncertainty\nEven with modern pipelines, variant calls are imperfect. Understanding the main sources of error is essential for interpreting downstream analyses and for designing robust deep models (Li 2014).\nMapping ambiguity arises when reads align almost equally well to multiple locations, such as segmental duplications, paralogous gene families, or repetitive elements. Reads may be arbitrarily assigned, down-weighted, or discarded, leading to false positives in one region and false negatives in another. Reference bias can favor the reference allele in ambiguous regions, causing systematic undercalling of alternate alleles.\nSystematic sequencing artifacts include context-specific errors (for example, homopolymer-associated indels), machine- and chemistry-specific error modes, and index hopping. These artifacts can create correlated false positives that cluster by batch or lane, making them difficult to distinguish from real rare variants.\nLow-coverage regions present another challenge. Stochastic sampling means that some alleles may be missed entirely, and allelic balance can deviate from the expected 50:50 ratio in heterozygotes. Somatic mosaic variants at low allele fraction can be mistaken for noise, while true germline variants may be undercalled.\nComplex variants and representation choices are also problematic. Small indels near homopolymers, multi-nucleotide variants, and overlapping indels can be represented as a single complex variant or decomposed into multiple SNVs, depending on the caller and normalization conventions. Discrepancies in representation complicate comparison across pipelines and benchmarks.\nThe deep learning models in later chapters inherit these errors and uncertainties. If a variant never enters the VCF, no model trained on VCFs can learn its effect. If genotype qualities are miscalibrated, models trained on hard calls may be overconfident in regions where the input is fundamentally noisy.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#difficult-regions-for-variant-calling",
    "href": "p1-ch01-ngs.html#difficult-regions-for-variant-calling",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.6 Difficult Regions for Variant Calling",
    "text": "1.6 Difficult Regions for Variant Calling\nCertain regions of the genome are inherently difficult to call with short reads, regardless of algorithmic sophistication. These regions are disproportionately responsible for discordant calls between pipelines and technologies (Li 2014).\n\n1.6.1 Segmental Duplications and Paralogs\nRegions with high sequence identity to other parts of the genome confound short-read aligners. Paralogous genes, such as SMN1 and SMN2, or CYP2D6 and its pseudogenes, are particularly challenging. Reads from one copy may map equally well to another, leading to ambiguous alignments and inflated mapping qualities if the ambiguity is not recognized. Variant callers may undercall true variation (to avoid false positives) or call spurious variants in the wrong paralog.\n\n\n1.6.2 Low-Complexity and Repetitive Sequence\nHomopolymers, short tandem repeats, and other low-complexity regions challenge both sequencing chemistry and base calling. Indel error rates are especially high, and many pipelines mask or flag these regions as low confidence. Yet variation in repeats can be biologically important, for example in triplet repeat expansion disorders, so models trained on callsets that ignore these regions will inherit blind spots.\n\n\n1.6.3 The HLA Region: A Case Study\nThe human leukocyte antigen (HLA) locus on chromosome 6p21 is among the most polymorphic regions in the human genome and among the most clinically important. HLA genes (HLA-A, HLA-B, HLA-C, HLA-DRB1, and others) harbor extensive allelic diversity, structural variation, and copy-number changes. Local sequence similarity, gene conversions, and pseudogenes create a dense thicket of near-identical sequences.\nHLA is difficult to call for several reasons. The extreme polymorphism means that many alleles differ by only a few bases, while others involve larger structural differences. Different HLA alleles may differ by only a few nucleotides, making accurate allele-level typing difficult with short reads alone. High homology among closely related genes and pseudogenes confuses alignment and local assembly. Standard reference-based alignment struggles because reads may match the reference poorly even when they represent common, well-characterized alleles. Structural variation and copy number differences, especially in class II regions, violate assumptions of simple diploid models. Reads carrying non-reference HLA alleles may fail to align or align with low mapping quality, causing systematic undercalling of alternate alleles.\nDespite these challenges, accurate HLA typing is essential for several clinical applications. In transplantation, HLA matching between donor and recipient is critical for solid organ and hematopoietic stem cell transplant outcomes. HLA alleles are the strongest genetic risk factors for many autoimmune conditions, including type 1 diabetes, rheumatoid arthritis, and multiple sclerosis; fine-mapping causal alleles and amino acid positions requires accurate genotyping (Sakaue et al. 2023). Specific HLA alleles, such as HLA-B*57:01 for abacavir and HLA-B*15:02 for carbamazepine, are pharmacogenomic markers for severe adverse drug reactions (Mallal et al. 2008; Chung et al. 2004). HLA diversity also shapes immune responses to pathogens, including HIV, hepatitis viruses, and SARS-CoV-2 (Robinson et al. 2020; Sakaue et al. 2023).\nBecause standard variant callers perform poorly in HLA, specialized tools have been developed. HLA imputation methods use dense reference panels to impute HLA alleles from array genotypes, enabling large-scale association studies (Sakaue et al. 2023). Sequence-based typing tools such as T1K perform HLA and KIR (killer immunoglobulin-like receptor) genotyping directly from WES, WGS, or RNA-seq data by aligning reads against allele databases (such as IPD-IMGT/HLA) rather than the linear reference genome (Song et al. 2022). Graph-based approaches that incorporate known HLA alleles as alternate paths can improve alignment and variant calling in this region (Garrison et al. 2018; Liao et al. 2023).\nFor the purposes of this book, HLA exemplifies a broader lesson: regions that are biologically rich are often technically difficult. Deep models trained on callsets that downweight or exclude these regions inherit their absence, and careful evaluation must either explicitly include or explicitly acknowledge them.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Zoomed-in view of the HLA region comparing a linear reference vs. graph/pangenome representation, with multiple alternative haplotypes and structural variants, highlighting why linear alignment fails and how graph alignment improves recall.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#benchmarking-and-ground-truth",
    "href": "p1-ch01-ngs.html#benchmarking-and-ground-truth",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.7 Benchmarking and Ground Truth",
    "text": "1.7 Benchmarking and Ground Truth\nEvaluating variant callers requires high-confidence truth sets and standardized benchmarking tools. Without careful benchmarking, it is easy to overfit to specific datasets, underestimate errors in difficult regions, or misinterpret the consequences of small improvements.\n\n1.7.1 GIAB Reference Samples\nThe Genome in a Bottle (GIAB) Consortium, coordinated by NIST, provides extensively characterized reference samples with validated variant calls across most of the genome (Zook et al. 2019). The primary GIAB samples include NA12878 (also known as HG001), a well-studied female of European ancestry from the CEPH/Utah pedigree with the longest history of characterization. The collection also includes HG002 through HG007: an Ashkenazi Jewish trio (HG002 to HG004) and a Han Chinese trio (HG005 to HG007), providing diversity and enabling trio-based validation.\nFor each sample, GIAB provides high-confidence variant calls, representing consensus calls derived from multiple sequencing technologies and variant callers that constitute the best current estimate of true genotypes. They also define high-confidence regions, genomic intervals where the truth set is believed to be reliable, as well as BED files defining difficult regions and stratifications by genomic context. Benchmarking tools such as hap.py and RTG Tools enable standardized comparison of callsets against truth, implementing reproducible reporting of precision, recall, and F1 by variant type (Krusche et al. 2019; “RealTimeGenomics/Rtg-Core” 2025).\n\n\n1.7.2 Benchmarking Metrics\nStandard metrics for variant calling include recall (sensitivity), defined as the fraction of true variants in the benchmark that are recovered by the caller; precision (positive predictive value), defined as the fraction of called variants that are present in the benchmark truth set; and F1 score, the harmonic mean of precision and recall providing a single summary statistic. These are typically reported separately for SNVs and indels and may be stratified by genomic context, such as performance inside versus outside difficult regions.\nMetrics can be defined per-variant, per-genotype, or per-site, and can also be aggregated at the sample level. For downstream models, genotype-level accuracy (getting the zygosity right) and sample-level completeness (fraction of callable genotypes per sample) are often more relevant than simply counting variant matches.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Example precision-recall or ROC curves for two variant callers evaluated on a GIAB-like benchmark, plus a small confusion-matrix-style illustration showing how false positives and false negatives map to the metrics.\n\n\n\n\n1.7.3 Limitations of Current Benchmarks\nGIAB truth sets have known limitations. They are derived primarily from a small number of deeply sequenced samples, often of European ancestry, and initially focused on “easy” regions with high confidence. High-confidence regions cover only approximately 85 to 90 percent of the genome, so performance in excluded regions is unknown. Performance in underrepresented ancestries, in complex regions, and for structural variants may differ substantially from GIAB metrics (Zook et al. 2019; Liao et al. 2023).\nMoreover, when benchmarks are reused for method development, there is a risk of overfitting to the benchmark: pipelines may be tuned to maximize F1 on GIAB-like datasets without improving performance in real-world cohorts. For deep learning-based callers, which have large capacity to absorb quirks in training data, this risk is especially salient. Later chapters revisit similar issues for benchmarking and evaluating deep models (Chapter 18, Chapter 19).\nOngoing efforts, including the T2T Consortium’s complete genome assemblies and the Human Pangenome Reference Consortium’s diverse haplotype collection, are expanding the scope of benchmarking resources (Liao et al. 2023).",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#sec-deepvar",
    "href": "p1-ch01-ngs.html#sec-deepvar",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.8 DeepVariant: CNNs for Variant Calling",
    "text": "1.8 DeepVariant: CNNs for Variant Calling\nDeepVariant replaces much of the hand-engineered logic in classical pipelines with a deep convolutional neural network that predicts genotypes directly from read pileups (Poplin et al. 2018). It is a canonical example of using deep learning to improve an existing workflow without fully rethinking the problem formulation.\n\n1.8.1 Image-Like Pileup Representation\nAround each candidate variant site, DeepVariant constructs a multi-channel tensor resembling an image. Each row corresponds to a read overlapping the site, with one dimension indexing positions relative to the candidate site. Channels encode information such as reference match/mismatch status, Phred-scaled base quality scores, mapping quality, strand orientation, allele support (reference versus alternate), and additional alignment features. The reference sequence and candidate alleles are overlaid.\nThis representation turns the variant calling problem into an image classification task: given a small, fixed-size “picture” of the local alignment context, predict the probability of each genotype. The pileup tensor captures not just which bases are present, but how they are arranged across reads, enabling the model to detect patterns like strand-biased support or mismatches clustered at read ends.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Example DeepVariant-style pileup image with color channels labeled (reference, base identity, base quality, strand, mapping quality), showing how reads stack around a potential variant site.\n\n\n\n\n1.8.2 Inception-Style CNN Classifier\nDeepVariant uses an Inception-style CNN architecture originally developed for natural image classification. Trained on high-confidence truth sets such as GIAB genomes, the CNN processes the pileup tensor through multiple convolutional layers, pooling operations, and non-linearities, finally outputting genotype probabilities for each candidate site (Poplin et al. 2018). It learns to recognize true variant patterns, including balanced allele support across strands, consistent base qualities, and clean alignments, while rejecting artifacts such as strand-biased support, mapping pileups in repeats, and inconsistent quality profiles.\nCrucially, DeepVariant learns to weigh quality signals jointly and end-to-end, rather than relying on manually defined summary statistics or post-hoc recalibration. During training, the model sees many examples of true variants and non-variants, along with their associated pileups, and learns complex decision boundaries that combine base quality, mapping quality, local context, and read-level patterns. Where VQSR fits a separate model on hand-selected annotations after calling, DeepVariant integrates the raw evidence directly into its classification.\nBecause the model is trained end-to-end on labeled examples, its genotype likelihoods tend to be well calibrated across a range of sequencing chemistries, instruments, and read lengths, especially when fine-tuned for specific settings (Yun et al. 2021). Once trained, the same architecture generalizes across whole-genome versus whole-exome data, PCR-free versus PCR-amplified libraries, and different instrument models and read lengths. This contrasts with classical pipelines where calibration is often a separate, post hoc step.\n\n\n1.8.3 Cohort Calling with DeepVariant and GLnexus\nDeepVariant operates primarily at the per-sample level: for each sample, it produces a gVCF of genotype likelihoods and candidate variant calls. To generate a multi-sample VCF, these gVCFs are combined by a joint genotyper and cohort-level variant filter.\nGLnexus is a widely used system for joint calling DeepVariant gVCFs at cohort scale (Yun et al. 2021). GLnexus merges per-sample likelihoods, applies cohort-level priors, and performs multi-sample genotype refinement and filtering. Together, DeepVariant and GLnexus form a modular pipeline: DeepVariant replaces HaplotypeCaller as the per-sample likelihood engine, while the overall structure (per-sample calls → cohort-level joint calling → filtering) remains similar.\nJoint calling matters for several reasons. It improves sensitivity for rare variants: a variant observed in only one or two individuals may have weak per-sample evidence, but by combining likelihoods across carriers, joint calling can recover true rare variants that would be filtered in single-sample analysis. Joint calling ensures consistent representation, so that the same variants are genotyped across all samples, avoiding the problem of comparing different candidate variant sites. Cohort-level quality filters can identify and remove systematic artifacts that affect subsets of samples, reducing batch effects and improving allele frequency estimates for downstream GWAS and PRS accuracy.\nThis combination has become a de facto standard for large WES and WGS projects, including recent releases of gnomAD and UK Biobank (Karczewski et al. 2020; Bycroft et al. 2018).\n\n\n1.8.4 Comparison: Classical Pipelines vs. DeepVariant\n\n\n\n\n\n\n\n\nAspect\nGATK HaplotypeCaller\nDeepVariant\n\n\n\n\nCore approach\nPair-HMM + hand-crafted heuristics\nCNN on pileup tensors\n\n\nFeature engineering\nExpert-designed (MQ, DP, FS, etc.)\nLearned end-to-end from data\n\n\nRead independence\nAssumed (violated in practice)\nImplicitly models dependencies across reads\n\n\nCalibration\nVQSR post-hoc recalibration\nWell-calibrated likelihoods after training\n\n\nGeneralization\nRequires species/platform tuning\nTransfers across species and platforms\n\n\nStructural variants\nLimited (SNVs/indels only)\nLimited (SNVs/indels only)\n\n\nImplementation burden\nMany interacting modules and thresholds\nOne large model + simpler pre/post-processing\n\n\n\nBoth approaches achieve comparable accuracy on high-quality Illumina data, but DeepVariant often shows advantages in difficult contexts, in calibration, and in cross-platform generalization. At the same time, DeepVariant still lives inside a broader classical pipeline: alignment, duplicate marking, BQSR, and joint genotyping remain largely unchanged.\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Side-by-side schematic of a classical GATK-style pipeline vs. a DeepVariant-enhanced pipeline, emphasizing which components are hand-crafted vs. learned, and where DL models plug into the overall workflow.\n\n\nBeyond DeepVariant, many long-read and graph-based variant callers adopt the same core idea: learn a mapping from read pileups or local assemblies to genotype probabilities. DeepVariant is thus a useful conceptual bridge between classical pipelines and the more ambitious, end-to-end models discussed later.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch01-ngs.html#significance-for-genomic-deep-learning",
    "href": "p1-ch01-ngs.html#significance-for-genomic-deep-learning",
    "title": "1  Sequencing: From Reads to Variants",
    "section": "1.9 Significance for Genomic Deep Learning",
    "text": "1.9 Significance for Genomic Deep Learning\nNGS and variant calling set the stage for everything else in this book. They determine what data we model, where we have coverage, and where we have systematic blind spots.\n\n1.9.1 Defining the Atoms We Model\nThe output of WES and WGS pipelines, a VCF of SNVs, indels, and inferred genotypes, defines the atoms that many downstream models operate on. Polygenic risk scores (PGS), GWAS summary statistics, genotype-based foundation models, and many variant annotation tools treat variants (or genomic positions) as discrete tokens.\nIf a variant is never called, it never appears in the training data, and no model can learn its effect. False positives introduce noise into labels and features; false negatives create blind spots where models must extrapolate from incomplete information. Choices about phasing, imputation, and representation (for example, multi-allelic versus biallelic decomposition) also determine whether models see haplotypes, genotypes, or scalar summary statistics. The quality of variant calls directly limits the quality of downstream models.\n\n\n1.9.2 Constraining Downstream Models\nUpstream decisions constrain what downstream sequence and variant effect models can learn. If an assay rarely observes indels or structural variants in certain repeat classes, deep models trained on those callsets will effectively learn a world where such variants do not exist. If certain ancestries are underrepresented in reference panels or truth sets, models trained on those data may perform poorly for those groups while appearing well-calibrated in benchmarks. If variant quality metrics (MQ, GQ, depth, strand bias) are heavily used in filtering, the resulting callset may be cleaner but less representative of challenging contexts. Difficult regions such as HLA and segmental duplications may be systematically excluded from training data, and models inherit their biases and gaps.\nFor regulatory sequence models and variant effect predictors in coding and noncoding regions (Chapter 11, Section 10.1, Section 10.3, Chapter 4), upstream variant calling determines which sites appear as candidates and how often certain patterns (for example, homopolymer indels, splice acceptor disruptions) are observed.\n\n\n1.9.3 Effect Sizes and Practical Impact\nVariant calling decisions matter because they modulate the effective effect sizes that downstream models can detect and learn from. Several regimes are worth distinguishing.\nCommon variants with small effects. For highly polygenic traits, individual variant effect sizes are tiny. A modest amount of genotype error or imputation noise mostly acts as additional measurement error, attenuating estimated effect sizes and reducing GWAS power but rarely creating spurious large effects. In this regime, improving variant calling in already “easy” regions yields diminishing returns compared to increasing sample size or improving phenotype quality.\nRare variants with large effects. Loss-of-function variants, damaging missense mutations, and certain splice-altering variants can have large effects on disease risk and molecular phenotypes. Here, false negatives dominate: if the variant is never called or is assigned low-quality genotypes, its effect is invisible to association tests and to deep models trained on called genotypes. Small improvements in recall in these regions can have outsized impact on gene discovery and clinical interpretation.\nMis-calibrated genotype probabilities. Many downstream models implicitly assume that genotype calls and quality scores are well calibrated. Overconfident but wrong calls effectively “inflate” effect size estimates for artifacts, while underconfident correct calls dilute true effects. DeepVariant-like calibration tends to preserve effect size estimates better, especially when models explicitly use genotype probabilities rather than hard calls.\nImputation quality and LD structure. For imputed variants, the squared correlation \\(r^2\\) between true and imputed genotypes acts as an attenuation factor on effect sizes: an association with true effect \\(\\beta\\) behaves as if its effect were approximately \\(r^2 \\beta\\) in downstream analyses. Improvements in imputation quality, especially in underrepresented ancestries or for low-frequency variants, therefore directly scale the effective effect sizes that models can learn.\nClinically critical loci and difficult regions. Many pharmacogenomic and immune-related effect sizes reside in technically challenging regions such as HLA, CYP gene families, and other paralog-rich loci. Global metrics (for example, genome-wide F1) may change only slightly when these regions improve, but the clinical effect size of such improvements, measured in terms of adverse drug reactions avoided or transplant matches correctly identified, can be enormous.\nWhen designing and evaluating deep models, it is therefore not enough to ask whether an upstream pipeline has “high accuracy” overall. We care about where improvements occur and which effect sizes they amplify or attenuate. Later chapters return to these themes when we discuss polygenic scores, variant interpretation, and clinical deployment (Chapter 3, Chapter 4, Chapter 23).\n\n\n1.9.4 Motivating End-to-End Learning\nDeepVariant is an early example of replacing a hand-designed component of the pipeline with a learned model. This paradigm, replacing feature engineering with learned representations, recurs throughout the book. DeepSEA and Basenji (Section 10.1) learn regulatory grammars from sequence. SpliceAI (Section 10.3) predicts splicing from local sequence context. DNA language models (Chapter 11) learn general-purpose representations from unlabeled genomes. In each case, the question is whether learned representations outperform hand-crafted features, and under what conditions.\nDeepVariant raises broader questions that echo throughout this book. Which parts of genomic analysis pipelines are amenable to end-to-end learning? When do learned representations and decision rules outperform hand-crafted features? How do we ensure that learned models remain interpretable and robust?\nSome recent work pushes further upstream, modeling raw sequencing signal (for example, nanopore current traces) or minimally processed reads directly, with the goal of learning both alignment and variant calling jointly. Others propose downstream models that reason directly over reads and phenotypes, bypassing intermediate variant calls. These directions blur the line between “variant calling” and “downstream modeling,” and foreshadow the joint, multi-scale foundation models discussed in later parts of this book.\n\n\n1.9.5 Looking Ahead\nThe remaining chapters in Part I describe how variant calls are linked to phenotypes, used to construct polygenic scores (Chapter 3), and integrated with sequence-based models of regulatory function and splicing (Chapter 11, Section 10.1, Section 10.3, Chapter 4). We also return to upstream choices when discussing confounders, dataset artifacts, and evaluation strategies (Chapter 21, Chapter 18, Chapter 19).\nFor now, the key takeaways are:\n\nVariant calling is a complex, multi-stage pipeline whose outputs are treated as ground truth by most downstream models.\nErrors, biases, and design choices in this pipeline propagate into every subsequent analysis.\nDeep learning has already improved important components of the pipeline and will likely play an increasing role in future “end-to-end” genomic systems.\n\n\n\n\n\n\n\nWarning\n\n\n\nVisual TODO: Conceptual “stack” figure showing raw sequence/signal → variant calling → variant-level representations (VCF, annotations) → genomic foundation models → downstream tasks (PGS, regulatory prediction, variant interpretation), with arrows indicating how errors/choices propagate upward.\n\n\n\n\n\n\nBrowning, Brian L., Xiaowen Tian, Ying Zhou, and Sharon R. Browning. 2021. “Fast Two-Stage Phasing of Large-Scale Sequence Data.” American Journal of Human Genetics 108 (10): 1880–90. https://doi.org/10.1016/j.ajhg.2021.08.005.\n\n\nBycroft, Clare, Colin Freeman, Desislava Petkova, Gavin Band, Lloyd T. Elliott, Kevin Sharp, Allan Motyer, et al. 2018. “The UK Biobank Resource with Deep Phenotyping and Genomic Data.” Nature 562 (7726): 203–9. https://doi.org/10.1038/s41586-018-0579-z.\n\n\nChung, Wen-Hung, Shuen-Iu Hung, Hong-Shang Hong, Mo-Song Hsih, Li-Cheng Yang, Hsin-Chun Ho, Jer-Yuarn Wu, and Yuan-Tsong Chen. 2004. “A Marker for Stevens–Johnson Syndrome.” Nature 428 (6982): 486–86. https://doi.org/10.1038/428486a.\n\n\nDabernig-Heinz, Johanna, Mara Lohde, Martin Hölzer, Adriana Cabal, Rick Conzemius, Christian Brandt, Matthias Kohl, et al. 2024. “A Multicenter Study on Accuracy and Reproducibility of Nanopore Sequencing-Based Genotyping of Bacterial Pathogens.” Journal of Clinical Microbiology 62 (9): e00628–24. https://doi.org/10.1128/jcm.00628-24.\n\n\nDePristo, Mark A., Eric Banks, Ryan Poplin, Kiran V. Garimella, Jared R. Maguire, Christopher Hartl, Anthony A. Philippakis, et al. 2011. “A Framework for Variation Discovery and Genotyping Using Next-Generation DNA Sequencing Data.” Nature Genetics 43 (5): 491–98. https://doi.org/10.1038/ng.806.\n\n\nGarrison, Erik, Jouni Sirén, Adam M. Novak, Glenn Hickey, Jordan M. Eizenga, Eric T. Dawson, William Jones, et al. 2018. “Variation Graph Toolkit Improves Read Mapping by Representing Genetic Variation in the Reference.” Nature Biotechnology 36 (9): 875–79. https://doi.org/10.1038/nbt.4227.\n\n\nGoodwin, Sara, John D. McPherson, and W. Richard McCombie. 2016. “Coming of Age: Ten Years of Next-Generation Sequencing Technologies.” Nature Reviews Genetics 17 (6): 333–51. https://doi.org/10.1038/nrg.2016.49.\n\n\nJiang, Tao, Yongzhuang Liu, Yue Jiang, Junyi Li, Yan Gao, Zhe Cui, Yadong Liu, Bo Liu, and Yadong Wang. 2020. “Long-Read-Based Human Genomic Structural Variation Detection with cuteSV.” Genome Biology 21 (1): 189. https://doi.org/10.1186/s13059-020-02107-y.\n\n\nKarczewski, Konrad J., Laurent C. Francioli, Grace Tiao, Beryl B. Cummings, Jessica Alföldi, Qingbo Wang, Ryan L. Collins, et al. 2020. “The Mutational Constraint Spectrum Quantified from Variation in 141,456 Humans.” Nature 581 (7809): 434–43. https://doi.org/10.1038/s41586-020-2308-7.\n\n\nKrusche, Peter, Len Trigg, Paul C. Boutros, Christopher E. Mason, Francisco M. De La Vega, Benjamin L. Moore, Mar Gonzalez-Porta, et al. 2019. “Best Practices for Benchmarking Germline Small Variant Calls in Human Genomes.” Nature Biotechnology 37 (5): 555–60. https://doi.org/10.1038/s41587-019-0054-x.\n\n\nLi, Heng. 2013. “Aligning Sequence Reads, Clone Sequences and Assembly Contigs with BWA-MEM.” arXiv. https://doi.org/10.48550/arXiv.1303.3997.\n\n\n———. 2014. “Towards Better Understanding of Artifacts in Variant Calling from High-Coverage Samples.” Bioinformatics 30 (20): 2843–51. https://doi.org/10.1093/bioinformatics/btu356.\n\n\n———. 2018. “Minimap2: Pairwise Alignment for Nucleotide Sequences.” Bioinformatics 34 (18): 3094–3100. https://doi.org/10.1093/bioinformatics/bty191.\n\n\nLiao, Wen-Wei, Mobin Asri, Jana Ebler, Daniel Doerr, Marina Haukness, Glenn Hickey, Shuangjia Lu, et al. 2023. “A Draft Human Pangenome Reference.” Nature 617 (7960): 312–24. https://doi.org/10.1038/s41586-023-05896-x.\n\n\nLoh, Po-Ru, Petr Danecek, Pier Francesco Palamara, Christian Fuchsberger, Yakir A Reshef, Hilary K Finucane, Sebastian Schoenherr, et al. 2016. “Reference-Based Phasing Using the Haplotype Reference Consortium Panel.” Nature Genetics 48 (11): 1443–48. https://doi.org/10.1038/ng.3679.\n\n\nMallal, Simon, Elizabeth Phillips, Giampiero Carosi, Jean-Michel Molina, Cassy Workman, Janez Tomažič, Eva Jägel-Guedes, et al. 2008. “HLA-B*5701 Screening for Hypersensitivity to Abacavir.” New England Journal of Medicine 358 (6): 568–79. https://doi.org/10.1056/NEJMoa0706135.\n\n\nNielsen, Rasmus, Joshua S. Paul, Anders Albrechtsen, and Yun S. Song. 2011. “Genotype and SNP Calling from Next-Generation Sequencing Data.” Nature Reviews. Genetics 12 (6): 443–51. https://doi.org/10.1038/nrg2986.\n\n\nNurk, Sergey, Sergey Koren, Arang Rhie, Mikko Rautiainen, Andrey V. Bzikadze, Alla Mikheenko, Mitchell R. Vollger, et al. 2022. “The Complete Sequence of a Human Genome.” Science 376 (6588): 44–53. https://doi.org/10.1126/science.abj6987.\n\n\nO’Connell, Jared, Deepti Gurdasani, Olivier Delaneau, Nicola Pirastu, Sheila Ulivi, Massimiliano Cocca, Michela Traglia, et al. 2014. “A General Approach for Haplotype Phasing Across the Full Spectrum of Relatedness.” PLOS Genetics 10 (4): e1004234. https://doi.org/10.1371/journal.pgen.1004234.\n\n\n“PacificBiosciences/Pbsv.” 2025. PacBio. https://github.com/PacificBiosciences/pbsv.\n\n\nPoplin, Ryan, Pi-Chuan Chang, David Alexander, Scott Schwartz, Thomas Colthurst, Alexander Ku, Dan Newburger, et al. 2018. “[DeepVariant] A Universal SNP and Small-Indel Variant Caller Using Deep Neural Networks.” Nature Biotechnology 36 (10): 983–87. https://doi.org/10.1038/nbt.4235.\n\n\n“RealTimeGenomics/Rtg-Core.” 2025. Real Time Genomics. https://github.com/RealTimeGenomics/rtg-core.\n\n\nRobinson, James, Dominic J Barker, Xenia Georgiou, Michael A Cooper, Paul Flicek, and Steven G E Marsh. 2020. “IPD-IMGT/HLA Database.” Nucleic Acids Research 48 (D1): D948–55. https://doi.org/10.1093/nar/gkz950.\n\n\nSakaue, Saori, Saisriram Gurajala, Michelle Curtis, Yang Luo, Wanson Choi, Kazuyoshi Ishigaki, Joyce B. Kang, et al. 2023. “Tutorial: A Statistical Genetics Guide to Identifying HLA Alleles Driving Complex Disease.” Nature Protocols 18 (9): 2625–41. https://doi.org/10.1038/s41596-023-00853-4.\n\n\nShafin, Kishwar, Trevor Pesout, Pi-Chuan Chang, Maria Nattestad, Alexey Kolesnikov, Sidharth Goel, Gunjan Baid, et al. 2021. “Haplotype-Aware Variant Calling with PEPPER-Margin-DeepVariant Enables High Accuracy in Nanopore Long-Reads.” Nature Methods 18 (11): 1322–32. https://doi.org/10.1038/s41592-021-01299-w.\n\n\nSmolka, Moritz, Luis F. Paulin, Christopher M. Grochowski, Dominic W. Horner, Medhat Mahmoud, Sairam Behera, Ester Kalef-Ezra, et al. 2024. “Detection of Mosaic and Population-Level Structural Variants with Sniffles2.” Nature Biotechnology 42 (10): 1571–80. https://doi.org/10.1038/s41587-023-02024-y.\n\n\nSong, Li, Gali Bai, X. Shirley Liu, Bo Li, and Heng Li. 2022. “T1K: Efficient and Accurate KIR and HLA Genotyping with Next-Generation Sequencing Data.” bioRxiv. https://doi.org/10.1101/2022.10.26.513955.\n\n\nVan der Auwera, Geraldine A., Mauricio O. Carneiro, Christopher Hartl, Ryan Poplin, Guillermo del Angel, Ami Levy-Moonshine, Tadeusz Jordan, et al. 2018. “From FastQ Data to High-Confidence Variant Calls: The Genome Analysis Toolkit Best Practices Pipeline.” Current Protocols in Bioinformatics 43 (1): 11.10.1–33. https://doi.org/10.1002/0471250953.bi1110s43.\n\n\nWenger, Aaron M., Paul Peluso, William J. Rowell, Pi-Chuan Chang, Richard J. Hall, Gregory T. Concepcion, Jana Ebler, et al. 2019. “Accurate Circular Consensus Long-Read Sequencing Improves Variant Detection and Assembly of a Human Genome.” Nature Biotechnology 37 (10): 1155–62. https://doi.org/10.1038/s41587-019-0217-9.\n\n\nYun, Taedong, Helen Li, Pi-Chuan Chang, Michael F Lin, Andrew Carroll, and Cory Y McLean. 2021. “Accurate, Scalable Cohort Variant Calls Using DeepVariant and GLnexus.” Bioinformatics 36 (24): 5582–89. https://doi.org/10.1093/bioinformatics/btaa1081.\n\n\nZheng, Zhenxian, Shumin Li, Junhao Su, Amy Wing-Sze Leung, Tak-Wah Lam, and Ruibang Luo. 2022. “Symphonizing Pileup and Full-Alignment for Deep Learning-Based Long-Read Variant Calling.” Nature Computational Science 2 (12): 797–803. https://doi.org/10.1038/s43588-022-00387-x.\n\n\nZook, Justin M., Jennifer McDaniel, Nathan D. Olson, Justin Wagner, Hemang Parikh, Haynes Heaton, Sean A. Irvine, et al. 2019. “An Open Resource for Accurately Benchmarking Small Variant and Reference Calls.” Nature Biotechnology 37 (5): 561–66. https://doi.org/10.1038/s41587-019-0074-6.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sequencing: From Reads to Variants</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html",
    "href": "p1-ch02-data.html",
    "title": "2  The Genomic Data Landscape",
    "section": "",
    "text": "2.1 Why Genomic Data Resources Matter\nOnce we can sequence genomes and call variants, we immediately face a new problem: interpretation. No single dataset is sufficient to decide whether a variant is benign, pathogenic, or relevant to a trait. Instead, modern genomics relies on a mosaic of complementary resources: reference genomes and gene annotations that define coordinates and consequences, population variation catalogs that reveal what survives in healthy individuals, cohort and biobank datasets that link variation to phenotypes, functional genomics atlases that map biochemical activity, and clinical databases that aggregate expert interpretations.\nThis chapter surveys these foundational resources. Later chapters draw from them repeatedly, either directly as model inputs or indirectly as labels, benchmarks, and priors. We begin with general genomic infrastructure (references, variation catalogs, cohorts) and then turn to functional and expression resources that provide the training labels for sequence-to-function models. Throughout, we emphasize not only what each resource contains, but also the biases and gaps that will propagate into the deep learning models built on top of them.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#why-genomic-data-resources-matter",
    "href": "p1-ch02-data.html#why-genomic-data-resources-matter",
    "title": "2  The Genomic Data Landscape",
    "section": "",
    "text": "Warning\n\n\n\nVisual suggestion: High-level “subway map” of the data landscape, showing how reads → reference genomes → variant catalogs → cohorts → functional genomics → expression → clinical resources connect, with arrows indicating where later chapters plug in (e.g., Section 10.1, Chapter 3, Chapter 4).",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#reference-genomes-and-gene-annotations",
    "href": "p1-ch02-data.html#reference-genomes-and-gene-annotations",
    "title": "2  The Genomic Data Landscape",
    "section": "2.2 Reference Genomes and Gene Annotations",
    "text": "2.2 Reference Genomes and Gene Annotations\nEvery genomic analysis begins with a coordinate system. Reference genomes define the scaffold onto which sequencing reads are mapped, while gene annotations overlay that scaffold with biological meaning, specifying where transcripts begin and end, which regions encode protein, and how exons are spliced together. These resources are so foundational that their assumptions often become invisible: a variant’s consequence, a gene’s constraint score, and a model’s training labels all depend on choices embedded in the reference assembly and annotation release. Understanding these dependencies is essential for interpreting results, recognizing systematic biases, and anticipating how analyses will generalize across datasets built on different genomic foundations.\n\n2.2.1 Reference Assemblies\nMost modern pipelines align reads to a small number of reference assemblies, predominantly GRCh38 or the newer T2T-CHM13 (Nurk et al. 2022). A reference genome is not simply a consensus sequence; it encodes a series of consequential decisions about how to represent duplications, alternate haplotypes, and unresolved gaps, all annotated with coordinates that downstream tools assume are stable.\nThe choice of reference shapes everything that follows. It determines which regions are “mappable” by short reads, how structural variants are represented, and how comparable results will be across cohorts and over time. Graph-based and pangenome references relax the assumption of a single linear reference, representing multiple haplotypes and ancestries within a unified coordinate system (Liao et al. 2023). Comparative multi-species references, such as those used in mammalian constraint maps (Sullivan et al. 2023), extend this idea across species, providing the evolutionary conservation scores that feed directly into deleteriousness predictors and gene-level constraint metrics.\nFor most of the datasets used in this book, however, the practical reality is still GRCh37 or GRCh38 coordinates, often with incremental patches. Models trained on these resources therefore inherit their blind spots: incomplete or collapsed segmental duplications, underrepresented ancestries in pangenome construction, and uneven quality across chromosomes and regions.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Side-by-side schematic of (1) a linear reference, (2) a graph/pangenome reference, and (3) a conservation track derived from multi-species alignment, with callouts indicating how each affects variant calling and model labels.\n\n\n\n\n2.2.2 Gene Models\nGene annotation databases such as GENCODE and RefSeq define exon-intron structures, canonical and alternative transcripts, start and stop codons, and untranslated regions that allow us to interpret variants in biological context (Frankish et al. 2019; O’Leary et al. 2016). These annotations are critical for distinguishing coding from non-coding variants, identifying splice-disrupting mutations, and mapping functional genomics signals to genes. They also establish the units (genes, transcripts, exons) that many downstream models implicitly operate on.\nThe MANE Select project provides a single matched transcript per protein-coding gene that is identical between GENCODE and RefSeq, simplifying clinical interpretation and reporting but further privileging a single isoform over biological complexity (Morales et al. 2022). This makes variant descriptions more consistent across laboratories and reports, yet it also risks encouraging a “one true isoform” mindset in contexts where tissue-specific or developmentally regulated isoforms matter.\nMany downstream resources, from variant effect predictors to polygenic score pipelines, implicitly assume that gene models are correct and complete. In practice, new isoforms continue to be discovered, alternative splicing remains incompletely cataloged, and cell-type-specific transcripts may be missing from bulk-derived annotations. Non-coding RNA genes and pseudogenes are even more unevenly annotated. These gaps propagate through every tool built on them: a model cannot learn about a regulatory element for a transcript that does not exist in the annotation.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Genome-browser-style panel showing (1) reference sequence, (2) two different transcript models for the same gene (GENCODE vs RefSeq), and (3) the MANE Select transcript, with a highlighted variant whose consequence changes depending on the chosen transcript.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#population-variant-catalogs-and-allele-frequencies",
    "href": "p1-ch02-data.html#population-variant-catalogs-and-allele-frequencies",
    "title": "2  The Genomic Data Landscape",
    "section": "2.3 Population Variant Catalogs and Allele Frequencies",
    "text": "2.3 Population Variant Catalogs and Allele Frequencies\nPopulation variant catalogs provide the empirical foundation for distinguishing pathogenic mutations from benign polymorphisms. Allele frequency, the proportion of chromosomes in a reference population carrying a given variant, serves as a powerful prior: variants observed at appreciable frequency in healthy individuals are unlikely to cause severe early-onset disease, while ultra-rare variants demand closer scrutiny. Beyond simple filtering, allele frequencies inform statistical frameworks for case-control association, provide training signal for deleteriousness predictors, and enable imputation of ungenotyped variants through linkage disequilibrium. The catalogs described below have progressively expanded in sample size, ancestral diversity, and annotation depth, transforming variant interpretation from an ad hoc exercise into a quantitative discipline.\nA crucial nuance is that these catalogs record variants that are compatible with being sampled in the first place. Gene-lethal variants that cause embryonic or early childhood death rarely appear, even if they are biologically important. Variants that cause severe Mendelian disease may be strongly depleted, while variants that predispose to late-onset disease (e.g., Alzheimer’s risk alleles) can persist at much higher frequencies. Throughout the book, we will repeatedly return to these distinctions because models trained on population data can only learn from the variants that are actually present in these catalogs.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Allele-frequency spectrum for (1) common polymorphisms, (2) rare but observed variants, and (3) hypothetical gene-lethal variants that never appear, annotated with examples of disease categories and how different filters are applied in clinical interpretation.\n\n\n\n2.3.1 dbSNP and the Variant Universe\nHistorically, dbSNP aggregated known single nucleotide polymorphisms and short indels into a single catalog, providing stable identifiers (rsIDs) that serve as common currency across tools and publications, basic frequency information where available, and a convenient handle for linking to other resources (Sherry et al. 2001). Modern whole-exome and whole-genome sequencing cohorts routinely discover millions of previously unseen variants, but dbSNP identifiers remain the standard way to refer to known polymorphisms and to glue together disparate resources.\n\n\n2.3.2 1000 Genomes and Early Reference Panels\nThe 1000 Genomes Project provided one of the first widely used multi-population reference panels, enabling imputation and linkage-disequilibrium-based analyses on genotyping arrays (Auton et al. 2015). Its samples continue to serve as benchmarks for variant calling performance, and its haplotype structure underlies many imputation servers and downstream analyses (Yun et al. 2021). Although its sample size is modest by current standards, 1000 Genomes remains a conceptual template for how to build and use multi-population reference panels.\n\n\n2.3.3 The Genome Aggregation Database (gnomAD)\nThe Genome Aggregation Database aggregates exome and genome data from a wide array of cohorts into harmonized allele frequency resources (Karczewski et al. 2020). gnomAD provides high-resolution allele frequencies for SNVs and indels across diverse ancestries, constraint metrics such as pLI and LOEUF that summarize a gene’s intolerance to loss-of-function variation, and per-variant annotations flagging poor quality regions, low complexity, and other caveats. Constraint metrics, in particular, have become standard features in machine learning models that prioritize disease-relevant genes and variants.\nThese resources are indispensable for filtering common variants in Mendelian disease diagnostics, distinguishing extremely rare variants from recurrent ones, and providing population genetics priors used by variant effect predictors and deleteriousness scores like CADD (Rentzsch et al. 2019; Schubach et al. 2024). At the same time, they reflect the compositions of the cohorts they aggregate: ancestry representation is uneven, structural variants and repeat expansions are less completely cataloged than SNVs and short indels, and individuals with severe disease may be underrepresented. All of these factors shape both classical statistical analyses and the deep learning models that ingest these data.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#cohorts-biobanks-and-gwas-summary-data",
    "href": "p1-ch02-data.html#cohorts-biobanks-and-gwas-summary-data",
    "title": "2  The Genomic Data Landscape",
    "section": "2.4 Cohorts, Biobanks, and GWAS Summary Data",
    "text": "2.4 Cohorts, Biobanks, and GWAS Summary Data\nLarge-scale biobanks and population cohorts have transformed human genetics from a discipline reliant on family studies and candidate gene approaches into one powered by population-level statistical inference. These resources link genomic data to electronic health records, lifestyle questionnaires, imaging, and longitudinal outcomes, enabling discovery of genetic associations across thousands of traits simultaneously. However, the composition of these cohorts carries consequences: the overrepresentation of European-ancestry individuals in most major biobanks creates systematic gaps in variant discovery, effect-size estimation, and polygenic score portability that propagate through downstream analyses (Sirugo, Williams, and Tishkoff 2019). These ancestry biases, and strategies for addressing them, are discussed in detail in Chapter 21.\nWhile this book focuses on models rather than specific cohorts, it is important to recognize that most GWAS and polygenic score methods in Chapter 3 assume data from either array genotyping with imputation or whole-exome/whole-genome sequencing with joint calling, as in DeepVariant/GLnexus-style pipelines (Yun et al. 2021). The ascertainment, quality control, and population composition of these cohorts shape what signals can be detected and how well models generalize.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Flow diagram for a typical GWAS/PGS pipeline: cohort enrollment → genotyping/sequencing → QC → imputation → association testing → summary statistics → polygenic scores, with callouts for where bias enters (e.g., ancestry composition).\n\n\n\n2.4.1 Large Population Cohorts\nModern human genetics relies on large cohorts with genome-wide variation and rich phenotyping. UK Biobank, with approximately 500,000 participants and deep phenotyping, has become a dominant resource for methods development and benchmarking (Bycroft et al. 2018). FinnGen leverages Finland’s population history and unified healthcare records to enable large-scale discovery for a wide range of diseases (Kurki et al. 2023). The All of Us Research Program prioritizes diversity, aiming to enroll one million participants with deliberate oversampling of historically underrepresented groups (All of Us Research Program Investigators 2019). Additional resources include the Million Veteran Program, Mexican Biobank, BioBank Japan, China Kadoorie Biobank, and emerging African genomics initiatives such as H3Africa (Sirugo, Williams, and Tishkoff 2019).\nTogether, these efforts enable genome-wide association studies (GWAS) for thousands of traits, development and evaluation of polygenic scores, and fine-mapping of causal variants and genes (Marees et al. 2018; Mountjoy et al. 2021). From a modeling perspective, they provide the large-scale genotype-phenotype matrices that power new architectures, from classical linear mixed models to foundation models trained on biobank-scale data.\n\n\n2.4.2 GWAS Summary Statistics\nBeyond individual-level data, many resources distribute GWAS summary statistics: per-variant effect sizes and p-values aggregated across cohorts. The GWAS Catalog compiles published results across traits (Sollis et al. 2023), while the PGS Catalog provides curated polygenic score weights and metadata for reproducibility (Lambert et al. 2021). Frameworks like Open Targets Genetics integrate fine-mapped signals and candidate causal genes across loci (Mountjoy et al. 2021).\nThese summary data are the raw material for many polygenic score methods (Chapter 3) and statistical fine-mapping algorithms. They enable meta-analysis across cohorts, transfer of genetic findings to new populations, and integration with functional annotations to prioritize causal variants. For deep learning, they also provide a sparse, trait-level view of the genome that can be combined with richer sequence-based or functional labels.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#functional-genomics-and-regulatory-landscapes",
    "href": "p1-ch02-data.html#functional-genomics-and-regulatory-landscapes",
    "title": "2  The Genomic Data Landscape",
    "section": "2.5 Functional Genomics and Regulatory Landscapes",
    "text": "2.5 Functional Genomics and Regulatory Landscapes\nThe vast majority of the human genome lies outside protein-coding exons, yet this non-coding space harbors the regulatory logic that governs when, where, and how much each gene is expressed. Functional genomics assays provide the experimental means to map this regulatory landscape: identifying transcription factor binding sites, nucleosome positioning, chromatin accessibility, histone modifications, and three-dimensional genome organization across cell types and conditions.\nFor the purposes of this book, these datasets serve a dual role. First, they supply the biological vocabulary for interpreting non-coding variants, linking sequence changes to potential regulatory consequences. Second, and more directly, they provide the training labels for sequence-to-function deep learning models. When a model learns to predict chromatin accessibility or histone marks from DNA sequence alone, it is learning a compressed representation of the regulatory code implicit in thousands of functional genomics experiments.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Multi-track genome browser view showing DNA sequence, chromatin accessibility, histone marks, and transcription factor ChIP-seq peaks across two cell types, annotated to show how a sequence window becomes a multi-task training label vector for a model like DeepSEA.\n\n\n\n2.5.1 ENCODE, Roadmap, and Related Consortia\nProjects like ENCODE, Roadmap Epigenomics, and Gene Expression Omnibus (GEO) are primary data-generation efforts that designed coordinated experimental campaigns, selected cell types and tissues for profiling, and produced comprehensive compendia of transcription factor ChIP-seq, histone modification ChIP-seq, open chromatin assays (DNase-seq, ATAC-seq), and chromatin conformation data (Hi-C and related methods) (Kagda et al. 2025; Kundaje et al. 2015; Edgar, Domrachev, and Lash 2002). These datasets map regulatory elements, chromatin states, and higher-order genome structure with tight experimental control and uniform processing pipelines.\nThe significance of these consortia for this book is less about any individual experiment than about the scale and standardization they provide. By generating hundreds of assays across dozens of cell types with consistent protocols, ENCODE and Roadmap created canonical reference datasets that define the regulatory landscape for the cell types they profiled. Many regulatory deep learning models in Section 10.1 and Section 10.3 are effectively trained on these resources.\n\n\n2.5.2 The Cistrome Data Browser\nWhile ENCODE and Roadmap produced authoritative datasets for their chosen cell types and factors, they represent only a fraction of publicly available functional genomics experiments. The Cistrome Data Browser addresses this gap by aggregating thousands of human and mouse ChIP-seq and chromatin accessibility datasets from ENCODE, Roadmap, GEO, and individual publications into a reprocessed, searchable repository (Zheng et al. 2019). All datasets pass through a uniform quality control and processing pipeline, enabling comparisons across experiments that were originally generated by different labs with different protocols.\nCistrome provides uniform peak calls and signal tracks, metadata for cell type, factor, and experimental conditions, and tools for motif analysis and regulatory element annotation. The tradeoff is heterogeneity: while the reprocessing harmonizes computational steps, the underlying experiments vary in sample preparation, sequencing depth, and experimental design. Cistrome thus expands coverage at the cost of the tight experimental control found in the primary consortia.\n\n\n2.5.3 From Assays to Training Labels\nSequence-to-function models transform these functional genomics resources into supervised learning problems. Models like DeepSEA (see Section 10.1) draw training labels from ENCODE, Roadmap, and Cistrome-style datasets collectively: each genomic window is associated with binary or quantitative signals indicating transcription factor binding, histone modifications, or chromatin accessibility across many assays and cell types (Zhou and Troyanskaya 2015; Zhou et al. 2018).\nThe quality, coverage, and biases of these labels directly constrain what models can learn. Cell types absent from the training compendium cannot be predicted reliably. Factors with few high-quality ChIP-seq experiments will have noisier labels. Systematic differences between assay types (peak-based binary labels versus quantitative signal tracks) shape whether models learn to predict occupancy, accessibility, or something in between. These considerations become central when we examine model architectures and training strategies in Section 10.1.\n\n\n2.5.4 Deep Mutational Scanning and Multiplexed Variant Assays\nAlthough most of this chapter focuses on genomic assays, a parallel ecosystem has emerged for deep mutational scanning (DMS) and other multiplexed variant assays that measure the fitness or functional impact of thousands of protein or regulatory variants in a single experiment. Benchmarks such as ProteinGym compile large DMS datasets across proteins to evaluate and compare protein fitness predictors (Notin et al. 2023), while TraitGym plays a similar role for DNA sequence models, curating multiplexed reporter assays and other high-throughput readouts of regulatory variant effects (Benegas, Eraslan, and Song 2025).\nThese resources sit at the interface between genomic and protein-level modeling. They provide dense, quantitative labels for synthetic or near-saturated variant libraries, complementing the sparse, naturally occurring variation captured in gnomAD and biobanks. Later chapters on protein sequence models and regulatory variant prediction return to these DMS-style datasets as key benchmarks and training sources.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Cartoon of a DMS/multiplexed assay pipeline: mutagenesis → pooled library → selection/screen → sequencing → fitness score per variant, with arrows indicating how these are aggregated into ProteinGym/TraitGym-style benchmarks.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#expression-and-eqtl-resources",
    "href": "p1-ch02-data.html#expression-and-eqtl-resources",
    "title": "2  The Genomic Data Landscape",
    "section": "2.6 Expression and eQTL Resources",
    "text": "2.6 Expression and eQTL Resources\nExpression datasets link sequence variation to transcriptional consequences, providing a bridge between regulatory elements and gene-level effects. While functional genomics assays reveal where transcription factors bind and which chromatin regions are accessible, expression data answer the downstream question: does this regulatory activity actually change how much RNA a gene produces?\nExpression quantitative trait loci (eQTLs) formalize this relationship statistically, identifying genetic variants associated with changes in transcript abundance. For variant interpretation and genomic prediction, eQTLs offer mechanistic hypotheses connecting non-coding variants to specific genes and tissues. For model training, expression data provide quantitative labels that integrate across many regulatory inputs converging on a single promoter. The resources below range from population-scale bulk tissue atlases to emerging single-cell datasets that resolve expression variation at cellular resolution.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Schematic of eQTL mapping: genotype matrix + expression matrix → association scan → locus plot linking variant, regulatory element, and target gene, with tissue labels.\n\n\n\n2.6.1 Bulk Expression Atlases\nProjects like the Genotype-Tissue Expression (GTEx) consortium provide RNA-seq expression profiles across dozens of tissues, eQTL maps linking variants to gene expression changes in cis, and splicing QTLs and other molecular QTLs (The GTEx Consortium 2020). With matched genotypes and expression data from nearly 1,000 post-mortem donors across 54 tissues, GTEx established foundational insights: most genes harbor tissue-specific eQTLs, regulatory variants typically act in cis over distances of hundreds of kilobases, and expression variation explains a meaningful fraction of complex trait heritability.\nEven when not explicitly cited, GTEx-like resources underpin expression prediction models such as PrediXcan and TWAS frameworks, colocalization analyses that ask whether a GWAS signal and an eQTL share a causal variant, and expression-based prioritization of candidate genes at trait-associated loci (Gamazon et al. 2015; Gusev et al. 2016). The GTEx design has limitations: post-mortem collection introduces agonal stress artifacts, sample sizes per tissue vary considerably, and some disease-relevant tissues (such as pancreatic islets or specific brain regions) remain undersampled. Complementary resources like the eQTLGen Consortium aggregate eQTL results from blood across larger sample sizes, trading tissue diversity for statistical power (Võsa et al. 2021).\n\n\n2.6.2 Single-Cell and Context-Specific Expression\nBulk RNA-seq averages expression across all cells in a tissue sample, obscuring the cell-type-specific programs that often mediate disease biology. Single-cell RNA-seq resolves this heterogeneity, identifying expression signatures for individual cell types, rare populations, and transitional states. Large-scale efforts like the Human Cell Atlas, Tabula Sapiens, and disease-focused single-cell consortia are building reference atlases that catalog cell types across organs and developmental stages (Regev et al. 2017; The Tabula Sapiens Consortium 2022).\nFor variant interpretation, single-cell data enable cell-type-specific eQTL mapping, revealing that a variant may influence expression in one cell type but not others within the same tissue. Spatial transcriptomics adds anatomical context, preserving tissue architecture while measuring gene expression. These technologies introduce computational challenges: sparsity from dropout, batch effects across samples and technologies, and massive scale with millions of cells. They also offer an increasingly fine-grained view of the link between genotype, regulatory state, and cellular phenotype. In this book, single-cell and spatial resources appear primarily in later chapters on multi-omics integration and systems-level models, but they represent the direction toward which expression genetics is moving.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Pair of panels: (1) bulk expression averaging across mixed cell types vs (2) a UMAP of single-cell profiles colored by cell type, with an inset showing a cell-type-specific eQTL that would be invisible in bulk data.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#variant-interpretation-databases-and-clinical-labels",
    "href": "p1-ch02-data.html#variant-interpretation-databases-and-clinical-labels",
    "title": "2  The Genomic Data Landscape",
    "section": "2.7 Variant Interpretation Databases and Clinical Labels",
    "text": "2.7 Variant Interpretation Databases and Clinical Labels\nAllele frequencies tell us what variants are tolerated in healthy populations, and functional genomics data reveal where the genome is biochemically active, but neither directly answers the clinical question: is this variant pathogenic? That determination requires integrating multiple lines of evidence, including family segregation, functional assays, computational predictions, and phenotypic observations, into a structured framework that can be applied consistently across variants, genes, and diseases.\nClinical variant interpretation databases aggregate these assessments from laboratories, expert panels, and research groups, providing labels that inform diagnostic decisions, guide research, and serve as training data for machine learning models. These databases have become critical infrastructure for both clinical genomics and computational method development, though their labels carry biases and circularity that propagate through any analysis built on them.\n\n2.7.1 ClinVar and Related Resources\nClinVar aggregates assertions of variant pathogenicity from clinical laboratories and researchers, along with supporting evidence and conflicting interpretations where relevant (Landrum et al. 2018). Its labels are central to diagnostic pipelines, benchmarking variant effect predictors, and training machine learning models in clinical genomics. Many variants, however, are classified as “variants of uncertain significance” (VUS), reflecting limited evidence or conflicting data; these VUS are both targets and potential pitfalls for predictive models.\nClinVar’s labels are not collected in isolation. As discussed in Chapter 4, clinical submissions increasingly incorporate computational scores like CADD as one piece of evidence, which creates subtle circularity when those same labels are used to evaluate or train computational predictors (Schubach et al. 2024). If a laboratory uses a high CADD score as supporting evidence for “likely pathogenic,” and that variant later appears as a positive label in ClinVar, models trained on ClinVar plus CADD may partly be learning to reproduce CADD itself. This circularity is a recurring methodological concern throughout the book.\n\n\n2.7.2 ClinGen and Expert Curation\nThe Clinical Genome Resource (ClinGen) complements ClinVar by providing expert-curated assessments at multiple levels of granularity (Rehm et al. 2015). ClinGen expert panels evaluate gene-disease validity, asking whether variation in a particular gene can cause a specific disease, and dosage sensitivity, determining whether haploinsufficiency or triplosensitivity leads to clinical phenotypes. These evaluations build on the catalog of Mendelian phenotypes maintained by OMIM (Online Mendelian Inheritance in Man), which provides curated gene-disease associations, clinical synopses, and literature summaries that have long served as a reference for clinical genetics (Amberger et al. 2015).\nFor individual variants, ClinGen Variant Curation Expert Panels apply the ACMG/AMP criteria systematically, assigning levels of evidence for pathogenicity or benignity. The FDA has recognized these curations as a valid source of scientific evidence for clinical validity (Pejaver et al. 2022). ClinGen also develops calibrated thresholds for computational predictors like CADD and REVEL, specifying score intervals that justify different strengths of evidence for pathogenicity or benignity. These calibrated thresholds directly inform how computational scores should be incorporated into variant classification workflows and highlight the tight coupling between data resources, guidelines, and model outputs.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Decision-graph for variant interpretation showing evidence types (population frequency, functional assays, computational scores, segregation, pharmacogenomics) converging into ClinVar/ClinGen/ClinPGx labels, with circularity highlighted (e.g., CADD used both as input evidence and training target).\n\n\n\n\n2.7.3 ClinPGx and Pharmacogenomics Resources\nClinPGx integrates the PharmGKB knowledge base, CPIC clinical guidelines, and PharmCAT annotation tool into a unified pharmacogenomics resource (Whirl-Carrillo et al. 2012). While most variant interpretation databases focus on rare disease-causing mutations, ClinPGx curates gene-drug associations that influence drug metabolism, efficacy, and adverse reactions. These pharmacogenomic variants are often common polymorphisms rather than rare pathogenic mutations, but their clinical importance for prescribing decisions makes them a distinct category of actionable genetic variation.\nThe CPIC guidelines provide evidence-based recommendations for adjusting drug selection or dosing based on pharmacogene diplotypes, and ClinPGx-annotated FDA drug labels document the regulatory status of these associations. From a modeling perspective, pharmacogenomic resources offer a complementary type of label that can be linked to variants, genes, and pathways in ways that differ from traditional disease-focused labels.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch02-data.html#how-later-chapters-use-these-resources",
    "href": "p1-ch02-data.html#how-later-chapters-use-these-resources",
    "title": "2  The Genomic Data Landscape",
    "section": "2.8 How Later Chapters Use These Resources",
    "text": "2.8 How Later Chapters Use These Resources\nThe genomic deep learning models that follow inherit both the strengths and limitations of the data they are trained on. Chapter 3 draws on GWAS summary statistics and biobank-scale cohorts to construct polygenic scores. Chapter 4 examines how annotation-based methods compress population frequencies, conservation, and functional signals into genome-wide deleteriousness scores. Chapters 10.1-10.3 use ENCODE, Roadmap, and Cistrome-style functional data as training labels for sequence-to-function models, while Chapters 7-17 revisit these resources as inputs, labels, and priors for genomic foundation models.\nBy surveying the data landscape in one place, we establish a common reference that later chapters can build on rather than re-introducing each resource from scratch. The recurring theme is that biases, gaps, and circularity in these foundational datasets propagate through every model trained on them. A variant effect predictor trained on ClinVar labels inherits the ascertainment biases of clinical sequencing; a chromatin model trained on ENCODE cell lines may not generalize to primary tissues; a constraint model trained on human populations may miss gene-lethal variants that never appear in any catalog. Understanding these foundations is essential for interpreting what models learn and anticipating where they will fail.\n\n\n\n\nAll of Us Research Program Investigators, All of Us; 2019. “The ‘All of Us’ Research Program.” New England Journal of Medicine 381 (7): 668–76. https://doi.org/10.1056/NEJMsr1809937.\n\n\nAmberger, Joanna S., Carol A. Bocchini, François Schiettecatte, Alan F. Scott, and Ada Hamosh. 2015. “OMIM.org: Online Mendelian Inheritance in Man (OMIM®), an Online Catalog of Human Genes and Genetic Disorders.” Nucleic Acids Research 43 (D1): D789–98. https://doi.org/10.1093/nar/gku1205.\n\n\nAuton, Adam, Gonçalo R. Abecasis, David M. Altshuler, Richard M. Durbin, Gonçalo R. Abecasis, David R. Bentley, Aravinda Chakravarti, et al. 2015. “A Global Reference for Human Genetic Variation.” Nature 526 (7571): 68–74. https://doi.org/10.1038/nature15393.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nBycroft, Clare, Colin Freeman, Desislava Petkova, Gavin Band, Lloyd T. Elliott, Kevin Sharp, Allan Motyer, et al. 2018. “The UK Biobank Resource with Deep Phenotyping and Genomic Data.” Nature 562 (7726): 203–9. https://doi.org/10.1038/s41586-018-0579-z.\n\n\nEdgar, Ron, Michael Domrachev, and Alex E. Lash. 2002. “Gene Expression Omnibus: NCBI Gene Expression and Hybridization Array Data Repository.” Nucleic Acids Research 30 (1): 207–10. https://doi.org/10.1093/nar/30.1.207.\n\n\nFrankish, Adam, Mark Diekhans, Anne-Maud Ferreira, Rory Johnson, Irwin Jungreis, Jane Loveland, Jonathan M Mudge, et al. 2019. “GENCODE Reference Annotation for the Human and Mouse Genomes.” Nucleic Acids Research 47 (D1): D766–73. https://doi.org/10.1093/nar/gky955.\n\n\nGamazon, Eric R., Heather E. Wheeler, Kaanan P. Shah, Sahar V. Mozaffari, Keston Aquino-Michaels, Robert J. Carroll, Anne E. Eyler, et al. 2015. “A Gene-Based Association Method for Mapping Traits Using Reference Transcriptome Data.” Nature Genetics 47 (9): 1091–98. https://doi.org/10.1038/ng.3367.\n\n\nGusev, Alexander, Arthur Ko, Huwenbo Shi, Gaurav Bhatia, Wonil Chung, Brenda W. J. H. Penninx, Rick Jansen, et al. 2016. “Integrative Approaches for Large-Scale Transcriptome-Wide Association Studies.” Nature Genetics 48 (3): 245–52. https://doi.org/10.1038/ng.3506.\n\n\nKagda, Meenakshi S., Bonita Lam, Casey Litton, Corinn Small, Cricket A. Sloan, Emma Spragins, Forrest Tanaka, et al. 2025. “Data Navigation on the ENCODE Portal.” Nature Communications 16 (1): 9592. https://doi.org/10.1038/s41467-025-64343-9.\n\n\nKarczewski, Konrad J., Laurent C. Francioli, Grace Tiao, Beryl B. Cummings, Jessica Alföldi, Qingbo Wang, Ryan L. Collins, et al. 2020. “The Mutational Constraint Spectrum Quantified from Variation in 141,456 Humans.” Nature 581 (7809): 434–43. https://doi.org/10.1038/s41586-020-2308-7.\n\n\nKundaje, Anshul, Wouter Meuleman, Jason Ernst, Misha Bilenky, Angela Yen, Alireza Heravi-Moussavi, Pouya Kheradpour, et al. 2015. “Integrative Analysis of 111 Reference Human Epigenomes.” Nature 518 (7539): 317–30. https://doi.org/10.1038/nature14248.\n\n\nKurki, Mitja I., Juha Karjalainen, Priit Palta, Timo P. Sipilä, Kati Kristiansson, Kati M. Donner, Mary P. Reeve, et al. 2023. “FinnGen Provides Genetic Insights from a Well-Phenotyped Isolated Population.” Nature 613 (7944): 508–18. https://doi.org/10.1038/s41586-022-05473-8.\n\n\nLambert, Samuel A., Laurent Gil, Simon Jupp, Scott C. Ritchie, Yu Xu, Annalisa Buniello, Aoife McMahon, et al. 2021. “The Polygenic Score Catalog as an Open Database for Reproducibility and Systematic Evaluation.” Nature Genetics 53 (4): 420–25. https://doi.org/10.1038/s41588-021-00783-5.\n\n\nLandrum, Melissa J, Jennifer M Lee, Mark Benson, Garth R Brown, Chen Chao, Shanmuga Chitipiralla, Baoshan Gu, et al. 2018. “ClinVar: Improving Access to Variant Interpretations and Supporting Evidence.” Nucleic Acids Research 46 (D1): D1062–67. https://doi.org/10.1093/nar/gkx1153.\n\n\nLiao, Wen-Wei, Mobin Asri, Jana Ebler, Daniel Doerr, Marina Haukness, Glenn Hickey, Shuangjia Lu, et al. 2023. “A Draft Human Pangenome Reference.” Nature 617 (7960): 312–24. https://doi.org/10.1038/s41586-023-05896-x.\n\n\nMarees, Andries T., Hilde de Kluiver, Sven Stringer, Florence Vorspan, Emmanuel Curis, Cynthia Marie-Claire, and Eske M. Derks. 2018. “[GWAS] A Tutorial on Conducting Genome-Wide Association Studies: Quality Control and Statistical Analysis.” International Journal of Methods in Psychiatric Research 27 (2): e1608. https://doi.org/10.1002/mpr.1608.\n\n\nMorales, Joannella, Shashikant Pujar, Jane E. Loveland, Alex Astashyn, Ruth Bennett, Andrew Berry, Eric Cox, et al. 2022. “A Joint NCBI and EMBL-EBI Transcript Set for Clinical Genomics and Research.” Nature 604 (7905): 310–15. https://doi.org/10.1038/s41586-022-04558-8.\n\n\nMountjoy, Edward, Ellen M. Schmidt, Miguel Carmona, Jeremy Schwartzentruber, Gareth Peat, Alfredo Miranda, Luca Fumis, et al. 2021. “An Open Approach to Systematically Prioritize Causal Variants and Genes at All Published Human GWAS Trait-Associated Loci.” Nature Genetics 53 (11): 1527–33. https://doi.org/10.1038/s41588-021-00945-5.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. “ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design.” Advances in Neural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nNurk, Sergey, Sergey Koren, Arang Rhie, Mikko Rautiainen, Andrey V. Bzikadze, Alla Mikheenko, Mitchell R. Vollger, et al. 2022. “The Complete Sequence of a Human Genome.” Science 376 (6588): 44–53. https://doi.org/10.1126/science.abj6987.\n\n\nO’Leary, Nuala A., Mathew W. Wright, J. Rodney Brister, Stacy Ciufo, Diana Haddad, Rich McVeigh, Bhanu Rajput, et al. 2016. “Reference Sequence (RefSeq) Database at NCBI: Current Status, Taxonomic Expansion, and Functional Annotation.” Nucleic Acids Research 44 (D1): D733–45. https://doi.org/10.1093/nar/gkv1189.\n\n\nPejaver, Vikas, Alicia B. Byrne, Bing-Jian Feng, Kymberleigh A. Pagel, Sean D. Mooney, Rachel Karchin, Anne O’Donnell-Luria, et al. 2022. “Calibration of Computational Tools for Missense Variant Pathogenicity Classification and ClinGen Recommendations for PP3/BP4 Criteria.” American Journal of Human Genetics 109 (12): 2163–77. https://doi.org/10.1016/j.ajhg.2022.10.013.\n\n\nRegev, Aviv, Sarah A Teichmann, Eric S Lander, Ido Amit, Christophe Benoist, Ewan Birney, Bernd Bodenmiller, et al. 2017. “The Human Cell Atlas.” Edited by Thomas R Gingeras. eLife 6 (December): e27041. https://doi.org/10.7554/eLife.27041.\n\n\nRehm, Heidi L., Jonathan S. Berg, Lisa D. Brooks, Carlos D. Bustamante, James P. Evans, Melissa J. Landrum, David H. Ledbetter, et al. 2015. “ClinGen — The Clinical Genome Resource.” New England Journal of Medicine 372 (23): 2235–42. https://doi.org/10.1056/NEJMsr1406261.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nSherry, S. T., M.-H. Ward, M. Kholodov, J. Baker, L. Phan, E. M. Smigielski, and K. Sirotkin. 2001. “dbSNP: The NCBI Database of Genetic Variation.” Nucleic Acids Research 29 (1): 308–11. https://doi.org/10.1093/nar/29.1.308.\n\n\nSirugo, Giorgio, Scott M. Williams, and Sarah A. Tishkoff. 2019. “The Missing Diversity in Human Genetic Studies.” Cell 177 (1): 26–31. https://doi.org/10.1016/j.cell.2019.02.048.\n\n\nSollis, Elliot, Abayomi Mosaku, Ala Abid, Annalisa Buniello, Maria Cerezo, Laurent Gil, Tudor Groza, et al. 2023. “The NHGRI-EBI GWAS Catalog: Knowledgebase and Deposition Resource.” Nucleic Acids Research 51 (D1): D977–85. https://doi.org/10.1093/nar/gkac1010.\n\n\nSullivan, Patrick F., Jennifer R. S. Meadows, Steven Gazal, BaDoi N. Phan, Xue Li, Diane P. Genereux, Michael X. Dong, et al. 2023. “Leveraging Base-Pair Mammalian Constraint to Understand Genetic Variation and Human Disease.” Science 380 (6643): eabn2937. https://doi.org/10.1126/science.abn2937.\n\n\nThe GTEx Consortium. 2020. “The GTEx Consortium Atlas of Genetic Regulatory Effects Across Human Tissues.” Science 369 (6509): 1318–30. https://doi.org/10.1126/science.aaz1776.\n\n\nThe Tabula Sapiens Consortium. 2022. “The Tabula Sapiens: A Multiple-Organ, Single-Cell Transcriptomic Atlas of Humans.” Science 376 (6594): eabl4896. https://doi.org/10.1126/science.abl4896.\n\n\nVõsa, Urmo, Annique Claringbould, Harm-Jan Westra, Marc Jan Bonder, Patrick Deelen, Biao Zeng, Holger Kirsten, et al. 2021. “Large-Scale Cis- and Trans-eQTL Analyses Identify Thousands of Genetic Loci and Polygenic Scores That Regulate Blood Gene Expression.” Nature Genetics 53 (9): 1300–1310. https://doi.org/10.1038/s41588-021-00913-z.\n\n\nWhirl-Carrillo, M, E M McDonagh, J M Hebert, L Gong, K Sangkuhl, C F Thorn, R B Altman, and T E Klein. 2012. “Pharmacogenomics Knowledge for Personalized Medicine.” Clinical Pharmacology & Therapeutics 92 (4): 414–17. https://doi.org/10.1038/clpt.2012.96.\n\n\nYun, Taedong, Helen Li, Pi-Chuan Chang, Michael F Lin, Andrew Carroll, and Cory Y McLean. 2021. “Accurate, Scalable Cohort Variant Calls Using DeepVariant and GLnexus.” Bioinformatics 36 (24): 5582–89. https://doi.org/10.1093/bioinformatics/btaa1081.\n\n\nZheng, Rongbin, Changxin Wan, Shenglin Mei, Qian Qin, Qiu Wu, Hanfei Sun, Chen-Hao Chen, et al. 2019. “Cistrome Data Browser: Expanded Datasets and New Tools for Gene Regulatory Analysis.” Nucleic Acids Research 47 (D1): D729–35. https://doi.org/10.1093/nar/gky1094.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Genomic Data Landscape</span>"
    ]
  },
  {
    "objectID": "p1-ch03-pgs.html",
    "href": "p1-ch03-pgs.html",
    "title": "3  GWAS & Polygenic Scores",
    "section": "",
    "text": "3.1 The GWAS Paradigm\nGenome-wide association studies (GWAS) and polygenic scores (PGS) form the statistical backbone of modern human genetics. GWAS connect variation in DNA to variation in traits. Polygenic scores then aggregate many small genetic effects across the genome into a single number per individual. Together, they have delivered striking insights into complex traits, but they also expose fundamental limitations that motivate the mechanistic models developed in later parts of this book.\nIn this chapter we:\nThroughout, we will connect to data resources introduced in Chapter Chapter 2 and to confounding and fairness issues discussed in Chapter Chapter 21.\nA GWAS requires three ingredients:\nThe basic GWAS workflow is:\nPractically oriented guides provide detailed recommendations on QC, covariate selection, and interpretation (Marees et al. 2018). Biobanks and consortia described in Chapter 2 provide the sample sizes that make modern GWAS possible.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GWAS & Polygenic Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch03-pgs.html#the-gwas-paradigm",
    "href": "p1-ch03-pgs.html#the-gwas-paradigm",
    "title": "3  GWAS & Polygenic Scores",
    "section": "",
    "text": "Genotypes – typically dense SNP arrays or imputed variants across the genome, often augmented with structural variants or exome data.\nPhenotypes – quantitative traits (e.g., height, LDL cholesterol) or binary outcomes (e.g., disease vs control), plus relevant covariates (age, sex, etc.).\nA statistical model – usually a regression model that tests one variant at a time for association with the phenotype.\n\n\n\nPerform quality control on individuals and variants.\nFor each variant, fit a regression model of the phenotype on genotype and covariates.\nRecord the estimated effect size and an association statistic (e.g., p-value).\nCorrect for multiple testing to control false positives.\nSummarize results across the genome (Manhattan and QQ plots) and follow up notable loci.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: Flow diagram of the GWAS pipeline with annotations: - Inputs: genotype matrix, phenotype vector, covariates. - “For each variant” loop with regression model. - Outputs: table of effect sizes and p-values, Manhattan and QQ plots.\n\n\n\n3.1.1 Continuous Phenotypes\nFor quantitative traits, the standard association model is linear regression. Consider a single bi-allelic variant (j). Let (g_{ij}) denote the genotype dosage for individual (i), encoded as 0, 1, or 2 copies of the alternative allele (or as an imputed fractional dosage). Let (c_i) be a vector of covariates (e.g., age, sex, ancestry principal components). The model is\n\\[\ny_i = \\alpha + \\beta_j g_{ij} + \\gamma^\\top c_i + \\varepsilon_i,\n\\]\nwhere:\n\n(y_i) is the phenotype for individual (i).\n() is the intercept (baseline phenotype when genotype and covariates are zero).\n(_j) is the per-allele effect size for variant (j).\n() is a vector of covariate coefficients.\n(_i) is a residual error term, typically assumed to be Gaussian with mean 0 and constant variance.\n\n\n3.1.1.1 Effect Size\nThe coefficient (_j) has a direct interpretation: it is the expected change in the phenotype associated with one additional copy of the alternative allele, holding covariates fixed. If phenotype units are meaningful (e.g., cm of height), (_j) is interpretable on that scale. Often we standardize phenotypes to zero mean and unit variance, so (_j) is in units of standard deviations per allele.\nBecause GWAS typically considers millions of variants, most individual (|_j|) are small. Nonetheless, in aggregate, many such effects can explain a substantial fraction of trait heritability, as we will see when we discuss polygenic scores and “missing heritability” (Yang et al. 2010).\n\n\n3.1.1.2 Significance Testing and Multiple Comparisons\nTo test association, we compute a test statistic for the null hypothesis (H_0: _j = 0). Under standard assumptions, the usual (t)-statistic for (_j) approximately follows a normal distribution in large samples. This yields a p-value for each variant.\nWith (M) variants tested (often (M 6)–(107)), we must correct for multiple comparisons. A widely used heuristic is the genome-wide significance threshold of (5 ^{-8}). This value reflects a Bonferroni correction for roughly one million effectively independent tests, accounting for LD among common SNPs (Pe’er et al. 2008).\nVariants with p-values below this threshold are reported as genome-wide significant hits. Variants with less extreme p-values may still contribute to polygenic scores, particularly in LD-aware methods.\n\n\n3.1.1.3 Covariates\nCovariates play two roles:\n\nPrecision: adjusting for variables like age and sex can reduce residual variance and increase power.\nControl of confounding: failing to adjust for variables related to both genotype and phenotype can produce spurious associations (e.g., if cases and controls differ systematically in age or sex).\n\nIn practice, GWAS covariate sets often include age, sex, study-specific technical covariates (batch, array type), and ancestry principal components (see below) (Marees et al. 2018).\n\n\n3.1.1.4 Ancestry PCs\nPopulation structure can induce confounding: if allele frequencies differ across subgroups and the phenotype also differs across groups for non-genetic reasons, naive GWAS may detect associations that reflect group differences rather than causal effects.\nPrincipal component analysis (PCA) on genotype data captures major axes of genetic variation (Price et al. 2006; Patterson, Price, and Reich 2006). The top principal components often correspond to broad ancestry gradients (e.g., continental-level differences). Including these PCs as covariates attenuates spurious associations due to ancestry, though it does not solve all forms of confounding; broader issues of population structure and fairness are discussed in Chapter Chapter 21.\n\n\n3.1.1.5 Intercept and Residuals\nThe intercept () and residuals (_i) are often overlooked. Systematic inflation in test statistics (e.g., due to cryptic relatedness or subtle structure) can manifest as a departure from the expected p-value distribution, even after including PCs. Genomic control, LD score regression, and more recent methods quantify and sometimes correct for this inflation, though we do not detail them here.\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: QQ plot and Manhattan plot for a sample GWAS: - Show expected vs observed (-_{10}(p)) to illustrate inflation/deflation. - Show genome-wide Manhattan plot with annotated genome-wide significant loci.\n\n\n\n\n\n3.1.2 Binary Phenotypes\nFor case–control traits (e.g., disease status), GWAS typically uses logistic regression. Let (y_i {0,1}) denote case (1) or control (0). The model is\n\\[\n\\log \\frac{P(y_i = 1)}{P(y_i = 0)} = \\alpha + \\beta_j g_{ij} + \\gamma^\\top c_i.\n\\]\nThe left-hand side is the log-odds of being a case. Here:\n\n(_j) represents the log-odds ratio (log-OR) per additional copy of the alternative allele.\n((_j)) is the odds ratio (OR).\n\nFor rare diseases, odds ratios are often interpreted as approximating relative risks, but strictly speaking they differ: the OR compares odds, not probabilities. Converting ORs into absolute risk requires baseline disease prevalence, which we discuss later when interpreting polygenic scores.\nCase–control sampling can distort absolute risk but preserves the ordering of risk: a variant that increases odds in the sampled data also increases risk in the source population. This is why GWAS conducted in case–control designs still provide useful effect sizes for polygenic scores, provided downstream models account for baseline incidence.\nLogistic regression shares the same covariate structure as linear regression, and the same challenges with confounding, population structure, and technical artifacts apply.\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: - Simple 2×2 table (allele count vs case/control) leading into logistic regression. - Plot of probability of disease vs genotype dosage for a variant with OR &gt; 1, illustrating the logistic curve.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GWAS & Polygenic Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch03-pgs.html#linkage-disequilibrium-and-association-signals",
    "href": "p1-ch03-pgs.html#linkage-disequilibrium-and-association-signals",
    "title": "3  GWAS & Polygenic Scores",
    "section": "3.2 Linkage Disequilibrium and Association Signals",
    "text": "3.2 Linkage Disequilibrium and Association Signals\nGWAS tests variants one at a time, but the genome is inherited in blocks. Nearby variants tend to be correlated because they are co-inherited on haplotypes. This linkage disequilibrium (LD) is central to interpreting GWAS results.\nA GWAS association signal at variant (j) may arise because:\n\nVariant (j) is itself causal for the phenotype.\nVariant (j) tags a causal variant (k) that is correlated with it in the population.\nMultiple causal variants in a region jointly influence the phenotype, producing a complex local pattern of association.\n\nUnderstanding LD is essential before moving to fine-mapping and polygenic scoring.\n\n3.2.1 Haplotype Structure and Recombination\nMeiosis recombines parental chromosomes through crossover events. Over many generations, recombination breaks down long-range correlations but preserves short-range structure. The result is:\n\nRegions of high LD (haplotype blocks) where many variants are strongly correlated.\nRecombination hotspots where LD decays rapidly.\n\nPatterns of LD vary across populations due to demographic history (bottlenecks, expansions, admixture). These differences play a major role in how GWAS signals and polygenic scores transfer across ancestries.\n\n\n3.2.2 Measuring Correlation: The (r^2) Statistic\nThe most commonly used measure of LD between two bi-allelic variants is the squared correlation (r^2) between their allele counts:\n\n(r^2 ) indicates nearly perfect correlation (variants are almost always observed together).\n(r^2 ) indicates independence.\n\nFrom a GWAS perspective:\n\nIf variant (j) is causal and variant (k) is in high LD with (j), both may show similar p-values.\nIf multiple variants are causal, LD patterns can cause their signals to blend into a single “peak” in the Manhattan plot.\n\nThis correlation structure complicates efforts to pinpoint which variants are truly causal.\n\n\n3.2.3 Causal Versus Tag Variants\nA causal variant directly influences the phenotype (e.g., by altering a protein, transcription factor binding, or splicing). A tag variant is merely correlated with a causal variant due to LD. Tag variants are often easier to genotype, especially on array platforms, and can stand in for causal variants in association analyses.\nGWAS catalogs are therefore catalogs of associated loci, not necessarily of causal variants. Distinguishing causal from tag variants requires additional information (fine-mapping, functional assays, or mechanistic models), which we discuss below and in later chapters.\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: Local locus illustration: - Top: Manhattan “zoom-in” showing a cluster of strongly associated variants. - Middle: LD heatmap (r²) across the locus. - Bottom: Track indicating “causal” variant(s) vs tag variants, possibly overlaying gene annotations.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GWAS & Polygenic Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch03-pgs.html#from-association-signals-to-fine-mapping",
    "href": "p1-ch03-pgs.html#from-association-signals-to-fine-mapping",
    "title": "3  GWAS & Polygenic Scores",
    "section": "3.3 From Association Signals to Fine-Mapping",
    "text": "3.3 From Association Signals to Fine-Mapping\nFine-mapping aims to move from “this region is associated” to “these are the most likely causal variants in this region.” Given a set of summary association statistics and an LD matrix, Bayesian fine-mapping methods estimate the probability that each variant is causal.\nAt a high level:\n\nDefine a region around an index SNP (e.g., all variants within 1 Mb).\nSpecify a prior over which variants are causal (e.g., at most (K) causal variants per region).\nUse the observed association statistics and LD to compute the posterior probability of each configuration of causal variants.\nDerive posterior inclusion probabilities (PIPs) for each variant and credible sets that contain the true causal variant(s) with a specified probability (e.g., 95%).\n\nComprehensive reviews describe how summary statistics and LD matrices from reference panels can be combined to perform fine-mapping at scale (Pasaniuc and Price 2016).\n\n3.3.1 Bayesian Fine-Mapping Framework\nBayesian fine-mapping methods differ in their priors and computational approximations, but they share common ingredients:\n\nA prior on the number of causal variants and their effect sizes.\nA likelihood model linking effect sizes to observed marginal associations given LD.\nPosterior inference to compute PIPs and credible sets.\n\nVariants with high PIPs are strong candidates for causal involvement. Credible sets reflect the uncertainty due to LD and limited sample size. Narrow credible sets (few variants) are more actionable for functional follow-up.\n\n\n3.3.2 Applications and Multi-Ancestry Leverage\nFine-mapping serves several downstream purposes:\n\nVariant prioritization: variants with high PIPs are prime targets for mechanistic follow-up (e.g., regulatory assays).\nGene prioritization: mapping credible-set variants to genes (via proximity, eQTLs, or chromatin interactions) helps identify likely effector genes.\nPolygenic score construction: PIPs can be used to weight variants or to select variants with high posterior probability of causality.\n\nMulti-ancestry data often sharpen fine-mapping. Because LD patterns differ across populations, a variant that is highly correlated with many others in one population may have fewer strong proxies in another. Joint fine-mapping across ancestries can therefore reduce credible set sizes and refine causal inferences (Pasaniuc and Price 2016).\nIntegration of fine-mapping with functional annotations and multi-omics data at scale—such as in large open resources linking GWAS, fine-mapping, and functional genomics—further improves prioritization of likely causal variants (Mountjoy et al. 2021).\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: Fine-mapping cartoon: - Panel A: Manhattan peak highlighting a broad associated region. - Panel B: Bar plot of PIPs for variants in the region. - Panel C: Example of a 95% credible set, indicating how many variants remain plausible. - Optional overlay: effect of adding a second ancestry on credible set narrowing.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GWAS & Polygenic Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch03-pgs.html#constructing-polygenic-scores",
    "href": "p1-ch03-pgs.html#constructing-polygenic-scores",
    "title": "3  GWAS & Polygenic Scores",
    "section": "3.4 Constructing Polygenic Scores",
    "text": "3.4 Constructing Polygenic Scores\nPolygenic scores (PGS) aggregate estimated variant effects across the genome into a single scalar per individual:\n\\[\n\\text{PGS}_i = \\sum_{j} w_j g_{ij},\n\\]\nwhere (w_j) is a weight assigned to variant (j) based on GWAS or fine-mapping, and (g_{ij}) is the genotype dosage for individual (i).\nThere are many design choices:\n\nWhich variants to include.\nHow to set the weights (w_j).\nHow to account for LD.\nHow to validate and calibrate the resulting score.\n\n\n3.4.1 Terminology: PGS vs PRS\n\n\n\n\n\n\nNoteTerminology: PGS vs PRS\n\n\n\nThe literature uses overlapping terminology:\n\nPolygenic risk score (PRS) – historically common, especially for disease endpoints.\nPolygenic score (PGS) – more general, used for both diseases and quantitative traits.\nGenomic risk score and related terms also appear, often interchangeably.\n\nIn this book we use polygenic score (PGS) as the default, with “risk” added when we specifically discuss disease risks. Methodological overviews of PGS construction and evaluation are available in (Choi, Mak, and O’Reilly 2020).\n\n\nWe now describe three families of approaches: clumping & thresholding, LD-aware Bayesian methods, and fine-mapping-informed scores.\n\n\n3.4.2 Clumping and Thresholding\nThe simplest and still widely used approach is clumping and thresholding (“C+T”):\n\nClumping:\n\nRank variants by their GWAS significance (e.g., p-value).\nStarting from the most significant variant, remove nearby variants within a specified window that are in high LD (e.g., (r^2 &gt; 0.1)–0.2).\nThis yields a set of approximately independent variants.\n\nThresholding:\n\nApply a p-value threshold (e.g., (5 ^{-8}), (10^{-5}), or even 1).\nRetain only variants with p-values below this threshold.\n\nWeighting:\n\nSet weights (w_j) equal to the GWAS effect size estimates (e.g., (_j)) for the retained variants, and zero otherwise.\n\n\nHyperparameters (LD window, (r^2) threshold, p-value threshold) are often chosen by grid search to maximize predictive performance in a validation set. This tuning can introduce overfitting, especially in small samples or when the validation set is not representative of future deployment populations.\nC+T scores are easy to compute and interpret, but they ignore much of the information in GWAS summary statistics:\n\nMost variants are discarded.\nLD is only handled via coarse pruning.\nVariants with modest p-values that collectively explain substantial variance may be underweight or excluded.\n\n\n\n3.4.3 LD-Aware Bayesian Methods\nA more principled approach is to model the joint distribution of effect sizes explicitly, accounting for LD among variants. In these methods, we treat the true effect sizes (= (_1, , _M)) as random variables drawn from a prior distribution, and use the GWAS summary statistics and LD matrix to infer posterior mean effect sizes ([_j ]). The posterior means (or related shrinkage estimates) become the PGS weights (w_j).\nLDpred, for example, assumes that a fraction (p) of variants have nonzero effects drawn from a Gaussian distribution, while the rest have zero effect (Vilhjálmsson et al. 2015). Given GWAS summary statistics and an LD reference panel, LDpred computes approximate posterior effect sizes that:\n\nShrink noisy estimates toward zero.\nBorrow strength across correlated variants.\nReduce overfitting compared with C+T.\n\nRelated methods (e.g., lassosum and others) use different priors or optimization strategies but share the general idea: jointly model effect sizes under LD rather than pruning it away. These methods generally yield better predictive performance than C+T when properly tuned, especially as sample sizes increase.\nHowever, they still face challenges:\n\nThey typically rely on an LD reference panel that may not match the target population.\nThey are sensitive to model misspecification (e.g., wrong prior on effect sizes).\nThey often assume a single ancestry or treat ancestries separately.\n\n\n\n3.4.4 Fine-Mapping-Informed Polygenic Scores\nFine-mapping outputs—particularly PIPs—provide an appealing basis for polygenic scores:\n\nVariants with high PIPs are more likely to be causal.\nFine-mapping can incorporate functional annotations and multi-ancestry information.\nPIPs can be used to select variants or to reweight effect sizes.\n\nTwo broad strategies are common:\n\nSelection: include only variants with PIP above a threshold (e.g., 0.1 or 0.5) and set (w_j) proportional to their estimated effect sizes.\nWeighting: use PIPs directly as weights (or as multiplicative factors), so that variants with higher PIPs contribute more to the score even if effect size estimates are similar.\n\nFine-mapping-informed PGS aim to concentrate weight on variants that are more likely to be biologically meaningful and robust across ancestries. Large-scale resources that jointly analyze GWAS, fine-mapping, and functional genomics provide datasets from which such scores can be derived (Mountjoy et al. 2021).\nThese approaches sit conceptually between purely statistical shrinkage (e.g., LDpred) and mechanistic models. They still rely on GWAS summary statistics but use additional structure—LD, functional annotations, and multi-ancestry patterns—to enrich the score.\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: Three-panel PGS construction schematic: - Panel A: C+T pipeline (Manhattan plot → pruning → few variants with raw betas). - Panel B: LD-aware Bayesian pipeline (summary stats + LD matrix → posterior effect sizes). - Panel C: Fine-mapping-informed pipeline (credible sets + PIPs → weighted score).",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GWAS & Polygenic Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch03-pgs.html#interpreting-polygenic-scores",
    "href": "p1-ch03-pgs.html#interpreting-polygenic-scores",
    "title": "3  GWAS & Polygenic Scores",
    "section": "3.5 Interpreting Polygenic Scores",
    "text": "3.5 Interpreting Polygenic Scores\nOnce a polygenic score has been computed for an individual, how should it be interpreted?\nAt a minimum, a PGS can be used to:\n\nRank individuals by genetic susceptibility (relative risk).\nStratify populations into risk quantiles (e.g., top 1% vs average).\nEstimate the proportion of phenotypic variance explained by common variants (on the liability scale for diseases).\n\n\n3.5.1 Relative versus Absolute Risk\nPolygenic scores are most naturally interpreted in relative terms. For a disease outcome, we might fit a logistic regression model in a target cohort:\n\\[\n\\log \\frac{P(y_i = 1)}{P(y_i = 0)} = \\alpha + \\theta \\, \\text{PGS}_i + \\eta^\\top z_i,\n\\]\nwhere (z_i) collects covariates (age, sex, etc.) and () is the effect of a one-unit increase in the PGS. We can rescale the PGS (e.g., to have unit standard deviation) so that (()) is the odds ratio per SD of PGS.\nRelative risk communication often focuses on percentiles:\n\nIndividuals in the top 1% of the PGS distribution may have several-fold higher disease odds than those near the median.\nRisk gradients can be displayed as odds ratios or hazard ratios by PGS decile or percentile.\n\nAbsolute risk requires combining the PGS with baseline incidence rates (e.g., age-specific disease rates in the population). Clinical guidelines increasingly emphasize absolute risk (e.g., 10-year risk of coronary artery disease) for decision-making, and using PGS in this context requires careful calibration and validation in representative populations (see Chapter Chapter 23).\n\n\n3.5.2 Ancestry, Linkage Disequilibrium, and Transferability\nA major challenge for PGS is transferability across populations:\n\nGWAS in large European-ancestry cohorts identify many variants and yield precise effect size estimates.\nThe same PGS often explains substantially less variance and exhibits poorer risk discrimination in non-European ancestries.\n\nSeveral factors contribute:\n\nLD differences: variants tagging causal alleles in one ancestry may not be in LD with them in another.\nAllele frequency differences: rare variants in one population may be common in another, affecting power and effect size estimates.\nGene–environment interactions and environment-specific exposures.\nStatistical artifacts due to mismatched LD reference panels and QC pipelines.\n\nEmpirical studies document pronounced drops in PGS performance when applied across ancestries and emphasize the importance of diverse training data and careful evaluation (Verma et al. 2024). Equity concerns are central: deploying PGS trained primarily in one ancestry can exacerbate health disparities if scores are systematically less accurate for underrepresented groups (see also Chapter Chapter 21).\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: - Panel A: Overlaid histograms of PGS for cases vs controls in a single ancestry, with risk-by-percentile curve. - Panel B: Bar plot or line plot comparing variance explained (R² or liability-scale (R^2)) for the same PGS across multiple ancestry groups, highlighting decreased performance.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GWAS & Polygenic Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch03-pgs.html#limitations-of-gwas-and-pgs-and-the-case-for-mechanistic-models",
    "href": "p1-ch03-pgs.html#limitations-of-gwas-and-pgs-and-the-case-for-mechanistic-models",
    "title": "3  GWAS & Polygenic Scores",
    "section": "3.6 Limitations of GWAS and PGS, and the Case for Mechanistic Models",
    "text": "3.6 Limitations of GWAS and PGS, and the Case for Mechanistic Models\nGWAS and PGS have transformed human genetics, but they have also revealed persistent gaps between statistical association and biological understanding.\n\n3.6.1 Achievements and the Clinical Adoption Gap\nGWAS have:\n\nIdentified thousands of loci associated with hundreds of traits.\nDemonstrated that common variants contribute meaningfully to disease risk.\nEnabled construction of PGS that rival or exceed traditional risk factors for some diseases in specific settings.\n\nYet clinical adoption remains limited:\n\nMany PGS offer modest incremental predictive power over standard risk factors.\nPerformance often varies sharply across ancestries.\nMechanistic interpretation is often shallow: we know where in the genome association lies but not exactly how it influences disease.\n\n\n\n3.6.2 Association Without Mechanism\nMost GWAS hits lie in noncoding regions. They often reside in enhancers, promoters, or other regulatory elements, but the causal chain from variant to molecular effect to disease is typically unknown. Even when credible sets are small, they frequently contain multiple plausible regulatory variants.\nThis “association without mechanism” problem limits:\n\nOur ability to identify drug targets.\nTranslation into therapeutic interventions.\nInterpretability and trust in genetic risk predictions.\n\n\n\n3.6.3 Population Transferability\nAs discussed above, PGS constructed from predominantly European-ancestry GWAS often perform poorly in other ancestries (Verma et al. 2024). This is not just a technical nuisance; it raises fundamental questions about what PGS capture:\n\nAre they measuring biology that is genuinely universal but poorly estimated in underrepresented groups?\nOr are they partly capturing ancestry-specific LD patterns, environmental context, and even subtle confounders?\n\nThese issues complicate the use of PGS in diverse clinical populations and underscore the importance of diverse cohorts and careful causal reasoning (Chapters Chapter 21 and Chapter 17).\n\n\n3.6.4 The Noncoding Variant Challenge\nMany trait-associated variants are noncoding and likely act through gene regulation, chromatin structure, or RNA processing rather than protein sequence. Without a mechanistic model of how sequence specifies regulatory activity, GWAS can tell us where something is happening but not what or why.\nDeep learning models trained on regulatory genomics data, such as those that predict chromatin accessibility, transcription factor binding, and gene expression from sequence (Zhou and Troyanskaya 2015; Zhou et al. 2018), begin to address this gap. They map sequence changes directly to predicted molecular consequences, providing hypotheses about regulatory mechanisms that underlie GWAS signals.\n\n\n3.6.5 Static Scores in a Dynamic Context\nPGS are typically static:\n\nComputed once from inherited genetic variants.\nInterpreted as a lifetime, context-independent risk modifier.\n\nIn reality, disease risk unfolds over time in a dynamic environment:\n\nExposures (diet, smoking, pollution) change across the life course.\nPhysiological states (e.g., inflammation, hormone levels) fluctuate.\nGene regulation and cellular states respond to these changing conditions.\n\nStatic PGS cannot capture temporal trajectories or gene–environment interactions. They are a coarse summary of inherited liability, not a full model of disease dynamics.\n\n\n3.6.6 Missing Heritability\nClassical quantitative genetics connects family resemblance to narrow-sense heritability (h^2): the proportion of phenotypic variance attributable to additive genetic effects. Early GWAS explained only a small fraction of this heritability, leading to the “missing heritability” puzzle (Manolio et al. 2009).\nSubsequent work showed that much of the “missing” component could be accounted for by many common variants of small effect, even if individually nonsignificant, when modeled jointly (Yang et al. 2010). Nonetheless, there remain gaps:\n\nRare variants with large effects.\nStructural variants, copy-number variation, and other classes not well captured by standard GWAS.\nEpistasis and gene–environment interactions.\n\nPooled across traits, GWAS and PGS suggest that complex traits are highly polygenic, but they do not fully close the gap between observed heritability, biological mechanism, and actionable clinical information.\n\n\n3.6.7 Toward Mechanistic Models\nThese limitations collectively motivate the mechanistic approaches that form the core of this book. We would like models that:\n\nConnect sequence variation directly to molecular phenotypes (e.g., regulatory activity, splicing, chromatin structure).\nIntegrate multi-omics data across scales (Chapters Section 10.3 and Chapter 17).\nProvide causal hypotheses about how variants influence cellular and organismal phenotypes.\nGeneralize across populations and contexts by modeling underlying biology rather than solely statistical association patterns.\n\nDeep learning models trained on large regulatory and transcriptomic datasets, such as those predicting chromatin accessibility, transcription factor binding, and expression from DNA sequence, are one step in this direction (Zhou and Troyanskaya 2015; Zhou et al. 2018). When combined with GWAS and fine-mapping results, these models can prioritize variants that are both statistically associated and predicted to be functionally impactful (Mountjoy et al. 2021).\nDownstream chapters will show how:\n\nMulti-omics integration (Chapter Chapter 17) connects molecular and clinical data.\nVariant effect prediction methods (Chapter Section 10.3 and Chapter Chapter 20) refine our understanding of GWAS loci.\nGenomic foundation models move beyond association to provide mechanistic insight and improved, equitable clinical translation (Part VI).\n\nThe goal is not to discard GWAS and PGS, but to build on them—replacing “association without mechanism” with models that make testable, mechanistic claims and support robust, fair deployment in real-world settings.\n\n\n\n\n\n\nWarning\n\n\n\nSuggested visual: Conceptual “bridge” figure: - Left: GWAS & PGS (Manhattan plot, PGS distribution) with labels “statistical association.” - Right: Mechanistic models (sequence → regulatory predictions → cellular phenotypes) with labels “biological mechanism.” - Middle: Fine-mapping and integration steps (PIPs, functional annotations, multi-omics). This figure should foreshadow Parts III–VI of the book.\n\n\n\n\n\n\nChoi, Shing Wan, Timothy Shin-Heng Mak, and Paul F. O’Reilly. 2020. “[PRS] Tutorial: A Guide to Performing Polygenic Risk Score Analyses.” Nature Protocols 15 (9): 2759–72. https://doi.org/10.1038/s41596-020-0353-1.\n\n\nManolio, Teri A., Francis S. Collins, Nancy J. Cox, David B. Goldstein, Lucia A. Hindorff, David J. Hunter, Mark I. McCarthy, et al. 2009. “Finding the Missing Heritability of Complex Diseases.” Nature 461 (7265): 747–53. https://doi.org/10.1038/nature08494.\n\n\nMarees, Andries T., Hilde de Kluiver, Sven Stringer, Florence Vorspan, Emmanuel Curis, Cynthia Marie-Claire, and Eske M. Derks. 2018. “[GWAS] A Tutorial on Conducting Genome-Wide Association Studies: Quality Control and Statistical Analysis.” International Journal of Methods in Psychiatric Research 27 (2): e1608. https://doi.org/10.1002/mpr.1608.\n\n\nMountjoy, Edward, Ellen M. Schmidt, Miguel Carmona, Jeremy Schwartzentruber, Gareth Peat, Alfredo Miranda, Luca Fumis, et al. 2021. “An Open Approach to Systematically Prioritize Causal Variants and Genes at All Published Human GWAS Trait-Associated Loci.” Nature Genetics 53 (11): 1527–33. https://doi.org/10.1038/s41588-021-00945-5.\n\n\nPasaniuc, Bogdan, and Alkes L. Price. 2016. “Dissecting the Genetics of Complex Traits Using Summary Association Statistics.” Nature Reviews Genetics 18 (2): 117–27. https://doi.org/10.1038/nrg.2016.142.\n\n\nPatterson, Nick, Alkes L. Price, and David Reich. 2006. “Population Structure and Eigenanalysis.” PLOS Genetics 2 (12): e190. https://doi.org/10.1371/journal.pgen.0020190.\n\n\nPe’er, Itsik, Roman Yelensky, David Altshuler, and Mark J. Daly. 2008. “Estimation of the Multiple Testing Burden for Genomewide Association Studies of Nearly All Common Variants.” Genetic Epidemiology 32 (4): 381–85. https://doi.org/10.1002/gepi.20303.\n\n\nPrice, Alkes L., Nick J. Patterson, Robert M. Plenge, Michael E. Weinblatt, Nancy A. Shadick, and David Reich. 2006. “Principal Components Analysis Corrects for Stratification in Genome-Wide Association Studies.” Nature Genetics 38 (8): 904–9. https://doi.org/10.1038/ng1847.\n\n\nVerma, Anurag, Jennifer E. Huffman, Alex Rodriguez, Mitchell Conery, Molei Liu, Yuk-Lam Ho, Youngdae Kim, et al. 2024. “Diversity and Scale: Genetic Architecture of 2068 Traits in the VA Million Veteran Program.” Science 385 (6706): eadj1182. https://doi.org/10.1126/science.adj1182.\n\n\nVilhjálmsson, Bjarni J., Jian Yang, Hilary K. Finucane, Alexander Gusev, Sara Lindström, Stephan Ripke, Giulio Genovese, et al. 2015. “Modeling Linkage Disequilibrium Increases Accuracy of Polygenic Risk Scores.” American Journal of Human Genetics 97 (4): 576–92. https://doi.org/10.1016/j.ajhg.2015.09.001.\n\n\nYang, Jian, Beben Benyamin, Brian P. McEvoy, Scott Gordon, Anjali K. Henders, Dale R. Nyholt, Pamela A. Madden, et al. 2010. “Common SNPs Explain a Large Proportion of the Heritability for Human Height.” Nature Genetics 42 (7): 565–69. https://doi.org/10.1038/ng.608.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>GWAS & Polygenic Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch04-cadd.html",
    "href": "p1-ch04-cadd.html",
    "title": "4  Deleteriousness Scores",
    "section": "",
    "text": "4.1 The Variant Prioritization Challenge\nA typical human genome contains approximately four to five million genetic variants relative to the reference assembly, encompassing single-nucleotide variants and short insertions and deletions. The vast majority of these are functionally neutral, representing the accumulated diversity of human evolution and population history. For any individual with a suspected genetic condition, the central interpretive challenge is to identify the handful of variants that plausibly contribute to disease from this enormous background of benign variation. This challenge of variant prioritization stands at the heart of clinical genomics: given a long list of candidate variants from exome or genome sequencing, which ones deserve experimental follow-up or clinical attention?\nThe data resources surveyed in Chapter 2 provide multiple complementary views of variant function, each with distinct strengths and limitations. Population frequency databases such as gnomAD reveal which variants survive in large cohorts of ostensibly healthy individuals, offering a powerful filter for identifying rare, potentially deleterious alleles (“The Genome Aggregation Database (gnomAD)” n.d.). Functional genomics consortia including ENCODE and the Roadmap Epigenomics Project indicate which genomic regions show evidence of biochemical activity across diverse cell types and developmental contexts. Clinical databases such as ClinVar and HGMD collect expert-curated variant classifications drawn from case reports and diagnostic laboratories, providing ground truth labels for known pathogenic and benign variants.\nEach of these sources is partial in important ways. Population databases are dominated by common variants, which are mostly tolerated by virtue of their high frequency. Rare and de novo variants, which are often most relevant for Mendelian disease, have sparse or no direct labels. Functional genomics data is inherently noisy and often context-specific: a region active in liver hepatocytes may be quiescent in neurons, and vice versa. Clinical databases are sparse and heavily biased toward well-studied genes and variant types, leaving vast swaths of the genome without reliable clinical annotations. The annotation density varies dramatically across the genome, with protein-coding exons densely labeled relative to deep intronic and intergenic sequences. Non-coding regions remain especially under-annotated despite harboring the majority of disease-associated variants identified by genome-wide association studies.\nBefore deep learning, variant effect predictors typically tackled this problem by focusing on one narrow signal. Conservation-based methods such as phyloP and GERP score each position according to its evolutionary constraint across multi-species alignments, under the logic that positions conserved over hundreds of millions of years are likely functionally important (Siepel et al. 2005; Davydov et al. 2010). Protein-level tools such as SIFT and PolyPhen predict the impact of amino acid substitutions based on sequence homology, physicochemical properties, and structural features (Ng and Henikoff 2003; Adzhubei et al. 2010). Positional annotations capture simple features like distance to splice sites or proximity to known regulatory elements. Each of these approaches captures a real biological signal, but each is also incomplete: conservation scores miss recently evolved functional elements, protein-level tools are blind to non-coding variants, and positional annotations lack the resolution to distinguish causal variants from linked neutral neighbors. Moreover, these early tools were limited in scope (primarily addressing missense single-nucleotide variants), built around relatively small feature sets, and trained on relatively modest numbers of labeled variants.\nCombined Annotation-Dependent Depletion (CADD) represented a fundamental shift in this landscape (Kircher et al. 2014; Rentzsch et al. 2019). Rather than relying on a single predictive signal, CADD defined a general framework for genome-wide variant prioritization that integrates dozens of heterogeneous annotations and uses evolutionary depletion as a proxy training label. The key insight was to avoid training directly on small sets of known pathogenic versus benign variants, which are scarce and biased toward certain genes and variant types. Instead, CADD contrasts variants that have survived purifying selection in the human lineage with matched simulated variants that could have occurred but did not. This evolutionary proxy strategy yields an enormous training set, enables genome-wide coverage, and produces scores that generalize across coding and non-coding regions alike.\nThis chapter focuses on the CADD framework because it establishes design patterns that recur throughout the deep learning models covered in subsequent chapters: proxy labels derived from evolutionary signals, large-scale training on millions of examples, integration of diverse features into unified scores, and genome-wide precomputation for downstream reuse.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch04-cadd.html#the-evolutionary-proxy-training-strategy",
    "href": "p1-ch04-cadd.html#the-evolutionary-proxy-training-strategy",
    "title": "4  Deleteriousness Scores",
    "section": "4.2 The Evolutionary Proxy Training Strategy",
    "text": "4.2 The Evolutionary Proxy Training Strategy\nCADD’s most important conceptual contribution was to reframe variant effect prediction as a large-scale machine learning problem with labels derived from evolutionary signal rather than clinical curation. A major obstacle to training a supervised variant effect predictor is the lack of gold-standard labels at scale. The scarcity and bias of known pathogenic variants has long limited supervised approaches to variant interpretation. ClinVar and similar databases contain tens of thousands of labeled variants, but these are concentrated in a small fraction of genes, skewed toward certain variant types (nonsense, frameshift, canonical splice site), and subject to ascertainment bias from clinical referral patterns. Truly benign variants are hard to certify, and truly pathogenic variants are rare and often context dependent. Training directly on such labels tends to produce models that perform well on variants similar to the training set but generalize poorly to the broader genome.\nRather than relying solely on curated clinical labels, CADD uses evolution as a weak supervisory signal, constructing two proxy classes of variants (Kircher et al. 2014; Rentzsch et al. 2019). The proxy-neutral class consists of variants that have been tolerated by purifying selection, while the proxy-deleterious class represents hypothetical mutations that could arise but are not observed. This design converts the question “How pathogenic is this variant?” into a closely related question: “Does this variant resemble mutations that are depleted by selection?”\n\n4.2.1 Proxy-Neutral Variants\nThe proxy-neutral class is built from variants that appear to have survived long-term purifying selection. CADD draws these from sequence differences that arose on the human lineage since the split from chimpanzees and became fixed or nearly fixed in modern humans (Kircher et al. 2014; Rentzsch et al. 2019). These derived human alleles are present at very high frequency in human populations, yet absent from the inferred human-chimp ancestral sequence. Because they have persisted over millions of years of evolution, most are presumed to be neutral or only weakly deleterious. They are distributed broadly across coding and non-coding regions, capturing a wide range of functional contexts.\nThis is not a perfect proxy for benign variants. Some observed alleles are genuinely pathogenic, particularly those with incomplete penetrance, late onset, or context-dependent effects. Variants under weak negative selection may persist at low to moderate frequencies for thousands of generations before eventual elimination. Population-specific bottlenecks and founder effects can elevate the frequency of otherwise deleterious alleles in particular groups. Despite these caveats, the proxy-neutral class is, on average, substantially enriched for tolerated alleles relative to a random sample of possible mutations. The key statistical insight is that systematic enrichment, even if imperfect at the individual variant level, provides a useful training signal when aggregated across millions of examples.\n\n\n4.2.2 Proxy-Deleterious Variants\nThe proxy-deleterious class is constructed by simulating mutations across the genome according to realistic mutational processes rather than through direct observation (Kircher et al. 2014; Rentzsch et al. 2019). The simulation matches local sequence context, typically using trinucleotide frequencies to capture the strong dependence of mutation rates on the identity of flanking bases. CpG dinucleotides, for example, have elevated mutation rates due to spontaneous deamination of methylated cytosines, and the simulation accounts for this by generating more CpG transitions in the proxy-deleterious set. Regional variation in mutation rates, driven by factors including replication timing, chromatin state, and local sequence composition, is similarly incorporated by scaling mutation counts within genomic windows. The simulator also adjusts for local substitution frequencies and indel length distributions inferred from the proxy-neutral set.\nThe logic underlying this construction is subtle but powerful. Simulated variants represent changes that could plausibly occur under human mutational processes but are generally not observed at high frequency in population databases. Many of these simulated variants would in fact be neutral if they were to arise; the simulation makes no attempt to identify truly deleterious mutations at the individual level. However, the proxy-deleterious class as a whole is enriched for alleles that are disfavored by selection, because the set of possible mutations includes many that disrupt conserved elements, alter protein function, or perturb regulatory sequences. By contrasting this set with the proxy-neutral class, CADD learns to recognize the annotation signatures that distinguish variants under purifying selection from those that have been tolerated.\n\n\n4.2.3 Training Objective\nWith proxy-neutral and proxy-deleterious classes in hand, CADD trains a binary classifier to distinguish between them (Kircher et al. 2014; Rentzsch et al. 2019). The input to this classifier is a feature vector describing each variant, encompassing the diverse annotations surveyed in the following section: gene model features, conservation scores, epigenetic signals, protein-level predictions, and more. The label is simply whether the variant was simulated (proxy-deleterious) or observed (proxy-neutral). The objective is straightforward: learn a decision function that separates these two classes as well as possible, assigning higher values to simulated variants and reflecting their predicted deleteriousness.\nEarly CADD versions employed linear support vector machines trained on approximately 30 million simulated versus observed variants with 63 annotation features plus selected interaction terms (Rentzsch et al. 2019). This relatively simple architecture was sufficient to capture the main structure of the problem, in part because the features themselves encode substantial biological knowledge. Later versions, including CADD v1.7, employ logistic regression-style models with expanded feature sets, retaining the same fundamental paradigm of contrasting simulated and observed variants while accommodating richer annotations (Schubach et al. 2024).\nThis evolutionary depletion framework is conceptually related to contrastive learning: the model learns a representation of variants that maximally distinguishes those that evolution has accepted from those it has not. Unlike modern self-supervised contrastive objectives, CADD uses a fixed set of hand-engineered features and a linear classifier, and the labels are derived from evolutionary simulations rather than augmentations of the same underlying data. The training set is extremely large, enabling complex decision boundaries and robust generalization. The resulting scores are precomputed genome-wide and reused for diverse downstream tasks, from rare disease gene discovery to variant filtration pipelines to evaluation baselines for newer models. In this sense, CADD can be understood as an early example of pretraining on a large-scale proxy task followed by transfer to clinical applications, a pattern that defines modern foundation models.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch04-cadd.html#integration-of-diverse-annotations",
    "href": "p1-ch04-cadd.html#integration-of-diverse-annotations",
    "title": "4  Deleteriousness Scores",
    "section": "4.3 Integration of Diverse Annotations",
    "text": "4.3 Integration of Diverse Annotations\nCADD’s second conceptual pillar is the integration of many weak, noisy annotations into a single composite score. Where earlier variant effect predictors typically relied on one or a few signals, CADD combines more than 60 features in its original incarnation and substantially more in version 1.7 (Kircher et al. 2014; Rentzsch et al. 2019; Schubach et al. 2024). This integrative approach recognizes that no single annotation captures the full complexity of variant function. Conservation scores miss recently evolved functional elements. Protein-level predictions are uninformative for non-coding variants. Regulatory annotations are noisy and incomplete. By learning optimal weights for combining these diverse signals, CADD achieves performance that exceeds any individual component.\nBecause Chapter 2 already surveys the underlying data resources in detail, this section focuses on the categories of features and how they function within the CADD framework. For specifics on individual databases such as ENCODE, Roadmap, gnomAD, and ClinVar, readers should consult the earlier chapter.\n\n4.3.1 Gene Model Annotations\nGene model annotations describe the local transcript and coding context of each variant. The most fundamental is the predicted sequence consequence: whether a variant is synonymous, missense, nonsense, frameshift, splice-site disrupting, or located in untranslated or intronic regions. These consequence categories capture qualitatively different modes of disruption, from silent changes that preserve protein sequence to truncating mutations that eliminate large portions of the gene product.\nBeyond simple consequence, CADD incorporates positional features such as distance to exon-intron boundaries and proximity to canonical splice sites. Variants near splice junctions have elevated potential to disrupt splicing even if they do not directly alter the canonical GT-AG dinucleotides. Distance to the start and stop codons provides additional context, as does the position within the reading frame for coding variants.\nGene-level attributes further enrich the annotation set. Constraint metrics derived from population data, such as the probability of loss-of-function intolerance (pLI) and the loss-of-function observed/expected upper bound fraction (LOEUF), quantify how tolerant each gene is to damaging variation (“The Genome Aggregation Database (gnomAD)” n.d.). Variants in highly constrained genes receive elevated deleteriousness scores, reflecting the empirical observation that such genes are enriched for disease associations. Known disease gene status from OMIM and similar resources provides complementary information about genes with established pathogenic roles.\nFor amino acid-changing variants, CADD includes protein-level features beyond simple consequence. Predicted impact on coding sequence from tools such as SIFT and PolyPhen-2 provides established assessments of whether substitutions are likely damaging (Ng and Henikoff 2003; Adzhubei et al. 2010). Amino acid physicochemical properties, including size, charge, hydrophobicity, and polarity, inform predictions about whether a substitution is conservative or radical. Grantham distances quantify the biochemical dissimilarity between amino acid pairs, while secondary structure and domain annotations from databases like Pfam provide structural context.\nThese gene model features allow CADD to make biologically meaningful distinctions. A synonymous variant in a tolerant gene with high LOEUF receives a very different score than a truncating variant in a highly constrained developmental regulator. The model learns these distinctions from the differential representation of variant types across the proxy-neutral and proxy-deleterious training classes.\n\n\n4.3.2 Conservation and Constraint\nEvolutionary conservation provides some of the strongest signals for variant deleteriousness, particularly in non-coding regions where direct functional labels are scarce. CADD incorporates multiple conservation metrics computed from multi-species alignments spanning mammals, vertebrates, and more distant taxa.\nBase-level conservation scores such as GERP (Genomic Evolutionary Rate Profiling) and phyloP quantify the deviation of observed substitution rates from neutral expectation (Davydov et al. 2010; Siepel et al. 2005). Positions with strong negative GERP scores show substitution rates far below neutral, indicating purifying selection has maintained these bases across tens or hundreds of millions of years of evolution. PhastCons provides a complementary view by identifying conserved elements, contiguous regions with elevated conservation that likely correspond to functional units. PhyloP scores individual positions without the smoothing implicit in element-based approaches, capturing both conservation (slow evolution) and acceleration (fast evolution) relative to neutral models.\nRegional measures of constraint complement base-level scores. These capture broader patterns of evolutionary pressure that may not be evident at single positions but emerge when considering larger windows. Measures of regional intolerance to variation derived from population datasets, such as gene- or exon-level constraint from gnomAD, add further context (“The Genome Aggregation Database (gnomAD)” n.d.). Mutation rate estimates, derived from substitution patterns in presumably neutral regions such as ancestral repeats, allow the model to distinguish true constraint from low mutation rate.\nConservation features are particularly valuable for non-coding variant interpretation, where biochemical annotations are often incomplete or absent. A deeply conserved non-coding position is likely functional even if no enhancer or promoter annotation overlaps it. Conversely, lack of conservation provides evidence (though not proof) that a position is tolerant to variation.\n\n\n4.3.3 Epigenetic and Regulatory Activity\nCADD incorporates regulatory annotations derived from functional genomics assays to capture the chromatin and regulatory context of each variant. These features draw primarily from large-scale consortium efforts including ENCODE and the Roadmap Epigenomics Project, which have profiled chromatin accessibility, histone modifications, and transcription factor binding across hundreds of cell types and tissues.\nDNase I hypersensitivity and ATAC-seq peaks identify regions of open chromatin, marking active regulatory elements including promoters, enhancers, and insulators. ChIP-seq signals for histone modifications provide additional context: H3K4me3 marks active promoters, H3K27ac marks active enhancers, H3K36me3 spans transcribed gene bodies, and H3K27me3 marks polycomb-repressed regions. Transcription factor ChIP-seq directly identifies binding sites for specific regulators, though coverage varies considerably across factors and cell types.\nChromatin state segmentations integrate multiple histone marks and accessibility signals into discrete functional categories. These segmentations, produced by algorithms such as ChromHMM, assign each genomic position to states like “active promoter,” “strong enhancer,” “weak enhancer,” “transcribed region,” or “heterochromatin.” By including these aggregate states alongside raw signals, CADD can capture combinatorial patterns that distinguish functional regulatory elements from background.\nThese epigenomic features help prioritize non-coding variants that disrupt active regulatory regions. A variant falling within an active enhancer marked by H3K27ac and DNase hypersensitivity in a relevant tissue receives elevated deleteriousness scores, even if its conservation is modest. The tissue specificity of regulatory annotations presents both opportunity and challenge: a variant may be highly consequential in one cellular context while neutral in another, and CADD’s genome-wide scores necessarily average across this heterogeneity.\n\n\n4.3.4 Additional Features\nBeyond the major annotation categories, CADD incorporates features capturing local sequence context and genomic architecture. GC content and CpG dinucleotide density affect mutation rates, chromatin structure, and gene regulation. Segmental duplications and low-complexity regions flag positions where mapping uncertainty may confound variant calls or where duplicated sequences complicate interpretation. Distance to transcription start sites, polyadenylation signals, telomeres, and centromeres provides coarse chromosomal and genic context. Regional recombination rates and other genomic descriptors round out the feature set.\nNot every individual annotation is informative in isolation. Many features are noisy, incomplete, or redundant with one another. The power of CADD lies in learning how to weight and combine these heterogeneous signals, up-weighting annotations that distinguish proxy-deleterious from proxy-neutral variants and down-weighting those that do not. This learned integration is more powerful than any manually specified combination rule and adapts automatically as new features are added in subsequent versions.\nFrom the perspective of this book, these features exemplify classic feature engineering: human experts select and pre-compute biologically meaningful quantities, which are then passed to a general-purpose machine learning algorithm. The transition to deep learning, explored in subsequent chapters, shifts much of this burden from manual feature design to learned representations, though as we will see with CADD v1.7, the two approaches can be productively combined.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch04-cadd.html#model-architecture-and-scoring",
    "href": "p1-ch04-cadd.html#model-architecture-and-scoring",
    "title": "4  Deleteriousness Scores",
    "section": "4.4 Model Architecture and Scoring",
    "text": "4.4 Model Architecture and Scoring\n\n4.4.1 Machine Learning Framework\nCADD’s classifier operates on a high-dimensional feature vector assembled for each variant. The input representation concatenates all annotations described in the previous section: gene model features, conservation scores, epigenomic signals, sequence context, and protein-level predictions where applicable. For a typical variant, this yields a vector of several dozen to over a hundred features, depending on the CADD version and whether the variant falls in coding or non-coding sequence.\nThe original CADD model uses a linear support vector machine trained to discriminate proxy-neutral and proxy-deleterious variants based on the annotation vector (Kircher et al. 2014; Rentzsch et al. 2019). The choice of a linear model was deliberate and reflects pragmatic considerations. With tens of millions of training examples and dozens of features, a linear SVM is computationally tractable while still capturing the main structure of the classification problem. Many features are correlated, and a linear model with appropriate regularization can nonetheless capture a useful decision boundary. The linearity also provides some interpretability, as feature weights indicate which annotations most strongly distinguish the proxy classes.\nIn CADD v1.7, the framework transitions to a logistic regression-style model with an expanded annotation set exceeding 100 features (Schubach et al. 2024). The fundamental paradigm remains unchanged: contrast simulated and observed variants using a discriminative classifier. The logistic formulation provides well-calibrated probability estimates that facilitate downstream score transformations, while the expanded feature set incorporates new annotations including protein language model scores and regulatory CNN predictions discussed in the following section.\nConceptually, the classifier learns a scoring function such that large positive values indicate variants whose annotation profiles resemble the proxy-deleterious class, while large negative values indicate profiles resembling the proxy-neutral class. Variants with intermediate scores occupy an ambiguous middle ground where the annotation evidence does not clearly favor either class. The raw output of this classifier is often referred to as the C-score or raw CADD score.\n\n\n4.4.2 PHRED-Scaled Scores\nRaw CADD scores are not directly interpretable as probabilities or biological effect sizes. The scale depends on model architecture, feature normalization, and training set composition, all of which vary across CADD versions. To provide a more intuitive and stable scoring system, CADD defines PHRED-like scaled scores based on the rank of each variant among all possible single-nucleotide substitutions in the reference genome (Rentzsch et al. 2019; Schubach et al. 2024).\nThe PHRED scaling follows the same logarithmic convention used in sequencing quality scores. A scaled score of 10 indicates that a variant falls in the top 10% of predicted deleteriousness among all possible substitutions. A score of 20 indicates the top 1%, and a score of 30 indicates the top 0.1%. More generally, a scaled score of n corresponds to the top 10^(-n/10) fraction of the deleteriousness distribution. This transformation compresses the raw scores into a 1-99 range that reflects percentile rank rather than absolute effect size.\nThis rank-based transformation has several practical consequences. First, it provides a simple interpretation: users can immediately understand that a variant with scaled score 20 is predicted to be more deleterious than 99% of possible substitutions. Second, it ensures comparability across CADD versions. Because the scaled score is defined relative to the full distribution of possible variants, a score of 20 always means “top 1%” even as the underlying model, features, and raw score distributions change between releases. Third, it facilitates direct comparison of scores between variants in different regions. Fourth, it sacrifices resolution in the bulk of the distribution. Most variants are predicted to be relatively benign, and these cluster in the low-score range where differences are difficult to interpret. The scaling concentrates dynamic range in the high-score tail where clinical interpretation typically focuses.\nIn rare disease pipelines, CADD scaled scores are commonly used as filters to enrich for potentially pathogenic variants before detailed interpretation. Typical thresholds range from 15 (top 3%) to 20 (top 1%) or higher, depending on the stringency required and the downstream analysis workflow. Variants with CADD scores of 20 or above are often considered moderately high deleteriousness candidates, while scores at or above 30 are frequently interpreted as strongly enriched for functional impact. These filters are not intended as definitive pathogenicity calls but rather as prioritization tools that reduce the variant burden to a manageable number for expert review. The thresholds remain heuristic and context-dependent; downstream interpretation should incorporate phenotype, segregation, and other lines of evidence.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch04-cadd.html#cadd-v1.7-integration-of-deep-learning-predictions",
    "href": "p1-ch04-cadd.html#cadd-v1.7-integration-of-deep-learning-predictions",
    "title": "4  Deleteriousness Scores",
    "section": "4.5 CADD v1.7: Integration of Deep Learning Predictions",
    "text": "4.5 CADD v1.7: Integration of Deep Learning Predictions\nCADD v1.7 demonstrates how the original annotation-integration framework naturally accommodates deep learning outputs and modern sequence models (Schubach et al. 2024). Rather than replacing CADD’s architecture with an end-to-end neural network, the developers adopted a pragmatic strategy: treat deep learning predictions as additional features within the existing integrative framework. This approach preserves CADD’s interpretable structure while benefiting from the representational power of large pretrained models. Broadly, CADD v1.7 adds three major categories of features: protein language model scores for coding variants, sequence-based CNN regulatory predictions for non-coding variants, and extended conservation scores from the Zoonomia consortium.\n\n4.5.1 Protein Language Model Features\nFor protein-coding variants, CADD v1.7 integrates variant effect scores from protein language models, particularly ESM-1v (Meier et al. 2021; Schubach et al. 2024). These models represent a paradigm shift in protein sequence analysis. Trained self-supervised on hundreds of millions of protein sequences using masked language modeling objectives, PLMs learn contextual embeddings that capture the evolutionary constraints and functional requirements shaping protein sequences. The resulting representations encode information about secondary structure, domain boundaries, binding interfaces, and catalytic sites without explicit supervision on any of these properties.\nESM-1v provides per-variant scores by comparing the log-likelihood of the reference and alternate amino acids at each position. Positions where the model confidently predicts the reference residue and assigns low probability to the alternate receive large effect scores, indicating the substitution violates learned sequence constraints. A large drop in likelihood suggests that the mutant is less compatible with the evolutionary sequence distribution learned by the model and is therefore more likely to be functionally disruptive. These scores correlate strongly with experimental measurements of variant effects from deep mutational scanning assays, demonstrating that PLMs capture genuine functional information (Notin et al. 2023).\nBy embedding ESM-1v-derived features into its annotation set, CADD v1.7 effectively delegates part of the representation learning to a large foundational protein model, then uses its own classifier to recalibrate and integrate these signals with other annotations. This division of labor plays to each model’s strengths: the PLM learns rich sequence representations from massive protein databases, while CADD’s integrative framework combines these representations with genomic context, conservation, and regulatory features that protein-only models cannot access. The result is access to rich protein context, including implicit structure, dynamics, and interaction information, that classical missense predictors cannot fully capture.\n\n\n4.5.2 Regulatory CNN Predictions\nFor non-coding variants, CADD v1.7 incorporates regulatory variant effect predictions from sequence-based convolutional neural networks trained on chromatin accessibility and related assays (Zhou and Troyanskaya 2015; Schubach et al. 2024). These CNNs, exemplified by DeepSEA and similar architectures covered in Chapters 5 and 6, take raw DNA sequence as input and predict a battery of chromatin features including transcription factor binding, histone modifications, and DNase hypersensitivity across diverse cell types.\nThe variant effect predictions are computed as delta scores: the difference in predicted regulatory activity between reference and alternate alleles. Large magnitude deltas indicate variants predicted to substantially alter local chromatin state or transcription factor occupancy. These predictions provide a learned, sequence-based view of regulatory impact that complements the annotation-based epigenomic features derived from experimental data.\nAlthough full-scale models like Enformer can predict a broad spectrum of regulatory readouts from large sequence contexts, their computational cost makes genome-wide integration challenging. CADD v1.7 instead uses smaller CNNs trained specifically on open-chromatin data, chosen to approximate Enformer-level performance on regulatory variant benchmarks while remaining tractable to run at scale. From CADD’s perspective, these CNN outputs are simply additional features: for each variant, the model receives summary statistics describing the predicted impact on regulatory activity in different cell types.\nBy incorporating CNN-derived regulatory predictions, CADD v1.7 uses early sequence-to-function deep learning models as feature generators within its broader integrative framework. This represents an important architectural pattern that recurs throughout genomic deep learning: pretrained sequence models provide representations or predictions that are then combined with other information sources in downstream tasks.\n\n\n4.5.3 Extended Conservation Scores\nCADD v1.7 updates its conservation and mutation-rate features to incorporate advances in comparative genomics and population genetics (Schubach et al. 2024). Deeper mammalian alignments from projects like Zoonomia, which sequenced over 200 mammalian species, provide substantially improved resolution for identifying constrained positions, particularly in non-coding regions where earlier alignments had limited power. The expanded phylogenetic scope allows detection of constraint that is specific to mammals or particular mammalian clades, complementing the broader vertebrate and eukaryotic conservation captured by earlier alignments.\nThese extended conservation metrics improve sensitivity for constrained elements in non-coding regions, provide more nuanced distinctions within moderately conserved regions, and complement the older GERP++ and phastCons scores. Improved models of genome-wide mutation rates further sharpen the distinction between true evolutionary constraint and regions with inherently low mutation rates. Earlier approaches sometimes conflated these signals: a region might appear conserved simply because few mutations arise there rather than because mutations are selectively removed. By incorporating refined mutation rate estimates derived from de novo mutation studies and population polymorphism patterns, CADD v1.7 can better distinguish these scenarios and assign appropriate deleteriousness scores.\nThese updates are particularly valuable for non-coding variant interpretation, where conservation signals are often the strongest available evidence for function. Improved detection of mammal-specific regulatory elements and better calibration against local mutation rates help identify pathogenic non-coding variants that earlier versions might have missed.\n\n\n4.5.4 Performance Improvements\nCADD v1.7 is evaluated on several benchmark datasets that span different variant types and functional readouts (Schubach et al. 2024). Clinical variant benchmarks drawn from ClinVar and gnomAD compare pathogenic and benign variant sets, providing a coarse approximation of the clinical classification task that motivates CADD’s development. Deep mutational scanning assays, summarized in resources like ProteinGym, offer experimentally measured variant effects for thousands of mutations across dozens of proteins, enabling evaluation against direct functional measurements rather than clinical labels (Notin et al. 2023). Saturation mutagenesis reporter assays for promoters and enhancers capture regulatory variant effects with nucleotide resolution, testing CADD’s performance on the non-coding variants that are often most challenging to interpret.\nAcross these benchmarks, incorporating PLM scores, regulatory CNN predictions, and updated conservation features yields consistent improvements in classification and ranking performance compared to earlier CADD versions. The gains are particularly pronounced for missense variants, where ESM-1v features provide substantial additional signal, and for non-coding variants in active regulatory regions, where CNN predictions complement annotation-based features. Stronger correlations with experimental fitness measurements for many proteins reflect the contribution of PLM features, while better prediction of expression changes from non-coding variants reflects the added CNN-based regulatory features.\nThese improvements validate the strategy of incorporating deep learning outputs as features while maintaining CADD’s interpretable integrative framework. Importantly, CADD v1.7 remains an annotation-integration method: the underlying model is still a relatively simple generalized linear model; it is the feature set that has become increasingly deep learning-flavored.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch04-cadd.html#benchmarking-against-alternative-approaches",
    "href": "p1-ch04-cadd.html#benchmarking-against-alternative-approaches",
    "title": "4  Deleteriousness Scores",
    "section": "4.6 Benchmarking Against Alternative Approaches",
    "text": "4.6 Benchmarking Against Alternative Approaches\nCADD exists within a crowded landscape of deleteriousness predictors spanning four decades of methodological development. Benchmarking against alternative scores helps clarify both where CADD excels and where specialized tools may be preferable. Other approaches include genome-wide integrative scores such as DANN, Eigen, GWAVA, and LINSIGHT, as well as coding-specific ensemble predictors such as REVEL, M-CAP, and more recent deep-learning-based missense models (Rentzsch et al. 2019).\n\n4.6.1 Coding Variants\nFor coding variants, especially missense changes, CADD competes with a crowded ecosystem of tools. Legacy single-task scores such as SIFT and PolyPhen pioneered sequence-based and structure-based prediction of amino acid substitution effects, using evolutionary conservation and physicochemical properties to identify potentially damaging missense variants (Ng and Henikoff 2003; Adzhubei et al. 2010). Integrative ensemble scores such as REVEL, M-CAP, and MetaSVM combine predictions from multiple individual tools, using machine learning to weight and integrate their outputs. Constraint-based metrics such as MPC provide model-based missense tolerability scores. Modern deep learning approaches exploit protein language models, structure prediction from AlphaFold, and end-to-end neural architectures that learn directly from sequence.\nIn systematic benchmarks across clinically annotated variants and deep mutational scanning datasets, CADD’s combination of evolutionary, protein-level, and gene-context features yields performance that is competitive with or superior to many specialized scores for Mendelian disease variant prioritization (Rentzsch et al. 2019; Schubach et al. 2024). The integration of ESM-1v features in version 1.7 closes much of the gap with pure PLM-based methods while retaining CADD’s advantages in interpretability and genome-wide coverage. CADD’s performance is particularly strong when variants must be ranked across diverse genes and consequence types, a setting that favors integrative approaches over methods tuned for specific protein families or variant classes.\nHowever, for purely missense-focused tasks, specialized ensemble methods may have an advantage. Tools optimized for loss-of-function variant interpretation may capture nuances that CADD’s genome-wide training misses. Structure-based methods incorporating AlphaFold predictions can model three-dimensional context that sequence-based features cannot fully capture. The appropriate choice of variant effect predictor depends on the specific application, available data, and interpretability requirements.\n\n\n4.6.2 REVEL and Other Ensemble Missense Scores\nREVEL (Rare Exome Variant Ensemble Learner) represents a prominent missense-specific ensemble predictor widely used in clinical laboratories (Ioannidis et al. 2016). It integrates predictions from a panel of individual tools, including SIFT, PolyPhen-2, PROVEAN, MutationAssessor, FATHMM, GERP++, phyloP, and phastCons, into a random forest model. The training data consists of pathogenic missense variants curated from ClinVar and other resources alongside rare putatively neutral missense variants from population datasets.\nREVEL is restricted in scope to missense single-nucleotide variants in protein-coding regions. Its scores range from 0 to 1, with higher values implying greater likelihood of pathogenicity. Common heuristics treat scores above 0.5 or 0.7 as increasingly strong evidence for deleteriousness, though more stringent thresholds at or above 0.8 may be appropriate for high-specificity applications. REVEL is often incorporated into diagnostic pipelines and ACMG/AMP-style variant interpretation workflows as one of several supporting lines of computational evidence.\nIn comparison to CADD, REVEL often outperforms on missense-only benchmarks, reflecting its focused training objective and use of many specialized missense predictors. However, CADD offers broader coverage, scoring non-coding and indel variants and integrating regulatory and conservation features not captured by REVEL. From the standpoint of this book, REVEL illustrates how ensemble learning over pre-existing tools can yield strong performance within a narrow variant class, complementing CADD’s genome-wide viewpoint.\n\n\n4.6.3 Non-coding Variants\nNon-coding variant interpretation presents fundamentally greater challenges than coding variant prediction. Ground-truth pathogenic non-coding variants are far rarer in clinical databases and heavily biased toward a small number of well-studied regulatory elements, particularly canonical splice sites and a handful of characterized enhancers. The vast majority of the non-coding genome lacks reliable pathogenicity labels, making supervised approaches difficult and benchmark construction problematic.\nFunctional genomics assays provide an alternative view of non-coding function, but their interpretation is complicated by noise, cell-type specificity, and the uncertain relationship between biochemical activity and phenotypic consequence. A variant may alter transcription factor binding in a reporter assay yet have no detectable effect on gene expression or organismal phenotype. Conversely, subtle regulatory perturbations may have profound effects in specific developmental contexts that are not captured by standard assays.\nWithin this challenging landscape, CADD’s integration of regulatory annotations and conservation allows it to rank plausible non-coding candidates genome-wide, particularly in promoters and enhancers covered by ENCODE and Roadmap data (Rentzsch et al. 2019). The addition of regulatory CNN predictions in version 1.7 provides learned sequence-based features that extend beyond annotation coverage. Specialized scores explicitly focused on regulatory function, such as GWAVA and LINSIGHT, integrate epigenomic and evolutionary features to prioritize non-coding variants. DeepSEA and related CNN-based methods predict regulatory activity and variant effects directly from DNA sequence (Zhou and Troyanskaya 2015).\nBenchmarking studies typically find that CADD is highly effective as a broad, genome-wide prioritization tool, often matching or approaching the performance of non-coding-specific scores on regulatory benchmarks (Rentzsch et al. 2019). Specialized sequence-based CNNs can outperform CADD for particular tasks, such as predicting the effect of variants in specific enhancers or promoters, but they are more computationally intensive and less straightforward to deploy as general-purpose annotation. CADD v1.7 narrows this gap by importing CNN-derived regulatory features into its annotation set, effectively blending sequence-based and integrative approaches.\nHowever, CADD’s performance on non-coding variants depends heavily on the availability and quality of underlying annotations. Variants in poorly annotated regions, including many distal enhancers and non-coding RNAs, receive scores driven primarily by conservation, which may miss recently evolved or lineage-specific functional elements.\n\n\n4.6.4 Population Frequency Correlation\nBecause CADD uses evolutionary depletion as its training signal, its scores naturally correlate with population allele frequencies. A basic sanity check for any deleteriousness score is this correlation: variants with higher predicted deleteriousness should, on average, be rarer in population datasets such as gnomAD, reflecting stronger purifying selection.\nCommon variants in gnomAD tend to have low CADD scores, reflecting the expectation that alleles reaching high frequency have survived purifying selection. Known pathogenic variants, such as truncating variants in severe Mendelian genes, tend to have high CADD scores and low allele frequencies. Very rare variants, particularly singletons observed in only one individual, show a broad distribution of scores with a substantial fraction in the high-score tail (Rentzsch et al. 2019; “The Genome Aggregation Database (gnomAD)” n.d.). A negative correlation between CADD and allele frequency is observed across variant classes, though the strength of this relationship varies by consequence, being strongest for protein-truncating variants and weaker for some synonymous changes.\nThis correlation is useful for many applications. High CADD scores often highlight variants under purifying selection, which are enriched for functional and potentially pathogenic alleles. The relationship provides a sanity check: if CADD assigned high scores to common variants, something would be wrong with either the model or the frequency data.\nHowever, this correlation also means that CADD partially recapitulates frequency-based filtering. In downstream pipelines, it is important not to double-count this signal by applying both aggressive frequency cutoffs and strict CADD thresholds. Such redundant filtering can exclude variants that fail one criterion but might be genuinely pathogenic. The optimal strategy depends on the application: for highly penetrant Mendelian variants, frequency filtering alone may suffice; for variants with incomplete penetrance or population-specific effects, CADD provides complementary information beyond frequency.\n\n\n4.6.5 Limitations and Circularity with ClinVar\nDespite its strengths, CADD has important limitations that should inform its use in research and clinical settings.\nFirst, the proxy labels are imperfect. Simulated variants are not purely deleterious, and fixed human lineage variants can be mildly deleterious or linked to other fitness-modulating changes. CADD’s labels are therefore noisy, and its scores should not be interpreted as precise probabilities of disease. Second, context matters in ways that CADD does not capture. The framework does not explicitly model gene-phenotype relationships, inheritance mode, or tissue-specific expression; it provides a general measure of deleteriousness rather than disease specificity.\nThird, potential circularity between CADD scores and clinical databases such as ClinVar raises methodological concerns. Two forms of circularity are particularly relevant. Evaluation circularity arises when CADD is assessed on benchmark datasets that were themselves influenced by CADD. ClinVar submissions increasingly incorporate in silico evidence, including CADD scores, as part of their classification process. When we evaluate CADD on post-2014 ClinVar variants after clinical curation has already used CADD, we risk overestimating performance because the model is partially being judged against labels it helped create (Schubach et al. 2024). Variants with high CADD scores are more likely to be classified as pathogenic, and variants classified as pathogenic form the positive evaluation set, creating a feedback loop that inflates apparent performance.\nBroader sociotechnical feedback affects model development even if CADD’s core training labels derive from simulated versus observed variants rather than clinical databases. ClinVar and related resources still influence feature engineering, threshold selection, and choice of evaluation benchmarks. Over time, variants consistently prioritized by CADD are more likely to receive follow-up investigation, be published, and enter ClinVar as likely pathogenic, reinforcing the underlying signal. This feedback is not unique to CADD but affects any widely used predictive tool in genomics and medicine. As the field increasingly uses CADD and related scores to prioritize variants for experimental follow-up and clinical reporting, there is a risk that databases of known pathogenic variants become biased toward variants with high CADD scores.\nThese circularity concerns motivate several best practices for evaluation. Benchmarks should include datasets independent of clinical curation pipelines, such as deep mutational scanning experiments, reporter assays, and population-based burden tests where labels derive from experimental measurement rather than clinical judgment. Performance should be reported separately on pre-CADD and post-CADD ClinVar subsets when temporal stratification is possible. ClinVar-based evaluation should be treated as a sanity check confirming that CADD captures clinically relevant signals, not as the primary or sole measure of model quality.\nThese concerns foreshadow similar issues we will encounter in later chapters when genomic foundation models are evaluated on benchmarks that themselves rely on older predictive tools or clinical databases shaped by those tools.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "p1-ch04-cadd.html#significance-for-genomic-deep-learning",
    "href": "p1-ch04-cadd.html#significance-for-genomic-deep-learning",
    "title": "4  Deleteriousness Scores",
    "section": "4.7 Significance for Genomic Deep Learning",
    "text": "4.7 Significance for Genomic Deep Learning\nCADD occupies an important historical position at the junction between hand-crafted feature integration and modern deep, self-supervised representation learning. It anticipates many of the themes that recur throughout this book while also highlighting enduring challenges. Several aspects of its design resonate throughout the models and methods covered in subsequent chapters, making it a valuable conceptual anchor for understanding the field’s evolution.\nThe first connection is between annotation integration and multi-task deep models. CADD’s strategy of combining dozens of heterogeneous annotations into a single score anticipates the multi-task learning frameworks that define modern genomic deep learning. Models like DeepSEA, Basset, and Enformer, covered in Chapters 5 through 7 and revisited in Chapter 11, predict hundreds of functional genomics readouts from sequence and then reuse these predictions as building blocks for downstream tasks. The conceptual structure is similar: learn to predict many weak signals, then combine them for variant interpretation. In CADD v1.7, the boundary between these approaches blurs as deep networks including ESM-1v and regulatory CNNs provide features that CADD integrates (Meier et al. 2021; Zhou and Troyanskaya 2015; Schubach et al. 2024). The distinction between “annotation-based” and “deep learning-based” methods becomes one of degree rather than kind.\nThe second connection is between evolutionary proxy labels and self-supervised learning. CADD’s training on simulated versus observed variants uses the signature of selection as a rich, weak supervisory signal available across the entire genome (Kircher et al. 2014; Rentzsch et al. 2019). This strategy is conceptually parallel to the masked language modeling objectives that define modern protein and DNA language models. In both cases, the labels derive not from expert curation but from statistical regularities in large datasets: which tokens (amino acids, nucleotides, or variants) are observed versus which are plausible but absent. The resulting models learn representations that transfer to diverse downstream tasks, from variant effect prediction to structure determination to regulatory sequence design. Chapters 8 through 10 develop this connection in detail for transformer-based foundation models.\nThe third connection concerns genome-wide coverage and scalability. By precomputing scores for all possible single-nucleotide substitutions in the reference genome, CADD demonstrated the feasibility and utility of generating genome-wide variant annotations for downstream reuse. Users need not run the full model for each query; they simply look up precomputed scores from distributed files. Many genomic foundation models now follow an analogous pattern, precomputing embeddings or predictions for every base or variant and exposing them as reusable resources. Just as modern foundation models provide reusable embeddings or zero-shot predictions across many tasks, CADD provides a universal deleteriousness prior that can be plugged into diverse analyses, from GWAS fine-mapping to rare disease diagnosis. The infrastructure for distributing and querying such precomputed annotations has become a standard component of genomic analysis pipelines.\nThe fourth connection is composability with deep learning. CADD is not a direct competitor to modern sequence-based deep models but rather an integrative framework that increasingly incorporates them as features. This “deep features plus shallow integrator” pattern appears repeatedly in practical deployments where interpretability, calibration, or computational constraints favor hybrid approaches over end-to-end neural networks. Clinical variant interpretation pipelines, in particular, often combine CADD-style integrative scores with deep learning predictions and expert review, leveraging the strengths of each approach. Deep representations can be integrated into existing statistical pipelines, clinical workflows, and decision-support systems without requiring full-stack neural architectures everywhere.\nFinally, CADD highlights the limits of purely scalar scores. No single number can capture all dimensions of variant impact: tissue specificity, developmental timing, gene-environment interactions, or polygenic background. As genomic foundation models become more expressive, they will increasingly move beyond scalar “deleteriousness” toward richer predictions, such as cell-type-resolved gene expression changes and pathway-level perturbations. Nonetheless, CADD’s conceptual framework of proxy labels, feature integration, and evolutionary depletion remains a valuable anchor for understanding how the field arrived at its current deep learning-dominated landscape.\nAs we move into the CNN-based sequence-to-function models of Part II and the transformer-based genomic foundation models of Parts III and IV, it is helpful to remember that CADD solved a difficult problem using tools available at the time. The challenge of variant prioritization under data scarcity and annotation heterogeneity does not disappear with more powerful models. The deep learning systems that follow expand on CADD’s core ideas by learning representations directly from sequence and tying those representations to richer experimental readouts. Yet they still rely on many of the same data resources surveyed in Chapter 2 and confront many of the same challenges around evaluation bias, label circularity, and the fundamental difficulty of inferring causality from correlation. Understanding CADD’s solutions and limitations provides essential context for appreciating both the advances and the persistent challenges in genomic deep learning.\n\n\n\n\nAdzhubei, Ivan A., Steffen Schmidt, Leonid Peshkin, Vasily E. Ramensky, Anna Gerasimova, Peer Bork, Alexey S. Kondrashov, and Shamil R. Sunyaev. 2010. “A Method and Server for Predicting Damaging Missense Mutations.” Nature Methods 7 (4): 248–49. https://doi.org/10.1038/nmeth0410-248.\n\n\nDavydov, Eugene V., David L. Goode, Marina Sirota, Gregory M. Cooper, Arend Sidow, and Serafim Batzoglou. 2010. “Identifying a High Fraction of the Human Genome to Be Under Selective Constraint Using GERP++.” PLOS Computational Biology 6 (12): e1001025. https://doi.org/10.1371/journal.pcbi.1001025.\n\n\nIoannidis, Nilah M., Joseph H. Rothstein, Vikas Pejaver, Sumit Middha, Shannon K. McDonnell, Saurabh Baheti, Anthony Musolf, et al. 2016. “REVEL: An Ensemble Method for Predicting the Pathogenicity of Rare Missense Variants.” The American Journal of Human Genetics 99 (4): 877–85. https://doi.org/10.1016/j.ajhg.2016.08.016.\n\n\nKircher, Martin, Daniela M. Witten, Preti Jain, Brian J. O’Roak, Gregory M. Cooper, and Jay Shendure. 2014. “A General Framework for Estimating the Relative Pathogenicity of Human Genetic Variants.” Nature Genetics 46 (3): 310–15. https://doi.org/10.1038/ng.2892.\n\n\nMeier, Joshua, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu, and Alexander Rives. 2021. “[ESM-1v] Language Models Enable Zero-Shot Prediction of the Effects of Mutations on Protein Function.” bioRxiv. https://doi.org/10.1101/2021.07.09.450648.\n\n\nNg, Pauline C., and Steven Henikoff. 2003. “SIFT: Predicting Amino Acid Changes That Affect Protein Function.” Nucleic Acids Research 31 (13): 3812–14. https://doi.org/10.1093/nar/gkg509.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. “ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design.” Advances in Neural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nSiepel, Adam, Gill Bejerano, Jakob S. Pedersen, Angie S. Hinrichs, Minmei Hou, Kate Rosenbloom, Hiram Clawson, et al. 2005. “[PhastCons] Evolutionarily Conserved Elements in Vertebrate, Insect, Worm, and Yeast Genomes.” Genome Research 15 (8): 1034–50. https://doi.org/10.1101/gr.3715005.\n\n\n“The Genome Aggregation Database (gnomAD).” n.d. Accessed July 3, 2025. https://www.nature.com/immersive/d42859-020-00002-x/index.html.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Deleteriousness Scores</span>"
    ]
  },
  {
    "objectID": "p2--principles.html",
    "href": "p2--principles.html",
    "title": "Part III: Core Principles",
    "section": "",
    "text": "The previous part surveyed the architectural landscape of deep learning for genomics, from convolutional sequence-to-function models through protein and DNA language models to hybrid architectures that combine CNNs with transformers. These chapters focused on individual model families and their capabilities. Part III now steps back to examine the conceptual foundations that unite these approaches and distinguish foundation models from their task-specific predecessors.\nThree questions organize this part. First, how should genomic sequences be represented as input to neural networks? The choice of tokenization scheme, whether single nucleotides, k-mers, learned subword vocabularies, or biologically informed tokens, profoundly shapes what patterns a model can discover and how efficiently it processes long sequences. Second, what training objectives and adaptation strategies enable models to learn reusable representations from unlabeled data? The shift from supervised learning on narrow tasks to self-supervised pretraining on broad sequence data defines the foundation model paradigm. Third, how can these representations be applied to the clinically crucial problem of predicting variant effects? Variant effect prediction serves as both a unifying application that draws on all the ideas developed earlier and a window into how foundation models perform on tasks that matter for patient care.\nThese three chapters build on each other. 5  Sequence Representation & Tokens examines tokenization strategies from one-hot encoding through BPE to recent approaches that incorporate genomic annotations directly into the vocabulary. 7  Genomic Foundation Models: Concepts & Taxonomy develops a practical framework for understanding pretraining objectives, fine-tuning strategies, and the trade-offs involved in adapting foundation models to new tasks. 20  Variant Effect Prediction then applies these principles to variant interpretation, surveying how models like AlphaMissense, GPN-MSA, Evo 2, and AlphaGenome translate learned representations into pathogenicity predictions. Together, they provide the conceptual vocabulary needed to understand the multi-scale and systems-level approaches covered in Part IV.",
    "crumbs": [
      "Part III: Core Principles"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html",
    "href": "p2-ch05-tokens.html",
    "title": "5  Sequence Representation & Tokens",
    "section": "",
    "text": "5.1 From Sequence to Model: The Representation Problem\nEvery genomic deep learning model must answer a fundamental question before learning can begin: how should DNA sequence be represented as numerical input? This question might seem purely technical, a preprocessing detail to be settled and forgotten. Yet the choice of representation profoundly shapes what a model can learn, how efficiently it trains, and what biological phenomena it can capture. The previous chapters employed one-hot encoding without much discussion, treating it as the obvious default for CNN-based architectures like DeepSEA (Section 10.1) and SpliceAI (Section 10.3). This approach worked remarkably well for those models, but the emergence of transformer-based language models introduced new considerations around tokenization, vocabulary design, and the fundamental trade-offs between sequence compression and resolution.\nThe challenge can be understood through an analogy to natural language processing. When training a language model on English text, researchers must decide how to segment the continuous stream of characters into discrete tokens. One could treat each character as a token, preserving maximum resolution but creating very long sequences. Alternatively, one could use words as tokens, compressing the sequence but potentially losing information about word structure. Or one could learn a vocabulary of subword units that balances these concerns. Each choice affects what patterns the model can discover and how efficiently it can process long documents.\nDNA presents similar choices but with important differences. The genome has only four letters rather than dozens, no natural word boundaries, and biological structure that operates at multiple scales simultaneously. A transcription factor binding site might span 6-12 nucleotides, but the regulatory grammar linking multiple binding sites can extend over hundreds of base pairs. Coding sequences follow a strict three-nucleotide codon structure, while noncoding regions have no such constraint. Any representation scheme must navigate these biological realities while remaining computationally tractable.\nThis chapter examines the evolution of sequence representation strategies in genomic deep learning. We trace the progression from one-hot encoding through k-mer tokenization to modern approaches including Byte Pair Encoding, single-nucleotide tokens, and biologically-informed tokenization schemes. Understanding these choices clarifies design decisions in models throughout Parts III and IV, and illuminates why seemingly minor representation choices can dramatically affect model capabilities.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#from-sequence-to-model-the-representation-problem",
    "href": "p2-ch05-tokens.html#from-sequence-to-model-the-representation-problem",
    "title": "5  Sequence Representation & Tokens",
    "section": "",
    "text": "Warning\n\n\n\nVisual suggestion 10.1 – Representation trade-off comparison\nA single genomic sequence drawn once and tokenized four ways: one-hot bases, k-mers, BPE tokens, and single-nucleotide tokens. Under each, show: - Approximate sequence length (number of tokens) - “Resolution” (e.g., whether variants map cleanly to a single token) - Typical models that use the representation",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#gene-level-embeddings-a-road-not-taken",
    "href": "p2-ch05-tokens.html#gene-level-embeddings-a-road-not-taken",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.2 Gene-Level Embeddings: A Road Not Taken",
    "text": "5.2 Gene-Level Embeddings: A Road Not Taken\nBefore examining sequence tokenization strategies, it is worth asking whether sequence representation is necessary at all. When Word2Vec demonstrated that meaningful word embeddings could be learned from co-occurrence patterns in text corpora, an analogous approach for biology seemed natural: learn gene embeddings from co-expression patterns across experiments.\nGene2Vec (2019) pursued exactly this strategy, training Word2Vec-style embeddings on gene co-expression data from thousands of experiments (Du et al. 2019). Genes appearing in similar expression contexts received similar vector representations, capturing functional relationships without any sequence information. The resulting embeddings improved performance on gene function prediction and could identify functionally related genes that shared no obvious sequence similarity. Similar approaches emerged for other biological entities, embedding proteins based on interaction networks or pathways based on shared gene membership.\nYet gene-level embeddings did not become the dominant paradigm for genomic deep learning, and the reasons illuminate why sequence-based representations proved more powerful. Gene embeddings treat each gene as an atomic unit with no internal structure. They cannot distinguish between synonymous and nonsynonymous variants within a gene, cannot predict effects of novel mutations never seen during training, and cannot generalize to newly discovered genes absent from the original embedding corpus. The representations are static rather than compositional: a gene’s embedding captures its average behavior across training contexts but cannot adapt to the specific sequence context of a particular variant or regulatory configuration.\nThe field’s commitment to sequence-based representations reflects a fundamental insight: the information determining gene function is encoded in nucleotide sequence, and models that operate directly on sequence can learn this encoding rather than relying on pre-computed summaries. A sequence model can predict how a single nucleotide change alters splicing, expression, or protein function because it has learned the underlying sequence grammar. A gene embedding cannot. This distinction becomes critical for clinical applications, where the variants of greatest interest are often novel mutations never previously observed. The remainder of this chapter examines the various strategies for representing sequence while preserving this compositional, generalizable structure.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.2 – Gene2vec vs sequence models\nSchematic comparing: - A “gene graph” with gene2vec-style embeddings (nodes with vector representations) - A sequence model taking raw DNA as input Highlight how gene-level embeddings lack positional and base-resolution information, while sequence tokens preserve genomic structure.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#one-hot-encoding-the-cnn-foundation",
    "href": "p2-ch05-tokens.html#one-hot-encoding-the-cnn-foundation",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.3 One-Hot Encoding: The CNN Foundation",
    "text": "5.3 One-Hot Encoding: The CNN Foundation\nOne-hot encoding represents the simplest possible approach to sequence representation: each nucleotide becomes a sparse binary vector with a single active element indicating its identity. Adenine is encoded as [1, 0, 0, 0], cytosine as [0, 1, 0, 0], guanine as [0, 0, 1, 0], and thymine as [0, 0, 0, 1]. A sequence of length \\(L\\) thus becomes a matrix of dimensions \\(4 \\times L\\), interpretable as four channels analogous to the RGB channels of an image plus one additional channel.\nThis representation dominated the CNN era of genomic deep learning for good reason. One-hot encoding is lossless, preserving every nucleotide explicitly without any information compression. It maintains single-nucleotide resolution, enabling detection of effects from individual SNPs, which is critical for variant interpretation. The representation exhibits translation equivariance, meaning that convolutional filters learn position-invariant motifs that can be recognized anywhere in the sequence. And it requires no preprocessing, vocabulary construction, or tokenizer training, making implementation straightforward.\nDeepSEA, ExPecto, and SpliceAI all employed one-hot encoding without modification. The convolutional layers in these models learned to detect sequence patterns directly from the binary representation, with first-layer filters discovering motifs corresponding to transcription factor binding sites and deeper layers capturing combinations and spatial arrangements. The representation worked because CNNs process sequences through local operations, with each convolutional filter examining only a small window of positions at a time. The sparse, orthogonal nature of one-hot vectors posed no obstacle to this local processing.\nYet for transformer architectures, one-hot encoding presents significant challenges. Transformers compute attention between all pairs of positions in a sequence, with computational cost scaling as \\(O(L^2)\\) where \\(L\\) is the sequence length. A 10 kb sequence requires 10,000 tokens, meaning 100 million pairwise attention computations per layer. This quickly becomes prohibitive for the long sequences that genomic applications require. Furthermore, transformers typically learn dense embeddings for each token, but with only four possible nucleotides, there is little opportunity for the model to discover rich representations through the embedding layer. The sparse one-hot vectors provide minimal information for the embedding to transform. Most critically, practical transformer context windows of 512 to 4,096 tokens translate to only 512 to 4,096 base pairs when using one-hot encoding, a tiny fraction of genes or regulatory regions and far less than the context that proved valuable for models like Enformer and SpliceAI.\nThese limitations motivated the search for alternative representations that could compress genomic sequences into fewer tokens while preserving the information needed for biological prediction.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.3 – One-hot vs CNN filters\nA 1D DNA sequence mapped to a 4-channel one-hot matrix. Convolutional filters sliding across the matrix, with motif-like filters highlighted. Optional inset: “effective receptive field” of a deep CNN stack vs sequence length.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#k-mer-tokenization-the-dnabert-approach",
    "href": "p2-ch05-tokens.html#k-mer-tokenization-the-dnabert-approach",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.4 K-mer Tokenization: The DNABERT Approach",
    "text": "5.4 K-mer Tokenization: The DNABERT Approach\nK-mer tokenization treats overlapping subsequences of length \\(k\\) as tokens, drawing an analogy between k-mers and words in natural language. Just as sentences are composed of words that carry meaning through their sequence and combination, genomic sequences might be understood as composed of k-mer “words” that encode biological function through their arrangement. DNABERT (2021) pioneered this approach for genomic transformers, using 6-mers as tokens and training a BERT-style masked language model on human reference sequences (Ji et al. 2021).\nThe k-mer vocabulary has a fixed size of \\(4^k\\) possible tokens. For 6-mers, this yields 4,096 distinct tokens, comparable to the vocabulary sizes used in some natural language models. Each token represents six consecutive nucleotides, creating a direct correspondence between subsequence and token identity. The tokenization proceeds by sliding a window across the sequence and recording each k-mer encountered.\nDNABERT used overlapping k-mers, meaning that for a sequence like ACGTACGT, the 6-mer tokens would share five nucleotides with their neighbors. The sequence position advances by one nucleotide at a time, generating one token per position (minus the k-1 positions at the end where a complete k-mer cannot be formed). This overlapping design preserves positional information and ensures that every nucleotide contributes to multiple tokens, potentially providing redundancy that helps the model learn robust representations.\nThe DNABERT approach provided valuable proof of concept. It demonstrated that self-supervised pretraining on raw DNA sequences could improve performance over training from scratch, that learned embeddings could capture biologically meaningful regularities even when trained only on the reference genome, and that BERT-style architectures could be reused across multiple downstream tasks. DNABERT achieved state-of-the-art performance on prediction of promoters, splice sites, and transcription factor binding sites after fine-tuning with relatively small amounts of task-specific labeled data.\nHowever, subsequent analysis revealed fundamental limitations of k-mer tokenization that stemmed from the overlapping design. DNABERT-2 (2024) articulated these problems clearly (Zhou et al. 2024). First, overlapping k-mers provide no sequence compression. The number of tokens equals the number of nucleotides (minus a small constant), so context window limitations persist unchanged. A 10 kb sequence still requires approximately 10,000 tokens, and the quadratic attention complexity remains prohibitive for long sequences.\nSecond, overlapping tokenization creates ambiguity in how sequence positions map to tokens. A single nucleotide contributes to \\(k\\) different tokens, complicating interpretation of which token is responsible for any given prediction. This ambiguity becomes particularly problematic for variant effect interpretation, where one wants to understand how changing a specific nucleotide alters model predictions. The effect of a single nucleotide substitution propagates through \\(k\\) different tokens in ways that can be difficult to disentangle.\nThird, the overlapping design introduces sample inefficiency. The model must learn that overlapping tokens share nucleotides, a relationship that is obvious from the tokenization scheme but must be discovered through training. This redundancy consumes model capacity that could otherwise be devoted to learning more complex biological patterns.\nFourth, the fixed \\(4^k\\) vocabulary does not adapt to corpus statistics. Frequent and rare k-mers receive equal representation capacity in the embedding table, even though their importance for prediction may differ substantially. Common motifs that appear throughout the genome receive no more parameters than rare sequences that might represent sequencing errors or unique regulatory elements.\nThese limitations motivated exploration of alternative tokenization strategies that could achieve genuine sequence compression while preserving the information needed for biological prediction.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.4 – K-mer sliding window\nA short DNA sequence with overlapping 6-mers highlighted. Show how a single SNV changes several k-mer tokens. Side panel: token count vs k (e.g., bases vs 3-mer vs 6-mer) for a fixed window length.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#byte-pair-encoding-learning-the-vocabulary",
    "href": "p2-ch05-tokens.html#byte-pair-encoding-learning-the-vocabulary",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.5 Byte Pair Encoding: Learning the Vocabulary",
    "text": "5.5 Byte Pair Encoding: Learning the Vocabulary\nByte Pair Encoding offers a fundamentally different approach to tokenization. Rather than defining tokens through a fixed rule (every k consecutive nucleotides), BPE constructs a vocabulary by learning which subsequences appear frequently in the training corpus. The algorithm, originally developed for data compression, iteratively merges the most frequent adjacent token pairs until reaching a desired vocabulary size.\nThe BPE algorithm begins by initializing the vocabulary with single nucleotides: {A, C, G, T}. It then scans the training corpus to count all adjacent token pairs and identifies the most frequent pair. This pair is merged into a new token, added to the vocabulary, and all instances in the corpus are replaced with the new token. The process repeats, counting pairs again (now including the newly created token) and merging the next most frequent pair. Through many iterations, BPE builds a vocabulary of variable-length tokens that capture frequently occurring sequence patterns.\nThe key insight is that BPE produces genuine sequence compression. Unlike overlapping k-mers where each nucleotide generates its own token, BPE creates non-overlapping tokens that can span multiple nucleotides. A 10 kb sequence might compress to 2,000 or 3,000 tokens depending on its repetitive structure, enabling transformers to process much longer sequences within the same context window.\nDNABERT-2 replaced 6-mer tokenization with BPE and demonstrated dramatic improvements (Zhou et al. 2024). The new model achieved comparable performance to state-of-the-art approaches while using 21 times fewer parameters and requiring approximately 92 times less GPU time in pretraining. The efficiency gains stem directly from non-overlapping tokenization: actual sequence compression enables processing longer sequences with the same computational budget, and eliminating the redundancy of overlapping tokens allows the model to focus capacity on learning biological patterns rather than token relationships.\nThe BPE vocabulary learns corpus statistics through its construction process. Repetitive elements that appear frequently throughout the genome, such as Alu sequences or common regulatory motifs, receive dedicated tokens that span many nucleotides. These long tokens enable efficient representation of repetitive regions while preserving single-nucleotide resolution for unique sequences. Rare sequences that BPE never encountered during vocabulary construction are represented as concatenations of shorter subunits, maintaining the ability to encode any sequence while allocating more representation capacity to common patterns.\nGROVER (Genome Rules Obtained Via Extracted Representations) extended this approach by training BPE specifically on the human genome and selecting vocabulary using a custom next-k-mer prediction task (Sanabria et al. 2024). Analysis of the resulting token embeddings revealed that the learned vocabulary encodes biologically meaningful structure. Common tokens cluster separately from rare ones in embedding space. GC-rich tokens segregate from AT-rich tokens, reflecting the different properties of these sequence compositions. Token length correlates with specific embedding dimensions, allowing the model to represent both the content and extent of each token. Some tokens appear primarily in repetitive regions while others distribute broadly across the genome, and this localization pattern is captured in the learned representations.\nYet BPE introduces its own complications. The variable-length tokens mean that variant positions fall at different locations relative to token boundaries depending on the local sequence context. A SNP might fall in the middle of a long token in one context but at a token boundary in another, potentially affecting how the model represents and processes the variant. This context-dependence can complicate variant effect interpretation, as the same nucleotide change may alter different numbers of tokens depending on surrounding sequence.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.5 – BPE merges on DNA\nStart with a short sequence tokenized as individual bases. Show successive BPE merges building longer tokens. Overlay frequency counts or “motif-like” tokens to suggest that the learned vocabulary captures biologically relevant subsequences.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#single-nucleotide-tokenization-the-hyenadna-approach",
    "href": "p2-ch05-tokens.html#single-nucleotide-tokenization-the-hyenadna-approach",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.6 Single-Nucleotide Tokenization: The HyenaDNA Approach",
    "text": "5.6 Single-Nucleotide Tokenization: The HyenaDNA Approach\nWhile k-mer and BPE tokenization compress sequences to enable longer context windows, they sacrifice single-nucleotide resolution in doing so. This trade-off becomes problematic for variant effect prediction, where the precise position and identity of mutations is paramount. A single nucleotide polymorphism can completely alter protein function through mechanisms ranging from amino acid substitution to splice site disruption to regulatory element ablation. Multi-nucleotide tokens obscure exactly where variants fall and how they relate to the boundaries of biological features.\nHyenaDNA (2023) took the opposite approach, using single-nucleotide tokens with no compression whatsoever (Nguyen et al. 2023). Each nucleotide (A, C, G, T) is a separate token, maintaining the maximum possible resolution. Every nucleotide is independently represented in the token sequence, SNP effects can be isolated to specific token positions without ambiguity, and there are no tokenization artifacts that depend on surrounding sequence context.\nThe challenge with single-nucleotide tokens is sequence length. A 1 Mb region requires 1 million tokens, far beyond the capacity of any standard transformer. The quadratic attention complexity would require a trillion pairwise computations per layer, rendering the approach computationally infeasible with conventional architectures.\nHyenaDNA addressed this challenge through a fundamental architectural innovation rather than a tokenization compromise. The Hyena architecture replaces the attention mechanism with implicit convolutions that scale sub-quadratically with sequence length. Where attention computes explicit pairwise interactions between all positions, Hyena uses long convolutions parameterized by a small neural network, achieving similar representational power with \\(O(L \\log L)\\) complexity rather than \\(O(L^2)\\). This enables processing of sequences hundreds of times longer than attention-based transformers within the same computational budget.\nThe result was a 500-fold increase in context length over dense attention models while maintaining single-nucleotide resolution. HyenaDNA could process 1 Mb sequences where DNABERT was limited to approximately 500 bp and the Nucleotide Transformer to approximately 6 kb. On the Nucleotide Transformer benchmarks, HyenaDNA reached state-of-the-art performance on 12 of 18 datasets with orders of magnitude fewer parameters and less pretraining data. On GenomicBenchmarks, it surpassed prior state-of-the-art on 7 of 8 datasets by an average of 10 accuracy points.\nPerhaps most notably, HyenaDNA demonstrated the first use of in-context learning in genomics. The model could perform tasks based on examples provided in the context window without any fine-tuning, simply by conditioning on demonstration sequences. This capability, familiar from large language models, had not previously been shown for genomic sequences and suggests that very long context combined with high resolution enables qualitatively new forms of biological reasoning.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.6 – Context length vs resolution plot\nScatter or line plot showing different models on a 2D plane: - x-axis: context length (bp) - y-axis: token resolution (bases per token) Place: One-hot CNNs (short context, 1 bp/token), DNABERT (medium context, 6 bp/token), DNABERT-2 / BPE models (longer context, variable bp/token), HyenaDNA (very long context, 1 bp/token).",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#biologically-informed-tokenization",
    "href": "p2-ch05-tokens.html#biologically-informed-tokenization",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.7 Biologically-Informed Tokenization",
    "text": "5.7 Biologically-Informed Tokenization\nStandard tokenization schemes treat DNA as a homogeneous string of characters, ignoring the biological reality that different genomic regions serve fundamentally different functions and follow different structural rules. Coding sequences obey a strict codon structure where every three nucleotides encode an amino acid, while noncoding regions have no such constraint. Treating these regions identically wastes an opportunity to build biological knowledge directly into the representation.\n\n5.7.1 Codon-Aware Tokenization\nFor protein-coding regions, the natural unit of sequence is the codon, not the individual nucleotide. Several models exploit this structure by treating codons as tokens. GenSLMs (2022) pioneered codon-level tokenization for genomic foundation models, treating each three-nucleotide codon as a single token and exploiting the fact that codons are the biologically meaningful units of protein-coding sequence (Zvyagin et al. 2022). The 64-codon vocabulary captures the complete space of possible genetic code words, with each token corresponding to either an amino acid or a stop signal. This alignment with translation semantics means that mutations affecting amino acid identity (nonsynonymous changes) alter the token sequence, while synonymous mutations within a codon alter the specific token used but maintain the broader codon-family structure.\nLife-Code (2025) extended codon-aware tokenization to broader genomic contexts, encoding coding and noncoding regions in a way that respects reading frame and local biological function (Liu et al. 2025). The approach uses different tokenization strategies for different genomic regions based on their biological function. Coding regions are tokenized by codons, with each three-nucleotide unit encoding an amino acid becoming a single token. This aligns the token boundaries with the fundamental unit of protein translation, enabling the model to learn directly about amino acid sequences and protein structure. Noncoding regions, lacking codon structure, are tokenized by learned patterns that capture regulatory motifs and other functional elements.\nCodon tokenization offers several conceptual advantages for modeling coding regions. The approach provides natural compression, with a protein-coding sequence of 300 amino acids spanning 900 nucleotides but compressing to 300 codon tokens. This compression enables whole-gene or even whole-genome modeling within standard transformer context windows, as GenSLMs demonstrated by processing entire viral genomes as coherent sequences. The model can potentially learn codon usage biases, translational efficiency patterns, and other codon-level phenomena that would be obscured by arbitrary k-mer boundaries.\nThis biologically-informed design enables models like Life-Code to learn protein structure through knowledge distillation from protein language models, capture interactions between coding and noncoding regions within a unified framework, and achieve state-of-the-art results across tasks involving DNA, RNA, and protein. The approach demonstrates that tokenization need not be uniform across the genome, and that encoding biological knowledge in the representation itself can improve model capabilities.\nHowever, codon tokenization has significant limitations for general genomic modeling. The approach assumes a defined reading frame, which works for known coding sequences but fails for noncoding regions where no frame exists. Frame shifts, common in viral genomes and relevant for certain human genetic contexts, disrupt the codon structure and require special handling. Regulatory regions, introns, and intergenic sequences have no codon organization to leverage. These limitations restrict codon tokenization to applications where coding sequence dominates, such as protein-centric modeling or viral genomics where the majority of the genome encodes proteins.\nThe broader lesson is that tokenization can and perhaps should be informed by biological structure when that structure is known and relevant. BPE learns statistical patterns from the corpus, but those patterns need not correspond to biological units. Codon tokenization imposes biological semantics directly, at the cost of applicability to noncoding regions. Future approaches might combine these strategies, using codon-aware tokenization for coding regions and BPE or single-nucleotide tokens for noncoding sequence, though such hybrid schemes introduce complexity in handling transitions between regions.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.7 – Codon-aware vs base-level tokens\nShow a coding exon segmented into codons vs bases. Highlight a synonymous and a non-synonymous SNV at the codon level. Optional: link codon tokens to amino acid tokens to illustrate the sequence–protein bridge.\n\n\n\n\n5.7.2 Variant Tokens\nBioToken (2025) extends tokenization even further beyond sequence content to include explicit genomic structural annotations (Medvedev et al. 2025). Rather than treating variants as implicit changes in the sequence string, BioToken creates tokens that explicitly represent SNPs, insertions, and deletions. Known regulatory elements receive dedicated tokens encoding their presence and type. Gene structure, chromatin state, and other functional annotations are integrated directly into the token representation. This approach treats tokens as rich entities that bundle nucleotides with positional, functional, or experimental context.\nSuch variant-aware representations are especially attractive for variant effect prediction and clinical interpretation, where the input is often “reference plus variant” rather than a generic sequence. Embedding variants directly can enable the model to share information across genomic positions and contexts for similar variants, make it easier to integrate non-sequence features (such as constraint scores or population frequency) into a unified representation, and facilitate pretraining objectives that operate on variant events.\nBy incorporating biological inductive biases directly into tokenization, BioToken’s associated model (BioFM) achieves competitive or superior performance to specialized models like Enformer and SpliceAI with significantly fewer parameters, approximately 265 million compared to the billions in some contemporary models. This efficiency suggests that appropriate representation can substitute for model scale, at least partially, by making the learning problem easier through informed structure.\nThe cost is increased complexity in data preprocessing and model design. Variant tokens require careful handling of how reference and alternate alleles are represented, how indels that span multiple bases are encoded, and how the model learns to reason about variant-specific features versus general sequence context. But for translational applications, the payoff can be substantial: variant-aware tokens bring the model’s input space closer to the actual objects of biomedical interest.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.8 – Variant-aware tokenization\nPanel A: classic “reference sequence only” tokenization. Panel B: sequence plus explicit variant tokens (e.g., SNV markers or composite variant tokens). Emphasize how variant tokens can span multiple neighboring bases (e.g., indels) but still map to a conceptually single event.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#the-context-length-evolution",
    "href": "p2-ch05-tokens.html#the-context-length-evolution",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.8 The Context Length Evolution",
    "text": "5.8 The Context Length Evolution\nExamining the history of genomic deep learning reveals a consistent trend toward longer sequence context, reflecting growing appreciation for the importance of distal regulatory interactions. The earliest CNN models from 2015 to 2017, including DeepSEA and DeepBind, operated on sequences of approximately 1 kb, sufficient to capture local motifs and their immediate context. The next generation of models from 2018 to 2020, including ExPecto and SpliceAI, expanded to 10-40 kb windows, enabling capture of promoter-proximal regulatory elements and the extended context needed for accurate splice site prediction.\nThe transformer era beginning in 2021 brought divergent approaches. DNABERT with its overlapping k-mers was limited to approximately 512 bp of effective context, while Enformer combined CNN preprocessing with attention to achieve 200 kb contexts. The Nucleotide Transformer (2022-2023) pushed transformer-based models to 6 kb using k-mer tokenization (Dalla-Torre et al. 2023). Then HyenaDNA and Caduceus (2023-2024) demonstrated that sub-quadratic architectures could reach 1 Mb while maintaining single-nucleotide resolution through character-level tokenization. Most recently, Evo 2 (2025) has achieved similar million-base-pair contexts using single-nucleotide tokens with BPE-style learned embeddings.\nThis progression reflects biological reality. Enhancers can regulate genes from hundreds of kilobases away. TAD boundaries and loop anchors create long-range dependencies in chromatin organization. Understanding genome function requires integrating information across these distances, and representation schemes must enable architectures capable of capturing such interactions. From a design perspective, context length is now less a fixed constraint and more a tunable design dimension, mediated jointly by tokenization, architecture, and hardware budget.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.9 – Historical timeline\nTimeline of models with approximate context lengths and tokenization strategies: DeepSEA / ExPecto / SpliceAI (one-hot), DNABERT (k-mers), DNABERT-2 / genome BPE models, Nucleotide Transformer, HyenaDNA. Optionally color-code by architecture family (CNN, transformer, long-range hybrid).",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#trade-offs-and-practical-considerations",
    "href": "p2-ch05-tokens.html#trade-offs-and-practical-considerations",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.9 Trade-offs and Practical Considerations",
    "text": "5.9 Trade-offs and Practical Considerations\nThe choice between tokenization strategies involves multiple competing considerations that depend on the intended application. Compression and resolution exist in fundamental tension. Higher compression enables longer context windows within fixed computational budgets, but loses precision for identifying exactly where variants fall and how they relate to biological features. One-hot encoding and single-nucleotide tokenization provide no compression but maintain full resolution. Non-overlapping k-mers achieve approximately k-fold compression at the cost of k-nucleotide resolution. BPE provides variable compression depending on sequence repetitiveness, with corresponding variable resolution. For variant effect prediction, where single nucleotide changes can have dramatic phenotypic consequences, resolution is paramount and the computational costs of long single-nucleotide sequences are often justified.\nVocabulary size affects both model capacity and efficiency. Larger vocabularies require bigger embedding tables but may capture more complex patterns directly. Smaller vocabularies are parameter-efficient but require the model to learn compositional structure through multiple layers. The vocabulary size of one-hot encoding (4 tokens plus special tokens) minimizes embedding parameters but maximizes the compositional learning burden. K-mer vocabularies scale exponentially with k, reaching 4,096 for 6-mers. BPE vocabularies are tunable, typically ranging from 4,096 to 32,000 tokens for genomic applications. Codon-aware approaches use approximately 64 codons plus additional tokens for noncoding regions.\nComputational efficiency depends on both tokenization and architecture. For standard attention with \\(O(L^2)\\) complexity, any compression directly reduces cost: non-overlapping k-mers reduce attention cost by a factor of \\(k^2\\), and BPE with average compression \\(c\\) reduces cost by \\(c^2\\). But sub-quadratic architectures like Hyena change this calculus, making single-nucleotide tokenization computationally feasible at long contexts and eliminating the need to trade resolution for efficiency.\nFor variant effect prediction specifically, tokenization choice has direct implications. Single-nucleotide tokens (as in HyenaDNA) enable clean comparison of reference and alternate alleles at the same token position with no ambiguity about effect localization. K-mer tokens complicate matters because a single SNP changes \\(k\\) overlapping tokens, requiring aggregation across affected tokens and introducing potential boundary effects. BPE tokens create context-dependent effects where the same variant may fall at different positions relative to token boundaries depending on surrounding sequence, and where re-tokenization may be needed to properly represent the alternate allele.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion 10.10 – Design table\nA table summarizing tokenization strategies (rows) vs design axes (columns): context length, variant resolution, biological alignment, implementation complexity. Highlight recommended use cases (e.g., “best for VEP”, “best for genome-scale pretraining”).",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#the-emerging-consensus",
    "href": "p2-ch05-tokens.html#the-emerging-consensus",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.10 The Emerging Consensus",
    "text": "5.10 The Emerging Consensus\nRecent developments in the field suggest convergence toward several principles, though the optimal approach continues to evolve. First, single-nucleotide resolution has become the preferred choice for applications requiring precise variant interpretation. The development of sub-quadratic architectures like Hyena, Mamba, and state space models has eliminated the computational barriers that previously forced researchers to accept resolution trade-offs. When long context and high resolution can both be achieved, there is little reason to sacrifice resolution through compression.\nSecond, learned embeddings rather than fixed representations have become standard. Even single-nucleotide tokenization now typically involves trainable embeddings that transform the four nucleotide identities into dense vectors. This allows the model to discover meaningful representations of nucleotide properties rather than treating all positions equivalently.\nThird, biologically-informed augmentation has emerged as a promising direction for incorporating domain knowledge. Encoding codons in coding regions, incorporating functional annotations, or using species-specific vocabularies can provide useful inductive biases that improve learning efficiency and model interpretability.\nFourth, hybrid approaches that combine multiple representation strategies show promise for different genomic contexts. A model might use codon-level tokenization within genes while employing single-nucleotide tokens in regulatory regions, adapting the representation to the structure of each region.\nThe choice ultimately depends on the task at hand. Variant effect prediction demands high resolution and benefits most from single-nucleotide approaches. Species classification or repeat annotation may benefit from compression that enables comparison across longer regions. Expression prediction requires sufficient context to capture distal enhancers while maintaining resolution to identify causal variants. Understanding these trade-offs is essential for selecting or designing appropriate representations for specific applications.\nIn other words, there is no single “correct” tokenization. Instead, we see a toolbox of representations, each suited to particular regimes of context length, resolution, and task demands. For many practitioners, a reasonable heuristic has emerged: use single-nucleotide tokens when variant-level reasoning or high-resolution interpretability is central, use k-mers or BPE when context length is the primary bottleneck and tasks do not require base-level precision, and consider biologically-informed tokens when integrating multi-modal or annotation-rich data.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch05-tokens.html#implications-for-subsequent-chapters",
    "href": "p2-ch05-tokens.html#implications-for-subsequent-chapters",
    "title": "5  Sequence Representation & Tokens",
    "section": "5.11 Implications for Subsequent Chapters",
    "text": "5.11 Implications for Subsequent Chapters\nThe tokenization choices examined in this chapter set the stage for the design decisions discussed throughout the rest of the book. In Chapter 11, we will revisit why many DNA transformers still use 6-mers, and how models like the Nucleotide Transformer balance context length with biological resolution. In Chapter 12 and Chapter 14, we examine how long-range models like Enformer and Borzoi largely retained one-hot encoding or single-nucleotide input encodings for precision in variant effect prediction, leaning on architectural innovations rather than token compression to scale context. In Chapter 7, we explore how pretraining objectives interact with tokenization choices, including masked language modeling over k-mers versus bases, or variant-aware pretraining objectives over BioToken-style representations.\nThe representation problem remains an active area of research. As models grow larger and contexts extend further, new tokenization strategies may emerge that better balance compression, resolution, and biological structure. The field has moved from treating tokenization as a fixed preprocessing step to recognizing it as a fundamental design decision that shapes what models can learn and how they can be applied. Understanding sequence representation is therefore not a technical footnote but a core element of genomic foundation model design, with implications that ripple through every subsequent chapter of this book.\n\n\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nDu, Jingcheng, Peilin Jia, Yulin Dai, Cui Tao, Zhongming Zhao, and Degui Zhi. 2019. “Gene2vec: Distributed Representation of Genes Based on Co-Expression.” BMC Genomics 20 (1): 82. https://doi.org/10.1186/s12864-018-5370-x.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025. “Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. “[GROVER] DNA Language Model GROVER Learns Sequence Context in the Human Genome.” Nature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. “DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.\n\n\nZvyagin, Maxim, Alexander Brace, Kyle Hippe, Yuntian Deng, Bin Zhang, Cindy Orozco Bohorquez, Austin Clyde, et al. 2022. “GenSLMs: Genome-Scale Language Models Reveal SARS-CoV-2 Evolutionary Dynamics.” bioRxiv. https://doi.org/10.1101/2022.10.10.511571.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Sequence Representation & Tokens</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html",
    "href": "p2-ch06-transformers.html",
    "title": "6  Transformer Architecture for Genomics",
    "section": "",
    "text": "6.1 Why Transformers for Genomics?\nThe transformer architecture revolutionized natural language processing in 2017 and rapidly spread to other domains, including genomics. Between 2018 and 2023, transformers became the dominant paradigm for modeling biological sequences, powering protein language models like ESM and genomic models like DNABERT and Nucleotide Transformer. This chapter examines the core mechanisms that make transformers effective for genomic data, their architectural components, and the practical considerations for applying them to DNA, RNA, and protein sequences.\nWe begin by motivating why transformers matter for genomics, then systematically unpack the self-attention mechanism, positional encodings, and the standard transformer block. We discuss scaling considerations specific to genomic sequences, survey transformer variants used in genomic applications, and address training challenges. Finally, we consider the limitations that led to the development of alternative architectures like state space models, which we cover in depth in Chapter Chapter 11.\nConvolutional neural networks dominated early genomic deep learning because they naturally capture local patterns like transcription factor binding motifs, splice sites, and promoter elements. CNNs apply the same learned filters across all positions, implementing a form of translation equivariance that matches the biological intuition that a motif has similar effects regardless of where it appears in a regulatory region.\nHowever, CNNs have fundamental limitations when modeling genomic regulation. Their receptive fields are inherently local. Even with stacked layers and dilated convolutions, the effective context a CNN can integrate remains bounded, often spanning only a few kilobases. Gene regulation in eukaryotes operates over vastly longer ranges. Enhancers routinely act hundreds of kilobases from their target promoters. Topologically associating domains (TADs) organize chromatin contacts at megabase scales. Distal regulatory variants identified through GWAS often lie far from coding sequences, exerting their effects through long-range interactions that CNNs struggle to capture directly.\nTransformers address this limitation through their self-attention mechanism, which allows each position in a sequence to directly attend to all other positions in a single operation. This global receptive field enables modeling of long-range dependencies without requiring information to propagate through many layers. For genomics, this means enhancer-promoter interactions can be learned directly, regulatory context from distant elements can inform predictions at any position, and models can integrate information across entire genes or regulatory domains.\nThe attention mechanism also offers flexibility in how models aggregate information. Rather than applying fixed convolutional kernels, attention learns position-specific aggregation patterns that can adapt to the biological context. Different attention heads can specialize in different types of interactions, potentially capturing diverse regulatory mechanisms like enhancer-promoter communication, insulator boundaries, or promoter competition.\nThese properties made transformers particularly attractive for genomic foundation models. Proteins evolved through deep evolutionary time, creating complex structure-function relationships that benefit from global context integration. DNA regulatory elements interact across large genomic distances in ways that local CNNs miss. RNA secondary structure brings distant nucleotides into close three-dimensional proximity, creating long-range dependencies in the linear sequence.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#why-transformers-for-genomics",
    "href": "p2-ch06-transformers.html#why-transformers-for-genomics",
    "title": "6  Transformer Architecture for Genomics",
    "section": "",
    "text": "Note\n\n\n\nVISUAL SUGGESTION (CNN vs transformer receptive fields)\nFigure: Side-by-side comparison showing a CNN’s limited, layered receptive field (triangular expansion through convolution stack) versus a transformer’s global receptive field (all positions connect to all positions in attention layer). Overlay example showing enhancer-promoter pair 100kb apart that transformer captures in one layer but requires many CNN layers to connect.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#architectural-paradigms-for-sequences",
    "href": "p2-ch06-transformers.html#architectural-paradigms-for-sequences",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.2 Architectural Paradigms for Sequences",
    "text": "6.2 Architectural Paradigms for Sequences\nBefore diving into transformer mechanics, we briefly situate them within the broader landscape of sequence modeling architectures. Three main paradigms have dominated genomic deep learning over the past decade.\nCNNs were the first architecture to achieve strong performance on genomic tasks, pioneered by models like DeepSEA and DeepBind. Their strength lies in parameter efficiency (shared filters across positions) and the ability to learn hierarchical local features (motifs, motif combinations, regulatory grammar). Chapter 5 covers CNN-based regulatory prediction models in detail. CNNs remain competitive for tasks where local context dominates, such as splice site recognition or promoter classification. However, their limited receptive fields constrain performance on tasks requiring long-range integration.\nTransformers emerged from natural language processing, where they demonstrated unprecedented ability to model linguistic context and semantic relationships. The core innovation is self-attention, which computes interactions between all sequence positions simultaneously. This provides global context but comes at a computational cost that scales quadratically with sequence length. Despite this expense, transformers dominated genomic modeling from roughly 2018 through 2023 because their ability to capture long-range dependencies outweighed their computational demands for many applications.\nState space models (SSMs) represent a more recent development, offering linear computational complexity while maintaining long-range modeling capability. Architectures like Mamba have begun to challenge transformers’ dominance, particularly for ultra-long genomic contexts where transformer quadratic scaling becomes prohibitive. We defer detailed discussion of SSMs to Chapter Chapter 11, focusing here on transformers as the foundation from which these newer architectures emerged.\nThe progression from CNNs to transformers to SSMs reflects an ongoing tension between computational efficiency and modeling capacity. Each paradigm offers distinct trade-offs that remain relevant for different genomic applications. Understanding transformers in depth provides essential context for appreciating both why they succeeded and why the field is now exploring alternatives.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#the-self-attention-mechanism",
    "href": "p2-ch06-transformers.html#the-self-attention-mechanism",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.3 The Self-Attention Mechanism",
    "text": "6.3 The Self-Attention Mechanism\nSelf-attention is the defining component of transformer architecture. It allows each position in a sequence to aggregate information from all other positions through learned, input-dependent weights. This section unpacks the mathematical formulation and intuition behind self-attention.\nAt each position in the input sequence, self-attention computes three vectors: a query, a key, and a value. These are produced by multiplying the input embedding at that position by three learned weight matrices \\(W^Q\\), \\(W^K\\), and \\(W^V\\). The query represents “what this position is looking for,” the key represents “what this position offers,” and the value represents “what information this position carries.”\nThe attention mechanism then computes similarity scores between each query and all keys. Specifically, for position \\(i\\), we compute the dot product between its query \\(q_i\\) and every key \\(k_j\\) for positions \\(j = 1, \\ldots, L\\), where \\(L\\) is the sequence length. These scores are scaled by the square root of the key dimension \\(\\sqrt{d_k}\\) to prevent gradient instability when dimensions are large, yielding:\n\\[\n\\text{score}(q_i, k_j) = \\frac{q_i \\cdot k_j}{\\sqrt{d_k}}\n\\]\nA softmax function converts these scores into a probability distribution over positions, producing attention weights \\(\\alpha_{ij}\\) that sum to one across all \\(j\\):\n\\[\n\\alpha_{ij} = \\frac{\\exp(\\text{score}(q_i, k_j))}{\\sum_{j'=1}^L \\exp(\\text{score}(q_i, k_{j'}))}\n\\]\nThese weights determine how much each position \\(i\\) attends to each other position \\(j\\). High attention weight means position \\(i\\) strongly aggregates information from position \\(j\\); low weight means that position contributes little to the output at position \\(i\\).\nFinally, the output at position \\(i\\) is computed as a weighted sum of all value vectors, where the weights are the attention scores:\n\\[\n\\text{output}_i = \\sum_{j=1}^L \\alpha_{ij} v_j\n\\]\nThis weighted aggregation is the core of self-attention. Each output position receives a mixture of information from across the entire sequence, with the mixture proportions learned through backpropagation based on task objectives.\nMulti-head attention extends this mechanism by running multiple attention operations in parallel, each with different learned projections. If we use \\(H\\) heads, we split the model dimension \\(d\\) into \\(H\\) subspaces of dimension \\(d/H\\), compute separate queries, keys, and values for each head, run attention independently, then concatenate the outputs and project back to dimension \\(d\\). This allows different heads to capture different types of relationships. In genomic models, different heads might specialize in different regulatory patterns, such as one head attending to nearby positions (local context) while another attends to distal elements (long-range interactions).\nThe computational cost of self-attention is quadratic in sequence length because we compute \\(L \\times L\\) attention scores. For a sequence of length \\(L\\) and model dimension \\(d\\), computing all queries, keys, and values requires \\(O(Ld^2)\\) operations, while computing the \\(L^2\\) attention scores requires \\(O(L^2d)\\) operations. The quadratic term dominates for long sequences, making standard self-attention expensive for genomic contexts spanning hundreds of kilobases.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (attention computation flow)\nFigure: Schematic showing input embeddings transformed into Q, K, V matrices, computation of attention scores as QK^T heatmap, softmax normalization, and weighted aggregation of values. Include small example with L=6 positions showing how output at position 3 aggregates information from all positions with different weights.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#positional-encoding-representing-sequence-order",
    "href": "p2-ch06-transformers.html#positional-encoding-representing-sequence-order",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.4 Positional Encoding: Representing Sequence Order",
    "text": "6.4 Positional Encoding: Representing Sequence Order\nTransformers have a critical limitation: self-attention is permutation invariant. If you shuffle the order of input tokens, each position still attends to the same set of other positions with the same values, just in different order. The model has no inherent notion of sequence position. For genomic data where order matters fundamentally (5’ to 3’ directionality, strand orientation, spatial organization), this poses a serious problem.\nPositional encodings solve this by injecting information about token positions into the model. The original Transformer (Vaswani et al. 2017) used sinusoidal functions with different frequencies for each dimension. For position \\(pos\\) and dimension \\(i\\), the encoding is:\n\\[\n\\text{PE}(pos, 2i) = \\sin\\left(\\frac{pos}{10000^{2i/d}}\\right)\n\\] \\[\n\\text{PE}(pos, 2i+1) = \\cos\\left(\\frac{pos}{10000^{2i/d}}\\right)\n\\]\nThese fixed sinusoidal patterns have useful properties: they are deterministic (same for all sequences), allow the model to learn to attend by relative positions (since \\(\\text{PE}(pos+k)\\) can be written as a linear function of \\(\\text{PE}(pos)\\)), and generalize to sequence lengths not seen during training.\nHowever, many genomic models use learned positional embeddings instead. These are simply lookup tables where each position \\(pos\\) has a learned vector \\(E_{pos}\\) that is added to the input embedding. Learned positional embeddings offer more flexibility, allowing the model to discover position-dependent patterns specific to genomic data. The trade-off is that they must be trained and do not automatically extrapolate to longer sequences than those seen during training.\nRelative positional encodings represent a middle ground. Rather than encoding absolute positions, these schemes encode the relative distance or relationship between positions. T5-style relative position bias adds a learnable scalar bias to attention scores based on the distance between query and key positions. This helps the model learn that nearby positions often have stronger interactions than distant ones, while remaining agnostic about absolute position.\nAttention with Linear Biases (ALiBi) takes this further by adding a fixed linear penalty to attention scores based on distance, without any learned parameters. For a head with slope \\(m\\), the attention score between positions separated by distance \\(|i - j|\\) is penalized by \\(m|i - j|\\). Different heads use different slopes, encouraging some to focus locally and others globally. ALiBi has shown strong generalization to longer contexts than seen during training, making it attractive for genomic applications where sequence length varies.\nRotary Position Embeddings (RoPE) encode positions by rotating the query and key vectors in a high-dimensional space. The rotation angle depends on position, ensuring that the dot product between query and key depends on their relative distance. RoPE has become popular in recent language models and is beginning to appear in genomic transformers because it combines the benefits of relative encoding with efficient implementation.\nFor genomics, positional encoding must respect biological semantics. DNA has strand directionality: the sequence ACGT on the forward strand has different regulatory meaning than ACGT on the reverse strand. Positional encodings should allow the model to learn strand-specific patterns. Some genomic transformers use separate positional embeddings for forward and reverse strands. Others rely on the model to learn strand orientation from sequence content itself.\nGenomic coordinates pose another challenge. Should position 1 in the model correspond to a fixed genomic coordinate (e.g., transcription start site), or should it be relative to some local landmark? Different models make different choices based on their tasks. Models predicting regulatory activity often center sequences on gene promoters, using positions relative to the TSS. Foundation models trained on random genomic segments typically use positional encodings that reflect sequence order without reference to genomic coordinates.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (positional encoding schemes)\nFigure: Four panels comparing positional encoding methods. (a) Sinusoidal: wave patterns at different frequencies. (b) Learned: discrete embedding vectors. (c) ALiBi: attention score modification with distance-dependent penalty. (d) RoPE: rotation in 2D subspace. Include small example showing how different schemes affect attention between positions separated by different distances.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#the-transformer-block-architecture",
    "href": "p2-ch06-transformers.html#the-transformer-block-architecture",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.5 The Transformer Block Architecture",
    "text": "6.5 The Transformer Block Architecture\nA transformer model consists of stacked blocks, each containing self-attention and feed-forward components connected by residual connections and layer normalization. Understanding this block structure is essential for grasping how information flows through transformer models.\nEach transformer block has two main components: a multi-head self-attention layer and a position-wise feed-forward network. The attention layer enables global communication across all positions, allowing each position to gather information from the entire sequence. The feed-forward network processes each position independently, applying nonlinear transformations to the aggregated information.\nLayer normalization stabilizes training by normalizing activations across the feature dimension at each position. Two conventions exist for where to place layer normalization relative to the self-attention and feed-forward sublayers. Post-norm places normalization after each sublayer, applying it to the output before the residual connection. Pre-norm places normalization before each sublayer, normalizing the input to that sublayer. Pre-norm has become more common in recent models because it improves training stability, particularly for deep networks, though post-norm can achieve slightly better final performance with careful tuning.\nThe feed-forward network consists of two linear transformations with a nonlinearity between them. Typically, this expands the dimension by a factor of four, applies a nonlinear activation function (often GELU), then projects back to the original dimension. This expansion allows the model to process the attention-aggregated information through a high-dimensional nonlinear transformation before producing the output for the next layer.\nResidual connections wrap around both the attention and feed-forward sublayers, adding the input directly to the output. These connections serve two critical functions. First, they provide gradient highways during backpropagation, allowing gradients to flow directly through many layers without being repeatedly transformed. This enables training of very deep networks. Second, they create an inductive bias toward small, incremental refinements of the representation at each layer, rather than forcing each layer to construct an entirely new representation.\nThe flow through a transformer block with pre-norm looks like this: the input \\(X\\) is first normalized, then processed by multi-head attention to produce \\(X'\\), which is added back to the original input via residual connection, yielding \\(X + X'\\). This sum is again normalized, passed through the feed-forward network to produce \\(X''\\), and added to the input of the feed-forward layer via another residual connection, yielding the final output \\((X + X') + X'' = X + X' + X''\\).\nStacking depth determines how many times this refinement process occurs. Shallow transformers with few layers are parameter-efficient but may lack capacity for complex tasks. Deep transformers with many layers can learn more sophisticated representations but require more computation and careful optimization. Most genomic transformers use between 6 and 24 layers, though this varies by application. Models focused on short sequences (e.g., small RNA molecules) might use fewer layers, while foundation models trained on long genomic contexts often use deeper stacks.\nThe choice of depth involves balancing several considerations. Deeper networks can learn more complex functions and abstract representations, but they are harder to train, prone to overfitting without sufficient data, and more computationally expensive at both training and inference. For genomic applications, depth often correlates with the complexity of regulatory patterns being modeled. Simple motif-based tasks might benefit more from wider layers (larger \\(d\\)) than deeper stacks, while tasks requiring integration of hierarchical regulatory information (promoters → enhancers → TAD structure) may benefit from additional depth.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (transformer block schematic)\nFigure: Detailed diagram of a single transformer block showing pre-norm configuration. Input flows through LayerNorm → Multi-head Attention → Add & Norm → Feed-forward (with dimension expansion) → Add & Norm → Output. Annotate with typical dimensions (e.g., d=512, dff=2048) and show residual connections as bypass arrows.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#scaling-transformers-for-genomics",
    "href": "p2-ch06-transformers.html#scaling-transformers-for-genomics",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.6 Scaling Transformers for Genomics",
    "text": "6.6 Scaling Transformers for Genomics\nGenomic sequences present unique scaling challenges. DNA sequences can span millions of bases, far exceeding the typical context lengths in natural language processing. Tokenization choices (covered in Chapter Chapter 5) interact with sequence length: single-nucleotide tokens create very long sequences, while k-mer tokens reduce length at the cost of vocabulary size. Scaling transformers to genomic applications requires careful consideration of how to balance model size, context length, and computational resources.\nParameter scaling in transformers comes from two main sources: width and depth. Width refers to the model dimension \\(d\\), which determines the size of embeddings and hidden states. Increasing width allows the model to represent more complex patterns at each position but increases the number of parameters quadratically (since weight matrices are \\(d \\times d\\)). Depth refers to the number of stacked transformer blocks. Increasing depth allows the model to learn hierarchical abstractions through repeated refinement but also increases parameters linearly with layers.\nThe transformer scaling laws studied in natural language processing suggest that model performance improves smoothly with increased parameters, data, and compute. For genomics, similar principles apply, though the optimal ratios differ. Genomic sequences are less compressible than natural language (each nucleotide carries less predictable information than words in structured text), suggesting that genomic models might benefit more from depth than width compared to language models of similar parameter count.\nContext length scaling presents the central challenge for genomic transformers. Standard self-attention has \\(O(L^2)\\) complexity, where \\(L\\) is sequence length. A 10kb sequence tokenized at single-nucleotide resolution has 10,000 tokens, requiring 100 million attention computations per layer. A 200kb sequence has 200,000 tokens, requiring 40 billion attention computations per layer. This quadratic scaling rapidly becomes prohibitive.\nSeveral strategies address this computational bottleneck. Sparse attention patterns restrict which positions can attend to which others, reducing the quadratic cost. For example, local windowing allows each position to attend only to positions within a fixed window, reducing complexity to \\(O(Lw)\\) where \\(w\\) is window size. This works well when most relevant interactions are local, as often holds for regulatory sequences where nearby elements interact more strongly than distant ones.\nStrided attention patterns create a hierarchy where lower layers use local windows and upper layers attend to every \\(k\\)-th position. This captures both local fine-grained patterns and global coarse-grained structure while maintaining sub-quadratic complexity. Hybrid models like Enformer (Chapter Chapter 14) use this strategy, applying CNNs to downsample sequences before transformer layers.\nApproximations to full attention offer another approach. Linformer approximates the attention matrix through low-rank decomposition, reducing complexity to linear in sequence length at the cost of some expressiveness. Performer uses random feature methods to approximate attention scores without explicitly computing the full \\(L \\times L\\) matrix. These approximations work well in practice for some tasks but may lose important long-range dependencies.\nFor genomic applications, the choice among these strategies depends on the biological context. Regulatory prediction often benefits from local windowing because nearby elements dominate enhancer-promoter interactions. Foundation models trained to predict masked tokens may require global attention because the model must integrate information from across the entire sequence to make coherent predictions. Variant effect prediction sometimes requires selective attention to specific distal elements, which sparse patterns may miss.\nMemory requirements compound the computational challenge. Transformer training requires storing activations for backpropagation, and attention matrices can be particularly memory-intensive. Gradient checkpointing trades compute for memory by recomputing activations during the backward pass rather than storing them. This allows training larger models or longer sequences on fixed hardware at the cost of additional computation time.\nMixed precision training uses lower-precision (16-bit) floating point for most computations while maintaining higher precision (32-bit) for critical operations like loss computation and optimizer updates. Modern GPUs accelerate 16-bit arithmetic substantially, providing near 2× speedup with minimal precision loss for most models. Genomic transformers routinely use mixed precision to enable training on longer sequences or with larger batch sizes.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (scaling trade-offs)\nFigure: Multi-panel showing scaling relationships. (a) Parameter count vs model dimension and depth, with typical genomic model configurations marked. (b) Attention complexity vs sequence length for full, windowed, and sparse attention, with genomic length scales (1kb, 10kb, 100kb, 1Mb) indicated. (c) Memory usage vs sequence length showing impact of activation checkpointing.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#transformer-variants-in-genomic-applications",
    "href": "p2-ch06-transformers.html#transformer-variants-in-genomic-applications",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.7 Transformer Variants in Genomic Applications",
    "text": "6.7 Transformer Variants in Genomic Applications\nThe transformer architecture has been adapted in diverse ways for genomic modeling. This section surveys major variants and their design rationale.\nStandard encoder-only transformers process sequences bidirectionally, allowing each position to attend to all other positions including future positions. DNABERT and Nucleotide Transformer exemplify this architecture. They are trained with masked language modeling objectives where random tokens are masked and the model predicts them from bidirectional context. This works well for understanding genomic sequences where both upstream and downstream context matters, such as transcription factor binding sites influenced by flanking sequence or protein structures determined by both N-terminal and C-terminal residues.\nEncoder-only transformers excel at sequence representation tasks where the goal is to learn meaningful embeddings that capture biological properties. These embeddings can be used directly for downstream tasks like variant effect prediction or as features for other models. The bidirectional context allows rich representations but makes these models unsuitable for generative tasks where we need to sample sequences autoregressively.\nDecoder-only transformers use causal attention where each position attends only to itself and preceding positions. This enables autoregressive generation: the model generates sequences one token at a time, conditioning each new token on all previous tokens. GenSLM and other genomic foundation models trained on next-token prediction use this architecture. Causal attention is essential for generative modeling but provides less rich representations than bidirectional attention for fixed sequences because each position has access to only partial context.\nThe trade-off between encoder and decoder architectures reflects a fundamental tension in genomic modeling. Representation learning benefits from bidirectional context, while sequence generation requires causal structure. Some applications use both: a bidirectional encoder produces initial representations, then a causal decoder refines them for generation or prediction tasks.\nHybrid CNN-transformer architectures combine convolutional layers with transformer blocks. Models like Enformer and Borzoi (Chapter Chapter 14) apply convolutional stems to long sequences, downsampling through pooling, then pass the compressed representation through transformer layers. This exploits CNNs’ efficiency for local pattern extraction while using transformers for long-range integration. The downsampling addresses transformers’ quadratic complexity by reducing sequence length before attention.\nThese hybrid models achieve state-of-the-art performance on regulatory prediction tasks but blur the line between pure transformers and other architectures. They work because genomic regulation involves both local patterns (motifs, nucleosome positioning) and long-range interactions (enhancer-promoter loops, chromatin domains). The CNN-transformer combination matches this multi-scale structure.\nLong-range modifications adapt transformer attention for ultra-long genomic contexts. Genomic Interpreter uses 1D Swin transformers with hierarchical windowed attention, enabling megabase-scale modeling. Others use sparse attention patterns tailored to genomic structure, such as attending to fixed landmark positions (promoters, insulators) or using genomic distance-based sparsity patterns that assume nearby positions interact more strongly than distant ones.\nThese modifications share a common goal: reducing attention’s quadratic cost while preserving long-range capability. Success depends on whether the imposed structure matches actual genomic interactions. If enhancer-promoter loops occur at specific, regular spacing, fixed sparse patterns might work well. If interactions are highly variable and data-dependent, full attention or learned sparsity may be necessary.\nBidirectional versus causal attention has implications beyond generation. For variant effect prediction, bidirectional context allows the model to see both upstream and downstream changes when scoring a mutation. This can improve prediction quality because regulatory effects often depend on surrounding context. However, causal models may better capture directionality in processes like transcription or replication where 5’ to 3’ order matters mechanistically.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (transformer variants)\nFigure: Comparison of four architectures with attention pattern diagrams and use cases. (a) Bidirectional encoder (DNABERT): full attention matrix shown as filled triangle. (b) Causal decoder (GenSLM): lower triangular attention matrix. (c) Hybrid (Enformer): CNN stem → downsampled sequence → transformer layers. (d) Sparse (Genomic Interpreter): blocked attention pattern with local and strided blocks.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#training-considerations",
    "href": "p2-ch06-transformers.html#training-considerations",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.8 Training Considerations",
    "text": "6.8 Training Considerations\nTraining genomic transformers involves optimization algorithms, regularization strategies, and infrastructure choices that differ in important ways from natural language models.\nOptimization for transformers typically uses Adam or AdamW, adaptive learning rate algorithms that maintain per-parameter learning rates adjusted based on gradient statistics. AdamW adds weight decay directly to the parameter updates rather than to the loss function, which improves training stability and generalization for transformers. Learning rate schedules typically use warmup for the first few thousand steps, linearly increasing the learning rate from zero to a peak value, then decay (either linear or cosine) for the remainder of training.\nWarmup is particularly important for transformers because large learning rates early in training can cause instability when parameters are randomly initialized. Gradients in early iterations can be extremely large or small depending on initialization, and adaptive optimizers need time to build accurate gradient statistics. Warmup allows the optimizer to stabilize before applying full learning rates.\nFor genomics, learning rate tuning often requires domain-specific adjustment. Genomic sequences have different statistical properties than natural language, and the optimal learning rate may differ substantially from NLP defaults. Regulatory sequences with highly conserved motifs may require lower learning rates to avoid overfitting to these strong signals, while protein sequences with weaker conservation may benefit from higher learning rates that encourage exploration.\nRegularization prevents overfitting, particularly important for genomic applications where training data may be limited compared to the large models we wish to train. Dropout randomly zeros out activations during training, forcing the network to learn robust features that do not depend on specific neurons. Attention dropout applies this to attention weights, randomly dropping connections between positions. This prevents the model from over-relying on specific position pairs and encourages learning of distributed representations.\nWeight decay penalizes large parameter values, encouraging the model to use smaller, smoother weights. For transformers, weight decay is typically applied to all parameters except biases and layer normalization parameters. The weight decay coefficient must be tuned carefully: too little provides insufficient regularization, while too much overly constrains the model and reduces capacity.\nGradient issues plague deep network training. Vanishing gradients occur when gradients become extremely small as they backpropagate through many layers, preventing effective learning in early layers. Exploding gradients are the opposite problem where gradients grow exponentially, causing parameter updates that destabilize training. Transformers mitigate vanishing gradients through residual connections that provide direct gradient paths through the network. Exploding gradients are addressed through gradient clipping, which rescales gradients when their norm exceeds a threshold.\nFor genomic transformers, gradient issues often manifest differently than in language models. Genomic sequences have less hierarchical structure than natural language (no grammatical sentence structure), which affects gradient flow through attention layers. Imbalanced token frequencies (certain k-mers or amino acids appear much more often than others) can create gradient imbalances where common tokens receive large gradients while rare but biologically important tokens receive tiny gradients. Addressing this may require reweighting losses or using adaptive batch sampling.\nComputational infrastructure for genomic transformer training typically requires distributed approaches. Single-GPU training suffices only for small models on short sequences. Multi-GPU data parallelism replicates the model across GPUs, splitting batches across devices and aggregating gradients. This scales well up to batch sizes limited by convergence requirements. Model parallelism splits the model itself across devices, necessary when models are too large to fit on a single GPU. Pipeline parallelism divides layers across devices and pipelines the forward and backward passes.\nMixed precision training (mentioned earlier) is nearly universal in genomic transformer training. Modern GPUs provide specialized tensor cores that accelerate 16-bit operations dramatically. For genomics, mixed precision typically provides 1.5-2× speedup with no loss in final model quality, though careful attention to loss scaling and overflow detection is required.\nBatch size selection involves competing considerations. Larger batches provide more stable gradient estimates and better GPU utilization but require more memory and may reduce generalization. Genomic transformers often use gradient accumulation to simulate large batches: small batches are processed sequentially, gradients accumulated across them, then a single parameter update made. This provides the benefits of large batches without the memory cost.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (training dynamics)\nFigure: Two-panel figure showing typical training curves. (a) Learning rate schedule showing warmup and decay phases. (b) Training and validation loss over time, with annotations for common issues (overfitting, underfitting, gradient instability) and when to apply different interventions (increase regularization, reduce learning rate, add gradient clipping).",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#limitations-and-alternatives",
    "href": "p2-ch06-transformers.html#limitations-and-alternatives",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.9 Limitations and Alternatives",
    "text": "6.9 Limitations and Alternatives\nDespite their success, transformers have fundamental limitations that motivated development of alternative architectures. Understanding these limitations contextualizes recent innovations and guides architecture choice for specific genomic applications.\nThe quadratic complexity bottleneck is transformers’ most severe limitation. Computing all pairwise attention scores for a sequence of length \\(L\\) requires \\(O(L^2)\\) operations and memory. For genomic contexts of 100kb or more (roughly 100,000 single-nucleotide tokens), this becomes prohibitive. Even with sparse attention approximations, transformers struggle to scale to megabase-length contexts where some regulatory interactions occur.\nRecent genomic models have pushed context lengths to impressive scales (Enformer handles 200kb, AlphaGenome approaches 1Mb), but these often rely on hybrid architectures with significant downsampling or hierarchical windowing that may miss certain long-range patterns. Pure transformers without such modifications remain limited to shorter contexts.\nAlternative sub-quadratic architectures address this limitation directly. State space models (SSMs) like S4 and Mamba achieve linear complexity by representing sequences as continuous-time dynamical systems rather than discrete token-to-token interactions. These models maintain long-range memory through recurrent state updates while avoiding the quadratic attention bottleneck. Chapter Chapter 11 covers SSMs in detail, including Hyena DNA and the Evo family of genomic foundation models.\nHyena operators replace attention with long convolutions implemented efficiently in the Fourier domain, achieving sub-quadratic complexity. Mamba uses selective state space models that dynamically adjust state transitions based on input content. Both approaches show promise for ultra-long genomic contexts, potentially enabling whole-chromosome or even whole-genome modeling.\nWhen should we prefer transformers over these alternatives? Transformers excel when global context matters but sequences are not extremely long (under 10-50kb depending on resources). Their attention maps provide some interpretability, showing which positions the model considers relevant for specific predictions. Transformers have extensive tooling and pretrained models available from NLP research that transfer readily to genomics.\nCNNs remain preferable when computational efficiency is paramount and local patterns dominate. For splice site prediction or promoter classification where the relevant context spans at most a few hundred base pairs, a well-designed CNN may outperform transformers while using far fewer parameters and less compute. The inductive bias toward local patterns also provides regularization that helps with limited training data.\nHybrid approaches combining CNNs for local feature extraction with transformers for long-range integration often achieve the best of both worlds. As discussed in Chapter Chapter 14, models like Enformer demonstrate that architectural combinations can outperform pure transformers or pure CNNs on real genomic tasks.\nThe transition to sub-quadratic architectures is ongoing. Early results suggest SSMs match or exceed transformers on some genomic benchmarks while scaling to longer contexts. However, transformers benefit from years of engineering optimization and extensive pretrained models. The genomics community is actively exploring whether SSMs’ theoretical advantages translate to practical improvements across diverse tasks.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (architecture comparison)\nFigure: Comparison table or radar chart showing transformers, CNNs, and SSMs across multiple axes: sequence length capacity, parameter efficiency, interpretability, training stability, inference speed, and ecosystem maturity. Highlight trade-offs rather than declaring one superior.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch06-transformers.html#summary-and-forward-references",
    "href": "p2-ch06-transformers.html#summary-and-forward-references",
    "title": "6  Transformer Architecture for Genomics",
    "section": "6.10 Summary and Forward References",
    "text": "6.10 Summary and Forward References\nThis chapter examined transformer architecture from first principles through genomic applications. Transformers introduced global self-attention that addresses CNNs’ limited receptive fields, enabling modeling of long-range genomic interactions. The core mechanisms involve queries, keys, and values computing position-dependent aggregation weights that determine how information flows through the sequence.\nPositional encodings address transformers’ permutation invariance by injecting sequence order information. Multiple approaches exist (sinusoidal, learned, relative, RoPE), each with different properties for generalization and computational efficiency. Genomic applications must consider strand directionality and genomic coordinate systems when choosing positional encoding schemes.\nThe transformer block architecture combines multi-head attention with position-wise feed-forward networks, connected by residual connections and layer normalization. Stacking these blocks creates deep networks that learn hierarchical representations through repeated refinement. Design choices about depth, width, normalization placement, and component sizing affect model capacity and training stability.\nScaling transformers to genomic sequences involves trade-offs between parameters, context length, and compute. Quadratic attention complexity limits context lengths, motivating sparse attention patterns, hierarchical windowing, and hybrid architectures. Mixed precision training and gradient checkpointing enable larger models on available hardware.\nTransformer variants for genomics include bidirectional encoders for representation learning (DNABERT, Nucleotide Transformer), causal decoders for generation (GenSLM), and hybrid architectures combining CNNs with attention (Enformer, Borzoi). Each variant suits different tasks based on whether bidirectional context or autoregressive structure is more important.\nTraining considerations specific to genomics include learning rate schedules with warmup, dropout and weight decay regularization, gradient clipping for stability, and distributed training infrastructure. Genomic sequences’ unique statistical properties (token frequency imbalance, weaker hierarchical structure than language) affect optimization in subtle ways that may require task-specific tuning.\nTransformers’ quadratic complexity motivates alternatives, particularly state space models that achieve linear scaling while maintaining long-range capability. When to prefer transformers versus SSMs or CNNs depends on sequence length requirements, local versus global pattern importance, computational resources, and whether extensive pretrained models are available.\nLooking forward, transformers remain central to genomic foundation models despite emerging alternatives. Chapter Chapter 11 surveys DNA language models built on transformer and SSM architectures, trained through self-supervised objectives. Chapter Chapter 13 covers protein language models where transformers have achieved remarkable success at learning structure and function from sequence alone. Chapter Chapter 14 examines how regulatory prediction models combine transformers with CNNs to handle long genomic contexts efficiently.\nThe transformer architecture represents a watershed moment in genomic deep learning, enabling models that genuinely capture long-range dependencies essential for understanding gene regulation. While newer architectures may supersede transformers for some applications, the conceptual framework they introduced, particularly the idea that global context aggregation through learned attention is tractable and effective, continues to shape genomic modeling.\n\n\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transformer Architecture for Genomics</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html",
    "href": "p2-ch07-foundation.html",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "",
    "text": "7.1 From Task-Specific Models to Foundation Models\nThe preceding chapters traced deep learning architectures from convolutional networks for regulatory sequence prediction through recurrent and transformer-based models for variant effect prediction. These architectures established that neural networks could learn genomic patterns directly from sequence, often matching or exceeding expert-crafted features. However, most models operated within narrow task boundaries: DeepSEA predicted chromatin accessibility, SpliceAI predicted splicing outcomes, and Enformer mapped sequences to molecular readouts. Each model solved its specific problem well but offered limited transferability to other genomic questions.\nThe emergence of foundation models represents a fundamental shift in how we approach computational genomics. Rather than training separate models for each task, foundation models learn general representations that can be adapted to diverse downstream applications. This paradigm follows the transformative success of large language models in natural language processing and protein language models in structural biology, where models pretrained on vast unlabeled corpora have become infrastructure for entire research communities.\nGenomics presents unique challenges for the foundation model paradigm. The scale of genomic context necessary to capture distal regulatory interactions far exceeds typical sequence lengths in protein or language modeling. Single-nucleotide resolution is often essential, ruling out aggressive tokenization schemes that work well in other domains. The diversity of genomic tasks spans orders of magnitude, from predicting local chromatin states to estimating polygenic disease risk across populations. Despite these challenges, genomic foundation models have rapidly emerged as practical tools for variant interpretation, regulatory genomics, and complex trait prediction.\nThis chapter addresses the conceptual landscape of genomic foundation models rather than their implementation details. We define what distinguishes foundation models from task-specific architectures, organize the emerging ecosystem into a practical taxonomy, and establish design principles that guide model selection and development. The framework developed here will inform subsequent chapters as we examine training procedures, deployment strategies, and specific application domains.\nThe history of computational genomics reveals a consistent pattern: models become more general while maintaining or improving task-specific performance. Hand-crafted scores such as CADD, DANN, and SIFT established that integration of diverse genomic annotations could improve variant pathogenicity prediction (Rentzsch et al. 2019; Schubach et al. 2024). These approaches relied on expert feature engineering, combining conservation scores, functional annotations, and population frequency data through ensemble methods or logistic regression.\nTask-specific deep learning models demonstrated that neural networks could learn relevant features directly from sequence. DeepSEA predicted chromatin accessibility and transcription factor binding from 1 kb sequences using convolutional architectures (J. Zhou and Troyanskaya 2015). ExPecto extended this approach to gene expression prediction by modeling regulatory elements across multiple cell types (J. Zhou et al. 2018). Sei organized regulatory predictions into interpretable sequence classes through unsupervised clustering (Chen et al. 2022). SpliceAI achieved near-perfect splice site prediction through dilated convolutions over 10 kb contexts (Jaganathan et al. 2019). Enformer scaled sequence-to-function modeling to 200 kb windows and thousands of chromatin tracks through transformer architectures (Avsec et al. 2021).\nThese models succeeded within their specific domains but remained difficult to repurpose. Training a DeepSEA model required chromatin accessibility data. Using SpliceAI for regulatory prediction would require complete retraining on different labels. Each application domain needed its own model, trained from scratch on task-specific data.\nSequence language models introduced self-supervised learning to genomics. DNABERT applied masked language modeling to DNA sequences, demonstrating that general representations could be learned without task-specific labels (Ji et al. 2021). ESM and ESM-2 showed that protein language models pretrained on sequence alone could transfer effectively to structure prediction, variant effect prediction, and protein design (Rives et al. 2021; Lin et al. 2022). The Nucleotide Transformer family scaled DNA language modeling to cross-species training corpora (Dalla-Torre et al. 2023). HyenaDNA used implicit convolutions to reach million-token contexts at single-nucleotide resolution (Nguyen et al. 2023).\nTrue genomic foundation models emerged when models satisfied several criteria simultaneously: pretraining on large-scale genomic data with minimal supervision, production of general-purpose representations useful across diverse tasks, demonstrated transfer capability across assays and tissues and species, and standardized interfaces for embedding extraction and downstream adaptation. These properties distinguish foundation models from earlier approaches. A large Enformer model trained on chromatin data remains task-specific despite its size. A DNA language model trained on reference genomes qualifies as a foundation model even if its parameter count is modest, provided it produces reusable representations.\nThe shift from task-specific to foundation models changes the relationship between model developers and users. Task-specific models deliver predictions as their primary product. Foundation models deliver representations that users adapt to their own tasks. This distinction affects everything from model architecture design to evaluation strategies to deployment infrastructure.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#defining-genomic-foundation-models",
    "href": "p2-ch07-foundation.html#defining-genomic-foundation-models",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.2 Defining Genomic Foundation Models",
    "text": "7.2 Defining Genomic Foundation Models\nThe term “foundation model” appears frequently in genomics literature, sometimes applied to any large neural network trained on biological sequences. For practical purposes, establishing working criteria helps separate true genomic foundation models from ordinary deep learning approaches that happen to operate on DNA or protein sequences.\n\n7.2.1 Essential Properties\nA genomic foundation model satisfies several key properties that distinguish it from task-specific architectures.\nLarge-scale pretraining with minimal supervision. Foundation models train on entire genomes, pan-genomic sequence collections, or large assay compendia. The pretraining objectives include masked language modeling, next-token prediction, denoising, or multi-task sequence-to-function prediction. Critically, these objectives do not require dense task-specific labels for every training example. A model that requires annotated enhancers or curated pathogenic variants for every training instance does not qualify as a foundation model under this criterion.\nGeneral-purpose representations. Foundation models produce embeddings that prove useful across many downstream tasks. These representations can be extracted through forward passes and reused with simple linear probes or lightweight adapter modules rather than requiring full model retraining. The representations should encode biological information at multiple scales, from local sequence motifs to long-range regulatory grammar.\nBroad transfer capability. Foundation models support diverse downstream applications without architectural modifications or complete retraining. Transfer occurs across multiple dimensions: different assays (from chromatin accessibility to gene expression), different tissues and cell types, different species, and different variant types (from SNVs to structural variants). Evidence of broad transfer requires evaluation across multiple benchmarks rather than demonstration of performance on a single task.\nScale along at least one dimension. Foundation models operate at a scale that would be impractical for task-specific training. Some scale context length, as HyenaDNA scales to million-token windows at single-nucleotide resolution. Others scale parameter count, as the ESM and Nucleotide Transformer families reach billions of parameters. Still others scale data diversity through pan-genomic pretraining across hundreds of species or integration of many assays and cell types. The scaling dimension chosen reflects the model’s intended applications and architectural constraints.\nStandardized interfaces. Foundation models typically expose consistent APIs for common operations. These include embedding extraction for sequences or variants, sequence probability scoring, and mask-based in-silico mutagenesis for variant effect prediction. Models distributed through repositories such as Hugging Face often include documented recipes for downstream fine-tuning and example notebooks demonstrating common use cases.\n\n\n7.2.2 What Doesn’t Count\nMany excellent genomic models fail one or more of these criteria and should not be classified as foundation models. Early versions of DeepSEA trained specifically on chromatin accessibility data from a limited set of cell types lack the generality and standardized interface of foundation models, though later iterations that integrate many assays begin to approach foundation model territory (J. Zhou and Troyanskaya 2015). SpliceAI predicts splicing outcomes exceptionally well but was designed for that specific task and provides neither general-purpose embeddings nor easy transfer to other genomic prediction problems (Jaganathan et al. 2019). Even a very large Enformer-like model trained solely on human chromatin tracks remains bound to its specific prediction interface despite its scale and sophistication (Avsec et al. 2021).\nThe distinction between large models and foundation models matters for several reasons. It affects evaluation strategy, since foundation models must be assessed across families of tasks rather than single benchmarks. It affects integration into existing pipelines, since foundation models serve as feature extractors while task-specific models typically provide end-to-end predictions. It affects how we think about model development, since foundation model training requires different infrastructure and data curation than task-specific supervised learning.\n\n\n7.2.3 Why Definition Matters\nClear definitions enable meaningful comparisons and guide appropriate use. A practitioner selecting a model for regulatory variant interpretation needs to understand whether a model provides general embeddings that can be adapted to their specific cell type or delivers fixed predictions for a predetermined set of assays. A researcher developing new methods needs to know whether their model should be evaluated on single-task performance or multi-task transfer capability. A clinical laboratory implementing variant interpretation pipelines needs to understand what guarantees about robustness and generalization a model can provide.\nThe framework established here will guide our taxonomy of genomic foundation models and inform discussions of evaluation strategies and practical deployment.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#a-taxonomy-of-genomic-foundation-models",
    "href": "p2-ch07-foundation.html#a-taxonomy-of-genomic-foundation-models",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.3 A Taxonomy of Genomic Foundation Models",
    "text": "7.3 A Taxonomy of Genomic Foundation Models\nThe landscape of genomic foundation models can be organized into four broad families. Each family exhibits distinct characteristics, characteristic strengths and limitations, and typical application domains. Understanding this taxonomy helps practitioners select appropriate models for their tasks and helps researchers position new contributions within the broader ecosystem.\n\n\n\n\n\n\nWarning\n\n\n\nFigure suggestion: A 2x2 taxonomy grid organizing genomic foundation models. One axis could represent “sequence-native” versus “annotation-guided” approaches. The other axis could represent “molecular-scale” versus “systems-scale” predictions. The four quadrants would contain: DNA language models (HyenaDNA, DNABERT-2, NT v2, Caduceus, Evo-2, GROVER), sequence-to-function models (Enformer, Borzoi, Sei), variant-centric models (AlphaMissense, ESM-1v, EVE, CADD, Delphi, MIFM), and multi-omic models (Omni-DNA, cross-modal architectures, systems models). Each quadrant should list representative models with brief characterizations.\n\n\n\n7.3.1 DNA Language Models\nDNA language models learn sequence representations from raw nucleotide strings through self-supervised objectives. These models treat DNA as a language to be modeled without explicit functional labels, discovering patterns through statistical regularities in genomic sequence.\nCore characteristics. DNA language models typically use masked language modeling or autoregressive next-token prediction as their pretraining objective. They train on reference genomes or pan-genomic sequence collections spanning multiple species. The resulting models produce per-position or pooled sequence embeddings that can be extracted and used for downstream tasks. Critically, these embeddings are not tied to specific assays or cell types, making them applicable to any task that benefits from general sequence context.\nRepresentative models. DNABERT and DNABERT-2 apply BERT-style masked language modeling to DNA sequences, using overlapping k-mers as tokens (Ji et al. 2021; Z. Zhou et al. 2024). The Nucleotide Transformer family scales this approach to larger parameter counts and cross-species training, demonstrating improved transfer to diverse downstream tasks (Dalla-Torre et al. 2023). HyenaDNA achieves subquadratic complexity through implicit convolutions, enabling context lengths up to one million nucleotides at single-base resolution (Nguyen et al. 2023). Caduceus incorporates bidirectional processing and reverse-complement equivariance as architectural inductive biases. Evo-2 combines long-range attention with biological tokenization strategies. GROVER integrates learned BPE-style tokenization with training on regulatory tracks in addition to raw sequence (Sanabria et al. 2024).\nStrengths. DNA language models provide truly general representations not bound to specific assays, cell types, or experimental conditions. They can process and generate novel sequences that do not appear in reference genomes, making them suitable for de novo design tasks and synthetic biology applications. Their self-supervised training requires only genome sequences, making them scalable to any species with assembled genomes.\nLimitations. Without explicit functional grounding during pretraining, DNA language models may not capture subtle regulatory patterns that manifest only under specific cellular conditions. Their representations encode sequence patterns but do not directly predict molecular phenotypes. Performance on tasks requiring fine-grained functional discrimination may lag models trained with functional supervision.\nTypical applications. These models excel at tasks where general sequence context matters: sequence classification (identifying promoters, enhancers, transposons), motif discovery and refinement, variant effect prediction through embedding perturbation, sequence generation for synthetic biology, and transfer learning to new species or genomic contexts with limited labeled data.\n\n\n7.3.2 Sequence-to-Function Foundation Models\nSequence-to-function models predict molecular readouts directly from sequence through supervised or semi-supervised training on assay compendia. These models blur into foundation model territory when their output space is sufficiently broad and their internal representations prove useful for tasks beyond the original assay set.\nCore characteristics. These models map DNA sequences to high-dimensional vectors of molecular measurements, including chromatin accessibility, histone modifications, transcription factor binding, and gene expression levels. Training typically uses large collections of functional genomics assays spanning many cell types and conditions. The models learn regulatory grammar through supervised prediction of molecular phenotypes rather than through self-supervised sequence modeling.\nRepresentative models. Enformer predicts thousands of chromatin and expression tracks from 200 kb sequence windows through a transformer architecture with attention over long genomic contexts (Avsec et al. 2021). Borzoi extends this approach with refined architectures and expanded assay coverage. Sei organizes sequence-to-function predictions into interpretable sequence classes through unsupervised clustering, providing a discrete vocabulary for regulatory elements (Chen et al. 2022). Earlier models including DeepSEA and Basset established the sequence-to-function paradigm at smaller scales (J. Zhou and Troyanskaya 2015).\nStrengths. Explicit functional supervision provides strong mechanistic grounding. Predictions can be interpreted through comparison to experimental measurements. The models naturally support variant effect prediction by computing differences between reference and alternative allele predictions. When trained on sufficiently diverse assay collections, internal representations generalize beyond the specific prediction targets.\nLimitations. Models remain tied to the specific assays and cell types present during training. Extending predictions to new cell types typically requires retraining or collection of new data. Very rare cell types or transient cellular states may not be adequately represented in training data. The supervised training paradigm limits scalability compared to self-supervised approaches.\nTypical applications. These models serve well for regulatory variant interpretation in well-studied cell types, expression quantitative trait locus (eQTL) fine-mapping, enhancer identification and characterization, transcription factor binding site prediction, and regulatory mechanism discovery through perturbation analysis.\n\n\n7.3.3 Variant-Centric Foundation Models\nA third class of foundation models focuses on genetic variants as the fundamental unit of analysis rather than on raw sequence. These models embed variants using contextual information from local sequence, gene structure, population genetics, and external annotations, then predict variant pathogenicity, molecular consequences, or trait-level effect sizes.\nCore characteristics. Variant-centric models typically integrate information from multiple sources: local sequence context around the variant, conservation and population frequency patterns, protein structural context for coding variants, and functional annotations from databases. They may use genomic foundation models as feature extractors, combining sequence embeddings with variant-specific features. The outputs include pathogenicity scores, effect size estimates, or functional consequence predictions.\nRepresentative models. AlphaMissense applies protein language models to predict pathogenicity of missense variants across the human proteome (Cheng et al. 2023). ESM-1v uses evolutionary context to predict variant effects on protein function. EVE combines evolutionary and structural information for variant interpretation. CADD and its successors integrate diverse genomic annotations to score deleteriousness of any genetic variant (Rentzsch et al. 2019; Schubach et al. 2024). Delphi, MIFM, and related models couple genomic foundation model embeddings with polygenic score estimation for complex trait prediction (Georgantas, Kutalik, and Richiardi 2024; Rakowski and Lippert 2025; Wu et al. 2024).\nStrengths. Direct focus on variants aligns naturally with clinical applications and genetic association studies. Integration of multiple information sources provides robust predictions. Models can provide calibrated uncertainty estimates through ensemble approaches or variational methods. The variant-level interface simplifies integration into existing genetic analysis pipelines.\nLimitations. Most current models focus on single-nucleotide variants, with limited coverage of insertions, deletions, and structural variants. Predictions may be biased toward well-studied regions of the genome or commonly occurring variant types. The integration of multiple data sources creates dependencies on external databases that may not be uniformly available or accurate.\nTypical applications. Clinical variant interpretation for rare disease diagnosis, polygenic risk score construction for complex traits, prioritization of variants in genome-wide association studies, therapeutic target identification through variant effect prediction, and stratification of patient cohorts by genetic risk.\n\n\n7.3.4 Multi-Omic Foundation Models\nThe fourth category comprises models that natively integrate multiple molecular modalities. These models jointly process DNA sequence, chromatin state, gene expression, protein abundance, 3D genome structure, or even phenotypic descriptions, learning representations that span traditional boundaries between genomics, transcriptomics, and other omics layers.\nCore characteristics. Multi-omic models employ architectures that can handle heterogeneous input types, including transformer variants with cross-attention mechanisms, graph neural networks over molecular interaction networks, or modality-specific encoders combined through fusion layers. Training objectives encourage alignment across modalities through contrastive learning, joint prediction tasks, or generative modeling of multiple data types simultaneously.\nRepresentative models. Omni-DNA explores transformer-based autoregressive models that jointly handle DNA sequence and task-specific tokens representing molecular measurements (Li et al. 2025). Models integrating Hi-C or Micro-C data with sequence information capture 3D genome organization. Cross-modal architectures align DNA embeddings with chromatin state predictions or gene expression measurements through contrastive objectives. Systems-level models incorporate pathway annotations or gene ontology terms to constrain learned representations toward biologically meaningful subspaces.\nStrengths. Unified representations enable cross-modal queries such as “predict expression changes from a sequence variant” or “identify variants that affect chromatin organization in specific cell types.” Joint training can improve performance on individual modalities through multi-task learning effects. Mechanistic relationships between molecular layers can emerge naturally from data rather than requiring explicit modeling.\nLimitations. Data engineering becomes substantially more complex. Different molecular modalities require different measurement technologies, temporal sampling strategies, and quality control procedures. Training objectives must balance multiple tasks with potentially conflicting gradients. Computational requirements scale with the number of modalities and the complexity of cross-modal interactions. The field is still early, with few widely adopted models reaching production maturity.\nTypical applications. Systems biology investigations of disease mechanisms, drug discovery through multi-target effect prediction, cellular state modeling and trajectory inference, integration of genetic and environmental effects on phenotypes, and mechanistic modeling of regulatory networks.\n\n\n\n\n\n\nWarning\n\n\n\nTable suggestion: A comparison table with rows for the four model families and columns for: Context Length (typical range), Parameter Count (order of magnitude), Pretraining Objective (primary approach), Key Strengths (2-3 bullet points), Primary Limitations (2-3 bullet points), and Representative Applications (3-4 specific use cases). This would provide practitioners a quick reference for family characteristics and trade-offs.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#design-dimensions-a-framework-for-understanding-models",
    "href": "p2-ch07-foundation.html#design-dimensions-a-framework-for-understanding-models",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.4 Design Dimensions: A Framework for Understanding Models",
    "text": "7.4 Design Dimensions: A Framework for Understanding Models\nWithin and across the four families of genomic foundation models, individual models differ along several orthogonal design dimensions. Understanding these dimensions helps practitioners evaluate model suitability for specific tasks and helps researchers position new architectures within the design space.\n\n\n\n\n\n\nWarning\n\n\n\nFigure suggestion: A multi-axis diagram showing four orthogonal design dimensions: Data (species coverage, assay diversity, population diversity), Architecture (transformer/CNN/Hyena, attention patterns, parameter scaling), Objectives (MLM, autoregressive, multi-task, contrastive), and Tokenization (character-level, k-mer, learned BPE, resolution). Each axis should show concrete examples of choices (e.g., “1 species” vs “50+ species” on the data axis, “100M params” vs “10B params” on the architecture axis). The diagram should convey that models can make independent choices along each dimension.\n\n\n\n7.4.1 Data Composition\nThe choice of training data fundamentally shapes what patterns a model can learn and how well it generalizes beyond its training distribution.\nSpecies coverage. Models trained exclusively on human genomes focus on patterns relevant to human genetics and clinical applications. Cross-species training, as employed by Nucleotide Transformer and many protein language models, encourages learning of conserved regulatory elements and evolutionary constraints (Dalla-Torre et al. 2023; Rives et al. 2021). Pan-genomic approaches that incorporate multiple species may improve out-of-domain generalization but risk diluting human-specific signals relevant for clinical applications.\nSequence diversity. Training on reference genomes alone provides clean sequences but limited exposure to population-level variation. Incorporating sequences from diverse populations and variant databases improves robustness to common genetic variation. However, variant-augmented training requires careful design to avoid learning spurious associations between neutral variants and functional effects. Some models sample alleles from population databases to augment reference sequences during training, while others train on multiple reference assemblies when available.\nAnnotation integration. Models may train on raw sequence alone or may incorporate functional annotations as additional input channels or auxiliary prediction targets. DeepSEA-style models predict chromatin accessibility and transcription factor binding from sequence, effectively using these annotations as labels (J. Zhou and Troyanskaya 2015). Language models like GROVER integrate regulatory track information during pretraining rather than treating it as a downstream task (Sanabria et al. 2024). The degree of annotation integration trades off between generality (raw sequence only) and functional grounding (annotation-aware training).\nScale. The quantity of training data varies from single reference genomes (approximately 3 billion bases for human) to pan-genomic collections spanning hundreds of species and trillions of bases. For sequence-to-function models, scale also includes the number of assays, cell types, and experimental conditions represented. Larger and more diverse training data generally improves generalization, but with diminishing returns beyond a certain scale and potential concerns about data quality degradation when scraping very large corpora.\n\n\n7.4.2 Architecture Families\nArchitectural choices determine computational properties including maximum context length, memory requirements, training efficiency, and ease of adaptation to downstream tasks.\nTransformer architectures. Transformers dominate current genomic foundation models and come in several variants. Encoder-only models following the BERT design, such as DNABERT and Nucleotide Transformer, excel at classification and embedding tasks. They process sequences bidirectionally through masked language modeling objectives. Decoder-only models following the GPT design, including GROVER and some Omni-DNA variants, use autoregressive prediction and naturally support generative tasks. Encoder-decoder architectures combine bidirectional context encoding with flexible output generation, useful for tasks like sequence-to-text explanation or structure-guided design.\nThe attention mechanism itself varies across implementations. Full dense attention provides exact computation of all pairwise interactions but scales quadratically with sequence length. Sparse attention patterns, including local windows and strided patterns, reduce complexity while maintaining long-range modeling capacity. Linear attention approximations trade exact computation for reduced asymptotic complexity. Flash attention and other algorithmic optimizations improve memory efficiency and speed without changing model behavior.\nSub-quadratic long-range models. Attention-free architectures address the quadratic complexity bottleneck directly. Hyena-based models like HyenaDNA use implicit convolutions parameterized by small neural networks to achieve subquadratic scaling (Nguyen et al. 2023). State space models including Mamba and related architectures process sequences recurrently with linear complexity. These approaches enable much longer contexts than standard transformers with comparable parameter counts.\nHybrid architectures. Many successful models combine multiple architectural components. CNN-transformer hybrids use local convolutions followed by global attention, as seen in Enformer and related models (Avsec et al. 2021). Multi-scale approaches process sequences at multiple resolutions, using dilated convolutions or hierarchical attention patterns. Cross-attention mechanisms integrate information from multiple input modalities, such as sequence and chromatin state or DNA and protein sequence.\nParameter scaling. Genomic foundation models range from approximately 100 million parameters at the small end to over 10 billion parameters for the largest models. Larger models generally achieve better performance on downstream tasks, but with significantly higher computational costs for training and inference. The optimal scale depends on available training data, computational budget, and deployment constraints. Recent work suggests that smaller, more carefully trained models can approach or match the performance of larger models on many tasks.\n\n\n7.4.3 Context Length Capabilities\nThe genomic context a model can process constrains which biological phenomena it can capture and which applications it can serve effectively.\nShort context (under 1 kb). Models with kilobase-scale contexts capture local sequence patterns including transcription factor binding motifs, splice sites, and promoter elements. These models work well for tasks focused on local regulatory logic but cannot capture distal enhancer-promoter interactions or chromatin domain structure. Most early deep learning models for genomics operated at this scale due to computational constraints.\nMedium context (1-10 kb). At this scale, models capture complete genes with their proximal regulatory regions, local regulatory grammar involving multiple nearby elements, and some distal interactions within topologically associating domains. Many current models including DNABERT-2 and standard transformer implementations reach contexts in this range. This scale balances biological relevance with computational tractability for many applications.\nLong context (10-200 kb). Models reaching this scale can represent distal enhancer-promoter interactions, topologically associating domains (TADs) and their internal structure, and multi-gene regulatory clusters. Enformer operates at 200 kb context, enabling prediction of long-range regulatory effects (Avsec et al. 2021). This scale is particularly relevant for understanding complex regulatory regions such as gene-dense loci and super-enhancers.\nUltra-long context (over 200 kb). A few models extend beyond 200 kb, with HyenaDNA reaching up to one million nucleotides through its sub-quadratic architecture (Nguyen et al. 2023). At this scale, models can capture chromosomal domains, multi-megabase structural variants, and complex haplotype structure. Applications include structural variant interpretation, haplotype-aware variant effect prediction, and modeling of very long-range regulatory interactions.\nThe effective use of long context requires careful consideration of tokenization strategy and positional encoding schemes, as discussed below.\n\n\n7.4.4 Tokenization Strategies\nHow sequences are discretized into tokens affects model capacity, context length, positional resolution, and computational efficiency. This dimension interacts strongly with architecture choice and context requirements.\nCharacter-level tokenization. Treating each nucleotide as a separate token maintains single-base resolution and makes no assumptions about relevant sequence units. HyenaDNA and many sequence-to-function models use this approach (Nguyen et al. 2023). Character-level tokenization provides maximum flexibility for variant effect prediction and precise regulatory element mapping. However, it imposes the longest sequence lengths, requiring efficient architectures or aggressive downsampling for long-range modeling.\nK-mer tokenization. Grouping nucleotides into overlapping or non-overlapping k-mers reduces sequence length by a factor approaching k. For 6-mers, the vocabulary size reaches 4,096 tokens. DNABERT uses overlapping 6-mers, allowing the model to reach longer effective contexts within transformer attention limits (Ji et al. 2021). K-mer approaches introduce positional ambiguity at word boundaries and may not align naturally with biological units, but they often improve performance through implicit modeling of short motifs.\nLearned tokenization. Byte-pair encoding (BPE) and related methods discover tokenization schemes from data rather than using fixed vocabularies. Models like GROVER explore learned tokenization for DNA, potentially allocating vocabulary capacity more efficiently than k-mer schemes (Sanabria et al. 2024). Recent work with BioToken demonstrates that learned tokenizers can improve downstream task performance compared to fixed k-mer schemes (Medvedev et al. 2025). However, learned tokenization complicates interpretation and may not transfer well across domains or species.\nHierarchical and multi-resolution approaches. Some models use different tokenization schemes at different architectural layers. For example, early layers might operate on character-level tokens to capture fine-grained patterns, while later layers use learned pooling to reduce sequence length and expand receptive fields. This approach attempts to combine the resolution benefits of character-level encoding with the efficiency of coarser tokenization.\nThe choice of tokenization strategy should align with both the architecture’s computational constraints and the biological scales relevant to downstream applications. Single-nucleotide variant effect prediction strongly favors character-level or fine-grained tokenization. Expression prediction or chromatin state modeling may benefit from coarser tokenization that implicitly captures regulatory motifs.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#understanding-model-capabilities-through-the-taxonomy",
    "href": "p2-ch07-foundation.html#understanding-model-capabilities-through-the-taxonomy",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.5 Understanding Model Capabilities Through the Taxonomy",
    "text": "7.5 Understanding Model Capabilities Through the Taxonomy\nThe taxonomy and design dimensions established above provide a framework for matching models to specific genomic analysis tasks. Different families excel at different applications, and no single model dominates across all use cases.\n\n7.5.1 Matching Model Families to Task Requirements\nNovel sequence analysis. When working with sequences not present in reference genomes, such as synthetic constructs, pathogen genomes, or rare structural variants, DNA language models provide the most flexibility. Their self-supervised training on general sequence distributions transfers well to novel contexts without requiring task-specific labels. Models like HyenaDNA and Nucleotide Transformer can process and embed arbitrary sequences, making them suitable for de novo design and synthetic biology applications.\nRegulatory prediction in well-studied contexts. For predicting chromatin accessibility, transcription factor binding, or gene expression in cell types well-represented in training data, sequence-to-function models offer strong baselines. Enformer-style models directly output predictions for relevant assays and can be queried with specific genomic loci (Avsec et al. 2021). The mechanistic grounding from functional supervision often produces more interpretable predictions than language model embeddings.\nClinical variant interpretation. Variant-centric models like AlphaMissense and ESM-1v provide pathogenicity scores calibrated for clinical use (Cheng et al. 2023). These models integrate evolutionary context, population frequency, and protein structural information in ways optimized for distinguishing pathogenic from benign variants. For missense variant interpretation specifically, protein language models outperform DNA-based approaches on most benchmarks.\nSystems-level questions. Tasks requiring integration of multiple molecular layers, such as predicting phenotypic effects of regulatory variants on downstream pathways, benefit from multi-omic models. These models can jointly reason about DNA sequence, gene expression, and pathway activation. However, the relative immaturity of this model family means that practitioners often need to combine predictions from separate DNA and expression models rather than using a unified multi-omic architecture.\n\n\n7.5.2 Trade-offs Between Model Families\nThe taxonomy reveals consistent trade-offs that guide model selection and development priorities.\nGenerality versus specificity. DNA language models provide the most general representations but may underperform specialized models on specific tasks. Variant-centric models achieve excellent performance on pathogenicity prediction but offer limited utility for other genomic questions. Sequence-to-function models occupy a middle ground, specialized for regulatory prediction but still useful for related tasks like enhancer design.\nMechanistic grounding versus flexibility. Models trained with functional supervision (sequence-to-function and some variant-centric models) produce predictions that align with known biology and can be validated against experimental measurements. Self-supervised language models learn representations from sequence statistics without mechanistic constraints, providing greater flexibility but potentially missing important biological patterns that require specific cellular contexts to manifest.\nSingle-task performance versus transfer breadth. Task-specific fine-tuning of foundation models typically achieves the best performance on individual benchmarks. However, fully fine-tuned models lose some transfer capability, requiring separate models for each new task. Lightweight adaptation through linear probes or low-rank fine-tuning preserves more general knowledge while accepting some performance loss.\n\n\n7.5.3 Why Multiple Families Persist\nThe existence of four distinct families of genomic foundation models reflects fundamental differences in their intended use cases and biological scope. DNA language models emphasize generality and novel sequence handling. Sequence-to-function models prioritize mechanistic grounding and interpretability. Variant-centric models optimize for clinical decision-making. Multi-omic models aim for systems-level integration.\nThis specialization suggests that a single universal genomic foundation model may not emerge soon. Different applications have genuinely different requirements regarding context length, resolution, functional grounding, and interpretability. The field may converge on a small set of architectural patterns rather than a single dominant approach, similar to how natural language processing maintains distinct model families for different tasks despite the success of large language models.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#evaluation-beyond-single-benchmarks",
    "href": "p2-ch07-foundation.html#evaluation-beyond-single-benchmarks",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.6 Evaluation: Beyond Single Benchmarks",
    "text": "7.6 Evaluation: Beyond Single Benchmarks\nFoundation models by their nature resist evaluation on single tasks. Their value lies in transfer and reuse across many applications, making comprehensive evaluation substantially more complex than benchmarking task-specific models.\n\n7.6.1 Multi-task Assessment Requirements\nA genomic foundation model should be evaluated across families of related tasks rather than on isolated benchmarks. For DNA language models, this includes sequence classification tasks (promoter identification, enhancer detection, repeat classification), variant effect prediction across multiple variant types, transcription factor motif discovery, and transfer to non-human species when trained on cross-species corpora.\nFor sequence-to-function models, evaluation should span prediction of held-out assays, transfer to novel cell types or tissues, accuracy on regulatory variant effect prediction, and consistency between predicted and experimentally measured effects. Variant-centric models require assessment across coding and non-coding variants, calibration analysis for clinical thresholds, performance stratification by population ancestry, and comparison against existing clinical interpretation guidelines.\nThe diversity of evaluation tasks complicates comparison across models. A model that excels at promoter classification may underperform on eQTL fine-mapping. Direct comparisons require controlling for differences in training data, model scale, and evaluation protocols.\n\n\n7.6.2 Transfer Capability Versus Pretraining Performance\nFoundation models are intended for transfer, making performance on pretraining objectives only moderately predictive of downstream utility. A model with slightly worse masked language modeling loss may produce better embeddings for downstream classification if the loss function better aligns with useful representations. Conversely, a model that achieves very low pretraining loss through memorization may transfer poorly to novel sequences or tasks.\nEvaluation should explicitly test transfer capability through several mechanisms:\n\nZero-shot performance using frozen embeddings with no task-specific training\nFew-shot learning with minimal labeled examples (10-100 per class)\nCross-domain transfer from training to evaluation on different sequence types, species, or assay modalities\nRobustness to distribution shift including population variation, sequencing artifacts, and batch effects\n\nThese evaluations reveal whether a model has learned general principles of genomic organization or has simply memorized patterns in its training data.\n\n\n7.6.3 Robustness Across Domains and Distributions\nGenomic foundation models deployed in clinical or research settings encounter sequences, variants, and contexts not represented in training data. Evaluation should probe robustness to various distribution shifts:\n\nPopulation diversity: Performance stratified by genetic ancestry\nSequencing technology: Consistency across Illumina, PacBio, and Nanopore data\nAssembly quality: Degradation when applied to draft genomes versus finished assemblies\nRare variants: Calibration for very low-frequency or singleton variants\nStructural variants: Handling of insertions, deletions, inversions beyond single-nucleotide changes\n\nModels showing strong performance on reference genome benchmarks may fail on real-world data if they have learned spurious correlations with assembly artifacts or population-specific patterns.\n\n\n\n\n\n\nWarning\n\n\n\nFigure suggestion: An evaluation pyramid with four tiers. The base tier represents molecular readouts (chromatin accessibility, TF binding, RNA expression). The second tier shows functional predictions (regulatory element annotation, variant effect scores). The third tier represents cellular phenotypes (cell state classification, differentiation trajectories). The apex shows organismal and clinical outcomes (disease risk, drug response, organismal fitness). Each tier should indicate representative evaluation datasets and the strength of validation evidence typically available (strong at the base, weaker toward the apex). Arrows connecting tiers illustrate that robust validation requires accumulation of evidence across multiple levels.\n\n\n\n\n7.6.4 Benchmark Suites and Community Resources\nSeveral standardized benchmark suites enable systematic comparison of genomic foundation models.\nProteinGym evaluates variant effect prediction across thousands of proteins through deep mutational scanning data (Notin et al. 2023). The benchmark includes multiple protein families and variant types, enabling assessment of transfer across proteins and mechanistic understanding of mutation effects.\nTraitGym assesses genomic foundation models on complex trait prediction tasks (Benegas, Eraslan, and Song 2025). The benchmark spans quantitative traits, binary outcomes, and disease phenotypes, testing models’ ability to integrate regulatory information for polygenic prediction.\nNucleotide Transformer benchmarks provide diverse DNA-level tasks including regulatory element classification, enhancer-promoter linking, and transcript abundance prediction across cell types (Dalla-Torre et al. 2023). These benchmarks explicitly compare transformer-based DNA foundation models.\nComparative evaluations such as the recent comparison of five DNA foundation models (DNABERT-2, Nucleotide Transformer V2, HyenaDNA, Caduceus-Ph, GROVER) across classification, expression prediction, variant effect, and TAD recognition tasks reveal that no single model dominates all benchmarks (Manzo, Borkowski, and Ovcharenko 2025). Such studies establish performance bands and identify model-specific strengths.\nGV-Rep and variant representation benchmarks explicitly test how well genomic foundation models represent genetic variants and clinical contexts. These resources fill a gap in evaluation infrastructure by focusing on the variant representation layer rather than end-to-end task performance.\nTask-specific datasets remain relevant for focused applications. ClinVar provides ground-truth pathogenicity labels for clinical variant interpretation (Landrum et al. 2018). ENCODE and Cistrome supply functional genomics data for regulatory prediction (Kagda et al. 2025; Zheng et al. 2019). GTEx enables eQTL-based validation of expression prediction models (The GTEx Consortium 2020). Combining standardized benchmarks with domain-specific validation provides the most complete assessment of model capabilities.\n\n\n7.6.5 Evaluation Regimes\nGenomic foundation models can be evaluated in several distinct regimes that test different aspects of utility and deployment readiness.\nZero-shot evaluation uses frozen model embeddings with no task-specific training. This tests whether useful information is directly accessible through simple operations like cosine similarity or k-nearest neighbors. Zero-shot evaluation provides a lower bound on model utility and can reveal whether representations encode biologically meaningful structure.\nLinear probe evaluation trains shallow linear or logistic regression classifiers on frozen embeddings. This regime tests whether relevant information is linearly separable in the model’s representation space, providing a diagnostic for representation quality independent of downstream model complexity. Linear probes are computationally inexpensive and robust to overfitting on small labeled datasets.\nLightweight adaptation includes approaches like low-rank adaptation (LoRA), prompt tuning, or small MLP heads trained on frozen or partially frozen backbone models. These methods balance performance with computational cost and stability. They enable task-specific tuning without the full computational expense of end-to-end fine-tuning and with reduced risk of catastrophic forgetting.\nFull fine-tuning updates all model parameters on downstream tasks. This typically yields the best single-task performance but requires more labeled data and computation. Fine-tuning risks overfitting to narrow task distributions and losing general knowledge acquired during pretraining. Full fine-tuning evaluation establishes performance ceilings but may not reflect practical deployment constraints.\nAdapter ablation studies that compare these evaluation regimes on the same tasks reveal how much task-specific information must be learned versus how much can be extracted from pretrained representations. Large gaps between linear probe and fine-tuned performance suggest that relevant information is present but not easily accessible. Small gaps indicate that pretrained representations already encode task-relevant structure.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#the-foundation-model-ecosystem",
    "href": "p2-ch07-foundation.html#the-foundation-model-ecosystem",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.7 The Foundation Model Ecosystem",
    "text": "7.7 The Foundation Model Ecosystem\nGenomic foundation models exist within a broader ecosystem of infrastructure, community resources, and shared practices that enable their development, distribution, and application.\n\n7.7.1 Model Hubs and Distribution\nMost genomic foundation models are distributed through centralized repositories that provide standardized interfaces and documentation. Hugging Face hosts many DNA and protein language models with documented APIs for embedding extraction, tokenization, and fine-tuning. GitHub repositories often accompany publications, providing model weights, training code, and example notebooks. Some models are distributed through domain-specific platforms like ProteinGym or integrated into larger software ecosystems.\nStandardized distribution formats reduce friction in model adoption. Models packaged with consistent APIs can be swapped easily in downstream pipelines, enabling rapid benchmarking and experimentation. However, inconsistent documentation, incomplete training details, and missing preprocessing code remain common challenges in reproducing published results.\n\n\n7.7.2 Documentation and Reproducibility Requirements\nResponsible distribution of genomic foundation models requires comprehensive documentation covering training data provenance, preprocessing procedures, model architecture details, training hyperparameters, evaluation protocols, and known limitations or failure modes.\nData provenance is particularly important given that training data may include cohort-level genomic datasets with specific use restrictions or population-specific biases. Models trained on data from predominantly European ancestries should document this limitation. Models incorporating clinical annotations should clarify whether those annotations have been validated or are computationally predicted.\nReproducibility remains an active challenge. Many published foundation models cannot be retrained from scratch due to computational costs, proprietary data, or incomplete method descriptions. Standardized reporting guidelines analogous to those in machine learning conferences may improve reproducibility in genomic foundation model publications.\n\n\n7.7.3 Community Benchmarks and Leaderboards\nPublic leaderboards for genomic tasks encourage model development but also risk overfitting to specific benchmark distributions. ProteinGym and TraitGym provide test sets with held-out targets to mitigate this concern (Notin et al. 2023; Benegas, Eraslan, and Song 2025). Community challenges such as CAGI (Critical Assessment of Genome Interpretation) enable head-to-head comparison of variant interpretation methods including foundation model approaches.\nLeaderboards work best when they capture diverse evaluation criteria rather than single metrics. Rankings should consider computational efficiency, calibration quality, robustness across populations, and interpretability in addition to raw accuracy. Multi-objective evaluation prevents optimization for narrow benchmark performance at the expense of practical utility.\n\n\n7.7.4 Industry Versus Academic Models\nGenomic foundation models are developed by both academic research groups and industry. Academic models typically emphasize reproducibility and open access, with model weights and training code released publicly. Industry models may offer superior performance through access to proprietary data or computational resources but with limited transparency about training procedures and restricted access.\nNotable industry contributions include NVIDIA’s BioNeMo platform, which provides optimized implementations of genomic foundation models for efficient inference, and Microsoft’s integration of genomic models into Azure cloud infrastructure. Some models occupy a middle ground, with academic groups partnering with industry for computational resources while maintaining open publication and model release.\nLicensing terms vary. Most academic models use permissive open-source licenses allowing commercial use. Some models restrict commercial applications or require citation. Users should review license terms before deploying models in commercial or clinical settings.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#open-questions-and-frontiers",
    "href": "p2-ch07-foundation.html#open-questions-and-frontiers",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.8 Open Questions and Frontiers",
    "text": "7.8 Open Questions and Frontiers\nDespite rapid progress, genomic foundation models face several fundamental challenges that represent important directions for future research.\n\n7.8.1 Convergence or Divergence\nAn open question is whether the field will converge toward a small number of unified architectures or whether specialized model families will persist. In natural language processing, decoder-only transformers have largely unified the field despite earlier diversity of architectures. In genomics, the diversity of sequence lengths, resolution requirements, and functional contexts may preclude such convergence.\nA unified model would need to handle sequences from single nucleotides to megabases, operate on raw sequence and functional annotations, transfer across species and cell types, and serve both mechanistic modeling and predictive tasks. Whether such generality is achievable or desirable remains unclear. Specialized models may continue to outperform unified approaches on their target applications, suggesting that moderate architectural diversity could persist.\n\n\n7.8.2 What Genomic Foundation Models Still Cannot Do\nCurrent genomic foundation models have significant limitations that constrain their applicability.\nCausal reasoning. Existing models learn correlations in training data but do not distinguish causal from spurious relationships. A model might learn that certain motifs correlate with gene expression in training data due to cell-type-specific confounding rather than direct regulatory function. Integrating causal structure into model training or inference could improve robustness to distribution shifts and enable counterfactual reasoning about perturbations.\nMechanistic structure. Most models treat regulatory effects as black-box functions of sequence without imposing mechanistic constraints from biochemistry or physics. Hybrid approaches that combine neural network flexibility with mechanistic models of transcription factor binding, chromatin remodeling, or RNA folding may improve interpretability and generalization.\nRare variant interpretation. Foundation models trained on reference genomes and common variants may not calibrate well for ultra-rare or de novo variants. Improved integration of protein structure constraints, evolutionary information, and functional assay data could strengthen rare variant interpretation.\nLong-range and structural variants. While models like HyenaDNA demonstrate feasibility of very long contexts, most models do not adequately handle complex structural variants involving inversions, duplications, or translocations (Nguyen et al. 2023). Better integration of sequence topology and copy number could improve structural variant interpretation.\nTemporal and dynamic regulation. Current models produce static predictions that do not account for temporal dynamics of gene regulation, developmental trajectories, or response to environmental perturbations. Incorporating temporal information through sequential modeling or dynamical systems could enable prediction of regulatory dynamics.\n\n\n7.8.3 Scaling Limits\nThe recent success of large language models has encouraged scaling of genomic foundation models along multiple dimensions. However, biological constraints may impose practical limits. Single-nucleotide resolution over megabase contexts may not provide additional benefits if most regulatory interactions occur over shorter ranges. Parameter counts beyond billions may yield diminishing returns given limited training data and finite biological complexity.\nAlternative scaling strategies deserve exploration. Rather than naively increasing model size, future work might scale the diversity of training data across species, populations, and functional contexts, incorporate more structured biological knowledge through hybrid architectures, or improve sample efficiency through better pretraining objectives. The most productive scaling dimension likely depends on the target application.\n\n\n7.8.4 Clinical Deployment Readiness\nTranslation of genomic foundation models to clinical use faces substantial challenges beyond predictive performance. Clinical deployment requires robust performance across diverse patient populations including underrepresented ancestries, calibrated uncertainty quantification for risk-benefit decision-making, interpretability that enables clinicians to understand model predictions, prospective validation demonstrating clinical utility beyond retrospective benchmarks, and regulatory approval processes that current models do not yet satisfy.\nAddressing these requirements will likely require domain adaptation techniques that adjust models to clinical populations, ensemble methods that provide well-calibrated uncertainty estimates, mechanistic interpretation frameworks that connect predictions to biological mechanisms, integration with electronic health record systems and clinical workflows, and accumulation of prospective validation evidence demonstrating patient benefit.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch07-foundation.html#summary-and-forward-references",
    "href": "p2-ch07-foundation.html#summary-and-forward-references",
    "title": "7  Genomic Foundation Models: Concepts & Taxonomy",
    "section": "7.9 Summary and Forward References",
    "text": "7.9 Summary and Forward References\nThis chapter established a conceptual framework for understanding genomic foundation models as a distinct class of computational tools. We defined genomic foundation models through five essential properties: large-scale pretraining with minimal supervision, general-purpose representations, broad transfer capability, scale along at least one dimension, and standardized interfaces for downstream use. This definition separates true foundation models from task-specific architectures that may be large but lack generality.\nWe organized the emerging ecosystem into four families. DNA language models learn sequence distributions through self-supervision and provide general embeddings. Sequence-to-function models predict molecular readouts from sequence through functionally supervised training. Variant-centric models focus on genetic variants as atomic units, integrating sequence context with population and functional annotations. Multi-omic models jointly represent DNA and other molecular layers through cross-modal architectures.\nFour orthogonal design dimensions shape model behavior: data composition including species coverage and assay diversity, architecture families spanning transformers to sub-quadratic alternatives, pretraining objectives from masked language modeling to multi-task prediction, and tokenization strategies that trade resolution against context length. Understanding these dimensions helps match models to applications and positions new contributions within the design space.\nEvaluation of genomic foundation models requires multi-task assessment, measurement of transfer capability, and robustness testing across domains and populations. Emerging benchmark suites including ProteinGym, TraitGym, and DNA foundation model comparisons enable systematic evaluation, though gaps remain in coverage of clinical and rare variant interpretation tasks (Notin et al. 2023; Benegas, Eraslan, and Song 2025).\nThe foundation model ecosystem includes model hubs, documentation standards, community benchmarks, and industry contributions that collectively enable model development and deployment. Open challenges include potential convergence toward unified architectures versus persistence of specialized families, integration of causal and mechanistic structure, improved rare and structural variant interpretation, and satisfaction of clinical deployment requirements.\nThe conceptual framework established here will guide subsequent chapters. Chapter 8 examines how genomic foundation models are actually trained, including data curation, objective design, and optimization strategies. Chapter 20 recasts variant effect prediction in the foundation model era, while Chapter 17 explores multi-omic integration and systems-level modeling. Throughout these applications, the taxonomy and design principles developed in this chapter provide structure for understanding a rapidly evolving field.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nKagda, Meenakshi S., Bonita Lam, Casey Litton, Corinn Small, Cricket A. Sloan, Emma Spragins, Forrest Tanaka, et al. 2025. “Data Navigation on the ENCODE Portal.” Nature Communications 16 (1): 9592. https://doi.org/10.1038/s41467-025-64343-9.\n\n\nLandrum, Melissa J, Jennifer M Lee, Mark Benson, Garth R Brown, Chen Chao, Shanmuga Chitipiralla, Baoshan Gu, et al. 2018. “ClinVar: Improving Access to Variant Interpretations and Supporting Evidence.” Nucleic Acids Research 46 (D1): D1062–67. https://doi.org/10.1093/nar/gkx1153.\n\n\nLi, Zehui, Vallijah Subasri, Yifei Shen, Dongsheng Li, Yiren Zhao, Guy-Bart Stan, and Caihua Shan. 2025. “Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning.” arXiv. https://doi.org/10.48550/arXiv.2502.03499.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, et al. 2022. “[ESM-2] Language Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction.” bioRxiv. https://doi.org/10.1101/2022.07.20.500902.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025. “Comparative Analysis of Deep Learning Models for Predicting Causative Regulatory Variants.” bioRxiv: The Preprint Server for Biology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. “ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design.” Advances in Neural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. “[ESM-1b] Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.” Proceedings of the National Academy of Sciences of the United States of America 118 (15): e2016239118. https://doi.org/10.1073/pnas.2016239118.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. “[GROVER] DNA Language Model GROVER Learns Sequence Context in the Human Genome.” Nature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nThe GTEx Consortium. 2020. “The GTEx Consortium Atlas of Genetic Regulatory Effects Across Human Tissues.” Science 369 (6509): 1318–30. https://doi.org/10.1126/science.aaz1776.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nZheng, Rongbin, Changxin Wan, Shenglin Mei, Qian Qin, Qiu Wu, Hanfei Sun, Chen-Hao Chen, et al. 2019. “Cistrome Data Browser: Expanded Datasets and New Tools for Gene Regulatory Analysis.” Nucleic Acids Research 47 (D1): D729–35. https://doi.org/10.1093/nar/gky1094.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. “DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Genomic Foundation Models: Concepts & Taxonomy</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html",
    "href": "p2-ch08-pretrain.html",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "",
    "text": "8.1 Learning from Unlabeled Genomes\nFoundation models do not emerge fully formed. Before they can predict variant effects, interpret regulatory sequences, or guide experimental design, they must first learn general representations from vast amounts of unlabeled genomic data. This learning process is called pretraining, and the choice of pretraining objective fundamentally shapes what a model learns, how efficiently it trains, and which downstream tasks it ultimately excels at.\nThis chapter explores the landscape of pretraining strategies for genomic models. We begin with the conceptual foundations: why pretraining works, how self-supervised learning creates useful supervision from sequence structure alone, and the connections to language modeling paradigms from NLP. We then survey the major families of pretraining objectives, including masked language modeling, next-token prediction, denoising, contrastive learning, and multi-task approaches. For each, we examine the core algorithmic principles, genomic adaptations, and trade-offs between objectives.\nBeyond objectives themselves, effective pretraining requires careful decisions about data curation, augmentation strategies, curriculum design, and computational infrastructure. We address these practical considerations alongside the theoretical motivations. Finally, we examine how leading models were pretrained in practice, extracting lessons from DNABERT, HyenaDNA, Enformer, and ESM-2 that inform future work.\nBy the end of this chapter you should understand:\nGenomics presents a paradox: we have enormous quantities of sequence data but relatively sparse functional annotations. Reference genomes span billions of nucleotides across thousands of species. Population sequencing projects catalog millions of individuals. Yet experimental labels—ChIP-seq peaks, expression measurements, clinical outcomes—are available for only a tiny fraction of possible sequences and contexts.\nThis imbalance motivates pretraining. Rather than training models from scratch on small labeled datasets, we can first learn general-purpose sequence representations from unlabeled genomes, then adapt these representations to specific tasks through fine-tuning or few-shot learning. The intuition is that many patterns relevant to regulatory function, splice site recognition, or protein folding are embedded in sequence statistics themselves. A model that learns to predict missing nucleotides or adjacent sequence context must implicitly capture motifs, constraints, and compositional structure that generalize across tasks.\nSelf-supervised learning provides the algorithmic framework for extracting supervision from unlabeled data. Instead of requiring external labels, self-supervised objectives construct prediction tasks from the data’s inherent structure. In genomics, this might mean masking portions of a sequence and predicting the masked content, predicting the next token in a sequence, or distinguishing augmented views of the same sequence from unrelated sequences. These artificial tasks force the model to build representations that capture sequence properties useful for many downstream applications.\nThe connection to natural language processing is direct. Models like BERT and GPT revolutionized NLP by pretraining on massive text corpora before fine-tuning on specific tasks. Genomic sequences are discrete symbol sequences much like text, and many of the same algorithmic principles apply. However, genomics introduces unique considerations: DNA has no word boundaries, both strands encode information, motifs are compositional, and biological function depends on spatial organization at multiple scales.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#the-pretraining-paradigm",
    "href": "p2-ch08-pretrain.html#the-pretraining-paradigm",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.2 The Pretraining Paradigm",
    "text": "8.2 The Pretraining Paradigm\nThe standard deep learning workflow for genomics now follows a two-stage process: pretraining followed by fine-tuning or adaptation. During pretraining, the model processes large volumes of unlabeled sequence data under a self-supervised objective designed to encourage useful representations. The result is a pretrained model with learned parameters that encode general sequence properties. During fine-tuning, these pretrained parameters are adapted to specific labeled tasks, often with far less data than would be required to train from scratch.\nThis paradigm succeeds because of the transfer hypothesis: features learned on one task can improve performance on related tasks. A model pretrained to predict masked DNA tokens learns motif patterns, sequence constraints, and compositional structure. When fine-tuned to predict transcription factor binding, these representations provide a strong initialization that accelerates convergence and improves generalization. The pretrained model has already learned “what DNA looks like,” so the fine-tuning stage need only specialize these representations to the binding prediction task.\nGenomics is particularly well-suited to this approach. We have orders of magnitude more unlabeled sequence than labeled functional data. Reference genomes provide billions of training examples at zero annotation cost. Even when functional labels exist, they are often sparse (covering small genomic regions), noisy (from experimental variability), or context-specific (measured in particular cell types or conditions). Pretraining allows us to leverage the full scope of genomic sequence diversity before specializing to narrower labeled datasets.\nThis contrasts sharply with training models from scratch on supervised tasks alone. Without pretraining, models must learn both general sequence structure and task-specific patterns simultaneously from limited labeled examples. This is not only data-inefficient but also risks overfitting to spurious correlations in small datasets. Pretraining separates these learning stages: general representations come from abundant unlabeled data, while task-specific refinement uses precious labeled examples more efficiently.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (pretraining paradigm overview): A two-stage diagram showing (1) pretraining on unlabeled genome sequences with self-supervised objectives, producing a pretrained model, then (2) fine-tuning on labeled data (e.g., ChIP-seq peaks, variant effects) to produce a task-specific model. Arrows indicate parameter initialization from pretraining to fine-tuning.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#masked-language-modeling",
    "href": "p2-ch08-pretrain.html#masked-language-modeling",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.3 Masked Language Modeling",
    "text": "8.3 Masked Language Modeling\nMasked language modeling treats sequences as partially observed and trains models to predict missing content from surrounding context. Inspired by BERT’s success in NLP, MLM has become the dominant pretraining objective for genomic models. The core idea is simple: randomly mask portions of an input sequence, feed the corrupted sequence to the model, and train the model to reconstruct the original tokens at masked positions.\nIn practice, a masking strategy replaces selected tokens with a special [MASK] token or leaves them unchanged with some probability. For DNA sequences, this might mean masking individual nucleotides, k-mers, or byte-pair encoding tokens depending on the tokenization scheme. The model processes the masked sequence through its layers and produces predictions for the masked positions. The loss function is typically cross-entropy over the vocabulary at each masked position, computed only for masked tokens to avoid wasting computation on unmasked positions.\nMLM encourages bidirectional context integration. Unlike left-to-right language models that can only condition on past tokens, MLM models see both left and right context when predicting masked positions. For genomics, this is biologically appropriate: regulatory function depends on patterns both upstream and downstream of any given position. A transcription factor binding site might be recognized through flanking sequences on both sides, and splicing signals require coordination between donor and acceptor sites separated by hundreds of bases.\nThe choice of masking strategy significantly impacts what models learn. Random masking of individual tokens creates a simple objective where each prediction is relatively local. Span masking, which masks contiguous blocks of tokens, forces models to infer longer-range dependencies and compositional patterns. Whole-word masking in NLP masks all tokens corresponding to a word, preventing trivial solutions from subword statistics alone. In genomics, masking entire k-mers or motifs rather than individual bases may encourage learning of functional modules rather than just nucleotide co-occurrence.\nMasking rates present a trade-off. Higher masking rates (e.g., 30-40%) provide more supervision per sequence but make the prediction task harder and may destabilize training. Lower masking rates (e.g., 10-15%) are more stable but require more data to achieve equivalent coverage. The standard 15% rate from BERT represents a reasonable compromise, though genomic models have explored a range of values depending on context length and tokenization granularity.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (MLM mechanics): A schematic showing an input DNA sequence, the same sequence with 15% of tokens masked, the model architecture processing the masked sequence, and predictions at masked positions. Highlight how bidirectional attention allows each position to see both upstream and downstream context.\n\n\n\n8.3.1 Genomic Adaptations of MLM\nDNABERT pioneered MLM for genomic sequences by applying it to overlapping k-mer tokens. Rather than treating DNA as individual nucleotides, DNABERT tokenizes sequences into all possible 6-mers with overlapping windows. Masking then operates at the k-mer level: entire 6-mers are masked as units. This design encourages the model to learn k-mer level patterns that correspond to transcription factor binding motifs and other short functional elements.\nDNABERT-2 adopted byte-pair encoding tokenization, which learns a vocabulary of variable-length subword units from the training corpus. BPE tokens might represent single nucleotides, common motifs, or repeated elements depending on their frequency. MLM with BPE tokens balances the flexibility of single-nucleotide models with the compositional structure of fixed k-mer approaches. However, BPE introduces its own complexities: the learned vocabulary may not align with biological functional units, and different tokenization schemes can lead to different learned representations.\nThe Nucleotide Transformer family applies MLM with variable-length masking and very long context windows, pretraining on sequences up to 1000 nucleotides or more. By scaling both model capacity and context length, these models capture longer-range dependencies relevant to enhancer-promoter interactions, chromatin domain structure, and coordinated regulation of gene clusters.\nBiological considerations inform masking decisions beyond algorithmic choices. Masking functional elements like transcription factor binding sites or splice motifs creates harder but more biologically relevant prediction tasks. If the training corpus includes evolutionary conservation information, masking conserved regions may teach models about functional constraint. Conversely, masking repetitive or low-complexity regions may provide less informative supervision.\n\n\n8.3.2 What MLM Learns\nMLM objectives drive models to capture multiple aspects of sequence organization. At the lowest level, models learn nucleotide-level statistics and local constraints: CpG dinucleotide frequencies, GC content biases, and simple repeat patterns. These basic properties are necessary but not sufficient for biological function.\nAt a higher level, MLM encourages learning of motif patterns. To accurately predict masked positions in transcription factor binding sites, models must recognize surrounding motif context. Predicting splice donor or acceptor sequences requires models to encode the consensus patterns characteristic of these sites. Over many training examples, models implicitly build representations of motifs as distributed patterns across embedding dimensions.\nBeyond individual motifs, MLM captures sequence grammar: how motifs combine, their spatial relationships, and context-dependent usage. If certain transcription factor motifs co-occur at specific distances, masking one motif and predicting it from the other reinforces this grammatical relationship in the learned representations. This compositional learning is difficult to achieve with supervised learning alone, which typically provides coarse binary labels rather than fine-grained structural information.\nFinally, MLM captures evolutionary conservation patterns. Conserved sequences are often conserved because mutations would disrupt function. By learning to predict these conserved patterns from surrounding context, models implicitly learn which sequence features are constrained by selection. This knowledge transfers to downstream tasks like variant effect prediction, where the model can recognize when a mutation disrupts a learned conserved pattern.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#next-token-prediction-and-autoregressive-models",
    "href": "p2-ch08-pretrain.html#next-token-prediction-and-autoregressive-models",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.4 Next-Token Prediction and Autoregressive Models",
    "text": "8.4 Next-Token Prediction and Autoregressive Models\nNext-token prediction represents an alternative pretraining paradigm where models learn to predict each token in a sequence given only the preceding tokens. This autoregressive approach, popularized by GPT-style language models, treats sequence generation as a core capability rather than a secondary feature. The objective is straightforward: for a sequence of length \\(T\\), predict token \\(t\\) from tokens \\(1\\) through \\(t-1\\), maximizing the likelihood of the observed sequence under the model.\nAlgorithmically, next-token prediction requires causal masking in the attention mechanism. Unlike MLM’s bidirectional attention, autoregressive models prevent each position from attending to future positions. This ensures predictions at position \\(t\\) depend only on positions \\(1, \\ldots, t-1\\), matching the conditional probability factorization inherent in the objective. The loss function is still cross-entropy over the vocabulary, but computed at every position rather than only at masked locations.\nThis objective has a distinct flavor from MLM. By predicting sequences token by token, autoregressive models naturally learn generative capabilities. They can sample new sequences by predicting the first token, conditioning on it to predict the second, and so forth. This makes autoregressive pretraining attractive for sequence design applications where generating novel sequences is the goal rather than a side benefit.\nThe trade-off is computational and statistical efficiency. MLM sees bidirectional context and predicts multiple positions per sequence in parallel. Autoregressive models see only left context and must process sequences sequentially during generation. For pretraining, however, teacher forcing allows efficient parallel computation: the model predicts all positions simultaneously during training by feeding in the ground truth sequence shifted by one position. Generation at inference time is slower, but pretraining speed is comparable to MLM.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (autoregressive vs bidirectional): A side-by-side comparison showing (1) bidirectional attention in MLM where each position sees full context, and (2) causal attention in autoregressive models where each position sees only leftward context. Illustrate the difference in attention masks and how it affects representation learning.\n\n\n\n8.4.1 Genomic Applications of Autoregressive Pretraining\nDNA sequences have no inherent directionality: both strands encode information, and regulatory function is often strand-agnostic. This complicates autoregressive modeling, which assumes a natural left-to-right reading order. Early autoregressive genomic models addressed this by training separate models for forward and reverse strands or by augmenting training data with reverse-complement sequences.\nEvo-2 represents a recent large-scale autoregressive genomic model trained on whole genomes with long-context transformers. By predicting next tokens across chromosome-length sequences, Evo-2 learns long-range dependencies and generates coherent synthetic genomes. This capability is useful for designing regulatory circuits, generating training data through synthetic augmentation, and exploring sequence space beyond observed genomes.\nProtein sequence models also benefit from autoregressive pretraining. ESM models, which predict amino acid sequences autoregressively, learn protein grammar and evolutionary constraints that transfer to structure prediction and function annotation tasks. For proteins, where N-terminus to C-terminus directionality has biological significance, autoregressive models are more natural than for bidirectional DNA.\nSequence design is a primary use case for autoregressive genomic models. Generating functional promoters, enhancers, or protein coding sequences benefits from coherent left-to-right generation that respects grammatical constraints learned during pretraining. Conditional generation, where the model generates sequences conditioned on desired properties, is also straightforward with autoregressive models by incorporating conditioning information into the context at each step.\n\n\n8.4.2 Trade-offs Between MLM and Autoregressive Objectives\nThe choice between MLM and next-token prediction involves several considerations. For tasks requiring understanding of full sequence context, MLM’s bidirectional attention provides richer representations. Predicting transcription factor binding at a specific location benefits from seeing both upstream and downstream sequence. MLM models learn these bidirectional relationships explicitly during pretraining.\nFor generative tasks, autoregressive models are more principled. Their sequential prediction structure matches the generation process exactly, whereas generating from MLM models requires iterative masking and filling or auxiliary generative heads. Autoregressive models can also naturally handle variable-length sequences and streaming data.\nPretraining efficiency differs between objectives. MLM predicts only 15% of tokens per sequence but uses bidirectional context for each prediction. Autoregressive models predict all tokens but with unidirectional context. Empirically, MLM often converges faster to good downstream performance, but autoregressive models scale well to very large datasets and long contexts.\nTask-specific performance depends on alignment between pretraining and downstream objectives. If the downstream task involves predicting missing information from context (variant effect prediction, binding site identification), MLM pretraining provides better transfer. If the downstream task involves generation or sequential decision-making (sequence design, sampling from conditional distributions), autoregressive pretraining aligns more naturally.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#denoising-objectives",
    "href": "p2-ch08-pretrain.html#denoising-objectives",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.5 Denoising Objectives",
    "text": "8.5 Denoising Objectives\nDenoising objectives generalize masked language modeling by introducing more complex forms of corruption beyond simple token masking. The core principle remains: corrupt the input in some way, then train the model to reconstruct the original uncorrupted sequence. By varying the corruption strategy, we can teach models different aspects of sequence structure and robustness properties.\nToken substitution replaces input tokens with random tokens from the vocabulary. Unlike masking, which uses a special symbol, substitution creates realistic corrupted sequences that resemble sequencing errors or natural variation. The model must learn to distinguish correct from incorrect tokens based on surrounding context. This encourages representations that capture local consistency and motif structure.\nDeletion and insertion corruptions remove or add tokens at random positions, shifting subsequent tokens and changing sequence length. This teaches models about position-invariant features and functional elements that remain identifiable despite surrounding changes. For genomics, insertions and deletions are biologically realistic: indels are common mutation types, and models that handle them gracefully during pretraining may better predict their effects downstream.\nSequence permutation randomly shuffles spans of tokens, disrupting syntactic structure while preserving token content. Reconstructing the original order from the scrambled sequence forces the model to learn ordering dependencies and grammatical constraints. In genomics, this might reveal motif ordering rules or constraints on enhancer element organization.\nMulti-corruption strategies combine several corruption types simultaneously: some tokens masked, others substituted, still others deleted or permuted. This creates a richer supervision signal that captures multiple aspects of sequence organization. However, multi-corruption makes the reconstruction task harder and may slow convergence if not carefully balanced.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (denoising strategies): A set of examples showing an original DNA sequence followed by the same sequence under different corruption types (masking, substitution, deletion/insertion, permutation). For each, show the corrupted input and highlight the model’s reconstruction task.\n\n\n\n8.5.1 Genomic Denoising Strategies\nSimulating sequencing errors provides biologically motivated corruption for genomic models. Base miscalls, systematic biases from sequencing platforms, and quality score patterns can all be incorporated into corruption strategies. Models trained with such corruptions may generalize better to real sequencing data with platform-specific error profiles.\nVariant augmentation introduces biologically realistic sequence changes based on population variation. Randomly substituting alleles at known polymorphic sites or inserting variants from databases like gnomAD creates corrupted sequences that reflect natural genetic diversity. The model learns to recognize variants as systematic deviations from reference patterns, which may improve variant effect prediction downstream.\nStructural variation simulation models larger-scale genomic changes: tandem duplications, copy number variation, and segmental rearrangements. These corruptions are harder to implement but capture realistic sources of genomic diversity beyond single-nucleotide changes. Models trained with structural variation corruptions may better understand how gene dosage, enhancer duplication, or domain boundary disruptions affect function.\nRobustness to distribution shift is a key benefit of denoising pretraining. If downstream applications involve sequences from different populations, environments, or sequencing platforms than the pretraining corpus, models pretrained with appropriate corruptions can maintain performance despite distribution mismatch. This is particularly valuable in clinical genomics, where validation cohorts often differ from discovery cohorts in ancestry, sequencing technology, or phenotyping protocols.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#contrastive-learning",
    "href": "p2-ch08-pretrain.html#contrastive-learning",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.6 Contrastive Learning",
    "text": "8.6 Contrastive Learning\nContrastive learning takes a fundamentally different approach to self-supervised pretraining. Instead of reconstructing corrupted inputs, contrastive objectives train models to produce similar representations for different views of the same sequence while distinguishing them from representations of unrelated sequences. The intuition is that augmented versions of a sequence (e.g., with minor corruptions or transformations) should map to nearby points in representation space, while unrelated sequences should map to distant points.\nThe algorithmic framework typically involves constructing positive pairs and negative samples. For a given anchor sequence, positive pairs are created through augmentation: reverse complementation, random cropping, variant injection, or other transformations that preserve functional identity. Negative samples are drawn from other sequences in the training batch. The model produces embeddings for all sequences, and the contrastive loss encourages anchor and positive embeddings to be similar (high cosine similarity or low distance) while pushing apart anchor and negative embeddings.\nInfoNCE loss is the most common contrastive objective. For an anchor embedding \\(z_i\\) and positive embedding \\(z_i^+\\), InfoNCE maximizes:\n\\[\\log \\frac{\\exp(z_i \\cdot z_i^+ / \\tau)}{\\sum_j \\exp(z_i \\cdot z_j / \\tau)}\\]\nwhere the sum in the denominator runs over the positive and all negative samples, and \\(\\tau\\) is a temperature parameter controlling the concentration of the distribution. Lower temperatures make the model more discriminative.\nNT-Xent (normalized temperature-scaled cross entropy) is a variant used in SimCLR and related methods. It differs primarily in normalization details but shares the same core principle: maximize agreement between augmented views while minimizing agreement with unrelated examples.\nTriplet loss offers an alternative formulation using anchor-positive-negative triplets directly:\n\\[\\max(0, d(z_a, z_p) - d(z_a, z_n) + m)\\]\nwhere \\(d\\) is a distance metric (often Euclidean distance) and \\(m\\) is a margin hyperparameter. This loss explicitly enforces that positives are closer than negatives by at least margin \\(m\\).\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (contrastive learning): A diagram showing (1) an anchor sequence, (2) positive examples created through augmentation (reverse complement, cropped versions, variants), (3) negative examples from other sequences, and (4) the embedding space where the model pulls positives together and pushes negatives apart.\n\n\n\n8.6.1 Contrastive Strategies for Genomic Sequences\nAugmentation design is critical for contrastive learning. Augmentations must preserve functional identity while introducing variability: if augmentations change function, the contrastive objective will learn meaningless invariances. For genomic sequences, several augmentation strategies are biologically grounded.\nReverse complementation is the simplest and most reliable augmentation. DNA is double-stranded, and many regulatory elements function identically on either strand. Training the model to treat forward and reverse complement sequences as equivalent captures strand symmetry inherent in molecular biology.\nRandom cropping extracts overlapping windows from longer sequences. If a transcription factor binding site appears in multiple cropped windows, the model learns that the site is the functionally relevant feature regardless of surrounding context. This teaches position-invariant representations useful for tasks where absolute genomic coordinates are less important than local sequence content.\nVariant injection introduces common polymorphisms or simulated mutations into sequences. If the variants are neutral or do not disrupt function, treating the variant and reference sequences as positive pairs teaches the model robustness to genetic variation. This is particularly valuable for cross-population generalization, where models must recognize functional elements despite surrounding sequence polymorphism.\nNegative sampling strategies also matter. Random sequences from the genome provide straightforward negatives, but they may be too easy to distinguish: any functional sequence is easily separable from random intergenic sequence. Harder negatives, such as sequences from orthologous regions in related species or sequences with similar motif content but different functional annotations, provide more informative supervision.\nCross-species contrastive learning leverages evolutionary relationships. Orthologous sequences from different species share functional identity despite nucleotide divergence. Treating orthologous pairs as positives and non-orthologous pairs as negatives teaches the model to extract species-invariant functional features. This can improve cross-species transfer: a model pretrained with human-mouse contrastive pairs may generalize better to rat or primate sequences.\n\n\n8.6.2 Applications of Contrastive Genomic Representations\nSequence embedding quality improves with contrastive pretraining. Models trained contrastively produce embedding spaces where functionally similar sequences cluster together. This is useful for nearest-neighbor search, sequence retrieval, and unsupervised clustering of regulatory elements based on learned representations.\nVariant effect prediction benefits from contrastive learning through robustness to genetic variation. If the model learns that sequences differing only by neutral variants are functionally equivalent, it will better distinguish disruptive variants that genuinely alter function from benign polymorphisms. This aligns with the clinical need to prioritize rare, deleterious variants over common, neutral ones.\nEvolutionary relationships emerge naturally in contrastive representations. If orthologous sequences are treated as positives during pretraining, the learned embedding space reflects evolutionary distance: closely related species have nearby embeddings, while distantly related species are separated. This can inform phylogenetic analyses and cross-species prediction tasks.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#multi-task-pretraining",
    "href": "p2-ch08-pretrain.html#multi-task-pretraining",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.7 Multi-Task Pretraining",
    "text": "8.7 Multi-Task Pretraining\nMulti-task pretraining combines multiple related objectives during the same training run, jointly optimizing for several prediction tasks. The rationale is that different tasks provide complementary supervision signals: masking captures local patterns, chromatin prediction captures regulatory function, and conservation scoring captures evolutionary constraint. By learning representations that satisfy all tasks simultaneously, the model may develop richer and more general features than any single objective alone.\nTask selection is the first design decision. Ideally, tasks should be diverse enough to provide distinct supervision signals but related enough to benefit from shared representations. For genomic models, common combinations include:\n\nMasked language modeling for general sequence structure.\nChromatin accessibility prediction for regulatory function.\nGene expression prediction for transcriptional output.\nEvolutionary conservation scoring for functional constraint.\nVariant frequency prediction from population databases.\n\nEach task operates on the same input sequence but predicts different outputs using task-specific head layers. The shared backbone encoder processes the sequence into intermediate representations, and separate prediction heads map these representations to task-specific outputs.\nTask weighting determines how much each task contributes to the total loss. With \\(L_1, \\ldots, L_K\\) representing individual task losses, the multi-task loss is typically:\n\\[L_{\\text{total}} = \\sum_{k=1}^K w_k L_k\\]\nwhere \\(w_k\\) are task weights. Equal weighting (\\(w_k = 1\\) for all \\(k\\)) is simple but may lead to imbalanced learning if tasks have different scales or difficulties. Task-specific weights can be tuned by grid search, but this is expensive with many tasks.\nDynamic task weighting adjusts weights during training based on learning dynamics. Uncertainty-based weighting uses the magnitude of task losses as a signal: tasks with higher loss receive higher weight, encouraging the model to focus on harder objectives. Gradient-based methods balance task contributions by equalizing gradient magnitudes across tasks. These approaches require careful implementation to avoid instabilities.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (multi-task architecture): A diagram showing a shared encoder backbone processing an input sequence, then branching into multiple task-specific prediction heads (MLM head, chromatin prediction head, conservation scoring head, etc.). Illustrate how gradients from all tasks flow back through the shared encoder.\n\n\n\n8.7.1 Genomic Multi-Task Examples\nEnformer and Borzoi exemplify large-scale multi-task pretraining for genomics. Enformer predicts over 5,000 genomic assays simultaneously: ChIP-seq signals for hundreds of transcription factors and histone marks, DNase-seq and ATAC-seq accessibility, CAGE transcription initiation, and more. This massive multi-task objective forces the model to learn representations that capture diverse regulatory signals across cell types and experimental conditions.\nThe task diversity in Enformer provides supervision far richer than any single assay alone. A model trained only on DNase-seq might learn general accessibility patterns but miss transcription factor specificity. A model trained only on H3K27ac ChIP-seq might capture active enhancers but miss repressive marks. Training on all assays jointly allows the model to disentangle overlapping and complementary signals, learning representations that generalize across regulatory contexts.\nBorzoi extends this paradigm to full RNA-seq coverage prediction, jointly modeling transcription initiation, splicing, and transcript abundance. By predicting both chromatin signals and transcriptomic outputs, Borzoi learns connections between regulatory state and gene expression that are difficult to capture with either modality alone.\nCombined MLM and chromatin prediction represents another multi-task configuration. The model predicts masked tokens through a language modeling head while simultaneously predicting chromatin accessibility or other functional readouts through regression heads. This hybrid objective balances sequence-level pretraining with functional-level supervision, potentially combining the benefits of both approaches.\nRNA, DNA, and protein joint training is an emerging direction. Models like those in the ESM family predict protein sequences and structures jointly, while genomic models are beginning to incorporate RNA-seq, ribosome profiling, and protein-DNA binding data into unified multi-task frameworks. These cross-modality models may learn representations that bridge sequence, structure, and function across biological scales.\n\n\n8.7.2 When Multi-Task Helps and When It Hurts\nTask interference is a primary concern with multi-task learning. If tasks require conflicting representations, jointly optimizing for both may compromise performance on each compared to single-task baselines. In genomics, this might occur if one task benefits from very local features while another requires long-range context, forcing the model to choose a suboptimal architecture for both.\nNegative transfer occurs when adding a task during pretraining actually hurts downstream performance compared to training without it. This can happen if the additional task introduces noise, if task weights are poorly balanced, or if the auxiliary task shifts the learned representations away from features useful for the target downstream application.\nComputational overhead increases with the number of tasks. Each task requires a prediction head, loss computation, and storage of task-specific labels. Data loading and preprocessing become more complex when different tasks operate on different genomic regions or require different data formats. These costs must be weighed against potential benefits.\nThe benefits of multi-task pretraining are largest when tasks are complementary and data for individual tasks is limited. If chromatin data is sparse for a particular cell type but gene expression data is abundant, jointly training on both may improve performance on both compared to single-task models. The shared representations allow information to flow between tasks, compensating for data scarcity in any single modality.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#data-strategies-for-pretraining",
    "href": "p2-ch08-pretrain.html#data-strategies-for-pretraining",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.8 Data Strategies for Pretraining",
    "text": "8.8 Data Strategies for Pretraining\nCorpus construction establishes the foundation for pretraining. The choice of training data determines what patterns the model can learn and how well it will generalize to downstream tasks. For genomic models, this involves decisions about reference genomes, population variation, repeat handling, and chromosome representation.\nReference genomes are the standard starting point. Human genome assemblies like GRCh38 provide a high-quality, contiguous reference spanning all chromosomes. Training on the reference genome allows models to learn patterns characteristic of human DNA: base composition, repeat structure, gene organization, and regulatory architecture. However, the reference genome represents only a single haploid consensus sequence, missing the rich variation present in human populations.\nPopulation-scale variation can be incorporated through variant databases like gnomAD. Rather than training only on the reference sequence, we can inject variants at their observed population frequencies to create synthetic diploid genomes that reflect real genetic diversity. This teaches models that common polymorphisms are normal variation rather than errors, potentially improving robustness and variant effect prediction.\nPan-genome approaches extend this further by explicitly representing multiple high-quality genome assemblies from diverse individuals. Instead of a single linear reference, pan-genomes capture structural variation, copy number differences, and population-specific haplotypes. Models trained on pan-genome representations may better understand how sequences function across genetic backgrounds.\nRepeat masking decisions impact pretraining. Simple repeats, tandem repeats, and transposable elements occupy substantial genomic fractions but contribute less to regulatory function than unique sequences. Hard-masking repeats (replacing them with Ns) reduces training data size but may discard information relevant to some tasks. Soft-masking (lowercase) retains sequence information while marking repetitive regions, allowing models to learn differential representations for repeats and unique sequences.\nChromosome representation determines context window and segmentation. Some models train on entire chromosomes as single sequences, though this requires efficient long-range architectures. Others segment chromosomes into fixed-length windows (e.g., 1 kb, 10 kb, or 100 kb) and train on these fragments independently. Overlapping windows provide additional training examples but may create artificial dependencies at boundaries.\n\n8.8.1 Data Augmentation and Sampling\nData augmentation artificially increases training diversity without requiring additional labeled data. For genomic sequences, several augmentation strategies are standard.\nReverse complementation exploits DNA strand symmetry. Augmenting each training sequence with its reverse complement doubles the effective training data and encourages models to learn strand-invariant representations. This is typically done on-the-fly during training rather than pre-computing augmented examples.\nRandom cropping extracts variable-length windows from longer sequences or takes overlapping segments with stochastic offsets. This teaches position-invariant features: the model must recognize functional elements regardless of their absolute position within the training window.\nVariant injection randomly substitutes reference alleles with alternate alleles from population databases. This simulates genetic variation and teaches models to distinguish functional variants from neutral polymorphisms. Injection probabilities can match population allele frequencies for realistic augmentation.\nSampling strategies determine which genomic regions contribute to training. Uniform sampling draws sequences randomly across the genome, weighting all regions equally. This is unbiased but means coding regions (2% of the human genome) are underrepresented.\nGC content balancing samples sequences to match a target GC distribution, preventing models from exploiting compositional biases. High GC regions (CpG islands, gene-dense loci) and low GC regions (AT-rich deserts, heterochromatin) are sampled proportionally rather than uniformly.\nFunctional element enrichment oversamples genomic regions containing regulatory elements, transcription factor binding sites, or other features of interest. This biases the training distribution toward functional regions but can improve performance on downstream regulatory tasks by providing more supervision where it matters most.\nNegative example construction is important for contrastive and classification tasks. Random genomic sequences provide simple negatives, but shuffled sequences (preserving dinucleotide or higher-order statistics) or scrambled functional elements provide harder negatives that force models to learn genuine functional patterns rather than compositional shortcuts.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#curriculum-learning-and-training-schedules",
    "href": "p2-ch08-pretrain.html#curriculum-learning-and-training-schedules",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.9 Curriculum Learning and Training Schedules",
    "text": "8.9 Curriculum Learning and Training Schedules\nCurriculum learning orders training examples from easy to hard, gradually increasing task difficulty as the model improves. This mimics educational curricula where foundational concepts are taught before advanced topics. In genomics, curriculum strategies can be applied to context length, pattern complexity, or functional difficulty.\nContext length curricula start with short sequences and progressively increase length as training proceeds. A transformer model might train first on 512-base windows, then 2 kb, then 10 kb, gradually expanding receptive field and long-range dependency requirements. This stabilizes early training by focusing on local patterns before introducing distant interactions.\nLow-to-high complexity curricula begin with simple sequences (e.g., coding regions with clear structure) before introducing complex regulatory regions with overlapping, context-dependent motifs. This progression allows models to master basic patterns before tackling harder cases.\nCoarse-to-fine curricula move from chromosome-level patterns to base-level resolution. Early training might focus on predicting gene density, chromatin state, or large-scale structure. Later training refines to single-base predictions, motif boundaries, and precise functional annotations.\nTraining schedules encompass learning rate decay, batch size scaling, and warmup phases. Learning rate warmup gradually increases the learning rate from near-zero over the first few thousand steps. This prevents early training instability when the model has random initializations and large gradient variance.\nCosine decay schedules reduce learning rate following a cosine curve from peak to near-zero over training. This provides aggressive learning early when gradients are informative and gentle refinement late when the model nears convergence. Step decay schedules drop learning rate by a fixed factor at predetermined intervals (e.g., every 10 epochs).\nBatch size scaling increases batch size during training, enabled by distributed training infrastructure. Larger batches reduce gradient variance but may require learning rate adjustments to maintain convergence speed. Some studies suggest optimal batch sizes scale with model size: larger models benefit from larger batches.\nContext length curriculum is particularly important for transformer models trained on genomic sequences. Training directly on long contexts (e.g., 100 kb) from initialization is unstable: attention matrices scale quadratically with sequence length, memory requirements are prohibitive, and gradients may vanish or explode. Starting with short contexts and progressively increasing length allows models to build stable representations before facing long-range dependencies.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#loss-functions-and-optimization",
    "href": "p2-ch08-pretrain.html#loss-functions-and-optimization",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.10 Loss Functions and Optimization",
    "text": "8.10 Loss Functions and Optimization\nObjective-specific losses translate pretraining objectives into differentiable optimization targets. The choice of loss function impacts what the model learns and how efficiently it trains.\nCross-entropy loss is standard for MLM and next-token prediction. For a vocabulary of size \\(V\\), the model predicts a distribution \\(\\hat{p}(x_i | \\text{context})\\) over tokens at position \\(i\\), and cross-entropy measures disagreement with the true token:\n\\[L_{\\text{CE}} = -\\log \\hat{p}(x_i = x_i^{\\text{true}} | \\text{context})\\]\nAveraged over all masked or predicted positions, this loss is minimized when the model’s predicted distribution matches the true conditional distribution.\nMean squared error or Poisson loss apply to continuous-valued predictions like chromatin signal intensity. If predicting ChIP-seq read counts, Poisson loss accounts for count-based variability:\n\\[L_{\\text{Poisson}} = -\\log \\text{Poisson}(y; \\hat{\\lambda})\\]\nwhere \\(y\\) is the observed count and \\(\\hat{\\lambda}\\) is the predicted rate. MSE is simpler but ignores the discrete, count-based nature of the data.\nMulti-label classification losses handle cases where sequences have multiple overlapping labels (e.g., binding sites for multiple transcription factors). Binary cross-entropy per label or focal loss (which downweights easy examples) are common choices.\nRegression losses for continuous targets might use MSE, mean absolute error, or Huber loss (which is robust to outliers). The choice depends on the target distribution and desired sensitivity to extreme values.\nOptimization algorithms determine how gradient information updates model parameters. AdamW, a variant of Adam with decoupled weight decay, is the current standard for transformer pretraining. AdamW maintains running averages of gradients and squared gradients, enabling adaptive per-parameter learning rates that accelerate convergence compared to vanilla SGD.\nLearning rate schedules modulate the effective step size during training. Warmup phases prevent early instability. Cosine decay provides smooth reduction toward convergence. Linear decay is simpler but may not perform as well. Plateau-based schedules reduce learning rate when validation loss stops improving, though these require careful validation set construction to avoid overfitting to the validation metric.\nGradient clipping prevents training instability from occasional large gradients. Clipping gradients by global norm (scaling all gradients proportionally when the total norm exceeds a threshold) is standard practice, especially for recurrent and transformer models where exploding gradients can occur.\nMixed precision training uses lower-precision arithmetic (float16 or bfloat16 instead of float32) to reduce memory consumption and accelerate computation on modern GPUs. Loss scaling prevents underflow in float16, and careful handling of gradient updates ensures numerical stability. Mixed precision is now standard for large-scale pretraining.\n\n8.10.1 Loss Scaling and Multi-Task Balancing\nMulti-task loss balancing ensures all tasks contribute meaningfully to learning. If one task has loss values 100 times larger than another, gradients will be dominated by the high-magnitude task unless weights compensate.\nManual weighting requires setting \\(w_k\\) for each task through grid search or heuristic reasoning. This is feasible for small numbers of tasks but scales poorly to hundreds or thousands of tasks as in Enformer.\nUncertainty-based weighting parameterizes each task loss with a learned noise parameter \\(\\sigma_k^2\\):\n\\[L_{\\text{total}} = \\sum_{k=1}^K \\frac{1}{2 \\sigma_k^2} L_k + \\log \\sigma_k\\]\nThe model learns \\(\\sigma_k\\) during training, automatically balancing task contributions based on their uncertainty. Tasks with high uncertainty (high \\(\\sigma_k\\)) receive lower effective weight, while confident tasks (low \\(\\sigma_k\\)) receive higher weight.\nDynamic loss scaling adjusts task weights based on learning progress. If one task’s loss plateaus while another continues improving, increasing weight on the plateaued task may reinvigorate learning. Gradient magnitude balancing normalizes task gradients to similar scales before combining them, preventing any single task from dominating updates.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#pretraining-at-scale",
    "href": "p2-ch08-pretrain.html#pretraining-at-scale",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.11 Pretraining at Scale",
    "text": "8.11 Pretraining at Scale\nLarge-scale pretraining requires substantial computational resources and careful infrastructure design. Modern genomic foundation models train on clusters with hundreds or thousands of GPUs, consuming months of compute time and terabytes of data.\nFLOPs (floating-point operations) scale with model size, sequence length, and training dataset size. A transformer with \\(L\\) layers, hidden dimension \\(d\\), and attention heads \\(h\\) processing sequences of length \\(n\\) requires approximately \\(12 L d^2 n + 4 L d n^2\\) FLOPs per forward pass (ignoring feedforward layers). For models with billions of parameters on sequences of hundreds of kilobases, this amounts to petaFLOPs per training step.\nMemory footprint includes model parameters, activations, gradients, and optimizer states. For a model with \\(P\\) parameters, each forward pass stores activations proportional to \\(P \\cdot n\\) (sequence length times depth). Backward passes compute gradients of size \\(P\\), and AdamW stores two momentum buffers of size \\(P\\) each. The total memory scales as \\(\\sim 4P\\) for parameters and optimizer states, plus activation memory that grows with batch size and sequence length.\nDistributed training strategies parallelize computation across many devices. Data parallelism replicates the model on each device and splits training batches, aggregating gradients across devices. This scales well up to the point where communication overhead dominates, typically when batch size per device becomes too small.\nModel parallelism splits the model itself across devices, with different layers or layer components on different GPUs. Pipeline parallelism stages layers sequentially, overlapping forward and backward passes across pipeline stages. These strategies enable training models too large to fit on a single device but introduce communication and synchronization overhead.\n\n8.11.1 Data Throughput and Infrastructure\nData loading and preprocessing can become bottlenecks at scale. Efficiently reading genomic sequences, tokenizing them, and assembling batches requires optimized data pipelines. Preprocessing (tokenization, masking, augmentation) should happen in parallel with training using dedicated CPU workers.\nTokenization caching precomputes tokenized sequences and stores them on disk, avoiding repeated tokenization during training. This trades disk space for CPU time and significantly speeds up data loading when tokenization is expensive (e.g., byte-pair encoding).\nGPU utilization monitoring ensures hardware is fully used. Profiling tools identify bottlenecks: if GPUs idle waiting for data, improve data loading; if utilization is low during computation, increase batch size or optimize kernel efficiency.\nMulti-GPU and multi-node training distributes work across machines connected by high-bandwidth networks. Frameworks like PyTorch Distributed Data Parallel and DeepSpeed provide efficient synchronization and communication primitives. Gradient accumulation allows simulating large batch sizes by accumulating gradients over multiple mini-batches before updating parameters.\nCheckpointing strategies save model state periodically to enable recovery from failures and to provide intermediate models for evaluation. Frequent checkpointing (every few hundred steps) provides fine-grained recovery but consumes significant disk space and I/O bandwidth. Balancing checkpoint frequency with storage constraints is essential for long training runs.\nFault tolerance mechanisms handle hardware failures during training. Preemptible cloud instances, power outages, or hardware errors can interrupt training. Automatic checkpoint loading and job restarting minimize lost work. Some frameworks support dynamic rescheduling and elastic training, adjusting parallelism as resources become available or fail.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#monitoring-and-debugging-pretraining",
    "href": "p2-ch08-pretrain.html#monitoring-and-debugging-pretraining",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.12 Monitoring and Debugging Pretraining",
    "text": "8.12 Monitoring and Debugging Pretraining\nPretraining runs span weeks or months, and early detection of issues prevents wasted computation. Careful monitoring and debugging practices are essential.\nTraining loss curves should decrease smoothly in the early stages, eventually plateauing as the model approaches convergence. Sudden spikes suggest numerical instability, poor learning rate schedules, or corrupted batches. Persistent plateaus may indicate insufficient model capacity, inappropriate objectives, or optimization hyperparameters.\nPerplexity measures how well a language model predicts sequences. For an MLM or next-token objective, perplexity is the exponential of the average cross-entropy loss:\n\\[\\text{perplexity} = \\exp(L_{\\text{CE}})\\]\nLower perplexity indicates better sequence modeling. Tracking perplexity on held-out validation data monitors generalization: if training perplexity decreases but validation perplexity increases, the model is overfitting.\nGradient norms indicate whether gradients are well-scaled. Very small gradients (vanishing gradient problem) prevent learning, while very large gradients (exploding gradients) destabilize training. Tracking the global gradient norm and per-layer gradient norms helps diagnose these issues early.\nRed flags include loss explosions (often from numerical overflow or learning rate too high), gradient clipping activating frequently (gradients consistently too large), mode collapse in generative models (generating repetitive or degenerate sequences), and overfitting to the pretraining corpus (validation loss diverges from training loss).\n\n8.12.1 Debugging Strategies\nProbing tasks provide sanity checks during pretraining. Simple downstream evaluations (e.g., predicting DNase-seq peaks from sequence) can be run periodically on intermediate checkpoints. If probing performance plateaus or degrades, pretraining may not be learning useful representations.\nAttention pattern visualization examines what the model attends to. Inspecting attention weights at different layers and heads can reveal whether the model learns meaningful patterns: do heads attend to motif boundaries, promoter-enhancer distances, or splice sites? Or do attention patterns appear random or dominated by positional biases?\nEmbedding space analysis projects learned representations into low-dimensional space using t-SNE or UMAP. Sequences with similar function should cluster together. If embeddings fail to separate functional classes (e.g., enhancers vs silencers) or show no structure, representations may not capture relevant biology.\nAblation studies isolate the impact of design choices. If uncertain whether multi-task training helps, train a baseline model without auxiliary tasks and compare downstream performance. If unsure about a data augmentation strategy, run training with and without it. Ablations are expensive but provide definitive answers when debugging complex pretraining pipelines.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#choosing-the-right-pretraining-strategy",
    "href": "p2-ch08-pretrain.html#choosing-the-right-pretraining-strategy",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.13 Choosing the Right Pretraining Strategy",
    "text": "8.13 Choosing the Right Pretraining Strategy\nSelecting a pretraining approach involves balancing computational budget, target downstream tasks, data availability, and model architecture constraints. No single strategy is universally optimal, so understanding trade-offs is essential.\nCompute budget determines feasible scale. Pretraining large models on long contexts requires significant resources. If compute is limited, smaller models, shorter contexts, or single-task objectives may be more practical. If abundant compute is available, multi-task pretraining on diverse objectives and long contexts provides maximum flexibility.\nTarget downstream tasks influence objective selection. For tasks requiring sequence understanding (variant effect prediction, binding site classification), MLM or denoising objectives align well. For generative design (creating synthetic promoters or enhancers), autoregressive or diffusion-based objectives are more natural. For cross-species applications, contrastive learning on orthologous sequences may improve transfer.\nData availability shapes corpus construction. If only reference genomes are available, standard MLM pretraining suffices. If functional assays (chromatin, expression) exist at scale, multi-task pretraining leverages this supervision. If population variant databases are accessible, denoising with variant augmentation improves robustness.\nModel architecture constraints also matter. Convolutional models have limited receptive fields, so curriculum strategies on context length are less critical. Transformer models benefit from progressive context scaling. Recurrent models face vanishing gradients on long sequences, making denoising objectives with deletions/insertions challenging.\n\n8.13.1 Objective Selection Guidelines\nFor most general-purpose DNA or protein models, MLM pretraining provides a strong default. It learns bidirectional context, scales efficiently, and transfers well to diverse downstream tasks. DNABERT and DNABERT-2 exemplify this approach for genomics, while ESM models demonstrate its effectiveness for proteins.\nNext-token prediction is preferred when generation is the primary goal. If designing sequences from scratch, sampling from autoregressive models produces coherent outputs respecting learned grammar. Evo-2 and GPT-style genomic models exemplify this.\nMulti-task pretraining makes sense when functional labels are available at scale and tasks are complementary. Enformer’s success with thousands of chromatin assays shows the power of multi-task learning when data supports it. However, multi-task requires infrastructure to handle heterogeneous data and careful loss balancing.\nContrastive learning is valuable for cross-species or variant-focused applications. If the goal is to transfer models trained on model organisms to related species, or to improve robustness to genetic variation, contrastive pretraining on orthologous pairs or variant-augmented sequences provides targeted benefits.\n\n\n8.13.2 When to Pretrain from Scratch vs Fine-Tune\nStarting from a pretrained model is almost always preferable if an appropriate model exists. Fine-tuning a DNABERT-2 checkpoint on a new binding prediction task is faster and more data-efficient than training from scratch. However, several scenarios favor pretraining from scratch.\nNew tokenization schemes require retraining. If switching from k-mer tokens to byte-pair encoding or single-nucleotide tokens, the existing vocabulary and embeddings are incompatible. Starting fresh is necessary.\nNew species without suitable existing models may benefit from pretraining on that species’ genome. While DNABERT trained on human DNA transfers reasonably to mouse, more distant organisms (plants, bacteria) may require species-specific pretraining to capture their unique sequence properties.\nDifferent architectures cannot reuse pretrained weights. If moving from transformers to convolutional models or hybrid architectures, pretrained parameters do not apply directly. However, knowledge distillation or representation transfer may still help.\nMore data for the same domain suggests continued pretraining rather than starting fresh. If an existing model was pretrained on 3 billion tokens but a larger corpus is now available, continued pretraining from the existing checkpoint on the new data extends coverage without discarding prior learning.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#case-studies-how-leading-models-were-pretrained",
    "href": "p2-ch08-pretrain.html#case-studies-how-leading-models-were-pretrained",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.14 Case Studies: How Leading Models Were Pretrained",
    "text": "8.14 Case Studies: How Leading Models Were Pretrained\nExamining how successful models were pretrained provides concrete lessons and design patterns.\n\n8.14.1 DNABERT\nDNABERT introduced MLM pretraining to genomics by adapting BERT’s architecture to DNA sequences with overlapping k-mer tokenization. The model was pretrained on the human genome with 6-mer tokens, masking 15% of tokens at random. Training used standard BERT hyperparameters: AdamW optimizer with warmup, dropout regularization, and layer normalization.\nKey lessons from DNABERT include the importance of tokenization choice (k-mers capture motif-level patterns better than single nucleotides), the value of strand symmetry (reverse complement augmentation improved performance), and the transferability of representations (pretrained DNABERT generalized well to diverse regulatory tasks despite training only on raw genome sequence).\n\n\n8.14.2 HyenaDNA\nHyenaDNA demonstrated that efficient long-range architectures enable pretraining on extremely long contexts. By using Hyena layers (subquadratic attention alternatives), HyenaDNA scaled to 1 Mb contexts, far beyond standard transformers. Pretraining used single-nucleotide next-token prediction on the human genome with a curriculum that progressively increased context length from short to long.\nLessons from HyenaDNA include the feasibility of million-base contexts with appropriate architectures, the benefits of curriculum learning for context scaling, and the emergence of long-range regulatory patterns when models have sufficient receptive field.\n\n\n8.14.3 Enformer\nEnformer pioneered multi-task chromatin prediction at scale. The model was pretrained jointly on over 5,000 assays from ENCODE, Roadmap Epigenomics, and other consortia, using a hybrid convolutional-transformer architecture. Task weighting was carefully balanced to prevent any single assay from dominating training. The model predicts chromatin signals across 128 kb windows with 128 bp resolution.\nKey insights from Enformer include the power of large-scale multi-task learning (joint training on diverse assays improves all tasks), the importance of architectural design (combining convolutions for local patterns with transformers for long-range interactions balances efficiency and capacity), and the value of attention for interpretability (attention weights reveal learned enhancer-promoter contacts).\n\n\n8.14.4 ESM-2\nESM-2 represents the state-of-the-art for protein language models, scaling to 15 billion parameters on evolutionary databases containing billions of protein sequences. Pretraining used standard MLM on amino acid sequences, but at unprecedented scale. ESM-2 demonstrated that pretraining on evolutionary diversity (hundreds of millions of protein families) transfers exceptionally well to structure prediction, function annotation, and protein design tasks.\nLessons from ESM-2 include the benefit of extreme scale (larger models and more data continue to improve even at billions of parameters), the value of evolutionary information (pretraining on diverse sequences captures constraints not visible in individual genomes), and the emergence of structural understanding from sequence alone (ESM-2 representations contain information about 3D structure despite no explicit structural supervision).\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (case study comparison table): A table summarizing DNABERT, HyenaDNA, Enformer, and ESM-2 along dimensions such as objective (MLM vs next-token vs multi-task), architecture (transformer vs hybrid vs Hyena), pretraining corpus (human genome vs multi-species vs protein databases), context length, and key innovations.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#the-relationship-between-pretraining-and-transfer",
    "href": "p2-ch08-pretrain.html#the-relationship-between-pretraining-and-transfer",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.15 The Relationship Between Pretraining and Transfer",
    "text": "8.15 The Relationship Between Pretraining and Transfer\nPretraining objectives predict transfer performance, though not always in obvious ways. MLM pretraining emphasizes bidirectional understanding, which benefits classification and interpretation tasks requiring full context. Next-token prediction emphasizes generation, favoring sequence design applications. Multi-task pretraining on functional assays directly optimizes for functional understanding, often providing best transfer to similar downstream tasks.\nMisalignment between pretraining and downstream objectives can cause problems. If a model is pretrained autoregressively but then fine-tuned for bidirectional classification, the causal attention structure limits information flow. Conversely, an MLM-pretrained model cannot generate sequences without additional architectural modifications. Bridging these gaps may require intermediate objectives, hybrid architectures, or multi-stage pretraining.\nIntermediate objectives provide gradual adaptation. A model might first pretrain with MLM on raw sequence, then continue pretraining with chromatin prediction on functional labels, and finally fine-tune on a specific variant effect task. Each stage specializes representations progressively, transferring knowledge from abundant unlabeled data through intermediate supervision to the final task.\nFor further discussion of deployment and transfer strategies, see Chapter 9.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#open-questions-and-future-directions",
    "href": "p2-ch08-pretrain.html#open-questions-and-future-directions",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.16 Open Questions and Future Directions",
    "text": "8.16 Open Questions and Future Directions\nDespite rapid progress, many fundamental questions about genomic pretraining remain open.\nOptimal objective combinations are unclear. Should we jointly train with MLM and chromatin prediction, or train sequentially? How many auxiliary tasks help before we hit diminishing returns? Do contrastive and generative objectives complement each other, or do they interfere?\nScaling laws relating pretraining compute, data size, and model capacity to downstream performance are not yet well-characterized for genomics. In NLP, power-law relationships predict optimal model sizing and training duration given a compute budget. Establishing similar laws for genomic models would guide resource allocation.\nTask-aware pretraining vs truly general objectives presents a design tension. Enformer’s multi-task objective is highly task-aware, directly optimizing for chromatin predictions. DNABERT’s MLM is more general, agnostic to downstream tasks. Which approach generalizes better to unforeseen applications?\nIncorporating biological priors (e.g., known motifs, pathway structure, evolutionary constraints) vs learning from scratch remains debated. Hand-engineered features risk encoding false assumptions, but pure data-driven learning may rediscover basic biology inefficiently. Hybrid approaches that combine priors with learned representations are underexplored.\nContinual pretraining as new data arrives is increasingly relevant. As sequencing technologies improve and new assays emerge, how do we update pretrained models without catastrophic forgetting of prior knowledge? Online learning and elastic weight consolidation are potential solutions but remain largely untested in genomics.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch08-pretrain.html#summary-and-best-practices",
    "href": "p2-ch08-pretrain.html#summary-and-best-practices",
    "title": "8  Pretraining Objectives & Strategies",
    "section": "8.17 Summary and Best Practices",
    "text": "8.17 Summary and Best Practices\nPretraining objectives form the foundation of modern genomic models. This chapter has surveyed the major families: masked language modeling for bidirectional sequence understanding, next-token prediction for generation, denoising for robustness, contrastive learning for invariant representations, and multi-task learning for functional supervision.\nCore principles apply across objectives. Self-supervised learning leverages abundant unlabeled sequence data to learn general representations. Transfer from pretraining to fine-tuning improves data efficiency and generalization. Careful design of objectives, data strategies, and optimization details determines success.\nWhen designing pretraining strategies, consider:\n\nObjective alignment: Match pretraining objective to downstream task characteristics (bidirectional understanding vs generation).\nData coverage: Pretrain on diverse, representative genomic sequences; augment to cover variation.\nScale appropriately: Larger models and more data improve performance, but compute budget constrains ambition.\nMonitor carefully: Track loss curves, validation metrics, and probing tasks to catch issues early.\nEvaluate transfer: Pretraining is only valuable if it improves downstream performance; benchmark regularly.\n\nBest practices distilled from leading models include:\n\nUse MLM for most general-purpose DNA and protein models.\nApply multi-task pretraining when functional labels exist at scale.\nIncorporate data augmentation (reverse complement, cropping, variant injection) for robustness.\nScale context length gradually via curriculum learning for transformers.\nBalance multi-task losses carefully to avoid task domination.\nLeverage existing pretrained models when possible; pretrain from scratch only when necessary.\n\nThe next chapter (Chapter 9) explores how to deploy and adapt pretrained models to specific downstream tasks, closing the loop from general-purpose pretraining to specialized applications.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pretraining Objectives & Strategies</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html",
    "href": "p2-ch09-transfer.html",
    "title": "9  Transfer Learning & Deployment",
    "section": "",
    "text": "9.1 From Pretraining to Practice\nFoundation models are powerful starting points, not final products. The models described in previous chapters (Chapter 10, Chapter 6, Chapter 8) learn rich representations of genomic sequences through pretraining on massive unlabeled datasets, but deploying these models to solve real-world problems almost always requires adaptation. This adaptation process, broadly termed transfer learning, bridges the gap between generic pretraining objectives and specific downstream tasks.\nThe central challenge is that pretraining objectives rarely align perfectly with application needs. A model trained to predict masked tokens has learned useful sequence features, but predicting whether a variant causes disease or identifying tissue-specific enhancers requires different decision boundaries and often different output structures. Transfer learning provides strategies for leveraging pretrained knowledge while adapting to new tasks, balancing the preservation of learned representations against the need for task-specific fine-tuning.\nThis chapter surveys the landscape of transfer learning strategies in genomics, from simple feature extraction to full fine-tuning to more exotic approaches like few-shot learning and continual adaptation. We examine when each strategy is appropriate, how to avoid common pitfalls like catastrophic forgetting and distribution shift, and how to deploy adapted models in production settings. Throughout, we emphasize practical decision-making: given a pretrained model and a downstream task, which adaptation strategy will yield the best performance under realistic computational and data constraints?",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#from-pretraining-to-practice",
    "href": "p2-ch09-transfer.html#from-pretraining-to-practice",
    "title": "9  Transfer Learning & Deployment",
    "section": "",
    "text": "Warning\n\n\n\nVisual suggestion (conceptual overview): A diagram showing the transfer learning pipeline. Left side shows pretraining on large unlabeled corpus. Middle shows pretrained model. Right side branches to multiple adaptation strategies (frozen features, PEFT, full fine-tuning) leading to different downstream tasks. Include visual indicators of data requirements (small/medium/large) and computational cost (low/medium/high) for each strategy.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#the-transfer-learning-framework",
    "href": "p2-ch09-transfer.html#the-transfer-learning-framework",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.2 The Transfer Learning Framework",
    "text": "9.2 The Transfer Learning Framework\nTransfer learning operates across two domains: the source domain where pretraining occurs and the target domain where the model will be deployed. Understanding what transfers between these domains, and under what conditions transfer succeeds or fails, is essential for effective adaptation.\nThe source domain in genomics typically consists of abundant unlabeled sequence data. For DNA models, this might be the human genome or a pan-genome spanning multiple species. For protein models, it might be UniRef or a similar large-scale sequence database. Pretraining objectives like masked language modeling or next-token prediction encourage the model to learn generalizable sequence features: motifs, secondary structure patterns, long-range dependencies, and compositional regularities. These learned representations form the foundation for transfer.\nThe target domain, in contrast, is characterized by labeled examples of a specific task. This might be a few thousand enhancer sequences with activity measurements, variant-phenotype pairs from ClinVar, or chromatin accessibility profiles across genomic windows. The target task may have very different statistics from the pretraining distribution. Rare pathogenic variants are not representative of typical genomic sequence. Tissue-specific regulatory elements exhibit patterns that generic genome-wide pretraining may not emphasize.\nTransfer learning success depends on several factors. First, the relatedness of source and target tasks matters profoundly. If the target task involves sequence patterns similar to those encountered during pretraining, transfer is likely to help. If the target task requires fundamentally different inductive biases, transfer may provide little benefit or even hurt performance. Second, the quantity and quality of target domain data determines which adaptation strategies are feasible. With abundant labeled data, more aggressive fine-tuning is possible. With scarce labels, simpler approaches that avoid overfitting become necessary. Third, model capacity and architecture influence how effectively representations can be adapted. Larger models with more expressive internal representations offer more flexibility for adaptation but also greater risk of overfitting on small target datasets.\nNot all transfer is beneficial. Positive transfer occurs when pretraining accelerates learning on the target task or improves final performance beyond what training from scratch could achieve. This is most common when source and target are closely related and target data is limited. Negative transfer occurs when pretraining actively hurts target task performance, typically because the source domain introduced biases or learned features that conflict with the target task requirements. Neutral transfer describes situations where pretraining neither helps nor hurts, often seen when the target task has sufficient labeled data to learn effectively from scratch or when source and target domains are too dissimilar for meaningful knowledge sharing.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (transfer success factors): A three-panel conceptual figure. Panel A shows positive transfer with high source-target similarity and low data regime. Panel B shows negative transfer with misaligned objectives. Panel C shows neutral transfer with abundant target data. Use simple schematics with arrows indicating knowledge flow and performance comparisons between pretrained and from-scratch baselines.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#feature-extraction-with-frozen-backbones",
    "href": "p2-ch09-transfer.html#feature-extraction-with-frozen-backbones",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.3 Feature Extraction with Frozen Backbones",
    "text": "9.3 Feature Extraction with Frozen Backbones\nThe simplest and most computationally efficient adaptation strategy treats the pretrained model as a fixed feature extractor. The core idea is to freeze all parameters in the pretrained backbone and train only a lightweight classifier on top of the extracted representations. This approach eliminates the risk of catastrophic forgetting, where fine-tuning overwrites useful pretrained knowledge, and requires minimal computational resources since gradients need not flow through the entire model.\nImplementation is straightforward. Pass input sequences through the frozen pretrained model to obtain embeddings from one or more layers. These embeddings serve as fixed feature vectors that capture the model’s learned understanding of sequence patterns. Train a shallow supervised learning model (linear classifier, logistic regression, or small multilayer perceptron) to map embeddings to task labels. The backbone parameters remain untouched throughout training.\nLinear probing represents the most minimal variant of feature extraction. A single linear layer maps embeddings directly to predictions. This approach is extremely fast to train and introduces only a handful of parameters, making it ideal for very limited labeled data regimes where overfitting is a primary concern. For example, DNABERT embeddings have been used for binary enhancer classification with as few as a few hundred labeled examples, where a linear probe atop the [CLS] token representation achieves competitive performance without any fine-tuning of the backbone itself.\nShallow multilayer perceptrons extend linear probing by adding one or two hidden layers between embeddings and predictions. This introduces modest nonlinearity and capacity, allowing the model to learn slightly more complex decision boundaries while still avoiding the computational expense of backbones fine-tuning. With a few thousand labeled examples, shallow MLPs often outperform linear probes without requiring significantly more data or compute. For instance, HyenaDNA embeddings have been paired with 2-3 layer networks for splice site prediction tasks, where the additional capacity improves precision-recall tradeoffs compared to linear classifiers alone.\nThe advantages of frozen feature extraction are clear. There is no catastrophic forgetting since pretrained parameters never change. Computational requirements are minimal, with training typically completing in minutes rather than hours or days. The approach works well even with small labeled datasets, since only a small number of classifier parameters must be learned. However, these advantages come with limitations. The backbone cannot adapt to task-specific patterns, meaning performance is capped by how well the pretrained representations align with the target task. If the pretraining objective emphasized patterns that are irrelevant or misleading for the downstream task, frozen features may underperform models trained from scratch.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (feature extraction schematic): A two-panel diagram. Left panel shows pretrained model with frozen layers (indicated by lock icons) feeding into a small classifier head. Right panel shows training flow where only the classifier head receives gradient updates. Include data size and compute indicators showing this approach’s efficiency.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#parameter-efficient-fine-tuning",
    "href": "p2-ch09-transfer.html#parameter-efficient-fine-tuning",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.4 Parameter-Efficient Fine-Tuning",
    "text": "9.4 Parameter-Efficient Fine-Tuning\nParameter-efficient fine-tuning (PEFT) methods offer a middle ground between frozen feature extraction and full fine-tuning. The core principle is to update a small subset of parameters while keeping the majority of the model frozen, balancing the ability to adapt to task-specific patterns against computational cost and risk of overfitting. Several PEFT techniques have emerged in recent years, with LoRA being particularly prominent in genomic applications.\nLow-Rank Adaptation (LoRA) modifies weight matrices in the pretrained model by adding low-rank decompositions. Rather than updating large weight matrices directly, LoRA introduces pairs of smaller matrices whose product is added to the original weights. During fine-tuning, only these low-rank matrices are updated while the original pretrained weights remain frozen. The key hyperparameter is the rank, typically set between 8 and 64 for genomic models. Lower ranks introduce fewer parameters and reduce overfitting risk, while higher ranks increase expressiveness at the cost of more memory and potential overfitting. LoRA has been successfully applied to models like Nucleotide Transformer for tissue-specific gene expression prediction, where separate low-rank adapters capture tissue-specific regulatory patterns while sharing the bulk of the pretrained backbone. Memory savings can be substantial, with 10 to 100 times fewer trainable parameters compared to full fine-tuning.\nAdapter layers take a different architectural approach, inserting small bottleneck modules between transformer layers. Each adapter consists of a down-projection to a lower-dimensional space, a nonlinear activation, and an up-projection back to the original dimensionality. During training, the original transformer parameters remain frozen while only adapter parameters are updated. This approach has been explored in Enformer for tissue-specific chromatin predictions, where different adapters learn tissue-specific transformations of the shared pretrained representations. Adapters introduce slightly more parameters than LoRA but offer more architectural flexibility in where and how adaptation occurs.\nPrefix tuning prepends learnable prompt embeddings to the input, effectively conditioning the frozen backbone on task-specific context. While less common in genomics due to the lack of natural “prompt” structure in genomic sequences, prefix tuning has found limited application in settings where task context can be meaningfully encoded as additional input tokens. Other PEFT methods include BitFit, which tunes only bias terms while keeping all weights frozen, and compacter-style approaches that combine low-rank decomposition with parameter sharing across layers. These remain less explored in genomic contexts but may offer advantages for specific use cases.\nPEFT methods are most appropriate when working with moderate amounts of labeled data (thousands to tens of thousands of examples), when computational constraints limit the feasibility of full fine-tuning, or when managing multiple related tasks that share a common pretrained backbone. In the latter scenario, separate PEFT adapters can be trained for each task, enabling parameter-efficient multi-task deployment with a single shared model and task-specific lightweight adapters.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (PEFT methods comparison): A table or multi-panel figure comparing LoRA, adapters, and other PEFT approaches. Show architecture modifications, parameter counts, typical hyperparameter ranges, and example genomic applications for each method. Include a decision tree or flowchart suggesting when to use each approach based on data size and computational budget.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#full-fine-tuning",
    "href": "p2-ch09-transfer.html#full-fine-tuning",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.5 Full Fine-Tuning",
    "text": "9.5 Full Fine-Tuning\nFull fine-tuning updates all or most model parameters during adaptation, offering maximum flexibility to tailor the model to task-specific requirements but also introducing greater computational cost and risk of overfitting. When target datasets are large and performance is paramount, full fine-tuning can extract more value from pretrained models than simpler adaptation strategies.\nImplementation requires careful consideration of learning rates, regularization, and unfreezing strategies. Learning rates during fine-tuning are typically 10 to 100 times lower than those used during pretraining to avoid catastrophically disrupting learned representations. Gradual unfreezing, where top layers are unfrozen first and deeper layers are gradually brought into training, helps preserve low-level features while allowing high-level task-specific adjustments. Regularization techniques like weight decay, dropout, and early stopping on held-out validation sets help prevent overfitting to the target dataset.\nFull fine-tuning is appropriate when large labeled datasets (tens of thousands or more examples) are available, when the target task is substantially different from pretraining such that frozen or partially adapted representations are insufficient, or when performance requirements justify the computational expense. For example, fine-tuning Enformer on new chromatin assays with thousands of experimental tracks requires updating most model parameters to capture assay-specific signal patterns that differ from the original training distribution.\nBest practices emphasize starting conservatively. Begin with a frozen baseline to verify that transfer provides value before committing to full fine-tuning. Unfreeze layers gradually from top to bottom, monitoring validation performance at each stage. Compare final fine-tuned performance against both the frozen baseline and a from-scratch baseline trained on the same target data. If full fine-tuning does not substantially outperform simpler approaches, the additional cost may not be justified.\nThe risks of full fine-tuning are real. Catastrophic forgetting occurs when fine-tuning overwrites general knowledge learned during pretraining, degrading performance on related tasks or out-of-distribution examples. Overfitting to small target datasets is common, especially when model capacity far exceeds the information content of the labeled data. Computational expense can be prohibitive for very large models or resource-constrained settings. These considerations make full fine-tuning a high-reward but high-risk strategy that should be deployed judiciously.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (fine-tuning best practices): A flowchart showing the recommended fine-tuning workflow. Start with frozen baseline. Evaluate transfer benefit. If beneficial, proceed to gradual unfreezing. Monitor validation metrics. Compare final model against baselines. Include decision points where negative signals suggest stopping or reverting to simpler approaches.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#choosing-an-adaptation-strategy",
    "href": "p2-ch09-transfer.html#choosing-an-adaptation-strategy",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.6 Choosing an Adaptation Strategy",
    "text": "9.6 Choosing an Adaptation Strategy\nSelecting the appropriate adaptation strategy requires balancing three primary considerations: the amount of available labeled data, the similarity between pretraining and target tasks, and the computational budget available for adaptation. While no single rule covers all scenarios, several heuristics guide practical decision-making.\nData availability provides the first decision point. With fewer than 1,000 labeled examples, linear probing or simple feature extraction is often the only viable option. More complex adaptation strategies risk overfitting, and the limited signal in the data does not justify fine-tuning large numbers of parameters. With 1,000 to 10,000 examples, PEFT methods like LoRA or adapter layers offer a good balance of expressiveness and regularization. The model can learn task-specific patterns without the full freedom (and overfitting risk) of updating all parameters. With more than 10,000 labeled examples, full fine-tuning becomes feasible and may be necessary if the target task differs substantially from pretraining.\nTask similarity to pretraining provides the second decision axis. When the target task closely resembles patterns seen during pretraining (for example, predicting transcription factor binding after pretraining on genomic sequence), feature extraction may suffice. The pretrained representations already capture relevant patterns, and a shallow classifier can effectively separate positive and negative examples. For moderately different tasks, PEFT methods allow selective adaptation of the most task-relevant parameters while preserving general sequence understanding. For tasks very different from pretraining, full fine-tuning may be necessary to overcome the mismatch between learned features and task requirements, assuming sufficient labeled data is available.\nComputational budget imposes practical constraints. In minimal budget scenarios, only linear probing is feasible. With moderate budgets, LoRA offers an attractive performance-to-cost ratio, achieving much of the benefit of full fine-tuning with a fraction of the computational expense. With generous budgets, full fine-tuning becomes an option, though one should always compare against simpler baselines to verify the additional cost yields meaningful performance gains.\nEmpirical validation remains essential. No heuristic perfectly predicts which adaptation strategy will succeed for a given task. Always compare multiple approaches. Validate on held-out data drawn from the same distribution as the intended deployment setting. Monitor for signs of overfitting versus underfitting, adjusting the adaptation strategy accordingly. The goal is not to follow rigid rules but to develop intuition for which strategies are worth trying given the characteristics of the problem at hand.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (adaptation strategy decision tree): A comprehensive decision tree diagram with three entry points: data size, task similarity, and compute budget. Each path leads to a recommended strategy (linear probe, LoRA, or full fine-tuning) with typical performance expectations and caveats. Include example genomic applications at leaf nodes.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#few-shot-and-zero-shot-learning",
    "href": "p2-ch09-transfer.html#few-shot-and-zero-shot-learning",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.7 Few-Shot and Zero-Shot Learning",
    "text": "9.7 Few-Shot and Zero-Shot Learning\nFew-shot learning addresses scenarios where labeled examples are extremely scarce, typically between 10 and 100 examples per class. This regime is common in genomics: rare variant classes in ClinVar, novel cell types in single-cell studies, or newly characterized functional elements with limited experimental validation. Zero-shot learning goes further, attempting to transfer knowledge without any labeled examples in the target domain, relying entirely on representations learned during pretraining or on auxiliary information like textual descriptions.\nMeta-learning approaches explicitly train models to adapt quickly from few examples. Model-Agnostic Meta-Learning (MAML) learns initialization parameters that can be rapidly fine-tuned to new tasks with minimal data. Prototypical networks classify examples based on distance to learned class prototypes in embedding space, enabling classification with only a handful of examples per class. Matching networks use attention mechanisms to compute similarity between query examples and a small support set. These methods remain relatively underexplored in genomics but offer promise for settings where collecting large labeled datasets is prohibitively expensive.\nIn-context learning, where models make predictions by conditioning on a few examples provided as context, has emerged as a powerful capability in very large language models. Early evidence suggests that sufficiently large genomic models (at the scale of Evo-2 or beyond) may exhibit similar behavior, though this remains an active research frontier. The ability to perform complex tasks without explicit fine-tuning, simply by demonstrating the task through examples, could transform how genomic models are deployed in practice.\nZero-shot transfer relies entirely on pretrained knowledge without any task-specific adaptation. For protein variant effect prediction, models like ESM have demonstrated competitive zero-shot performance by scoring variants based on masked language model likelihoods. Variants that disrupt the model’s expectations for natural sequences are flagged as potentially deleterious. This works because pretraining on large protein sequence databases implicitly encodes structural and functional constraints. However, zero-shot approaches require very strong alignment between pretraining and target tasks. In genomics, most practical applications still require at least some labeled data for effective adaptation, and few-shot methods represent a more realistic minimal-data regime than true zero-shot transfer.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (few-shot learning conceptual): A schematic showing the few-shot learning setup. Left side shows a small support set (5-10 examples per class). Middle shows the adaptation mechanism (meta-learning, prototypes, or in-context learning). Right side shows predictions on query examples. Include performance curves showing how accuracy improves with increasing support set size.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#domain-adaptation-in-genomics",
    "href": "p2-ch09-transfer.html#domain-adaptation-in-genomics",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.8 Domain Adaptation in Genomics",
    "text": "9.8 Domain Adaptation in Genomics\nDomain adaptation addresses the challenge of applying models trained in one context (source domain) to a related but different context (target domain) where labeled data may be scarce or distribution shifts complicate direct transfer. Three types of domain shift are particularly relevant in genomics: cross-species transfer, cross-tissue transfer, and cross-assay transfer.\nCross-species transfer attempts to apply models trained on one organism to predict in another. The challenge is that evolutionary divergence introduces sequence differences that affect regulatory patterns, motif syntax, and functional constraints. Strategies for successful cross-species transfer include pretraining on multi-species data to learn conservation patterns, conservation-weighted fine-tuning that emphasizes evolutionarily constrained regions, and species-specific adapter layers that learn organism-specific adjustments to shared representations. For example, human-to-mouse regulatory element prediction faces the dual challenge of sequence divergence and lineage-specific regulatory innovations. Success depends on phylogenetic distance (closer species transfer more readily) and the degree of conservation of the target feature (highly conserved elements like core promoters transfer better than species-specific enhancers).\nCross-tissue transfer addresses tissue-specific regulatory programs. Gene expression and chromatin accessibility patterns vary dramatically across tissues, with thousands of tissue-specific enhancers and silencers. Effective strategies include shared backbones with tissue-specific prediction heads, tissue-conditional models that take tissue identity as input, and meta-learning approaches that train on many tissues to extract general principles of tissue-specific regulation. For instance, predicting brain-specific gene expression after training primarily on blood samples requires adapting to brain-specific enhancer usage and repressor activity. Broadly expressed housekeeping genes transfer more readily than tissue-restricted genes, providing a natural starting point for cross-tissue adaptation.\nCross-assay transfer tackles different molecular readouts of related biology. ChIP-seq and ATAC-seq both measure chromatin accessibility but with different biochemical mechanisms and signal characteristics. Bulk RNA-seq and single-cell RNA-seq quantify gene expression but at vastly different scales and with different noise profiles. Successful cross-assay transfer often requires multi-task pretraining on related assays to learn shared latent representations, domain adaptation via adversarial training to align distributions, or explicit modeling of the mechanistic relationships between assays. For example, transferring from ChIP-seq for specific transcription factors to ATAC-seq requires understanding that both capture open chromatin but with different resolution and sensitivity.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (domain adaptation types): A three-panel figure showing cross-species, cross-tissue, and cross-assay transfer scenarios. Each panel illustrates the source and target distributions, the type of shift involved, and example mitigation strategies. Use simple 2D projections of distribution overlaps to visualize the adaptation challenge.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#handling-distribution-shift",
    "href": "p2-ch09-transfer.html#handling-distribution-shift",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.9 Handling Distribution Shift",
    "text": "9.9 Handling Distribution Shift\nDistribution shift occurs when the statistical properties of the target deployment setting differ from the training distribution, potentially degrading model performance in subtle and hard-to-detect ways. Three types of distribution shift are particularly common in genomic applications: covariate shift, label shift, and concept drift.\nCovariate shift describes changes in the input distribution while the relationship between inputs and outputs remains stable. In genomics, GC content varies systematically across chromosomal regions and between species. Models trained on GC-rich regions may perform poorly on GC-poor regions not because the biological relationship has changed but because the input statistics differ. Detection involves comparing distributional statistics (GC content, repeat content, k-mer frequencies) between training and test sets. Mitigation strategies include importance weighting, where training examples are reweighted to match the target distribution, or explicit resampling to balance the training set.\nLabel shift occurs when the output distribution changes but the relationship between features and labels remains consistent. Pathogenic variant prevalence varies dramatically between clinical diagnostic settings and population sequencing studies. A model trained on case-enriched cohorts may produce miscalibrated predictions in population settings where most variants are benign. Detection involves comparing label frequencies between domains. Mitigation strategies include label rebalancing, recalibration of predicted probabilities, or explicit modeling of label shift through importance-weighted loss functions.\nConcept drift describes changes in the relationship between inputs and outputs across domains. Regulatory grammar may differ between species even when sequence composition is similar. Promoter motif syntax in yeast differs from mammals despite both species having TATA boxes and initiator elements. Detection is more challenging than for covariate or label shift, typically requiring monitoring of validation set performance and careful analysis of failure modes. Mitigation requires domain adaptation techniques that explicitly model distributional differences rather than assuming the learned relationship will transfer directly.\nDomain adaptation techniques address these shifts through several mechanisms. Importance weighting reweights training examples by the ratio of target to source density, effectively emphasizing examples similar to the target distribution. Domain-adversarial training learns representations that are invariant to domain identity, forcing the model to extract features that work across domains. Self-training uses model predictions on unlabeled target data as pseudo-labels, iteratively adapting to the target distribution. Subspace alignment projects source and target representations into a shared low-dimensional space where distributional differences are minimized.\nDetecting distribution shift before it causes deployment failures is critical. Statistical tests like Maximum Mean Discrepancy (MMD) or Kolmogorov-Smirnov tests can flag distributional differences. Visualizing embeddings from source and target domains in low-dimensional space (via PCA or t-SNE) reveals whether the domains occupy similar or disjoint regions of representation space. Monitoring performance on “canary” examples (known easy cases that should always be predicted correctly) provides an early warning system for severe distribution shift.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (distribution shift types and detection): A multi-panel figure showing covariate shift, label shift, and concept drift with simple 2D examples. For each type, show the source and target distributions, the nature of the shift, and detection methods. Include a flowchart for diagnosing which type of shift is present.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#multi-task-learning",
    "href": "p2-ch09-transfer.html#multi-task-learning",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.10 Multi-Task Learning",
    "text": "9.10 Multi-Task Learning\nMulti-task learning trains a single model to solve multiple related tasks simultaneously, sharing representations across tasks while maintaining task-specific prediction heads. In genomics, multi-task learning is particularly natural given that many regulatory signals (chromatin accessibility, histone marks, transcription factor binding) are mechanistically related and co-occur in predictable patterns.\nJoint training on related tasks provides several benefits. Regularization effects reduce overfitting since the model must learn representations that work across multiple tasks rather than overfitting to any single task. Improved generalization arises from extracting shared structure that transfers more readily to new contexts. Amortized learning allows smaller per-task datasets to benefit from the aggregate information across all tasks, effectively increasing the training data available to learn shared representations.\nTask weighting and balancing present a key challenge. Tasks often have different scales, label noise levels, and intrinsic difficulties. Without careful balancing, the model may overfit to the easiest or highest-signal task while underperforming on others. Manual weighting based on task importance or domain knowledge provides a simple baseline. Uncertainty-based weighting methods learn task-specific weights during training, automatically balancing task contributions. GradNorm adjusts task weights to balance gradient magnitudes, preventing any single task from dominating the optimization. Dynamic task prioritization schedules shift emphasis between tasks during training to improve overall multi-task performance.\nExamples in genomics demonstrate the power of multi-task learning. Enformer and Borzoi predict thousands of chromatin and expression tracks jointly, learning shared sequence-to-function mappings that generalize better than single-task models. Joint splicing and expression models capture the mechanistic link between alternative splicing decisions and transcript abundance. Combined variant effect prediction across multiple functional assays enables more robust pathogenicity assessment than any single assay alone.\nMulti-task learning helps when tasks share underlying biology and provide complementary information, when individual tasks have limited data but the aggregate dataset is substantial, or when tasks provide mutual regularization that improves generalization. Multi-task learning hurts when tasks conflict with incompatible objectives or when tasks have vastly imbalanced difficulty such that the model allocates most capacity to the easiest task. Insufficient model capacity to handle all tasks simultaneously leads to performance degradation across the board rather than the hoped-for synergy.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (multi-task learning architecture): A diagram showing a shared backbone feeding into multiple task-specific heads. Include examples of genomic multi-task scenarios (chromatin tracks, splice predictions, expression levels). Show how gradients from multiple tasks combine during training and include a panel illustrating task weighting strategies.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#continual-learning-and-model-updates",
    "href": "p2-ch09-transfer.html#continual-learning-and-model-updates",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.11 Continual Learning and Model Updates",
    "text": "9.11 Continual Learning and Model Updates\nContinual learning addresses the challenge of updating models as new data arrives without discarding previously learned knowledge. In genomics, new cell types, species, functional assays, and annotations emerge regularly. The naive approach of retraining from scratch whenever new data arrives is computationally expensive and wasteful of previously acquired knowledge. Continual learning methods offer strategies for incremental updates that preserve old knowledge while incorporating new information.\nRegularization-based approaches penalize changes to parameters that were important for previous tasks. Elastic Weight Consolidation (EWC) computes a Fisher information matrix to identify parameters critical for existing tasks, then adds regularization terms that discourage large changes to these parameters during training on new tasks. PackNet allocates different subsets of network capacity to different tasks by pruning unused connections after each task is learned. These methods work well when tasks arrive sequentially and computational resources for retraining are limited, but they require careful tuning of regularization strength to balance plasticity against stability.\nRehearsal strategies maintain a buffer of examples from previous tasks, mixing them with new data during training. This prevents catastrophic forgetting by providing continual exposure to old tasks while learning new ones. Generative replay extends this idea by using generative models to synthesize examples from previous tasks rather than storing real data, offering privacy advantages when direct storage is problematic. Rehearsal is particularly effective when storage is available and privacy concerns permit data retention, but it does not scale indefinitely as the number of tasks grows.\nArchitecture-based approaches add new capacity for new tasks rather than modifying existing parameters. Progressive networks append new columns or modules for each new task while keeping previous task parameters frozen. Dynamic architectures expand model capacity as needed, allocating additional parameters when existing capacity is insufficient. These methods avoid catastrophic forgetting entirely but result in growing model size over time, eventually becoming impractical for deployment.\nGenomic applications of continual learning include adding new cell types to expression prediction models as single-cell atlases expand, incorporating new species into pan-genome foundation models without retraining on all species from scratch, and updating variant effect predictors with new functional annotations as they become available. The key is recognizing that genomic knowledge is not static. Models deployed today will need to incorporate tomorrow’s discoveries, and continual learning provides the methodological framework for efficient, incremental updates.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (continual learning strategies): A comparison of regularization-based, rehearsal-based, and architecture-based continual learning. Show schematically how each approach handles sequential arrival of new tasks while preserving performance on old tasks. Include performance curves showing accuracy on old vs new tasks over time.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#practical-deployment-considerations",
    "href": "p2-ch09-transfer.html#practical-deployment-considerations",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.12 Practical Deployment Considerations",
    "text": "9.12 Practical Deployment Considerations\nDeploying adapted models in production settings requires attention to computational efficiency, infrastructure requirements, and operational monitoring beyond the research considerations that dominate model development. These practical concerns often determine whether a model transitions from publication to real-world impact.\nComputational requirements encompass inference cost in FLOPs, memory footprint, and latency constraints. Batch processing of thousands of variants for research studies has different requirements than real-time variant interpretation during clinical exome analysis. Hardware constraints matter: GPU availability enables certain deployment strategies while edge deployment in resource-constrained environments requires different optimizations. Understanding the inference compute budget and latency requirements upfront guides model selection and adaptation strategy.\nModel compression techniques reduce deployment costs. Quantization reduces numerical precision from FP32 to FP16 or INT8, typically with minimal accuracy loss and substantial speed and memory gains. Pruning removes weights with minimal impact on predictions, creating sparse models that require less storage and compute. Knowledge distillation trains a smaller student model to mimic a larger teacher, transferring knowledge into a more deployable form. For example, distilling Enformer for clinical deployment might compress the model from billions of parameters to millions while retaining most predictive performance, enabling deployment on modest hardware.\nInfrastructure considerations include model serving architectures (REST APIs for real-time inference, batch processing pipelines for large-scale analysis), version control for model checkpoints and code to ensure reproducibility, and monitoring systems that detect performance drift or input distribution changes in production. Data preprocessing and tokenization pipelines must be maintained carefully since mismatches between training and deployment preprocessing can silently degrade performance. Reference genome versions and annotation databases must be synchronized across the pipeline since coordinate systems and transcript definitions change over time.\nThese practical concerns are often neglected in research papers but dominate real-world deployment. A model that achieves state-of-the-art benchmark performance but requires expensive GPU infrastructure or produces results too slowly for clinical workflows will see limited adoption. Conversely, a slightly less accurate model that meets latency and cost constraints while providing actionable insights may have far greater practical impact.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (deployment pipeline): A flowchart showing the full deployment pipeline from raw input (sequence, variants) through preprocessing, model inference, postprocessing, and output delivery. Include infrastructure components (model serving, monitoring, version control) and decision points for computational optimization strategies (quantization, pruning, distillation).",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#validation-and-benchmarking",
    "href": "p2-ch09-transfer.html#validation-and-benchmarking",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.13 Validation and Benchmarking",
    "text": "9.13 Validation and Benchmarking\nProper validation is essential for reliably assessing adapted model performance and avoiding common pitfalls that lead to overoptimistic estimates. Several failure modes are pervasive in genomic model evaluation, many of which arise from subtle forms of data leakage or inappropriate evaluation protocols.\nData leakage occurs when information from the test set influences model training, creating an artificial inflation of reported performance. Test set overlap with pretraining data is a particular concern for foundation models trained on massive corpora that may inadvertently include sequences or variants later used for evaluation. Temporal leakage uses future information that would not have been available at the time a prediction would be made, common when datasets spanning multiple years are split randomly rather than temporally. Label leakage occurs when test set labels inform feature engineering or preprocessing steps, subtly incorporating information that biases evaluation.\nProper validation strategies depend on the deployment context. Held-out test sets should be drawn from the same distribution as the intended deployment setting whenever possible. If the model will be used for cross-tissue prediction, evaluation should include tissues not seen during training. If the model will be applied to new species, evaluation should include phylogenetically distant organisms. Temporal splits are critical for time-sensitive applications like clinical variant interpretation, where the model should be evaluated on variants discovered after the training data was collected. Cross-validation provides more robust estimates when data is limited, though careful attention to stratification and blocking is necessary to avoid leakage across folds.\nBenchmarking guidelines emphasize appropriate baselines and uncertainty quantification. Comparing against from-scratch training and simpler models (linear models, shallow networks) provides context for whether the complexity of adapted foundation models is justified. Reporting confidence intervals from multiple training runs with different random seeds captures performance variability. Testing on multiple datasets rather than a single benchmark reveals whether gains generalize or are dataset-specific. Failure case analysis, examining where and why the model makes errors, often reveals more about model behavior than aggregate metrics alone.\nThese evaluation principles complement the broader treatment of confounding and evaluation methodology in Chapter 21 and Chapter 19. Here we emphasize their specific relevance to transfer learning validation: ensuring that measured performance reflects true adaptation success rather than artifacts of the evaluation protocol.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (validation pitfalls and solutions): A table or multi-panel figure showing common validation pitfalls (data leakage, temporal leakage, inappropriate test sets) alongside correct validation protocols. Include checklist items for proper validation and examples of each pitfall from genomic applications.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#transfer-learning-case-studies",
    "href": "p2-ch09-transfer.html#transfer-learning-case-studies",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.14 Transfer Learning Case Studies",
    "text": "9.14 Transfer Learning Case Studies\nExamining specific successful (and unsuccessful) applications of transfer learning in genomics provides concrete illustrations of the principles discussed throughout this chapter. Four case studies span different model architectures, adaptation strategies, and application domains.\nDNABERT applied to chromatin accessibility prediction demonstrates feature extraction success. The model was pretrained using 6-mer masked language modeling on the human genome, learning to predict masked k-mers from surrounding context. For ATAC-seq peak classification, a linear probe on the [CLS] token embedding achieved competitive performance with CNNs trained from scratch while using 10 times less labeled data. This success reflects strong alignment between pretraining (learning local sequence patterns) and the target task (identifying accessibility signals that depend on motif composition). The lightweight adaptation strategy was appropriate given limited labeled ATAC-seq data.\nESM for variant effect prediction illustrates zero-shot and minimal-supervision transfer in the protein domain. ESM was pretrained on UniRef protein sequences using masked language modeling. For ClinVar pathogenicity classification, zero-shot scoring based on how much a variant reduces sequence likelihood proved competitive with supervised methods. Adding a linear probe on ESM embeddings further improved performance. This case exemplifies successful transfer when pretraining captures the target objective implicitly (evolutionary constraint and protein function are closely related) and when model scale is sufficient to learn generalizable representations.\nEnformer for cross-tissue gene expression shows benefits of full fine-tuning on related but distinct tasks. Enformer was pretrained on 5,313 chromatin and expression tracks across many cell types and tissues, learning sequence-to-function mappings over long genomic contexts. Fine-tuning with tissue-specific prediction heads captured tissue-specific regulatory logic, outperforming models trained from scratch on individual tissues. The large scale of both pretraining data and fine-tuning data justified the computational expense, and the mechanistic relationship between chromatin state and expression made transfer highly effective.\nHyenaDNA for regulatory element classification leverages long-range context through efficient attention mechanisms. Pretrained on the human genome with up to 1 million base pair contexts using next-token prediction, HyenaDNA embeddings capture distal regulatory relationships. LoRA adapters enabled efficient fine-tuning for enhancer and promoter classification, with long-range context improving accuracy on distal regulatory elements that depend on interactions spanning tens of kilobases. This case demonstrates the value of architecture-specific pretraining (long context) for tasks where long-range dependencies matter.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (case study comparison table): A table summarizing the four case studies with columns for: model, pretraining task and scale, target task, adaptation strategy, data regime, key results, and lessons learned. Include brief visual schematics of each model’s architecture.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#troubleshooting-transfer-failures",
    "href": "p2-ch09-transfer.html#troubleshooting-transfer-failures",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.15 Troubleshooting Transfer Failures",
    "text": "9.15 Troubleshooting Transfer Failures\nNot all transfer learning attempts succeed. When transfer fails to improve over training from scratch or when adapted models underperform expectations, systematic troubleshooting can identify the root cause and guide corrective actions.\nNegative transfer scenarios typically arise from pretraining on the wrong distribution, misaligned pretraining objectives, or target tasks too different from anything seen during pretraining. A model pretrained on coding sequences may struggle with long-range regulatory prediction. A model pretrained to predict conservation may not capture species-specific innovations. Recognizing these failure modes early avoids wasted effort on adaptation strategies that cannot succeed regardless of tuning.\nDiagnostic steps provide a systematic investigation framework. First, compare adapted model performance against a from-scratch baseline trained on the same target data. If the pretrained model does not outperform from-scratch training, transfer is not helping. Second, try simpler adaptation strategies before investing in complex ones. If linear probing fails, full fine-tuning is unlikely to help unless the target dataset is large. Third, visualize embeddings from pretrained model using dimensionality reduction (PCA, t-SNE, UMAP). If target task examples are not well-separated in embedding space, the pretrained representations are not useful for this task. Fourth, ablate pretraining entirely by comparing against randomly initialized models. This isolates whether pretrained weights provide value or whether architectural choices alone drive performance.\nWhen these diagnostics reveal fundamental mismatches between pretraining and target tasks, several solutions may help. Task-specific pretraining on related data more closely aligned with the target task can bridge the gap. For example, pretraining specifically on regulatory regions rather than the entire genome for regulatory prediction tasks. Hybrid approaches combining pretrained modules with from-scratch modules allow selective use of transfer where it helps. Trying different foundation models (revisiting the taxonomy in Chapter 6) may reveal better-suited alternatives. Finally, accepting that transfer does not help and training from scratch remains a valid option when the target task truly differs from anything the pretrained model has seen.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (troubleshooting flowchart): A detailed diagnostic flowchart for investigating transfer learning failures. Start with performance comparison against baselines, branch into diagnostic steps (embedding visualization, ablations, simpler methods), and end with recommended solutions based on diagnostic outcomes.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#future-directions-in-transfer-learning",
    "href": "p2-ch09-transfer.html#future-directions-in-transfer-learning",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.16 Future Directions in Transfer Learning",
    "text": "9.16 Future Directions in Transfer Learning\nThe field of transfer learning continues to evolve rapidly, with several emerging directions particularly relevant to genomic applications. These developments may reshape how foundation models are adapted and deployed in the coming years.\nPrompt-based adaptation for genomic language models extends the paradigm that has proven successful in natural language processing. Rather than fine-tuning model parameters, prompts provide task context that guides the model’s predictions. Early work suggests that sufficiently large genomic models may respond to sequence-based prompts or even cross-modal prompts that combine sequence with text descriptions. Developing effective prompting strategies for genomics remains an open challenge given the fundamentally different structure of genomic versus natural language data.\nTest-time adaptation updates models during inference based on characteristics of the test examples themselves. Rather than freezing models after training, test-time adaptation allows limited parameter updates to better match the deployment distribution. This is particularly relevant for handling distribution shift without requiring labeled data from the target domain. Methods like test-time training and entropy minimization show promise for improving robustness without sacrificing training-time performance.\nFederated learning enables collaborative training across institutions without sharing raw data, addressing privacy concerns that limit data sharing in clinical genomics. Multiple institutions train local models on their private data, then share only model updates that are aggregated to create a global model. This paradigm could enable training on far larger and more diverse datasets than any single institution can access, potentially improving model generalization and fairness.\nNeural architecture search for task-specific adaptations automates the design of optimal adaptation strategies. Rather than manually choosing between LoRA, adapters, or full fine-tuning, automated methods could search over adaptation architectures to find configurations that optimize performance given specific data and computational constraints. This could democratize transfer learning by reducing the expert knowledge required to effectively deploy foundation models.\nOpen challenges persist. Better theory predicting when transfer will help based on measurable properties of source and target tasks would reduce the trial-and-error nature of current practice. Automatic selection of adaptation strategies based on dataset characteristics and available compute could accelerate deployment. Transfer across very different modalities (DNA to protein to phenotype) remains difficult despite mechanistic relationships. Lifelong learning systems that continuously improve as new data arrives without periodic retraining from scratch would enable models to keep pace with the rapid evolution of genomic knowledge.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (future directions overview): A conceptual diagram showing emerging transfer learning paradigms. Include panels for prompt-based adaptation, test-time adaptation, federated learning, and neural architecture search, each with a simple schematic and example genomic application.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p2-ch09-transfer.html#summary-and-practical-guidelines",
    "href": "p2-ch09-transfer.html#summary-and-practical-guidelines",
    "title": "9  Transfer Learning & Deployment",
    "section": "9.17 Summary and Practical Guidelines",
    "text": "9.17 Summary and Practical Guidelines\nTransfer learning bridges the gap between general-purpose pretrained models and specific genomic applications, providing strategies that balance adaptation flexibility against computational cost and overfitting risk. This chapter has surveyed the landscape of transfer learning techniques, from simple feature extraction to full fine-tuning to exotic approaches like few-shot learning and continual adaptation.\nSeveral key principles emerge from this survey. First, match adaptation strategy to available data and compute. With minimal data, feature extraction is safest. With moderate data, PEFT methods offer good performance-to-cost ratios. With abundant data, consider full fine-tuning but always compare against simpler baselines. Second, validate carefully that transfer helps. Compare adapted models against from-scratch baselines trained on the same target data. Without this comparison, it is impossible to know whether pretrained models provide value. Third, consider domain shift and distribution mismatch. Models trained in one context may fail silently when deployed in another. Explicit domain adaptation and careful out-of-distribution evaluation help identify and mitigate these risks. Fourth, start simple and increase complexity as needed. Linear probes are fast to train and often surprisingly effective. Only invest in more complex adaptation when simpler approaches demonstrably fail.\nThe decision framework can be summarized through the following heuristics. For small datasets (fewer than 1,000 examples), use linear probing or shallow classifiers on frozen embeddings. For medium datasets (1,000 to 10,000 examples), consider LoRA or adapter-based PEFT methods that balance expressiveness and regularization. For large datasets (more than 10,000 examples), consider full fine-tuning if computational resources permit and the target task differs substantially from pretraining. For related tasks that share structure, explore multi-task learning to amortize learning across tasks. For domain shift scenarios, apply explicit adaptation techniques like importance weighting or domain-adversarial training. For continual updates as new data arrives, use rehearsal or regularization-based continual learning methods to avoid catastrophic forgetting.\nThese guidelines connect to later chapters where transfer learning principles are applied to specific domains. Clinical variant interpretation (Chapter 23) requires robust transfer strategies that generalize across populations and phenotypes. Systems biology applications (Chapter 17) benefit from multi-task learning across related molecular readouts. Drug discovery (Chapter 25) leverages transfer from large protein databases to small molecule binding prediction. Throughout Part IV, the adaptation strategies described here recur as essential components of effective genomic AI systems. By understanding when and how to transfer knowledge from pretrained models to downstream tasks, practitioners can more effectively navigate the rapidly expanding ecosystem of genomic foundation models.",
    "crumbs": [
      "Part III: Core Principles",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transfer Learning & Deployment</span>"
    ]
  },
  {
    "objectID": "p3--architectures.html",
    "href": "p3--architectures.html",
    "title": "Part II: Deep Learning Architectures",
    "section": "",
    "text": "Warning\n\n\n\n“While protein language models like ESM preceded DNA transformers chronologically, we present these architectures following the central dogma to maintain conceptual coherence.”\n\n\nPart I established the data resources, statistical foundations, and pre-deep learning variant scoring methods that preceded the current era of genomic modeling. This part turns to the architectural innovations that transformed what is computationally possible. The chapters that follow trace an arc from early convolutional neural networks through the explosion of transformer-based approaches to hybrid designs that attempt to combine the strengths of both paradigms.\nThe progression is not merely chronological. Each architecture embodies a different set of assumptions about biological sequence. Convolutional models assume that local motifs and their short-range combinations are the primary carriers of regulatory information. Transformer-based language models treat sequences as structured compositions of tokens whose meaning emerges from context, leveraging self-attention to capture dependencies across arbitrary distances. Hybrid architectures attempt to reconcile these perspectives, using convolutions to extract local features efficiently while deploying attention mechanisms to model long-range interactions that span tens or hundreds of kilobases.\n10  CNN Sequence-to-Function Models begins with the CNN-based models that first demonstrated deep learning could outperform handcrafted features for regulatory genomics. DeepSEA, ExPecto, and SpliceAI established the paradigm of training deep networks on functional genomics data to predict chromatin accessibility, transcription factor binding, gene expression, and splicing from sequence alone. These models remain widely used and provide the conceptual foundation for everything that follows. 13  Protein Language Models then examines protein language models, where the success of masked language modeling on natural language translated directly to amino acid sequences. Models like ESM and ProtTrans learn rich representations of protein structure and function without explicit supervision, and AlphaFold demonstrated that these representations could revolutionize structure prediction. 11  DNA and Genomic Models applies analogous language modeling strategies to DNA, surveying DNABERT, Nucleotide Transformer, HyenaDNA, and related approaches that treat genomic sequence as text to be understood through self-supervised pretraining. 12  RNA & Transcript-Level Models extends this treatment to RNA, covering models that predict secondary structure, capture splicing regulation beyond what CNN-based methods achieve, and represent the emerging frontier of RNA foundation models. Finally, 14  Long-range Hybrid Models examines hybrid architectures like Enformer and Borzoi that combine convolutional processing with transformer blocks to achieve context windows spanning hundreds of kilobases, enabling direct modeling of enhancer-promoter interactions and long-range chromatin effects.\nBy the end of this part, readers will have a working understanding of the major architectural paradigms in genomic deep learning: what each assumes, what each can and cannot capture, and how these design choices translate to practical performance on regulatory prediction tasks.",
    "crumbs": [
      "Part II: Deep Learning Architectures"
    ]
  },
  {
    "objectID": "p3-ch10-cnn.html",
    "href": "p3-ch10-cnn.html",
    "title": "10  CNN Sequence-to-Function Models",
    "section": "",
    "text": "10.1 DeepSEA: Regulatory Prediction from Sequence\nThe deep learning revolution in genomics began with convolutional neural networks (CNNs) that learned to predict molecular function directly from DNA sequence. Between 2015 and 2019, a series of models established paradigms that would shape the field for years to come. Rather than hand-crafting motif features, these models learn them directly from data, treating DNA as a signal to be processed by learnable filters.\nThis chapter focuses on three landmark 1D convolutional models that established the sequence-to-function paradigm:\nThough DeepVariant (Section 1.8) demonstrated that CNNs could outperform hand-crafted pipelines for variant calling by treating read pileups as images (Poplin et al. 2018), the models examined here solve a fundamentally different problem. Variant calling asks “is this a true variant?” while effect prediction asks “what does this variant do?” Yet they share a common lesson: learned representations can replace the hand-crafted features and heuristics that dominated earlier computational genomics.\nAt a high level, the CNN sequence-to-function lineage established four key ideas:\nTogether these models demonstrate how increasing architectural depth and context length enable capture of progressively longer-range biological dependencies: from the kilobase-scale regulatory elements recognized by DeepSEA, through the tens of kilobases of promoter-proximal sequence integrated by ExPecto, to the 10 kb windows required for accurate splice prediction by SpliceAI. Understanding these models provides essential context for the transformer-based foundation models in Part III, which extend and generalize many of the principles established here.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>CNN Sequence-to-Function Models</span>"
    ]
  },
  {
    "objectID": "p3-ch10-cnn.html#sec-reg",
    "href": "p3-ch10-cnn.html#sec-reg",
    "title": "10  CNN Sequence-to-Function Models",
    "section": "",
    "text": "10.1.1 The Noncoding Variant Challenge\nThe vast majority of disease-associated variants identified by GWAS lie in noncoding regions of the genome (Maurano et al. 2012). Across thousands of loci mapped to complex traits, only a small minority directly alter protein-coding sequences; the remainder fall in introns, intergenic regions, and putative regulatory elements where their functional consequences are far less obvious. This presents both an interpretive challenge and an opportunity. If we could predict how noncoding variants affect gene regulation, we would have a powerful tool for moving from statistical association to biological mechanism.\nYet in 2015, the field lacked systematic methods to predict how noncoding variants affect regulatory activity. Existing approaches relied on overlap with known annotations: if a variant fell within a ChIP-seq peak or DNase hypersensitive site, it might be flagged as potentially functional. This strategy had obvious appeal since it grounded predictions in experimental observations, but it suffered from fundamental limitations. Overlap-based annotation offered no mechanism for predicting the direction or magnitude of a variant’s effect on regulatory activity. A variant might fall within an enhancer, but would it strengthen or weaken the enhancer? By how much? These questions could not be answered by checking whether genomic coordinates intersected.\nFurthermore, overlap-based methods could not score variants in regions lacking experimental coverage, which was problematic given that functional genomics experiments, despite their scale, still covered only a fraction of cell types and conditions. At the same time, large-scale epigenomic consortia such as ENCODE and Roadmap Epigenomics were generating thousands of transcription factor ChIP-seq, histone ChIP-seq, and DNase/ATAC-seq profiles across many cell types (Kundaje et al. 2015; Kagda et al. 2025). DeepSEA asked a simple but transformative question: can we learn regulatory grammar directly from DNA sequence to predict these assays?\nDeepSEA, introduced by Zhou and Troyanskaya in 2015, fundamentally changed this paradigm by learning to predict chromatin features directly from DNA sequence (Zhou and Troyanskaya 2015). Rather than asking “does this variant overlap a known regulatory element?”, DeepSEA asks “what regulatory activities does this sequence encode, and how would a mutation change them?” This shift from annotation lookup to sequence-based prediction opened a new chapter in computational genomics, one where deep neural networks could learn the relationship between DNA sequence and molecular function without requiring hand-crafted features or explicit motif definitions.\n\n\n10.1.2 Learning Regulatory Code from Sequence\nDeepSEA’s central insight was that deep convolutional networks could learn the sequence patterns underlying regulatory activity without explicit feature engineering. This represented a departure from earlier computational approaches to regulatory genomics, which typically required defining sequence features a priori. Methods like gapped k-mer SVMs (gkm-SVM) required specifying which k-mers to count and how to weight them. Position weight matrices for transcription factor binding sites required curating motif databases like JASPAR or TRANSFAC. These approaches worked, but they encoded human assumptions about what sequence features mattered and could not easily discover novel patterns or complex dependencies.\nDeepSEA instead learned relevant sequence features automatically from data. The convolutional layers of the network function analogously to motif scanners, detecting local sequence patterns that correlate with regulatory activity. But unlike predefined motif scanners, these filters are learned during training, allowing the network to discover whatever patterns best predict the training labels. Deeper layers in the network can then learn combinations of these patterns, capturing regulatory “grammar” such as motif spacing, orientation preferences, and cooperative binding arrangements. The network does not know in advance which patterns matter; it learns them by optimizing predictions on hundreds of thousands of genomic sequences with experimentally measured chromatin profiles.\n\n10.1.2.1 Architecture\nThe original DeepSEA architecture was deliberately simple by modern standards, comprising a stack of convolutional layers followed by fully connected layers that integrate information across the sequence.\nThe input to the network is a 1000 bp DNA sequence, one-hot encoded into a binary matrix with four channels (one per nucleotide) and 1000 positions. This representation treats sequence as a signal to be processed by convolution, analogous to how image recognition networks process pixel values. Each position in the sequence is represented by exactly one active channel, encoding which nucleotide (A, C, G, or T) is present.\nThe network processes this input through three convolutional layers, each followed by ReLU activation and max pooling. The first convolutional layer uses 320 filters of width 8, scanning the sequence for local patterns roughly the size of transcription factor binding sites. Max pooling after each convolution reduces the spatial dimension, progressively compressing the 1000-position input into a more compact representation. The second and third convolutional layers use 480 and 960 filters respectively, with narrower widths applied to the already-pooled representation. These deeper layers can learn combinations of the patterns detected by earlier layers, building increasingly abstract representations of sequence features.\nAfter the convolutional stack, a fully connected layer with 925 units integrates information across all positions in the compressed representation. This layer allows the network to learn relationships between sequence features at different positions, capturing spatial dependencies that pure convolution cannot represent. Finally, an output layer with 919 sigmoid units produces independent probability predictions for each chromatin profile.\nThe total number of parameters is modest by contemporary standards (approximately 60 million) but was substantial for genomics applications at the time. Training used stochastic gradient descent with momentum on sequences sampled from the human genome, with chromosome 8 held out for testing.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: DeepSEA architecture\nCompact diagram illustrating: (1) 1 kb one-hot sequence input; (2) convolution + pooling stack; (3) fully connected layer; (4) 919-task output vector with example labels (e.g., “H3K27ac, liver”, “CTCF, GM12878”).\n\n\n\n\n10.1.2.2 Training Data\nDeepSEA was trained on 919 chromatin profiles compiled from ENCODE and Roadmap Epigenomics, two consortium efforts that had systematically mapped the epigenomic landscape across diverse human cell types and tissues (Kagda et al. 2025; Kundaje et al. 2015). These profiles represented three major categories of regulatory annotation.\nTranscription factor binding profiles, numbering 690 in total, captured the genomic locations where specific proteins bind DNA. These were derived from ChIP-seq experiments targeting factors like CTCF (a ubiquitous insulator protein), p53 (a tumor suppressor), and GATA1 (a hematopoietic transcription factor). Each profile represents a binary classification problem: for a given sequence, is the central region bound by this factor in this cell type?\nHistone modification profiles, numbering 104, captured the locations of specific chemical modifications to histone proteins. Marks like H3K4me3 (trimethylation of lysine 4 on histone H3) are associated with active promoters, while H3K27ac (acetylation of lysine 27) marks active enhancers. H3K27me3 marks repressed regions through Polycomb-mediated silencing. These modifications do not directly encode regulatory logic but reflect the functional state of chromatin and correlate with gene expression.\nDNase I hypersensitivity profiles, numbering 125, captured regions of open chromatin across cell types. DNase hypersensitive sites mark regions where DNA is accessible to regulatory proteins, identifying potential regulatory elements regardless of which specific factors bind there. Unlike transcription factor ChIP-seq, DNase-seq provides a relatively unbiased view of regulatory potential.\nFor each 1000 bp input sequence, the model predicts the probability that the central 200 bp region exhibits each of these 919 chromatin features. The narrower prediction window relative to the input window allows the network to use flanking sequence as context for predicting the central region’s activity. Training used sequences sampled from the human genome, excluding chromosome 8 which was reserved for evaluation. This chromosome-level holdout prevents overfitting to sequence homology or linkage disequilibrium patterns that might leak between training and test sets.\n\n\n10.1.2.3 Multi-Task Learning\nA key architectural decision was predicting all 919 features simultaneously rather than training separate models for each. This multi-task learning approach offers several advantages that compound as the number of tasks increases.\nShared representations in early layers benefit all tasks. The first convolutional layer learns general sequence features such as GC content, dinucleotide frequencies, and common motifs that are useful across many prediction problems. By sharing these representations, the network amortizes the cost of learning basic sequence features across all tasks rather than relearning them independently.\nJoint prediction provides regularization. Predicting many correlated features simultaneously prevents overfitting to any single task. If a convolutional filter becomes overly specific to one transcription factor, it will harm predictions for other related factors, providing a pressure toward learning generalizable representations. This implicit regularization is particularly valuable when some tasks have limited training data.\nEfficiency gains are substantial. One model serving all 919 prediction tasks requires far less computation than training and maintaining 919 separate models. This matters not only for initial training but for deployment, where a single forward pass produces all predictions.\nThe multi-task framework also reveals relationships between chromatin features. Weights connecting shared representations to different output tasks can be analyzed to understand which features rely on similar sequence patterns. This provides a form of interpretability that separate models would not offer.\n\n\n\n10.1.3 Variant Effect Prediction\nWith a trained model that maps sequence to chromatin profiles, variant effect prediction becomes straightforward in principle: predict chromatin profiles for both reference and alternative allele sequences, then compute the difference. This produces a 919-dimensional vector describing how the variant is predicted to alter regulatory activity across all profiled features. A variant might be predicted to increase CTCF binding while decreasing DNase accessibility, or to have no effect on any chromatin feature, depending on where it falls and what sequence context it disrupts or creates.\nThis approach has a crucial property: it requires no training on variant data. The model learns to predict chromatin profiles from sequence during training, using only reference genome sequences and their experimentally measured chromatin states. Variant effect prediction is then a form of transfer: the model applies what it learned about sequence-function relationships to score mutations it has never seen. This ab initio capability distinguishes sequence-based models from approaches that learn directly from observed variant effects, which are inevitably biased toward common variants where statistical power exists.\n\n10.1.3.1 Single-Nucleotide Sensitivity\nFor the approach to work, the model must achieve single-nucleotide sensitivity: changing one base must be capable of substantially altering predictions. This is not guaranteed. A model could achieve good performance on chromatin prediction by learning only coarse sequence features (GC content, repeat density) that are insensitive to point mutations. Such a model would be useless for variant interpretation.\nDeepSEA achieves genuine single-nucleotide sensitivity, and the authors validated this using allelic imbalance data from digital genomic footprinting. For 57,407 variants showing allele-specific DNase I sensitivity across 35 cell types, DeepSEA predictions correlated strongly with the experimentally observed allelic bias. Variants predicted to increase chromatin accessibility tended to show higher accessibility on the corresponding allele, and vice versa. This correlation would not exist if the model were insensitive to point mutations.\nThe validation is particularly compelling because allelic imbalance represents an independent experimental readout. The model was not trained to predict allelic imbalance; it was trained to predict chromatin profiles from reference sequences. That it correctly predicts the direction of allelic effects demonstrates that the learned sequence-function relationships capture genuine biology rather than spurious correlations.\n\n\n10.1.3.2 In Silico Saturation Mutagenesis\nBeyond scoring individual variants, DeepSEA enables a powerful computational experiment: in silico saturation mutagenesis (ISM). By systematically predicting effects of all possible single-nucleotide substitutions within a sequence, one can identify which positions are most critical for regulatory function. At each position, three alternative nucleotides can be substituted, and the predicted change in chromatin profiles can be computed for each. Positions where substitutions produce large predicted effects are presumably functionally constrained, while positions tolerant of substitution are less critical.\nISM analysis of regulatory elements reveals sequence positions where mutations would most strongly perturb function. These critical positions often correspond to transcription factor binding motifs learned by the model. When the predicted effects are visualized along a regulatory sequence, clear patterns emerge: core motif positions show strong predicted effects, while flanking positions are more tolerant. This provides a form of motif discovery that emerges from the model’s learned representations rather than from explicit motif searching.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: Saturation mutagenesis\nHeatmap for an enhancer region: x-axis = sequence position, y-axis = alternative allele; color = change in predicted DNase signal. Overlay motif logo to highlight correspondence between learned and known motifs.\n\n\n\n\n\n10.1.4 Functional Variant Prioritization\nBeyond predicting chromatin effects for individual variants, DeepSEA introduced a framework for prioritizing likely functional variants among large sets of candidates. This addresses a practical problem in human genetics: GWAS and sequencing studies identify many variants in a region, most of which are not causal. Which variants should be prioritized for follow-up?\nExpression quantitative trait loci (eQTLs) represent variants statistically associated with gene expression changes. However, most eQTL signals reflect linkage disequilibrium rather than direct causation. A lead eQTL variant may simply be correlated with the true causal variant, which could be any of dozens of SNPs in the same LD block. DeepSEA demonstrated improved ability to distinguish likely causal eQTL variants from nearby non-causal variants compared to overlap-based methods. The intuition is straightforward: if a variant is truly causal, it should disrupt a sequence feature that matters for gene regulation.\nDeepSEA’s performance advantage over gkm-SVM was particularly notable for transcription factor binding prediction. The deep CNN achieved higher AUC for nearly all transcription factors tested. More revealing was the pattern with respect to sequence context: gkm-SVM showed no improvement when given longer input sequences (extending context from 200 bp to 500 bp to 1000 bp), while DeepSEA performance improved substantially with additional context. This difference reflects the fundamental limitation of gapped k-mer methods, which count k-mers without learning relationships between motifs at different positions.\n\n\n10.1.5 Evolution of the DeepSEA Framework\nThe original DeepSEA established the sequence-to-chromatin prediction paradigm. Subsequent work from the same research group expanded and refined this approach, building a lineage of models with progressively greater scope and sophistication.\nExPecto, published in 2018, included an updated chromatin prediction model nicknamed “Beluga” that served as the foundation for tissue-specific expression prediction (Zhou et al. 2018). Beluga incorporated several architectural improvements over the original DeepSEA. The number of predicted chromatin profiles expanded from 919 to 2,002, covering additional transcription factors and histone modifications across more cell types. The architecture deepened, adding additional convolutional layers with residual connections that facilitated training and improved gradient flow. The input context expanded from 1000 bp to 2000 bp, allowing the model to capture longer-range sequence dependencies.\nSei represents the current state of the DeepSEA lineage, predicting 21,907 chromatin profiles, a 24-fold expansion over the original (Chen et al. 2022). The Sei architecture introduces dual linear and nonlinear paths, dilated convolutions to expand the receptive field, and spatial basis functions for memory-efficient integration across positions. Beyond raw prediction performance, Sei introduced sequence class annotations that cluster the 21,907 chromatin predictions into interpretable regulatory categories.\n\n\n\nModel\nYear\nChromatin Targets\nInput Length\nArchitecture\n\n\n\n\nDeepSEA\n2015\n919\n1000 bp\n3 conv + FC\n\n\nBeluga\n2018\n2,002\n2000 bp\nDeep residual CNN\n\n\nSei\n2022\n21,907\n4000 bp\nDual-path + dilated conv\n\n\n\n\n\n10.1.6 What DeepSEA Learns\nAnalysis of DeepSEA’s first-layer filters reveals learned sequence patterns corresponding to known transcription factor binding motifs. Many filters match canonical motifs from databases like JASPAR, indicating that the network has independently discovered the sequence preferences of well-characterized transcription factors. Beyond individual motifs, DeepSEA implicitly learns aspects of regulatory “grammar,” including motif spacing requirements, orientation preferences, and combinatorial logic.\nHowever, the original DeepSEA architecture’s limited receptive field constrained its ability to learn long-range dependencies. Max pooling after each convolutional layer progressively reduces spatial resolution, and the fully connected layer can only integrate information from the resulting compressed representation. Dependencies spanning hundreds or thousands of base pairs, such as enhancer-promoter communication, are difficult to capture in this framework. This limitation motivated later architectures with expanded context windows, culminating in models like Enformer (Chapter 14) with effective receptive fields spanning hundreds of kilobases.\n\n\n10.1.7 Limitations\nDeepSEA represents a major advance, but understanding its limitations is essential for appropriate application. The model predicts chromatin profiles for specific cell types included in training, but the same sequence may have different regulatory activity in cell types not represented. The model treats each input sequence independently, without considering three-dimensional chromatin structure, the current transcriptional state of the cell, or other variants in the same individual. While DeepSEA accurately predicts the binary presence or absence of chromatin features, its quantitative predictions of signal strength are less reliable. Finally, the 1 kb context window cannot capture distal enhancers tens of kilobases away from their target promoters.\n\n\n10.1.8 Significance\nDeepSEA established several paradigms that shaped subsequent genomic deep learning. The “sequence-in, function-out” paradigm treats DNA sequence as the sole input and molecular function as the output, learning the mapping without hand-engineered features. Multi-task chromatin prediction, jointly modeling many related tasks, proved both more efficient and more effective than training separate models. Variant effect prediction via sequence comparison provided a general framework for interpreting genetic variation. The approach demonstrated that deep learning could extract biologically meaningful patterns from raw sequence data at scale.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: DeepSEA summary panel\nMulti-panel figure summarizing: (A) architecture schematic; (B) example saturation mutagenesis plot; (C) GWAS enrichment or ROC curves comparing DeepSEA scores to earlier feature-based methods.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>CNN Sequence-to-Function Models</span>"
    ]
  },
  {
    "objectID": "p3-ch10-cnn.html#sec-trans",
    "href": "p3-ch10-cnn.html#sec-trans",
    "title": "10  CNN Sequence-to-Function Models",
    "section": "10.2 ExPecto: From Chromatin to Expression",
    "text": "10.2 ExPecto: From Chromatin to Expression\n\n10.2.1 The Expression Prediction Challenge\nDeepSEA demonstrated that deep learning could predict chromatin features from DNA sequence alone. Yet chromatin accessibility and transcription factor binding are intermediate phenotypes. The ultimate functional readout for most regulatory variants is their effect on gene expression. A variant might disrupt a transcription factor binding site, but does that binding site actually regulate a nearby gene? In which tissues? By how much?\nExPecto, introduced by Zhou et al. in 2018, addressed these questions by extending the sequence-to-chromatin paradigm to predict tissue-specific gene expression levels (Zhou et al. 2018). The framework’s name reflects its core capability: expression prediction. Rather than stopping at chromatin predictions, ExPecto integrates predicted regulatory signals across a 40 kb promoter-proximal region to predict absolute expression levels in 218 tissues and cell types.\nCritically, ExPecto predicts expression effects ab initio from sequence, without training on any variant data. This enables scoring of rare variants, de novo mutations, and even hypothetical mutations never observed in any population. In effect, ExPecto builds a modular pipeline: sequence to predicted chromatin features (Beluga CNN), spatial aggregation of chromatin features relative to each transcription start site (TSS), and tissue-specific linear models for gene expression.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: ExPecto pipeline\nThree-box diagram: (1) Beluga CNN over a 40 kb window; (2) distance-binned feature aggregation; (3) per-tissue linear model outputting expression for that gene.\n\n\n\n\n10.2.2 The Modular Architecture\nExPecto comprises three sequential components, each addressing a distinct computational challenge: learning regulatory sequence features, connecting them to promoters over genomic distance, and modeling tissue-specific expression programs.\n\n10.2.2.1 Component 1: Epigenomic Effects Model (Beluga CNN)\nThe first component is an enhanced version of DeepSEA, predicting 2,002 chromatin profiles across more than 200 cell types. Key architectural improvements over the original DeepSEA include expanded chromatin targets (from 919 to 2,002), a wider input window (from 1,000 bp to 2,000 bp), deeper architecture (six convolutional layers with residual connections rather than three), and broader cell type coverage.\n\n\n\nFeature\nDeepSEA (2015)\nExPecto/Beluga (2018)\n\n\n\n\nChromatin targets\n919\n2,002\n\n\nInput window\n1,000 bp\n2,000 bp\n\n\nConvolution layers\n3\n6 (with residual connections)\n\n\nCell types\n~125\n&gt;200\n\n\n\nThe CNN scans the 40 kb region surrounding each transcription start site (TSS) with a moving window (200 bp step size), generating chromatin predictions at 200 spatial positions. For each gene, this produces 2,002 × 200 = 400,400 features representing the predicted spatial chromatin organization around the TSS.\n\n\n10.2.2.2 Component 2: Spatial Feature Transformation\nThe 400,400-dimensional feature space poses optimization challenges for downstream expression prediction. ExPecto addresses this through spatial transformation, a biologically motivated dimensionality reduction that captures the known distance-dependent relationship between regulatory elements and their target promoters.\nThe transformation applies ten exponential decay functions separately to upstream and downstream regions:\n\\[\n\\text{expression} = \\sum_{i,k} \\left( \\beta_{ik}^{\\text{up}} \\cdot \\mathbf{1}(t_d &lt; 0) + \\beta_{ik}^{\\text{down}} \\cdot \\mathbf{1}(t_d &gt; 0) \\right) \\cdot \\sum_{d \\in D} p_{id} \\cdot e^{-a_k \\cdot |t_d|}\n\\]\nwhere \\(p_{id}\\) is the predicted probability for chromatin feature \\(i\\) at spatial bin \\(d\\), \\(t_d\\) is the mean distance to TSS for bin \\(d\\), and \\(a_k\\) represents decay constants (0.01, 0.02, 0.05, 0.1, 0.2). This transformation reduces dimensionality 20-fold (to 20,020 features) while preserving spatial information and encoding the prior belief that nearby elements contribute more than distant ones.\n\n\n10.2.2.3 Component 3: Tissue-Specific Linear Models\nThe final component comprises 218 L2-regularized linear regression models (one per tissue), each predicting log RPKM expression from spatially-transformed features. Linear models were chosen deliberately: they provide interpretability, prevent overfitting given the high-dimensional feature space, and enable straightforward coefficient analysis to identify which chromatin features drive expression in each tissue.\nBecause the upstream Beluga CNN is tissue-agnostic, the combination of a shared sequence-to-chromatin model with separate tissue-specific linear heads provides a clean separation between sequence-level regulatory grammar and tissue-specific regulatory programs.\n\n\n\n10.2.3 Expression Prediction Performance\nExPecto achieved 0.819 median Spearman correlation between predicted and observed expression (log RPKM) across 218 tissues and cell types, a substantial improvement over prior sequence-based expression models, which were typically limited to narrower regulatory regions (&lt;2 kb) and fewer cell types.\nBeyond predicting absolute expression levels, ExPecto captures tissue-specific expression patterns. Analysis of model coefficients reveals automatic learning of cell-type-relevant features without explicit tissue labels. The liver expression model assigns top weights to transcription factors profiled in HepG2 (liver-derived) cells. The breast tissue model weights estrogen receptor and glucocorticoid receptor features from breast cancer cell lines most heavily among its positive coefficients. These patterns emerge purely from learning to predict expression, without any tissue identity information provided to the chromatin features.\nModel coefficients also reveal the relative contributions of different chromatin feature types. Transcription factors and histone marks receive consistently higher weights, reflecting their direct mechanistic roles in transcriptional regulation. DNase I features receive significantly lower weights despite indicating regulatory activity. This discrepancy likely reflects that DNase hypersensitivity marks the presence of regulatory activity without specifying its type or causal relationship to expression.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: ExPecto performance\n\nScatter plot of predicted vs. observed expression for a representative tissue; (2) bar chart of per-tissue correlation; (3) example delta-expression scores for variants near a gene with multiple nearby regulatory elements.\n\n\n\n\n\n10.2.4 Variant Effect Prediction\nExPecto’s expression predictions enable scoring variant effects through in silico mutagenesis: predict expression with reference allele, predict with alternative allele, and compute the difference:\n\\[\n\\Delta \\text{expression} = f(\\text{sequence}_{\\text{alt}}) - f(\\text{sequence}_{\\text{ref}})\n\\]\nBecause the model never trains on variant data, predictions are unconfounded by linkage disequilibrium, a fundamental advantage over statistical eQTL approaches.\nExPecto correctly predicted the direction of expression change for 92% of the top 500 strongest-effect GTEx eQTL variants. Prediction accuracy increases with predicted effect magnitude: variants with stronger predicted effects show higher eQTL direction concordance, consistent with the expectation that true causal variants should have larger predicted effects.\nTraditional eQTL studies face fundamental limitations. Linkage disequilibrium confounds causal inference: only 3.5 to 11.7% of GTEx lead variants are estimated to be truly causal. ExPecto’s sequence-based predictions sidestep this limitation: the model scores variants based on predicted functional impact rather than population associations, works identically for any allele frequency, and leverages expression training data from many tissues even when eQTL data is unavailable.\n\n\n10.2.5 GWAS Variant Prioritization\nZhou et al. applied ExPecto to prioritize variants from approximately 3,000 GWAS studies. GWAS loci with stronger predicted effect variants were significantly more likely to replicate in independent studies (p = 6.3×10⁻¹⁸⁹). The framework can identify causal variants that statistical association alone cannot distinguish.\nThe authors experimentally validated three top-ranked ExPecto predictions for immune-related diseases using luciferase reporter assays. In all cases, the ExPecto-prioritized variants showed significant allele-specific regulatory activity, while the original GWAS lead variants showed no differential activity.\n\n\n\n\n\n\n\n\n\n\nDisease\nExPecto-Prioritized SNP\nGene\nReporter Effect\np-value\n\n\n\n\nCrohn’s disease / IBD\nrs1174815\nIRGM\nDecreased expression\n3×10⁻⁶\n\n\nBehçet’s disease\nrs147398495\nCCR1\nChanged activity\n7×10⁻¹⁰\n\n\nChronic HBV infection\nrs381218\nHLA-DOA\n4-fold change\n1×10⁻⁹\n\n\n\n\n\n10.2.6 In Silico Saturation Mutagenesis\nThe computational efficiency of ExPecto enables exhaustive characterization of the regulatory mutation space. The authors computed predicted effects for all possible single nucleotide substitutions within ±1 kb of each TSS, covering over 140 million mutations across 23,779 human genes. This identified more than 1.1 million mutations with strong predicted expression effects.\nFor each gene, the comprehensive mutagenesis profile defines its “variation potential” (VP), the collective effects of all possible mutations on that gene’s expression. VP correlates with known biological properties: tissue-specific genes show lower VP than broadly expressed genes, and genes under stronger evolutionary constraint tend to have higher VP.\n\n\n10.2.7 The 40 kb Regulatory Window\nExPecto’s ±20 kb window around each TSS represents an empirically optimized trade-off. Smaller windows decreased prediction performance, while larger windows (50 to 200 kb) showed negligible improvement. This suggests that most regulatory information for promoter-proximal expression lies within 40 kb of the TSS, at least within the linear modeling framework employed by ExPecto. Distal enhancers beyond this window, while biologically important, likely require more sophisticated integration approaches. Enformer (Chapter 14), with its 200 kb effective receptive field, addresses this limitation.\n\n\n10.2.8 Limitations\nWhile the chromatin CNN captures nonlinear sequence patterns, the final expression model is linear. This prevents modeling of complex regulatory logic such as synergistic interactions between elements, competitive binding, or threshold effects. The 40 kb window misses distal enhancers operating over hundreds of kilobases and three-dimensional chromatin interactions. The TSS-centric framework may limit predictions for genes with multiple alternative promoters or tissue-specific promoter usage. Expression models trained on GTEx, Roadmap, and ENCODE data inherit their biases in ancestry composition, tissue representation, and cell line artifacts.\n\n\n10.2.9 Significance\nExPecto established several paradigms that influenced subsequent genomic deep learning. The modular sequence-to-expression prediction architecture demonstrated the value of decomposing the problem into chromatin prediction, spatial integration, and expression modeling. Ab initio variant effect prediction, achieved by training without variant data, avoids LD confounding and enables causal inference rather than mere association. The framework demonstrated that deep learning could move beyond predicting intermediate molecular phenotypes to predict cellular phenotypes directly from sequence.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: ExPecto interpretability\nHeatmap of linear model coefficients for a single tissue, with y-axis = chromatin marks, x-axis = distance bins relative to TSS, showing which marks and distances drive expression.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>CNN Sequence-to-Function Models</span>"
    ]
  },
  {
    "objectID": "p3-ch10-cnn.html#sec-splice",
    "href": "p3-ch10-cnn.html#sec-splice",
    "title": "10  CNN Sequence-to-Function Models",
    "section": "10.3 SpliceAI: Splicing Prediction",
    "text": "10.3 SpliceAI: Splicing Prediction\n\n10.3.1 The Splicing Challenge\nWhile DeepSEA and ExPecto addressed chromatin state and gene expression, a distinct class of functional variants operates through a different mechanism: disruption of pre-mRNA splicing. The spliceosome achieves remarkable precision, recognizing the correct splice sites among millions of potential candidates in the human transcriptome. Yet the sequence determinants underlying this specificity remained incompletely understood, limiting interpretation of variants that might alter splicing.\nThe clinical stakes are substantial. As discussed in Chapter 1, variant calling pipelines identify thousands of variants per exome and millions per genome, but annotation frameworks traditionally focus on coding consequences. Variants affecting splicing outside the canonical GT/AG dinucleotides are systematically underascertained, even though splice-disrupting mutations are a major mechanism of Mendelian disease. The ACMG/AMP guidelines (Chapter 2) recognize splicing evidence as supporting pathogenicity, but until recently, computational tools lacked the accuracy to identify cryptic splice variants reliably.\nSpliceAI, introduced by Jaganathan et al. in 2019, demonstrated that deep neural networks could learn the sequence rules governing splicing with near-spliceosomal precision (Jaganathan et al. 2019). The model predicts splice site locations directly from pre-mRNA sequence, enabling identification of “cryptic splice” variants that create novel splice sites or disrupt existing ones in ways that evade traditional annotation-based detection.\n\n\n10.3.2 Prior Approaches and Limitations\nBefore SpliceAI, splice site prediction relied on methods with limited sequence context. MaxEntScan models core splice motifs using maximum entropy, limited to approximately 9 bp context around donor/acceptor sites (Yeo and Burge 2004). GeneSplicer combines Markov models with decision trees. NNSplice represents an early neural network approach with narrow receptive fields. These methods captured the essential GT (donor) and AG (acceptor) dinucleotides and surrounding consensus sequences, but could not model the long-range determinants that contribute to splicing specificity.\nThe limitations parallel those of pre-deep-learning variant effect predictors like CADD (Chapter 4), which aggregate many annotation features but lack the capacity to learn complex sequence dependencies. Prior methods produced many false positive predictions and missed variants acting through distal mechanisms.\n\n\n10.3.3 The SpliceAI Architecture\nSpliceAI employs an ultra-deep residual convolutional network that integrates information across 10,000 nucleotides of sequence context. This represents an order of magnitude expansion beyond prior methods and reflects the same architectural intuition that motivated ExPecto’s 40 kb regulatory window: functional genomic predictions often require long-range context that shallow models cannot capture.\n\n10.3.3.1 Input Representation\nLike DeepSEA and ExPecto, SpliceAI uses one-hot encoded nucleotide sequences as input. The four nucleotides are encoded as binary vectors, with no hand-crafted features or annotations. This end-to-end learning approach forces the network to discover relevant sequence patterns from training data. The input window spans 10,000 nucleotides (5,000 on each side of the position of interest), providing context for recognizing distant determinants like branch points, exonic splicing enhancers, and intron/exon length constraints.\n\n\n10.3.3.2 Residual Block Design\nThe architecture’s fundamental unit is the residual block, comprising batch normalization, ReLU activation, and dilated convolutions. Residual connections address the vanishing gradient problem that had limited earlier deep networks:\n\\[\n\\text{output} = \\text{input} + F(\\text{input})\n\\]\nThis design enables training of networks with 32 layers, far deeper than the 3-layer DeepSEA or 6-layer ExPecto/Beluga architectures. Skip connections from every fourth residual block feed directly to the penultimate layer, accelerating training convergence and enabling gradient flow through the full network depth.\n\n\n10.3.3.3 Dilated Convolutions\nStandard convolutions with small kernels would require many layers to achieve a 10,000 bp receptive field. SpliceAI uses dilated convolutions that exponentially expand the receptive field while maintaining computational efficiency. A dilated convolution with dilation rate \\(d\\) samples input positions at intervals of \\(d\\) rather than consecutively. By stacking convolutions with increasing dilation rates, the network can efficiently integrate information across the full 10 kb window while maintaining sensitivity to local motif patterns.\n\n\n10.3.3.4 Output Predictions\nFor each position in the pre-mRNA sequence, SpliceAI outputs three probabilities summing to one: the probability of being a splice acceptor, splice donor, or neither. This per-position classification enables fine-grained predictions across entire transcripts.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: SpliceAI architecture\nDiagram showing: (1) 10 kb one-hot input; (2) stack of residual blocks with increasing dilation; (3) per-position output track with donor/acceptor probabilities, highlighting canonical and cryptic sites.\n\n\n\n\n\n10.3.4 Training and Performance\nSpliceAI was trained on GENCODE V24 annotations, using 20,287 protein-coding genes with principal transcripts selected when multiple isoforms existed. The training/test split used odd versus even chromosomes, with genes having paralogs on training chromosomes excluded from the test set to prevent information leakage.\n\n\n\nSet\nChromosomes\nGenes\nDonor-Acceptor Pairs\n\n\n\n\nTraining\n2, 4, 6, 8, 10-22, X, Y\n13,384\n130,796\n\n\nTesting\n1, 3, 5, 7, 9\n1,652\n14,289\n\n\n\nSpliceAI-10k achieved remarkable accuracy, with 95% top-k accuracy (compared to 57% for MaxEntScan) and 0.98 PR-AUC. Even complex genes exceeding 100 kb, such as CFTR, are often reconstructed perfectly to nucleotide precision.\nPerformance improved substantially with context length:\n\n\n\nModel\nContext (each side)\nPR-AUC\n\n\n\n\nSpliceAI-80nt\n40 bp\n0.87\n\n\nSpliceAI-400nt\n200 bp\n0.93\n\n\nSpliceAI-2k\n1,000 bp\n0.96\n\n\nSpliceAI-10k\n5,000 bp\n0.98\n\n\n\nThis progression confirms that distal sequence features thousands of nucleotides from splice sites contribute meaningfully to splicing decisions.\n\n\n10.3.5 The Delta Score\nSpliceAI predicts variant effects by comparing splice site predictions for reference and alternative sequences:\n\\[\n\\Delta\\text{score} = \\max_{|p - v| \\leq 50} \\left| P_{\\text{alt}}(p) - P_{\\text{ref}}(p) \\right|\n\\]\nwhere \\(v\\) is the variant position and \\(p\\) ranges over positions within 50 bp of the variant. The maximum change across all positions captures variants that strengthen existing sites, weaken existing sites, or create entirely new splice sites.\nCritically, the model was trained only on reference transcript sequences and splice junction annotations. It never saw variant data during training. Variant effect prediction is thus a challenging test of whether the network learned genuine sequence determinants of splicing.\nSpliceAI detects several classes of splice-altering variants: donor/acceptor loss (disruption of annotated sites), donor/acceptor gain (creation of novel sites), exon skipping, intron retention, and cryptic exon activation (deep intronic variants activating pseudoexons).\n\n\n10.3.6 Validation\n\n10.3.6.1 RNA-seq Validation\nThe authors validated predictions using GTEx RNA-seq data from 149 individuals with matched whole-genome sequencing. Focusing on rare, private mutations, they found that mutations predicted to have functional consequences were strongly enriched at novel splice junctions. Validation rates tracked closely with Δ scores:\n\n\n\nΔ Score Threshold\nValidation Rate\n\n\n\n\n≥ 0.2\n~50%\n\n\n≥ 0.5\n~75%\n\n\n≥ 0.8\n~85%\n\n\n\n\n\n10.3.6.2 Population Genetics Evidence\nPredicted cryptic splice variants (Δ score ≥ 0.8) showed 78% depletion at common allele frequencies compared to singletons, nearly matching the 82% depletion of frameshift, stop-gain, and essential splice disruptions. This population genetics signature provides orthogonal evidence that predictions identify genuinely functional variants.\nThe average human genome carries approximately 11 rare protein-truncating variants and 5 rare functional cryptic splice variants. Cryptic splice variants outnumber essential GT/AG splice-disrupting variants roughly 2:1.\n\n\n\n10.3.7 Clinical Impact: De Novo Mutations in Rare Disease\nThe central clinical finding of SpliceAI is that cryptic splice mutations constitute a major, previously underappreciated cause of rare genetic disorders. This represents one of SpliceAI’s most compelling applications: exome or genome sequencing often reveals no obvious coding variant explaining a patient’s phenotype, but re-examining intronic and synonymous variants with SpliceAI can reveal strong splice-disrupting candidates.\nThe authors analyzed de novo mutations in 4,293 individuals with intellectual disability and 3,953 individuals with autism spectrum disorders, compared to 2,073 unaffected sibling controls. De novo mutations predicted to disrupt splicing (Δ ≥ 0.1) were significantly enriched in affected individuals:\n\n\n\nCohort\nEnrichment vs. Controls\np-value\n\n\n\n\nIntellectual disability\n1.51-fold\n4.2×10⁻⁴\n\n\nAutism spectrum disorder\n1.30-fold\n0.020\n\n\n\nBased on the excess of de novo mutations in cases versus controls, approximately 9% of pathogenic de novo mutations in intellectual disability and 11% in autism act through cryptic splicing. In absolute terms, approximately 250 cases across the cohorts could be explained by de novo cryptic splice mutations.\nIncluding cryptic splice mutations in gene discovery analyses identified 5 additional candidate genes for intellectual disability and 2 additional genes for autism that would have fallen below discovery thresholds when considering only protein-coding mutations.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: SpliceAI clinical example\nCase-style figure showing: (A) patient variant deep within an intron; (B) SpliceAI delta score track; (C) RNA-seq sashimi plot illustrating the predicted aberrant splice junction.\n\n\n\n\n10.3.8 What SpliceAI Learned\nBeyond prediction accuracy, SpliceAI provides mechanistic insights. Comparison of models trained on different context lengths revealed that apparent “degeneracy” in splice motifs is explained by long-range determinants. In silico mutagenesis experiments confirmed that SpliceAI learned canonical splicing elements: introducing the optimal branch point sequence at various distances from splice acceptors increased predicted splice strength specifically when placed 20-45 nucleotides upstream, matching the known functional range. The SR-protein binding motif GAAGAA enhanced splice site strength when placed in expected exonic locations (Jaganathan et al. 2019).\nNovel exon-creation events were significantly associated with existing nucleosome positioning, supporting a causal role for nucleosome occupancy in exon definition and demonstrating that SpliceAI implicitly captures chromatin-related effects despite not being trained on chromatin data.\n\n\n10.3.9 Limitations\nSpliceAI predicts splice sites based on sequence alone, without modeling tissue-specific alternative splicing. Many cryptic splice variants produce partial shifts rather than complete disruption, and the Δ score correlates with penetrance but does not precisely quantify isoform ratios. While substantially better than prior methods, sensitivity for deep intronic variants (41% at Δ ≥ 0.5) remains lower than for variants near exons. Subsequent work has explored tissue-specific splicing models, transformer-based architectures, and integration of RNA-seq directly into training, themes we revisit in Chapter 12 and Chapter 20.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>CNN Sequence-to-Function Models</span>"
    ]
  },
  {
    "objectID": "p3-ch10-cnn.html#sec-cnn-summary",
    "href": "p3-ch10-cnn.html#sec-cnn-summary",
    "title": "10  CNN Sequence-to-Function Models",
    "section": "10.4 Architectural Progression and Common Themes",
    "text": "10.4 Architectural Progression and Common Themes\nThe three models examined in this chapter share a common foundation while addressing increasingly complex biological questions. All use one-hot encoded DNA sequence as input and convolutional neural networks to learn relevant patterns. All achieve variant effect prediction through comparison of reference and alternative allele predictions, without requiring variant-level training data. All demonstrate that deep learning can discover biologically meaningful patterns from sequence alone.\n\n\n\n\n\n\n\n\n\nFeature\nDeepSEA\nExPecto\nSpliceAI\n\n\n\n\nPrimary task\nChromatin state\nGene expression\nSplice sites\n\n\nContext window\n1 kb\n40 kb\n10 kb\n\n\nArchitecture depth\n3 layers\n6 layers\n32 layers\n\n\nOutput type\nMulti-label classification\nRegression\nPer-position classification\n\n\nTraining data\nENCODE/Roadmap\nGTEx expression\nGENCODE annotations\n\n\nVariant interpretation\nAllelic imbalance\nExpression effect\nΔ score\n\n\n\nThe progression from DeepSEA to SpliceAI illustrates several themes. First, context length matters: 1 kb suffices for local regulatory element recognition, but expression and splicing require integration over tens of kilobases. Second, architectural depth enables capture of longer-range dependencies: the 32-layer SpliceAI could not have been trained with 2015-era techniques. Third, task-specific architectures can achieve remarkable accuracy: SpliceAI’s focus on splice sites yields near-spliceosomal precision.\nYet these models also share limitations. All assume reference genome context, scoring variants in isolation without considering other variants in the same individual. All are trained on human data and may not transfer well to other species. All require experimental validation for clinical applications.\n\n10.4.1 Task Specificity vs. Foundation Models\nThese CNN models represent a different design philosophy from the foundation model approach explored in Parts III and IV. Rather than learning general sequence representations that transfer across tasks, each model focuses computational capacity on a single problem. SpliceAI’s representations do not obviously transfer to chromatin prediction; ExPecto’s chromatin model was purpose-built for expression prediction.\nThis specialization has both advantages and limitations. Task-specific models achieve remarkable accuracy on their target problems, but require separate training for each new application. Later chapters will explore whether self-supervised foundation models can match task-specific performance while providing broader utility (Chapter 11; Chapter 7).\nThe tension between specialized and general-purpose models remains unresolved. For clinical applications requiring high accuracy on specific tasks, specialized models like SpliceAI may remain preferred. For discovery applications requiring broad coverage of molecular mechanisms, foundation models may prove more valuable.\n\n\n10.4.2 Tissue-Specific Model Specialization\nThe CNN models discussed in this chapter primarily aim for broad coverage across cell types and assays, training on diverse ENCODE and Roadmap Epigenomics data to learn generalizable regulatory patterns. An alternative strategy focuses computational capacity on a single tissue or disease context, trading breadth for depth in biologically targeted applications.\nTREDNet exemplifies this tissue-specific approach (Hudaiberdiev et al. 2023). Rather than predicting chromatin features across hundreds of cell types, TREDNet trains specifically on pancreatic islet enhancer data to identify candidate causal variants at type 2 diabetes and glycemic trait GWAS loci. This narrow focus allows the model to learn regulatory patterns specific to islet biology that might be diluted in pan-tissue training, while sacrificing applicability to other tissues. The tradeoff between specialized depth and general breadth recurs throughout this book: foundation models in Parts III and IV generally favor breadth, but disease-specific fine-tuning remains valuable when the clinical question is well-defined and training data for the relevant tissue are available.\n\n\n10.4.3 Integration with Variant Interpretation\nAll three models contribute to modern variant interpretation pipelines. DeepSEA and Sei scores indicate regulatory potential. ExPecto predictions prioritize expression-altering variants. SpliceAI Δ scores support splicing evidence in ACMG/AMP classification. These predictions complement protein-effect predictors and provide independent evidence types for clinical interpretation (Chapter 20).\nThe models also established expectations for the field: public web servers, downloadable code and weights, rigorous validation against orthogonal data sources, and clear articulation of limitations. These norms have persisted as genomic deep learning has grown in scope and ambition.\nPart III turns to transformer-based architectures and self-supervised learning, approaches that aim to learn general-purpose sequence representations applicable across many tasks rather than optimizing for single prediction targets. The CNN models examined here provide essential context for understanding what transformers must improve upon and what accuracy standards they must meet.\n\n\n\n\n\n\nWarning\n\n\n\nVISUAL SUGGESTION: Comparative summary\nTable or figure comparing DeepSEA, ExPecto, and SpliceAI along axes such as: input context length, architecture depth, primary output (chromatin, expression, splicing), multi-task targets, typical clinical/research use cases, and key limitations.\n\n\n\n\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nHudaiberdiev, Sanjarbek, D. Leland Taylor, Wei Song, Narisu Narisu, Redwan M. Bhuiyan, Henry J. Taylor, Xuming Tang, et al. 2023. “[TREDNet] Modeling Islet Enhancers Using Deep Learning Identifies Candidate Causal Variants at Loci Associated with T2D and Glycemic Traits.” Proceedings of the National Academy of Sciences 120 (35): e2206612120. https://doi.org/10.1073/pnas.2206612120.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nKagda, Meenakshi S., Bonita Lam, Casey Litton, Corinn Small, Cricket A. Sloan, Emma Spragins, Forrest Tanaka, et al. 2025. “Data Navigation on the ENCODE Portal.” Nature Communications 16 (1): 9592. https://doi.org/10.1038/s41467-025-64343-9.\n\n\nKundaje, Anshul, Wouter Meuleman, Jason Ernst, Misha Bilenky, Angela Yen, Alireza Heravi-Moussavi, Pouya Kheradpour, et al. 2015. “Integrative Analysis of 111 Reference Human Epigenomes.” Nature 518 (7539): 317–30. https://doi.org/10.1038/nature14248.\n\n\nMaurano, Matthew T., Richard Humbert, Eric Rynes, Robert E. Thurman, Eric Haugen, Hao Wang, Alex P. Reynolds, et al. 2012. “Systematic Localization of Common Disease-Associated Variation in Regulatory DNA.” Science 337 (6099): 1190–95. https://doi.org/10.1126/science.1222794.\n\n\nPoplin, Ryan, Pi-Chuan Chang, David Alexander, Scott Schwartz, Thomas Colthurst, Alexander Ku, Dan Newburger, et al. 2018. “[DeepVariant] A Universal SNP and Small-Indel Variant Caller Using Deep Neural Networks.” Nature Biotechnology 36 (10): 983–87. https://doi.org/10.1038/nbt.4235.\n\n\nYeo, Gene, and Christopher B. Burge. 2004. “Maximum Entropy Modeling of Short Sequence Motifs with Applications to RNA Splicing Signals.” Journal of Computational Biology 11 (2-3): 377–94. https://doi.org/10.1089/1066527041410418.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>CNN Sequence-to-Function Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html",
    "href": "p3-ch11-dna.html",
    "title": "11  DNA and Genomic Models",
    "section": "",
    "text": "11.1 From Supervised CNNs to Self-Supervised Genomic Language Models\nGenomic language models extend the ideas of protein language models (Chapter 13) to the DNA level. They treat genomes themselves as a corpus, learn statistical regularities through self-supervision, and reuse those representations for many downstream tasks. Where Chapters 5–7 focused on supervised sequence-to-function CNNs and specialized architectures, and Chapter 5 focused on representation and tokenization, this chapter turns to genomic foundation models: large, often transformer-based or hybrid architectures trained on unlabeled genomic sequence at scale.\nThese models aim to provide a single, reusable backbone for tasks ranging from regulatory annotation and variant effect prediction to cross-species transfer and clinical prioritization. They mark the transition from building one model per dataset to constructing general-purpose genomic backbones analogous to BERT, GPT, and ESM in natural and protein language modeling.\nThe CNN era represented by DeepSEA, ExPecto, and SpliceAI (Chapters 5–7) shared a common pattern. Models took one-hot encoded DNA sequence around a locus as input, predicted task-specific labels such as chromatin marks, expression levels, or splice junctions, and optimized supervised loss functions against those labels. This approach achieved remarkable performance but suffered from three fundamental constraints.\nThe first constraint was label dependence. Every new assay, cell type, or phenotype required new labeled data to train a model. A chromatin accessibility model trained on ENCODE data could not predict histone modifications without additional labeled examples for those marks. This created substantial overhead for each new application.\nThe second constraint was task coupling. Model design became tightly coupled to the specific task. SpliceAI’s architecture was specialized for splice junction prediction, with convolutions designed to capture the relevant spatial patterns. ExPecto’s spatial feature transformation was engineered specifically for the distance-dependent relationship between regulatory elements and transcription start sites. These architectural choices, while effective for their intended purposes, did not transfer naturally to other problems.\nThe third constraint was limited reuse. Features learned for one problem did not automatically transfer to others. A model trained to predict chromatin accessibility might learn representations of regulatory motifs, but those representations were not directly accessible for other tasks like variant effect prediction or gene expression modeling without substantial re-engineering.\nProtein language models showed a different route: self-supervised learning on unlabeled sequences, with downstream tasks solved by probing or fine-tuning. Genomic language models import this recipe to DNA. The training data comprises large collections of genomic sequences across species, individuals, or functional regions. The training objectives include masked language modeling, where the model predicts masked bases or tokens from surrounding context, and next-token or sequence modeling, where the model predicts the next token in a sequence. Some models combine these self-supervised objectives with auxiliary tasks such as predicting known annotations.\nThese pretrained models can be used in multiple ways. The simplest approach freezes the model and trains lightweight probes for specific tasks. Fine-tuning updates the entire model or uses adapter modules for specialized downstream applications. Zero-shot or few-shot scoring compares log-likelihoods of alternative sequences or alleles without any task-specific training. The promise is that once a sufficiently powerful backbone is trained, it becomes the default starting point for nearly any DNA-level prediction problem.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#from-supervised-cnns-to-self-supervised-genomic-language-models",
    "href": "p3-ch11-dna.html#from-supervised-cnns-to-self-supervised-genomic-language-models",
    "title": "11  DNA and Genomic Models",
    "section": "",
    "text": "Note\n\n\n\nFigure suggestion: Side-by-side comparison showing the supervised CNN paradigm (left panel: fixed architecture trained for specific chromatin prediction task) versus the self-supervised language model paradigm (right panel: general backbone pretrained on unlabeled sequence, then adapted to multiple downstream tasks with lightweight heads).",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#dnabert-bert-for-k-merized-dna",
    "href": "p3-ch11-dna.html#dnabert-bert-for-k-merized-dna",
    "title": "11  DNA and Genomic Models",
    "section": "11.2 DNABERT: BERT for K-merized DNA",
    "text": "11.2 DNABERT: BERT for K-merized DNA\nDNABERT applied the BERT masked language modeling framework to genomic sequences, using overlapping k-mers (typically 6-mers) as tokens and training on human reference sequences (Ji et al. 2021). As discussed in Chapter 5, this design had several defining characteristics.\nThe tokenization scheme converted DNA sequences into overlapping k-mers, creating a discrete vocabulary of size \\(4^k\\). For 6-mers, this yields a vocabulary of 4,096 tokens. The model used the standard BERT architecture with masked token prediction as its training objective. Context windows were relatively modest, spanning a few hundred base pairs (typically 512 tokens). The model was then fine-tuned on downstream tasks including promoter classification, splice site prediction, and transcription factor binding site identification.\nDNABERT provided proof of concept for several important ideas. Self-supervised pretraining on raw DNA can improve performance over training from scratch. Learned embeddings capture biologically meaningful regularities, even when trained only on the reference genome. BERT-style architectures can be re-used across multiple downstream tasks with modest fine-tuning.\nHowever, the k-mer design introduced significant limitations detailed in Chapter 5. The overlapping k-mer tokenization provided no true sequence compression, as each nucleotide participated in multiple adjacent tokens. This created ambiguity in positional interpretation, since the precise position of a variant within the k-mer vocabulary was unclear. The quadratic attention complexity of transformers combined with redundant overlapping tokens severely limited the effective context length.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#dnabert-2-improved-tokenization-and-efficiency",
    "href": "p3-ch11-dna.html#dnabert-2-improved-tokenization-and-efficiency",
    "title": "11  DNA and Genomic Models",
    "section": "11.3 DNABERT-2: Improved Tokenization and Efficiency",
    "text": "11.3 DNABERT-2: Improved Tokenization and Efficiency\nDNABERT-2 revisited both tokenization and architecture, demonstrating how much representation choices matter for genomic language models (Zhou et al. 2024). The key differences relative to the original DNABERT addressed its core limitations.\nThe tokenization scheme adopted improved approaches such as BPE-style merges that better compress redundancies and reduce effective sequence length. This allowed the model to represent longer genomic contexts within the same number of tokens. Architectural refinements improved efficiency, enabling scaling to larger contexts and training corpora without prohibitive memory costs.\nOn standardized benchmarks spanning sequence classification, regulatory element prediction, and variant effect scoring, DNABERT-2 achieved consistent gains over both the original DNABERT and non-pretrained baselines. These improvements validated the importance of thoughtful tokenization design for genomic applications.\nThe DNABERT family collectively established three important principles. Self-supervision on DNA works and is competitive with hand-engineered pipelines for many sequence annotation tasks. Tokenization choices have large practical consequences, as the seemingly minor decision of how to convert nucleotides into tokens substantially affects both computational efficiency and downstream performance. Masked language model training can produce reusable representations for diverse sequence tasks, suggesting that the foundation model paradigm transfers effectively from natural language to genomic sequence.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#nucleotide-transformer-scaling-context-and-diversity",
    "href": "p3-ch11-dna.html#nucleotide-transformer-scaling-context-and-diversity",
    "title": "11  DNA and Genomic Models",
    "section": "11.4 Nucleotide Transformer: Scaling Context and Diversity",
    "text": "11.4 Nucleotide Transformer: Scaling Context and Diversity\nDNABERT demonstrated feasibility, but its context windows and training data were modest relative to the scale of genomes. The Nucleotide Transformer pushed much further, emphasizing scale and diversity in both model size and training corpus (Dalla-Torre et al. 2023).\nThe training corpus spanned genomic data from multiple species and populations, exposing the model to diverse sequence patterns. The architecture comprised transformer encoders of various sizes, from moderate to very large parameter counts. Context length expanded to approximately 6 kb per input sequence, representing an order-of-magnitude increase over DNABERT while still using dense attention. The training objective remained masked language modeling on subsequences sampled from genomes.\nThe Nucleotide Transformer work contributed several important ideas to the field. Cross-species pretraining, where training spans many genomes rather than a single reference, exposes the model to diverse sequence patterns, different regulatory architectures, and evolutionary constraints that recur across lineages. This mirrors the use of large multi-species multiple sequence alignments in protein language models but operates at the raw DNA level.\nTo quantify representation quality, the Nucleotide Transformer introduced a benchmark panel of genomic tasks that has become a standard yardstick for subsequent DNA language models. Typical tasks include promoter and enhancer classification, histone mark and chromatin accessibility prediction, variant and pathogenicity proxies, and regulatory element type classification. Models are evaluated via linear probes, shallow classifiers, or light fine-tuning.\nAs with protein and natural-language models, performance improved predictably with larger models, more pretraining data, and longer context windows. These scaling trends help forecast the returns from investing in even larger genomic language models.\n\n\n\n\n\n\nNote\n\n\n\nTable suggestion: Comparison table showing key model characteristics:\n\n\n\nModel\nArchitecture\nMax Context\nComplexity\n\n\n\n\nDNABERT\nTransformer\n512 bp\n\\(O(L^2)\\)\n\n\nNucleotide Transformer\nTransformer\n6 kb\n\\(O(L^2)\\)\n\n\nHyenaDNA\nHyena\n1 Mb\n\\(O(L \\log L)\\)\n\n\nCaduceus\nMamba\n1 Mb\n\\(O(L)\\)",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#gpn-cross-species-pretraining-for-variant-effect-prediction",
    "href": "p3-ch11-dna.html#gpn-cross-species-pretraining-for-variant-effect-prediction",
    "title": "11  DNA and Genomic Models",
    "section": "11.5 GPN: Cross-Species Pretraining for Variant Effect Prediction",
    "text": "11.5 GPN: Cross-Species Pretraining for Variant Effect Prediction\nWhile the Nucleotide Transformer demonstrated the value of scaling, the Genomic Pre-trained Network (GPN) explored a complementary direction: what can be learned from cross-species pretraining on relatively small, well-annotated genomes (Benegas, Batra, and Song 2023). Rather than scaling to the largest possible model and training corpus, GPN asked whether the self-supervised paradigm could yield useful variant effect predictors even in a more constrained setting.\nGPN was trained on unaligned reference genomes from Arabidopsis thaliana and seven related species within the Brassicales order. The training objective was masked language modeling on DNA sequences, predicting masked nucleotides from surrounding context. This is the same fundamental objective used by DNABERT and the Nucleotide Transformer, but applied to a much smaller and more phylogenetically focused corpus.\nThe key insight from GPN was that self-supervised DNA language models learn biologically meaningful representations without explicit supervision on functional annotations. Analysis of the trained model revealed emergent encoding of gene structure, including exon-intron boundaries and splice sites, as well as DNA sequence motifs associated with transcription factor binding and other regulatory functions. The model discovered these patterns purely from the statistical regularities of genomic sequence across related species.\nFor variant effect prediction, GPN used a likelihood ratio approach. Given a reference and alternate allele at a position, the model computes the log-likelihood of each under the learned sequence distribution. Variants that substantially reduce sequence likelihood, relative to the reference, are inferred to be more disruptive. This scoring strategy exploits the fact that constrained positions should have confident predictions for the reference allele, while unconstrained positions allow more flexibility.\nEvaluated on A. thaliana variants using allele frequencies from the 1001 Genomes Project and a comprehensive database of GWAS associations, GPN outperformed traditional conservation scores including phyloP and phastCons. This was notable because phyloP and phastCons are computed from explicit multiple sequence alignments and evolutionary models, while GPN learned its representations from unaligned sequences through self-supervision alone.\nGPN established several principles that would influence subsequent work. First, cross-species pretraining captures evolutionary constraints that transfer to variant effect prediction, even without alignment-based conservation calculations. Second, relatively small models trained on focused phylogenetic groups can outperform larger generic conservation measures for species within that group. Third, the masked language modeling objective naturally produces representations suitable for variant scoring via likelihood comparisons.\nThe limitation of the original GPN was its scope. Training on plant genomes did not directly produce a human variant effect predictor. The later GPN-MSA addressed this gap by incorporating multi-species alignments and training on mammalian genomes, achieving strong performance on human variant benchmarks as discussed in Chapter 20. However, the original GPN remains important as a demonstration that the DNA language model paradigm extends beyond model organisms and can discover biologically meaningful patterns through self-supervision on comparatively modest training data.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#hyenadna-megabase-context-at-single-nucleotide-resolution",
    "href": "p3-ch11-dna.html#hyenadna-megabase-context-at-single-nucleotide-resolution",
    "title": "11  DNA and Genomic Models",
    "section": "11.6 HyenaDNA: Megabase Context at Single-Nucleotide Resolution",
    "text": "11.6 HyenaDNA: Megabase Context at Single-Nucleotide Resolution\nQuadratic attention limits transformer context length to tens of kilobases at best, even with aggressive engineering. This is a fundamental architectural constraint: processing a 100 kb sequence with dense attention requires on the order of \\(10^{10}\\) attention computations per layer. HyenaDNA addressed this limitation by replacing attention with a Hyena long-convolution architecture that scales sub-quadratically, enabling processing of sequences up to 1 Mb in length (Nguyen et al. 2023).\nThe Hyena architecture uses implicit convolutions, parameterizing long convolutional filters through neural networks rather than storing explicit filter weights. This approach achieves \\(O(L \\log L)\\) complexity through efficient FFT-based convolution, compared to the \\(O(L^2)\\) complexity of standard attention. The result is a 500-fold increase in context length over previous dense attention models while maintaining single-nucleotide resolution.\nHyenaDNA introduced several qualitative advances that matter for biological applications. Processing megabase-scale windows allows the model to see entire gene bodies plus their flanking regulatory regions, long-range enhancer-promoter interactions spanning tens to hundreds of kilobases, and topologically associating domain (TAD) scale structure. This aligns better with biological reality, where regulatory interactions often span substantial genomic distances.\nDespite its long context, HyenaDNA maintains base-level resolution by using single-nucleotide tokens. This means single-nucleotide variants can be evaluated in the context of megabases of surrounding sequence without the ambiguity introduced by k-mer tokenization.\nOn Nucleotide Transformer benchmarks and additional tasks, HyenaDNA demonstrated in-context learning behaviors that had not previously been observed in genomic models. Performance improved when examples were included in the input context without updating model weights, suggesting that at sufficient scale, DNA models can adapt to new tasks or distributions via prompts rather than fine-tuning. This mirrors phenomena observed in large natural language models.\nOn GenomicBenchmarks and related evaluations, HyenaDNA achieved state-of-the-art results on the majority of tasks, often by substantial margins. These results illustrated that architectural innovations enabling longer context can simultaneously provide both extended range and improved predictive accuracy.\n\n\n\n\n\n\nNote\n\n\n\nFigure suggestion: Visualization showing the dramatic expansion of context length across genomic language models, with representative regulatory phenomena (TF binding sites, enhancer-promoter loops, TAD boundaries) marked at their characteristic length scales. Models plotted chronologically from DNABERT (512 bp) through Nucleotide Transformer (6 kb) to HyenaDNA (1 Mb).",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#caduceus-bidirectional-modeling-with-reverse-complement-equivariance",
    "href": "p3-ch11-dna.html#caduceus-bidirectional-modeling-with-reverse-complement-equivariance",
    "title": "11  DNA and Genomic Models",
    "section": "11.7 Caduceus: Bidirectional Modeling with Reverse-Complement Equivariance",
    "text": "11.7 Caduceus: Bidirectional Modeling with Reverse-Complement Equivariance\nA unique challenge in genomic sequence modeling is the double-stranded nature of DNA. Any sequence can be read from either strand, and the reverse complement of a sequence encodes the same information from the opposite strand’s perspective. For many biological processes, predictions should be identical or related in a consistent way regardless of which strand is presented to the model.\nStandard neural networks can produce divergent predictions for a sequence and its reverse complement, even when training data is augmented with both orientations. This inconsistency is problematic for applications like regulatory element prediction, where the functional element exists on one physical stretch of DNA regardless of how we choose to represent it computationally.\nCaduceus addressed this challenge by building reverse-complement equivariance directly into the architecture (Schiff et al. 2024). The model extends the Mamba architecture, a state-space model with linear complexity in sequence length, to support both bidirectionality and reverse-complement equivariance. The BiMamba component enables information flow in both directions along the sequence, while the MambaDNA block ensures that predictions for a sequence and its reverse complement are mathematically related in the expected way.\nThe architectural innovations in Caduceus serve distinct purposes. Bidirectionality allows each position to incorporate information from both upstream and downstream context, which matters for tasks where the relevant context is not directionally asymmetric. Reverse-complement equivariance ensures consistent predictions across strand orientations, reducing spurious variability and improving calibration.\nOn downstream benchmarks, Caduceus outperformed previous long-range models. On challenging long-range variant effect prediction tasks, Caduceus exceeded the performance of models with ten times as many parameters that did not leverage bidirectionality or equivariance. This suggests that incorporating appropriate biological inductive biases can be as valuable as scaling model size.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#grover-generative-regulatory-foundation-models",
    "href": "p3-ch11-dna.html#grover-generative-regulatory-foundation-models",
    "title": "11  DNA and Genomic Models",
    "section": "11.8 GROVER: Generative Regulatory Foundation Models",
    "text": "11.8 GROVER: Generative Regulatory Foundation Models\nMost genomic language models focus on modeling raw DNA sequence. GROVER takes a complementary approach, shifting attention from sequence to regulatory tracks (Sanabria et al. 2024). Rather than treating DNA as the primary input, GROVER is trained on multi-track functional genomics signals including ATAC-seq, histone modifications, and other epigenomic assays across many cell types and tissues.\nThe training objective predicts masked or held-out regulatory profiles conditioned on neighboring tracks, cell-type embeddings, or limited sequence context. The architecture uses a transformer-style backbone tailored to spatiotemporal grids of genomic positions crossed with assays and cell types.\nGROVER occupies a role analogous to self-supervised vision models for images. It treats regulatory profiles as a high-dimensional signal over the genome and learns rich representations of regulatory states at each position. This supports tasks like imputation of missing assays, denoising of noisy experimental data, and cell-type-specific activity prediction.\nWhile not a pure DNA language model, GROVER-style systems complement sequence-based models in important ways. DNA language models capture what the genome can do, encoding the potential regulatory activities specified by the sequence. Regulatory foundation models like GROVER capture what the genome is actually doing in specific contexts, representing the realized regulatory state in particular cell types and conditions. Later chapters explore how sequence-based and regulatory foundation models can be combined, using DNA language models to parameterize sequence priors and regulatory models for context-specific readouts.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#genslms-codon-tokenization-and-whole-genome-modeling",
    "href": "p3-ch11-dna.html#genslms-codon-tokenization-and-whole-genome-modeling",
    "title": "11  DNA and Genomic Models",
    "section": "11.9 GenSLMs: Codon Tokenization and Whole-Genome Modeling",
    "text": "11.9 GenSLMs: Codon Tokenization and Whole-Genome Modeling\nThe DNA language models discussed thus far, including DNABERT, Nucleotide Transformer, HyenaDNA, and Caduceus, were designed primarily for human and multi-species genomics applications such as regulatory prediction and variant effect estimation. GenSLMs (Genome-scale Language Models) represents a distinct design point that targets pathogen surveillance and viral evolution rather than human regulatory genomics (Zvyagin et al. 2022). The model illustrates how different biological applications motivate different architectural and tokenization choices, even within the broader family of genomic foundation models.\nGenSLMs operates at the codon level rather than the nucleotide level. Where most DNA language models tokenize sequences into nucleotides, k-mers, or BPE-derived subwords, GenSLMs treats each three-nucleotide codon as a single token. This choice reflects an explicit alignment with the central dogma of molecular biology: codons are the fundamental units of translation from nucleic acid to protein, and mutations at the codon level determine amino acid changes that drive phenotypic evolution. The approach yields a vocabulary of 64 codon tokens (plus special tokens for noncoding regions and frame shifts), intermediate in size between character-level tokenization (4 tokens) and typical BPE vocabularies (4,096 to 32,000 tokens).\nThe codon-level tokenization enables GenSLMs to model entire viral genomes as sequences of manageable length. A SARS-CoV-2 genome spans approximately 30,000 nucleotides, which translates to roughly 10,000 codons. This places whole-genome modeling within reach of standard transformer context windows, avoiding the architectural innovations required to handle megabase-scale human sequences. The approach trades single-nucleotide resolution for the ability to capture genome-wide patterns and cross-protein dependencies that would be difficult to model at nucleotide resolution.\nThe training strategy follows a two-stage paradigm. The foundation model was pretrained on over 110 million prokaryotic gene sequences from the BV-BRC database, exposing the model to broad codon usage patterns and gene-level structure across bacterial diversity. This pretraining corpus provided the model with general understanding of coding sequence organization without being specific to any particular pathogen. The model was then fine-tuned on 1.5 million SARS-CoV-2 genome sequences to learn the specific evolutionary landscape of the virus.\nRemarkably, a GenSLM model trained only on sequences from the first year of the pandemic, before Delta or Omicron variants emerged, could subsequently distinguish between variants of concern in its learned embedding space. When new variant sequences were projected into the model’s latent space, they clustered according to lineage identity despite the model never having observed these variants during training. This generalization suggests that the model learned structural features of SARS-CoV-2 evolution that transferred to novel variants, providing a foundation for real-time surveillance applications.\nGenSLMs also revealed interpretable attention patterns across the viral genome. Cross-protein attention showed coupling between the Spike protein and nonstructural proteins (nsp3, nsp5) that differed between Delta and Omicron lineages. These patterns suggest that the model captured biologically meaningful co-evolutionary relationships rather than arbitrary sequence statistics, though the mechanistic interpretation of such patterns remains an area for further investigation.\nFrom a computational perspective, GenSLMs demonstrated that genomic foundation models can be trained at unprecedented scale. The project achieved 1.63 Zettaflops of total computation across training runs, with sustained performance of 121 PFLOPS in mixed precision on GPU-based supercomputers. Training on specialized AI hardware accelerators (Cerebras CS-2 clusters) reduced convergence time from over a week to less than a day. This work received the 2022 Gordon Bell Special Prize for High Performance Computing-Based COVID-19 Research, establishing a benchmark for large-scale genomic model training.\nThe GenSLMs approach highlights several broader lessons for the field. First, tokenization should be aligned with biological semantics when possible. Codon-level tokenization makes sense for coding sequences where the codon-to-amino-acid mapping is the relevant biological transformation. Second, pretraining corpora can be chosen strategically to provide useful inductive biases. Prokaryotic gene pretraining exposed the model to diverse codon usage and gene organization before specializing to a particular virus. Third, different applications motivate different scales. Pathogen surveillance requires whole-genome context but benefits from relatively compact genomes, while human regulatory genomics requires kilobase to megabase context around specific loci.\nThe model’s application to emerging pathogen detection illustrates a use case distinct from the variant effect prediction focus of most human-centric genomic foundation models. Rather than scoring individual mutations for pathogenicity, GenSLMs aims to characterize entire genomes and identify novel variants that may represent public health concerns. This surveillance application places different demands on the model: speed of inference across many sequences, robust generalization to novel variants, and interpretable representations that can guide downstream analysis.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#evo-2-genome-scale-language-modeling-across-all-life",
    "href": "p3-ch11-dna.html#evo-2-genome-scale-language-modeling-across-all-life",
    "title": "11  DNA and Genomic Models",
    "section": "11.10 Evo 2: Genome-Scale Language Modeling Across All Life",
    "text": "11.10 Evo 2: Genome-Scale Language Modeling Across All Life\n\n\n\n\n\n\nWarning\n\n\n\nTODO: Flesh out this section with more detail on architecture, training corpus composition, benchmark performance, and generative capabilities. Add discussion of zero-shot variant scoring methodology and cross-species transfer results.\n\n\nEvo 2 represents the next frontier in genomic foundation models: training at truly genome-scale across the full diversity of life. While previous models either focused on specific organisms (DNABERT on human, GPN on plants, GenSLMs on viruses) or trained on multi-species corpora at more limited scale (Nucleotide Transformer), Evo 2 aims to learn universal genomic patterns that span bacteria, archaea, eukaryotes, and phages.\nThe training corpus for Evo 2 draws from the OpenGenome2 dataset, comprising 9.3 trillion DNA tokens across all domains of life. This massive scale exposes the model to the full spectrum of genomic organization, from compact prokaryotic gene arrangements to sprawling eukaryotic regulatory landscapes with extensive noncoding sequence. The model comes in two sizes: a 7 billion parameter variant suitable for most applications and a 40 billion parameter version for maximum capacity.\nThe architecture builds on StripedHyena 2, a hybrid design that combines convolutional operations with selective attention mechanisms. This enables the model to process sequences up to 1 million tokens (nucleotides) in length while maintaining computational tractability. The autoregressive training objective, predicting the next base given all previous bases, differs from the masked language modeling used in DNABERT and related models, potentially providing complementary strengths for sequence generation and likelihood-based scoring.\nEvo 2 exhibits several forms of emergent biological knowledge despite training only on raw sequence. The model learns to identify exon-intron boundaries without explicit annotation, discovers transcription factor binding site patterns that match known motifs, captures aspects of protein secondary and tertiary structure when processing coding sequences, and even identifies prophage insertion regions in bacterial genomes. These capabilities emerge from pure sequence statistics, demonstrating that genome-scale pretraining captures fundamental biological organization.\nFor variant effect prediction, Evo 2 enables zero-shot scoring via likelihood ratios. By comparing the model’s probability for sequences containing reference versus alternative alleles, variants can be scored for their consistency with learned genomic patterns. On benchmarks of pathogenic versus benign variants, Evo 2’s zero-shot scores achieve competitive performance with specialized supervised methods, though careful calibration remains necessary before clinical application. The model also supports classification of variants of uncertain significance in genes like BRCA1 through simple classifiers trained on its embeddings.\nThe pan-species training enables several cross-species applications. Variant interpretation extends naturally to non-model organisms, supporting conservation genomics and agricultural breeding programs where labeled training data is scarce. The model’s learned representations cluster sequences by phylogenetic relationships even without explicit evolutionary modeling. This makes Evo 2 particularly valuable for applications in livestock genomics, crop improvement, and wildlife conservation where human-trained models provide limited guidance.\nBeyond discriminative tasks, Evo 2 demonstrates generative capabilities. The model can synthesize plausible mitochondrial genomes, prokaryotic operons, and eukaryotic regulatory regions with coherence across kilobase to megabase scales. Inference-time search procedures enable controllable generation with specified properties, such as desired GC content or regulatory motif composition. Recent work has shown that inference-time scaling, where additional computation at test time improves generation quality, applies to genomic generation tasks including prediction of epigenomic structure.\nThe trade-off inherent in Evo 2’s design is generality versus specialization. As a generalist model spanning all life, it may be outperformed by human-specific models like AlphaMissense or tissue-specific models on narrow benchmarks. However, its breadth enables applications beyond the scope of specialized models, particularly in organisms and genomic contexts where training data is limited. The model represents a bet that the shared principles of genome organization across life provide sufficient signal for a single foundation to support diverse applications.\n\n\n\n\n\n\nNote\n\n\n\nFigure suggestion: Multi-panel figure showing (A) training corpus composition across the tree of life, (B) StripedHyena 2 architecture schematic highlighting hybrid attention-convolution blocks, (C) t-SNE projection of sequence embeddings colored by taxonomic group, and (D) zero-shot variant effect scores compared to experimental pathogenicity labels.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#central-dogma-aware-and-annotation-enriched-models",
    "href": "p3-ch11-dna.html#central-dogma-aware-and-annotation-enriched-models",
    "title": "11  DNA and Genomic Models",
    "section": "11.11 Central-Dogma-Aware and Annotation-Enriched Models",
    "text": "11.11 Central-Dogma-Aware and Annotation-Enriched Models\nThe tokenization discussion in Chapter 5 described how biological structure can be encoded directly into the input representation. Recent models push this idea further by integrating central dogma knowledge and genomic annotations into the modeling framework itself.\n\n11.11.1 Life-Code: The Central Dogma as Inductive Bias\nLife-Code proposes codon-aware, central-dogma-informed tokenization to bridge DNA, RNA, and protein within a single language-modeling framework (Liu et al. 2025). The key insight is that different genomic regions should be tokenized differently based on their biological function.\nCoding regions are tokenized as codons, the three-nucleotide units that specify amino acids during translation. This respects the genetic code’s fundamental structure and enables the model to learn patterns at the level of the biological unit of selection for protein-coding sequences. Noncoding regions, which lack this inherent three-nucleotide structure, are tokenized via learned subword units optimized during training. The resulting unified representations span DNA, RNA, and protein, enabling knowledge sharing across modalities.\nLife-Code uses knowledge distillation from protein language models to import protein-level structural knowledge into DNA and RNA sequence representations. This improves performance on tasks involving coding sequence, such as predicting the effects of missense mutations or expression changes, and achieves competitive or state-of-the-art results on tasks across all three omic modalities.\n\n\n11.11.2 BioToken: Encoding Variants and Structure\nBioToken extends tokenization beyond nucleotide content to include explicit genomic annotations (Medvedev et al. 2025). Rather than representing a genomic region purely as a string of nucleotides, BioToken creates tokens that encode additional biological context.\nVariant-aware tokens explicitly represent SNPs, insertions, and deletions as distinct tokens rather than as implicit changes in the underlying sequence. Structural annotations encode information about exons, introns, UTRs, promoters, enhancers, and other regulatory elements. Functional context tokens include signals such as conservation scores, chromatin state, or known regulatory motifs.\nThis design moves toward fully structured genomic language models where the input is not only DNA bases but also position-specific metadata. The resulting representations can directly integrate sequence, structure, and functional annotations in a unified framework.\nThe associated model BioFM, built on BioToken, achieves competitive or superior results relative to specialized models like Enformer and SpliceAI across genomic benchmarks including noncoding pathogenicity prediction, expression modulation, sQTL prediction, and long-range genomic interactions. Notably, BioFM achieves state-of-the-art performance with significantly fewer parameters (265M), substantially reducing training costs and computational requirements compared to larger models.\nLife-Code and BioToken foreshadow the multi-modal, multi-omic foundation models discussed in Part IV, where sequence is only one of many integrated information streams.\n\n\n\n\n\n\nNote\n\n\n\nFigure suggestion: Comparative diagram showing three tokenization approaches for the same genomic locus: (top) standard nucleotide tokenization, (middle) Life-Code with region-specific codon and subword tokens, (bottom) BioToken composite tokens encoding sequence, variants, and functional annotations.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#using-genomic-language-models-in-practice",
    "href": "p3-ch11-dna.html#using-genomic-language-models-in-practice",
    "title": "11  DNA and Genomic Models",
    "section": "11.12 Using Genomic Language Models in Practice",
    "text": "11.12 Using Genomic Language Models in Practice\nGenomic language models support multiple usage patterns analogous to those established for protein language models. Understanding these patterns is essential for applying the models effectively.\n\n11.12.1 Embeddings as Universal Features\nThe simplest approach extracts embeddings from a pretrained model and uses them as features for downstream tasks. The workflow involves several steps: extract embeddings for windows around loci of interest, pool or select positions relevant to the task (such as promoters, candidate enhancers, or variant sites), and train a lightweight downstream model such as a linear layer, small MLP, or logistic regression.\nThis approach supports diverse applications. Regulatory element classification can distinguish promoters, enhancers, silencers, and insulators based on their learned representations. Chromatin state prediction uses sequence embeddings to predict ATAC-seq or histone mark presence as an alternative to supervised models like DeepSEA. Variant effect scoring replaces or augments hand-crafted features in frameworks like CADD with language model derived features, analogous to CADD v1.7’s incorporation of protein language model features. Splicing and transcript modeling combines language model embeddings with specialized architectures like SpliceAI.\nBecause the language model remains frozen in this approach, it is computationally efficient and avoids catastrophic forgetting when new tasks are added. The pretrained model serves as a general-purpose feature extractor whose representations support many downstream applications.\n\n\n11.12.2 Fine-Tuning and Task-Specific Heads\nWhen more labeled data is available, fine-tuning can significantly improve performance beyond what frozen embeddings provide. Full fine-tuning updates all language model parameters for a specific task, allowing the model to specialize its representations. Adapter-based tuning inserts small bottleneck modules into each layer and updates only those, keeping the backbone mostly frozen while still allowing task-specific adaptation.\nFull fine-tuning tends to achieve the highest performance when sufficient labeled data is available, but it requires more compute and risks catastrophic forgetting of general knowledge. Adapter-based approaches provide a middle ground, achieving most of the performance gains while maintaining computational efficiency and preserving the backbone’s general capabilities.\n\n\n11.12.3 Zero-Shot and Few-Shot Scoring\nFor variant interpretation, genomic language models enable zero-shot scoring based on sequence likelihood. The approach computes the model’s probability for a sequence containing the reference allele and compares it to the probability for the sequence containing the alternative allele. Variants that substantially reduce sequence probability are inferred to be more disruptive.\nThis approach requires no variant-specific training data and can score any single-nucleotide variant in any genomic context the model has learned to represent. The quality of zero-shot scoring depends on how well the model’s learned probability distribution captures biological constraints, which tends to improve with model scale and training data diversity.\nFew-shot approaches include task examples in the input context, allowing the model to adapt its behavior based on demonstrations without parameter updates. HyenaDNA demonstrated that genomic models at sufficient scale exhibit this in-context learning capability, opening new possibilities for rapid task adaptation.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#emerging-themes-and-current-limitations",
    "href": "p3-ch11-dna.html#emerging-themes-and-current-limitations",
    "title": "11  DNA and Genomic Models",
    "section": "11.13 Emerging Themes and Current Limitations",
    "text": "11.13 Emerging Themes and Current Limitations\nThe development of genomic language models over the past several years has established several important themes while also revealing significant limitations.\nSelf-supervision provides a viable path to general genomic representations. Models trained purely on the statistical structure of DNA sequence, without any functional labels, learn representations that transfer to diverse downstream tasks. This validates the foundation model paradigm for genomics and suggests continued scaling will yield further improvements.\nScale and diversity matter substantially for model quality. Performance improves predictably with model size, training data volume, and training data diversity. Including multiple species, populations, and genomic contexts yields more robust representations than training on a single reference genome.\nLong-range context is biologically necessary for many applications. Regulatory phenomena operate at tens to hundreds of kilobases, and the development of efficient architectures like HyenaDNA and Caduceus finally allows modeling these interactions at single-base resolution. The progression from 512 bp to 1 Mb context lengths represents a fundamental capability improvement.\nBiological inductive biases can substitute for scale in some applications. Reverse-complement equivariance in Caduceus, central dogma awareness in Life-Code, and variant encoding in BioToken all demonstrate that incorporating domain knowledge into model architecture improves data efficiency and often matches or exceeds the performance of larger generic models.\nSelf-supervision and supervision are complementary rather than competing approaches. Self-supervised language models excel at learning broad, reusable features, but they do not automatically solve every downstream problem. Specialized architectures and supervised objectives, such as Enformer and related models discussed in Chapter 14, remain crucial for accurate quantitative prediction of complex genomic readouts.\nSeveral important limitations remain. Current models struggle with complex variant patterns beyond single-nucleotide changes, including indels, structural variants, and epistatic interactions across distant loci. Training data and labels remain skewed toward certain ancestries, raising concerns about performance and calibration in underrepresented populations. Interpretability is limited, as it remains difficult to explain why a model assigns a particular score to a variant in terms that connect to biological mechanism. Integration with other data modalities (chromatin, expression, 3D genome structure, clinical phenotypes) is still in its early stages.\nThe evaluation of these models also presents challenges. Benchmarks often focus on classification tasks with clear labels (promoter versus nonpromoter, pathogenic versus benign), but many real applications involve continuous regulatory effects or context-dependent outcomes that are harder to assess. The field would benefit from standardized evaluation protocols that better capture the diversity of genomic applications and the nuances of regulatory prediction. These evaluation challenges are explored in depth in Chapter 18 and Chapter 19.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch11-dna.html#summary",
    "href": "p3-ch11-dna.html#summary",
    "title": "11  DNA and Genomic Models",
    "section": "11.14 Summary",
    "text": "11.14 Summary\nThis chapter surveyed the landscape of genomic language models, from early proof-of-concept systems like DNABERT through scaled models like Nucleotide Transformer to architectural innovations enabling megabase context in HyenaDNA and Caduceus. We examined how models like GROVER complement sequence-based approaches by learning from regulatory tracks, how GenSLMs demonstrated domain-specific tokenization for viral surveillance, and how Evo 2 pushed toward universal genome-scale modeling across all life. Finally, we explored annotation-enriched architectures like Life-Code and BioToken that incorporate biological structure directly into the modeling framework.\nThe key lessons are that self-supervised pretraining transfers effectively to genomics, that architectural choices enabling long-range context provide both efficiency and accuracy improvements, and that biological inductive biases (reverse-complement equivariance, central dogma awareness, variant encoding) can substitute for raw scale in some applications. These models establish a foundation for the field but leave important gaps in our ability to predict quantitative molecular readouts, integrate multi-omic context, and provide mechanistic explanations of their predictions.\nIn Chapter 14, we turn to Enformer and related long-range sequence-to-function models that explicitly predict molecular readouts from sequence. These models close the loop between self-supervised sequence understanding and supervised functional prediction, addressing a key limitation of pure language models: their indirect relationship to quantitative molecular phenotypes.\n\n\n\n\nBenegas, Gonzalo, Sanjit Singh Batra, and Yun S. Song. 2023. “[GPN] DNA Language Models Are Powerful Predictors of Genome-Wide Variant Effects.” Proceedings of the National Academy of Sciences 120 (44): e2311219120. https://doi.org/10.1073/pnas.2311219120.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025. “Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. “[GROVER] DNA Language Model GROVER Learns Sequence Context in the Human Genome.” Nature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nSchiff, Yair, Chia-Hsiang Kao, Aaron Gokaslan, Tri Dao, Albert Gu, and Volodymyr Kuleshov. 2024. “Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling.” arXiv. https://doi.org/10.48550/arXiv.2403.03234.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. “DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.\n\n\nZvyagin, Maxim, Alexander Brace, Kyle Hippe, Yuntian Deng, Bin Zhang, Cindy Orozco Bohorquez, Austin Clyde, et al. 2022. “GenSLMs: Genome-Scale Language Models Reveal SARS-CoV-2 Evolutionary Dynamics.” bioRxiv. https://doi.org/10.1101/2022.10.10.511571.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>DNA and Genomic Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html",
    "href": "p3-ch12-rna.html",
    "title": "12  RNA & Transcript-Level Models",
    "section": "",
    "text": "12.1 Why RNA Modeling Is Different\nRNA sits in the middle of the central dogma as both an information bottleneck and a structured biochemical object. It carries sequence-level constraints inherited from DNA, codon-level constraints imposed by the genetic code, and structural constraints from base pairing and tertiary packing. At the same time, the transcriptome we observe in RNA-seq is a dynamic readout of cellular state, shaped by transcription, splicing, degradation, and translation.\nThis chapter focuses on models that operate directly on RNA sequences. These include models of RNA secondary structure, RNA foundation models pretrained on large corpora of noncoding RNA, codon-level foundation models for mRNA, and applications in mRNA design and noncoding RNA function. Models that treat RNA primarily as a readout of DNA (for example, DNA-to-RNA-seq hybrid models such as Borzoi) are covered in the Hybrid and Long-Range Models chapter, which we explicitly cross-reference when appropriate.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#why-rna-modeling-is-different",
    "href": "p3-ch12-rna.html#why-rna-modeling-is-different",
    "title": "12  RNA & Transcript-Level Models",
    "section": "",
    "text": "12.1.1 RNA as molecule versus transcriptome readout\nIt is useful to distinguish two complementary views of RNA. The first treats RNA as a molecule. Individual RNA molecules have a primary sequence over an alphabet of A, C, G, U (or T in sequencing data). They form secondary structure through intramolecular base pairing, creating stems, loops, and bulges. These secondary structures organize into tertiary structure that positions helices and loops in three-dimensional space. RNA molecules also carry chemical modifications such as m⁶A, pseudouridine (Ψ), m⁵C, and dozens of others. In this molecular view, modeling goals include secondary structure prediction, RNA-protein binding prediction, RNA-RNA interaction modeling, and the design of synthetic RNAs with desired structural and functional properties.\nThe second view treats RNA as a transcriptome readout. At the level of an RNA-seq experiment, we measure coverage profiles along the genome, splice junction usage and isoform abundances, and cell-type-specific expression patterns and responses to perturbations. Here, the modeling goal is to explain how genomic sequence and chromatin state give rise to these readouts. Borzoi and related hybrid models treat this as a sequence-to-signal problem and are covered in the hybrid chapter. This RNA chapter focuses on models whose input is RNA sequence itself.\nThis distinction mirrors the difference between protein language models (which see protein sequences) and models that predict proteomics readouts. Both are important, but they live at different levels of the modeling stack.\n\n\n12.1.2 The role of secondary structure and modifications\nCompared with DNA and protein, RNA is unusually structure-sensitive. Many noncoding RNAs (tRNAs, rRNAs, snRNAs, ribozymes) are defined as much by their secondary structure motifs as by their sequence. Local base pairing creates long-range dependencies: a base at position \\(i\\) may pair with one hundreds of nucleotides away. Epitranscriptomic modifications alter pairing preferences, stability, and protein binding, often in a context-dependent manner.\nAny realistic RNA representation must at least acknowledge that sequence alone is an incomplete description of RNA behavior. This has led to models that either explicitly predict secondary structure and use it as an input feature, or learn representations from sequence that implicitly encode structure, often supervised by structure probing data or known structural motifs. The tension between sequence-only models (which are simpler to train and apply) and structure-aware models (which better capture RNA’s physical reality) runs throughout this chapter.\n\n\n12.1.3 Data sources and biases\nRNA foundation models are trained on diverse corpora, but these corpora reflect systematic biases. Noncoding RNA databases such as Rfam contain well-characterized structural RNA families, but coverage is uneven. tRNAs, rRNAs, and snRNAs are abundant and well-annotated, while many classes of long noncoding RNAs remain poorly characterized. The massive expansion of RNA-seq data has provided sequence-level coverage of coding transcripts, but annotation of isoform-specific functions and structures lags behind. Structure probing experiments (SHAPE, DMS-seq, icSHAPE) provide valuable supervision but are limited to a small fraction of RNAs and cellular contexts.\nThese biases have practical consequences. Models trained predominantly on structured housekeeping RNAs may not generalize well to regulatory lncRNAs, which often lack stable secondary structures. Conversely, models trained on coding sequences may struggle with the structural constraints of ncRNAs. Awareness of training data composition is essential when interpreting model predictions and choosing appropriate tools for specific tasks.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#rna-secondary-structure-prediction",
    "href": "p3-ch12-rna.html#rna-secondary-structure-prediction",
    "title": "12  RNA & Transcript-Level Models",
    "section": "12.2 RNA Secondary Structure Prediction",
    "text": "12.2 RNA Secondary Structure Prediction\nBefore the arrival of deep learning and RNA foundation models, RNA secondary structure prediction was its own mature field with decades of work. Understanding this history clarifies what modern models actually add.\n\n12.2.1 Classical approaches\nClassical RNA structure prediction methods relied on two main strategies. Thermodynamic folding models used algorithms like Mfold and ViennaRNA with experimentally calibrated nearest-neighbor energy parameters to evaluate the free energy of candidate secondary structures. Dynamic programming algorithms such as Zuker’s algorithm identified minimum free energy (MFE) structures or computed partition functions over the ensemble of possible structures. These methods were physically grounded and interpretable, but their accuracy was limited by the completeness of the energy parameter sets and by the complexity of real cellular environments.\nComparative or covariation approaches took a different route. For aligned homologous RNAs, compensatory mutations (for example, G-C to A-U) that preserve base pairing suggest structural constraints. Databases such as Rfam capture these consensus structures. Comparative methods are powerful but require multiple sequence alignments, which are not always available for novel or highly diverged RNAs. They also assume that structure is conserved across the homologous set, an assumption that breaks down for rapidly evolving regulatory RNAs or RNAs with condition-specific alternative structures.\nThese classical methods succeeded for well-studied RNA families and short, structured molecules. Their performance was limited for long RNAs with many alternative structures, RNAs embedded in complex cellular environments, and cases where modifications and protein binding dramatically reshape folding.\n\n\n12.2.2 Deep learning for structure prediction\nModern deep learning approaches bring RNA structure prediction into the sequence-to-structure modeling paradigm. Models such as SPOT-RNA [REF] and related architectures use convolutional or attention-based networks to predict base pairing probabilities or contact maps from sequence. Some methods treat structure as a dense matrix prediction problem, similar to protein contact maps, while others output per-nucleotide pairing states or structural profiles.\nIntegration of structure probing data as supervision allows models to learn patterns that go beyond thermodynamic rules. High-throughput SHAPE, DMS-seq, and icSHAPE experiments provide genome-wide or transcriptome-wide measurements of nucleotide flexibility or solvent accessibility. These data, while noisy and condition-specific, offer direct experimental constraints on structure. Models trained on such data can learn to predict structure in contexts (cell types, conditions, binding states) where classical energy models have no calibrated parameters.\nDeep learning models often outperform classical methods on benchmark datasets, particularly for long RNAs or RNAs with complex pseudoknots. However, they typically require task-specific supervision and do not yet offer the broad, reusable representations that foundation models provide. The gap between these specialized structure predictors and general-purpose RNA foundation models is a current research frontier.\n\n\n12.2.3 Toward structure-aware representations\nRNA secondary structure prediction is also a natural downstream task for RNA foundation models. Pretrained sequence encoders can be fine-tuned to predict pairing probabilities or local structural contexts from per-nucleotide embeddings. Some models incorporate explicit structure tokens or graphs, representing stems and loops as nodes and edges and learning jointly over sequence and structure. Others rely purely on sequence pretraining and show that learned representations implicitly encode structural preferences when probed with downstream tasks.\nThe key idea is that structure is both an objective and a prior. RNA models should learn representations that make structural predictions easy, and structural tasks provide a strong constraint on what good representations must capture. This dual role of structure (as supervision and as emergent property) distinguishes RNA modeling from DNA and protein modeling, where structure plays a less central role in sequence-level tasks.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#rna-foundation-models",
    "href": "p3-ch12-rna.html#rna-foundation-models",
    "title": "12  RNA & Transcript-Level Models",
    "section": "12.3 RNA Foundation Models",
    "text": "12.3 RNA Foundation Models\nRNA foundation models aim to do for RNA what protein language models did for proteins: learn general-purpose representations from large unlabeled corpora that can be reused across many tasks.\n\n12.3.1 Pretraining corpora and tokenization\nTypical RNA foundation model corpora include noncoding RNA databases (Rfam families, lncRNA catalogs, miRNA repositories), curated sets of structured RNAs such as tRNAs, rRNAs, snRNAs, and ribozymes, and sometimes coding sequences, though many models reserve these for codon-level approaches (Section 8.4). The composition of training corpora reflects trade-offs between diversity and quality. Large-scale inclusion of unannotated transcripts increases corpus size but introduces noise from splicing artifacts, degradation products, and genomic DNA contamination. Restriction to well-curated families improves data quality but risks overfitting to well-studied RNA classes.\nMost RNA foundation models use simple nucleotide-level tokenization with an alphabet of A, C, G, U (or T). Some augment this with special tokens for unknown bases, gaps, or masked positions. A few explore k-mer tokenization to increase effective context length while keeping sequence lengths manageable, or joint sequence-structure tokens where tokens encode both base identity and structural state (paired versus unpaired) when such annotations are available. The choice of tokenization reflects a trade-off between resolution (single nucleotides) and context length or efficiency (k-mers), echoing similar design decisions in DNA models.\n\n\n12.3.2 Architectures and objectives\nMost current RNA foundation models follow the masked language modeling (MLM) paradigm. RNA-FM uses a transformer encoder pretrained on tens of millions of ncRNA sequences with an MLM objective, learning contextual embeddings for each nucleotide Chen et al. (2022). Related models such as RNAErnie and RNA-MSM [REF] explore variations on the transformer architecture, multi-task learning, or MSA-style inputs for homologous RNAs.\nCommon pretraining objectives include masked token prediction at the nucleotide level, span masking to encourage modeling of longer motifs, contrastive objectives distinguishing real sequences from shuffled or decoy sequences, and in some cases multi-task auxiliary heads for structural features (pairing probability, accessibility) or family classification. The goal is to learn embedding spaces in which structurally or functionally related RNAs cluster together, providing a basis for transfer learning.\nArchitectural choices vary in how they handle long-range structure. Standard transformers with self-attention have quadratic complexity in sequence length, limiting context windows. Some models use sparse attention patterns (local windows plus global tokens) or linear-complexity attention variants. Others incorporate graph neural networks or message-passing layers that operate on predicted or known secondary structure graphs. These hybrid sequence-structure architectures remain an active area of development.\n\n\n12.3.3 Downstream tasks\nRNA foundation models are evaluated and fine-tuned on a wide range of tasks. Secondary structure prediction fine-tunes per-nucleotide embeddings to predict pairing status, contact maps, or SHAPE reactivity profiles. RNA-protein binding prediction uses high-throughput CLIP-seq datasets to predict binding preferences of RNA-binding proteins (RBPs). Expression and stability tasks predict transcript stability or steady-state expression from UTR sequences, poly(A) signals, and other regulatory motifs. Family and function classification assign RNAs to Rfam families or functional classes (tRNA, rRNA, miRNA, lncRNA), often outperforming handcrafted features.\nWhile still young compared to protein language models, RNA foundation models show promising zero-shot and few-shot transfer, especially for structurally constrained RNAs where sequence motifs are highly informative. Benchmarking is complicated by the diversity of RNA types and tasks. A model that excels at ncRNA family classification may not generalize to mRNA stability prediction or codon optimization. Task-specific evaluation remains essential, but broad pretrained representations offer a useful starting point across the RNA modeling landscape.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#codon-level-models-for-mrna",
    "href": "p3-ch12-rna.html#codon-level-models-for-mrna",
    "title": "12  RNA & Transcript-Level Models",
    "section": "12.4 Codon-Level Models for mRNA",
    "text": "12.4 Codon-Level Models for mRNA\nCoding sequences occupy a special niche. Each triplet of nucleotides encodes an amino acid, but synonymous codons differ in tRNA availability, translation speed, co-translational folding effects, and mRNA stability. Pure protein language models, which see only amino acid sequences, cannot capture these codon-level signals.\n\n12.4.1 Codon tokenization and central dogma consistency\nCodon-level foundation models treat mRNA as a sequence over a 61-codon alphabet (excluding the three stop codons), or combine codon tokens with context from surrounding UTRs. Models such as cdsFM, EnCodon, and DeCodon tokenize coding sequences into codons and pretrain using masked codon prediction and related objectives Naghipourfar et al. (2024). Life-Code extends this idea into a central-dogma-wide framework, linking DNA, RNA, and protein representations via shared or aligned embedding spaces Liu et al. (2025).\nThis codon view allows models to capture codon usage bias and its relationship to expression levels, model translation elongation dynamics and co-translational folding, and distinguish between synonymous variants that are neutral at the protein level but strongly affect expression. The transition from nucleotide tokenization to codon tokenization is not merely a change in alphabet size. It encodes a biological prior: that the fundamental units of coding sequence are codons, not individual nucleotides.\n\n\n12.4.2 What codon-level models add beyond protein language models\nCompared with protein language models, codon-level models can directly model mRNA design problems where the amino acid sequence is fixed but codon choice is variable. They provide more faithful representations for tasks dependent on translation efficiency, ribosome pausing, or mRNA stability. They bridge RNA and protein spaces, especially in frameworks like Life-Code that jointly model DNA, RNA, and protein sequences.\nHowever, codon models still typically ignore secondary structure and modifications. An mRNA’s local structure can affect ribosome access and translation rate, and modifications like m⁶A influence transcript stability and localization. Combining codon-aware tokenization with structure-aware embeddings is an important open direction. Some recent work has begun to explore joint codon-structure models, but these remain in early stages compared to the mature protein structure prediction models.\n\n\n12.4.3 Training data and biases\nCodon-level models are trained on coding sequences, often from model organisms with abundant expression data. This creates a bias toward highly expressed, well-characterized genes. Rare codon combinations, tissue-specific isoforms, and synthetic constructs outside natural codon usage distributions may be underrepresented. Transfer learning to non-model organisms or synthetic biology applications requires careful validation.\nExpression-supervised training (using RNA-seq or ribosome profiling data as targets) helps models learn codon optimality, but introduces the confound that expression is influenced by many factors beyond codon choice: promoter strength, chromatin state, RNA processing, and post-transcriptional regulation. Disentangling codon effects from these other factors remains a challenge in both model training and downstream interpretation.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#mrna-design-and-optimization",
    "href": "p3-ch12-rna.html#mrna-design-and-optimization",
    "title": "12  RNA & Transcript-Level Models",
    "section": "12.5 mRNA Design and Optimization",
    "text": "12.5 mRNA Design and Optimization\nOne of the most direct applications of RNA and codon-level models is mRNA sequence design: choosing nucleotide sequences that encode a desired protein while optimizing expression, stability, safety, and manufacturability.\n\n12.5.1 Design objectives\nKey objectives for mRNA design include high protein expression in a target cell type or tissue, mRNA stability in vivo and during manufacturing, controlled translation kinetics that influence co-translational folding and post-translational modifications, and low immunogenicity and safety, especially for vaccine or therapeutic applications. Some of these objectives are local (avoiding splice-like cryptic motifs in the CDS or UTRs), while others are global (codon adaptation across the whole transcript, global GC content). Trade-offs are common: increasing GC content may improve stability but can introduce unwanted secondary structure or innate immune activation.\nThe COVID-19 mRNA vaccines provided a high-profile demonstration of mRNA design principles [REF]. Optimization included pseudouridine modification to reduce innate immune activation, codon optimization for high expression in human cells, UTR design to enhance stability and translation, and careful control of secondary structure to avoid aggregation during manufacturing. These design choices were informed by decades of basic research and empirical optimization, but recent models offer the possibility of more systematic, data-driven design.\n\n\n12.5.2 Model-based optimization\nRNA and codon foundation models enable several model-based design strategies. Scoring and screening use pretrained models to score large candidate sets for expression or stability and select top designs. Gradient-based editing, when models are differentiable with respect to input embeddings, allows approximate gradients to guide codon substitutions or UTR edits. Generative design combines language-model-style generation with constraints (for example, fixed amino acid sequence) to sample diverse, high-scoring mRNAs.\nEmpirically, data-driven codon optimization can outperform classical codon adaptation indices, especially when trained on context-specific expression data. Classical indices like CAI or tAI rely on genome-wide codon frequencies or tRNA abundances but do not capture local context effects, co-translational folding, or regulatory motifs. Deep models trained on high-throughput reporter assays or ribosome profiling data can learn these context-dependent effects, though they require substantial training data and may not generalize across distant organisms or synthetic contexts.\n\n\n12.5.3 UTRs and regulatory elements\nBeyond coding regions, 5′ and 3′ UTRs play crucial roles. The 5′ UTR influences translation initiation, ribosome scanning, and upstream open reading frames. The 3′ UTR affects stability, localization, and miRNA-mediated regulation. RNA foundation models can embed UTR sequences and support tasks like predicting translation efficiency from 5′ UTR sequence, predicting mRNA half-life from 3′ UTR motifs, and designing UTRs that tune expression to desired levels.\nUTR design is particularly challenging because UTRs harbor regulatory elements (AU-rich elements, miRNA binding sites, protein binding motifs) that interact with cellular context in complex ways. A UTR that works well in one cell type may fail in another due to differential expression of RNA-binding proteins or miRNAs. Context-specific training or fine-tuning is often necessary, and validation in relevant cell types remains essential.\nThese design tasks link naturally to the Design and Engineering chapter, where sequence generative models are discussed in more detail. Here we emphasize that RNA-specific representations are crucial when the design target is an mRNA, because design constraints (structure, codon usage, regulatory motifs) differ fundamentally from those in DNA or protein design.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#noncoding-rna-classification-and-function",
    "href": "p3-ch12-rna.html#noncoding-rna-classification-and-function",
    "title": "12  RNA & Transcript-Level Models",
    "section": "12.6 Noncoding RNA Classification and Function",
    "text": "12.6 Noncoding RNA Classification and Function\nRNA that does not encode protein (ncRNA) spans a wide spectrum: housekeeping RNAs like tRNAs, rRNAs, snRNAs, and snoRNAs; regulatory RNAs like miRNAs, siRNAs, piRNAs, and lncRNAs; structural and catalytic RNAs including ribozymes and riboswitches; and circular RNAs (circRNAs) and other noncanonical species. Each class has characteristic length ranges, structural motifs, genomic contexts, and functional mechanisms.\n\n12.6.1 Classic feature-based approaches\nHistorically, ncRNA classification relied on manually engineered sequence features (k-mers, motif counts, GC content), secondary structure features (minimum free energy, base-pairing probabilities, structural motif counts), and genomic context features (proximity to coding genes, conservation patterns, chromatin marks). These features fed into conventional classifiers like support vector machines, random forests, or shallow neural networks. Performance was reasonable for well-studied classes like miRNAs and tRNAs, where strong sequence and structure signatures exist, but did not generalize well to new RNA classes or underrepresented families like lncRNAs, which often lack stable secondary structures and conserved motifs.\nThe challenge of lncRNA classification illustrates the limits of handcrafted features. LncRNAs are defined partly by what they lack (no long open reading frame) rather than what they possess (conserved structure or motif). Their functions are diverse: chromatin scaffolding, transcriptional regulation, post-transcriptional control, and more. Many lncRNAs are lineage-specific or poorly conserved. Distinguishing functional lncRNAs from transcriptional noise remains an open problem, and classical feature sets often collapse to generic statistics like length and GC content, which provide little discriminative power.\n\n\n12.6.2 Foundation model-based classification\nRNA foundation models offer a more flexible approach. Per-nucleotide embeddings can be pooled (via mean pooling, attention pooling, or CLS tokens) into fixed-dimensional representations. Simple classifiers on top of these embeddings can distinguish RNA classes, often with better robustness and transfer to new datasets. For circRNAs or lncRNAs, which may lack strong sequence motifs, foundation models can exploit subtle distributional patterns learned during pretraining.\nEmbedding-based methods also support few-shot learning. Given a handful of newly discovered RNAs with known function, their embeddings can seed new clusters in representation space, guiding functional annotation. This is particularly valuable for emerging RNA classes or organism-specific ncRNAs that are underrepresented in training data. However, few-shot performance depends critically on whether the new RNA class shares distributional properties with training data, a condition that is difficult to verify without extensive validation.\n\n\n12.6.3 Target prediction and interaction modeling\nFor regulatory ncRNAs, function often depends on interactions: miRNA-mRNA targeting via seed matches and context features, lncRNA-protein or lncRNA-DNA interactions, and RNA-RNA base pairing in antisense regulation. Extensions of RNA foundation models to paired inputs (for example, bi-encoder or cross-encoder architectures) can model these interactions, though training data is sparse and noisy.\nMiRNA target prediction has benefited from large-scale CLIP experiments and reporter assays, providing supervised training data for interaction models. However, context-specific effects (differential expression of competing RNAs, cellular localization, RNA modifications) remain difficult to capture. LncRNA-protein interactions are even less well characterized, with most interactions inferred from proximity or co-immunoprecipitation rather than direct binding assays. Foundation models can provide useful priors for these tasks, but they do not yet replace experimental validation.\nThis area of interaction modeling intersects with network and systems-level modeling in later chapters, where ncRNAs are often represented as nodes in regulatory networks. The challenge is to integrate sequence-level representations from RNA foundation models with network-level constraints from expression data, perturbation experiments, and pathway annotations.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#clinical-and-translational-applications",
    "href": "p3-ch12-rna.html#clinical-and-translational-applications",
    "title": "12  RNA & Transcript-Level Models",
    "section": "12.7 Clinical and Translational Applications",
    "text": "12.7 Clinical and Translational Applications\nRNA-level models are already entering clinical and translational workflows, often in combination with DNA- and protein-level models.\n\n12.7.1 Variant interpretation at the RNA level\nEven when a variant is defined at the DNA level, its effects often manifest through RNA. Splice-altering variants create or destroy splice sites, influence exon inclusion, or activate cryptic exons (cross-reference to the Splicing chapter for detailed treatment of splice prediction models). Variants in UTRs alter stability, translation efficiency, or miRNA binding. Synonymous coding variants modify codon usage, affecting translation or co-translational folding.\nRNA and codon foundation models can contribute by scoring synonymous and UTR variants for predicted effects on expression or stability, providing prior probabilities or embeddings used by integrated variant effect predictors (covered in the Variant Effect Prediction chapter), and helping prioritize variants for functional RNA assays such as massively parallel reporter assays of UTRs or codon variants.\nThe challenge in variant interpretation is integrating these RNA-level predictions with DNA-level conservation, protein-level constraint, and clinical outcome data. A variant may have minimal effects on mRNA expression but large effects on protein function, or vice versa. Comprehensive variant effect prediction requires multi-level models that propagate uncertainty from DNA to RNA to protein to phenotype.\n\n\n12.7.2 RNA therapeutics and biomarkers\nBeyond vaccines, RNA models are relevant to siRNA and antisense oligonucleotide design, where off-target effects and secondary structure influence efficacy and safety; RNA-based biomarkers such as expression signatures in oncology or immune profiling, where latent RNA representations can support better clustering and risk stratification; and gene therapy and base editing, where guide RNAs are designed with sequence and structure constraints.\nIn many of these cases, RNA foundation models serve as building blocks in larger pipelines that also integrate protein, DNA, and clinical features. For example, cancer expression signatures often combine RNA-based subtype classification with DNA-based mutation profiles and protein-based pathway activation scores. RNA models provide one component of this multi-modal architecture, aligning with the multi-scale narratives of later chapters.\nRNA biomarkers face particular challenges in clinical translation. Expression levels are sensitive to sample handling, batch effects, and population stratification. Reference-free normalization methods (TPM, RPKM) partially address these issues but do not eliminate them. Models trained on one cohort may not generalize to other hospitals, sequencing platforms, or demographic groups. Careful validation on held-out cohorts and diverse populations is essential before clinical deployment.\n\n\n12.7.3 Regulatory and ethical considerations\nRNA therapeutics raise regulatory questions around stability, immunogenicity, and long-term effects. Models that optimize these properties must be validated against regulatory standards, which are still evolving. Ethical considerations include equitable access to RNA-based diagnostics and therapeutics, particularly in low-resource settings where sequencing infrastructure is limited. Model interpretability is also critical: clinicians need to understand why a model recommends a particular codon choice or UTR design, not just that it achieves high performance on a benchmark.\nThese considerations extend beyond RNA to all genomic foundation models, but they are particularly acute for RNA therapeutics because of the rapid pace of clinical translation and the high stakes of vaccine and gene therapy applications.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch12-rna.html#relationship-to-other-chapters",
    "href": "p3-ch12-rna.html#relationship-to-other-chapters",
    "title": "12  RNA & Transcript-Level Models",
    "section": "12.8 Relationship to Other Chapters",
    "text": "12.8 Relationship to Other Chapters\nBecause RNA sits at the center of the central dogma, this chapter naturally overlaps with others. The table below summarizes those relationships and guides the reader to more detailed discussions elsewhere.\n\n\n\n\n\n\n\n\nChapter\nOverlap\nResolution\n\n\n\n\nCh 7 (Splicing)\nSpliceAI, sQTL prediction, cryptic splice site activation, and other pre-mRNA processing tasks all involve RNA.\nThe Splicing chapter focuses on models whose inputs are genomic sequence around splice junctions and whose targets are splicing outcomes. This RNA chapter focuses on models that treat mature RNA sequences (including structured ncRNAs and mRNAs) as the primary input. Cross-reference SpliceAI and related models here only at a high level.\n\n\nCh 9 (Hybrid / Long-range)\nModels like Borzoi predict RNA-seq coverage, splicing patterns, and other transcriptomic signals directly from DNA Linder et al. (2025).\nHybrid models take DNA as input and RNA-level readouts as output. They remain in the Hybrid chapter as exemplars of long-context sequence-to-signal modeling. This RNA chapter instead focuses on RNA-input models; we cross-reference Borzoi when discussing transcriptome readouts but do not re-explain its architecture.\n\n\nCh 7 (DNA & Genomic FMs)\nSome DNA foundation models are pretrained, evaluated, or supervised using transcript-based signals (RNA-seq coverage, splicing scores).\nThe DNA chapter emphasizes models whose primary pretraining data are genomic sequences, even if some objectives involve RNA-derived labels. Here we emphasize models whose primary input is RNA or codonized mRNA. When a model blurs the line, describe it once in detail (usually in the DNA or Hybrid chapter) and reference it here briefly.\n\n\nCh 14 (Networks & Multi-omics)\nRNA is a central modality in many multi-omic integration and network models (for example, gene expression as one node type or view).\nThe multi-omics chapter treats RNA mostly as a continuous vector of expression values. This chapter treats RNA as a discrete sequence with structure. When discussing multi-omics models, we refer readers to Chapter 14 and focus here on the sequence-level representations that may feed into those systems.\n\n\nCh X (Variant Effect Prediction)\nRNA-level variant effects (UTR variants, synonymous variants, splice variants) contribute to overall variant pathogenicity scoring.\nThe Variant Effect Prediction chapter integrates predictions from multiple levels (DNA conservation, protein constraint, splicing effects, expression changes). This chapter provides the RNA-level component of that integration. We cross-reference the VEP chapter when discussing how RNA models fit into comprehensive variant interpretation pipelines.\n\n\nCh X (Design & Engineering)\nmRNA design and codon optimization are central design tasks in synthetic biology.\nThe Design chapter covers generative models and optimization strategies across DNA, RNA, and protein. This chapter focuses specifically on RNA design constraints (structure, codon usage, UTR regulation) and RNA-specific tools. We cross-reference the Design chapter for broader context on generative modeling and in silico directed evolution.\n\n\n\nThis chapter has established RNA as a distinct modeling domain with its own architectures (RNA foundation models, codon-level models), training paradigms (structure-supervised learning, codon-masked modeling), and applications (mRNA design, ncRNA classification, RNA therapeutic design). The next chapters will explore how genomic models extend to longer contexts and integrate multiple genomic signals, building toward the multi-scale and multi-omic perspectives of later sections.\n\n\n\n\nChen, Jiayang, Zhihang Hu, Siqi Sun, Qingxiong Tan, Yixuan Wang, Qinze Yu, Licheng Zong, et al. 2022. “[RNA-FM] Interpretable RNA Foundation Model from Unannotated Data for Highly Accurate RNA Structure and Function Predictions.” arXiv. https://doi.org/10.48550/arXiv.2204.00300.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025. “Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nNaghipourfar, Mohsen, Siyu Chen, Mathew K. Howard, Christian B. Macdonald, Ali Saberi, Timo Hagen, Mohammad R. K. Mofrad, Willow Coyote-Maestas, and Hani Goodarzi. 2024. “[cdsFM - EnCodon/DeCodon] A Suite of Foundation Models Captures the Contextual Interplay Between Codons.” bioRxiv. https://doi.org/10.1101/2024.10.10.617568.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>RNA & Transcript-Level Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html",
    "href": "p3-ch13-plm.html",
    "title": "13  Protein Language Models",
    "section": "",
    "text": "13.1 The ESM Model Family\nBefore transformers revolutionized genomic sequence modeling, they first transformed our ability to model proteins. The field built upon decades of computational progress, from David Baker’s Rosetta framework that pioneered physics-based protein structure prediction and design through sampling and energy minimization, to the deep learning revolution of the past decade. This progression moved from early generative models like DeepSequence that captured epistatic interactions in protein families (Riesselman, Ingraham, and Marks 2018), to EVE’s unsupervised prediction of disease variants from evolutionary data (Frazer et al. 2021), to the ESM family’s demonstration that transformers trained on massive sequence databases learn representations encoding structure and function (Rives et al. 2021). The trajectory culminated in AlphaFold2’s solution to the protein structure prediction problem (Jumper et al. 2021) and AlphaMissense’s proteome-wide variant pathogenicity scoring (Cheng et al. 2023), establishing that self-supervised learning on biological sequences could match or exceed decades of specialized computational methods. The transformative impact of this work was recognized with the 2024 Nobel Prize in Chemistry, awarded to Demis Hassabis and John Jumper for AlphaFold2 and to David Baker for computational protein design. These advances validated and extended the central dogma’s sequence → structure → function paradigm, demonstrating that deep learning models could compress the entire chain of causation into learned representations that predict functional consequences directly from amino acid sequences.\nThe success of protein language models (PLMs) established a paradigm that would later inspire genomic foundation models: treat biological sequences as a form of natural language, train large transformer models on massive unlabeled sequence databases, and extract functional knowledge through self-supervised learning. The analogy between protein sequences and natural language runs deeper than mere metaphor. Both encode complex information in linear strings of discrete tokens, whether amino acids or words. Both exhibit hierarchical structure, with motifs combining into domains as words combine into phrases. Both have syntax in the form of structural constraints and semantics in the form of functional meaning. And crucially, both are shaped by evolutionary pressure: natural selection filters protein sequences just as cultural selection shapes language.\nThis chapter examines how protein language models pioneered biological foundation modeling, from the ESM family’s demonstration that transformers can learn protein structure and function from sequence alone, to their application in variant effect prediction and structure determination. Understanding PLMs provides essential context for the genomic language models covered in subsequent chapters, as many architectural choices and training strategies transfer directly from proteins to DNA.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#the-esm-model-family",
    "href": "p3-ch13-plm.html#the-esm-model-family",
    "title": "13  Protein Language Models",
    "section": "",
    "text": "13.1.1 ESM-1b: Establishing the Paradigm\nThe Evolutionary Scale Modeling (ESM) project, developed at Meta AI Research, demonstrated that transformer language models trained on protein sequences learn biologically meaningful representations without explicit supervision (Rives et al. 2021). The key insight was that masked language modeling, the same objective that powers BERT in natural language processing, could be applied directly to amino acid sequences.\nESM-1b was trained on UniRef50, a clustered database of approximately 33 million protein sequences covering the known diversity of protein families. UniRef50 clusters sequences at 50% identity, providing broad coverage while reducing redundancy (Suzek et al. 2007). This curation strategy ensures the model sees diverse evolutionary solutions to protein function rather than memorizing overrepresented families.\nThe architecture follows the BERT-style bidirectional transformer design with 650 million parameters distributed across 33 layers, a hidden dimension of 1,280, and 20 attention heads. The maximum sequence length of 1,024 amino acids accommodates most individual protein domains and many complete proteins. The training objective is masked language modeling: the model learns to predict randomly masked amino acids given surrounding context. This is analogous to BERT’s masked token prediction, but operates on amino acids rather than words.\n\n\n13.1.2 Emergent Biological Knowledge\nDespite never seeing structural or functional labels during training, ESM learns representations that capture fundamental biological properties. This emergent knowledge manifests across multiple levels of protein organization.\nAt the level of secondary structure, attention patterns in ESM correlate with alpha helices and beta sheets. The model implicitly learns that certain amino acid patterns form specific structural elements, encoding this knowledge in its internal representations without any explicit supervision on structure labels.\nESM’s attention heads also capture residue-residue contacts, identifying amino acids that are distant in sequence but close in three-dimensional space. This emergent capability suggests the model learns aspects of protein folding from sequence statistics alone. When researchers analyzed which sequence positions attend to each other in trained ESM models, they found strong correspondence with experimentally determined contact maps.\nThe model’s masked token predictions correlate with position-specific conservation scores from multiple sequence alignments. ESM effectively learns which positions tolerate variation and which are evolutionarily constrained, extracting this information from the statistical patterns in sequence databases rather than from explicit conservation annotations.\nAttention also concentrates on catalytic residues, binding sites, and other functionally important positions, even without explicit functional annotation in the training data. The model discovers that certain sequence positions are more informative about surrounding context, and these positions frequently correspond to sites of biological importance.\n\n\n13.1.3 ESM-2: Scaling Up\nESM-2 extended the ESM approach with larger models and improved training (Lin et al. 2022). The model family spans several orders of magnitude in scale, from 8 million to 15 billion parameters, enabling systematic study of how biological knowledge scales with model capacity.\n\n\n\nModel\nParameters\nLayers\nContact Prediction Performance\n\n\n\n\nESM-2 (8M)\n8M\n6\nBaseline\n\n\nESM-2 (35M)\n35M\n12\n+5%\n\n\nESM-2 (150M)\n150M\n30\n+8%\n\n\nESM-2 (650M)\n650M\n33\n+12%\n\n\nESM-2 (3B)\n3B\n36\n+15%\n\n\nESM-2 (15B)\n15B\n48\nState-of-the-art\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nValidate contact prediction performance values\n\n\nPerformance scales smoothly with model size across structure prediction, contact prediction, and variant effect tasks. This phenomenon mirrors the scaling laws observed in natural language processing, where larger models consistently capture more nuanced patterns and achieve better downstream performance. The predictable scaling relationship suggests that continued investment in model size yields reliable returns in biological accuracy.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#alternative-architectures-the-prottrans-family",
    "href": "p3-ch13-plm.html#alternative-architectures-the-prottrans-family",
    "title": "13  Protein Language Models",
    "section": "13.2 Alternative Architectures: The ProtTrans Family",
    "text": "13.2 Alternative Architectures: The ProtTrans Family\nThe ProtTrans family explored multiple transformer architectures for protein sequences, demonstrating that the protein language modeling paradigm generalizes beyond the specific design choices of ESM (Elnaggar et al. 2021).\nProtBERT applies the BERT-style bidirectional encoder to protein sequences, trained on the Big Fantastic Database (BFD) comprising approximately 2.1 billion protein sequences (Devlin et al. 2019; Jumper et al. 2021). This massive training corpus, substantially larger than UniRef50, provides even broader coverage of protein sequence space.\nProtT5 adapts the encoder-decoder architecture from T5, enabling both understanding and generation tasks (Raffel et al. 2019). The encoder processes input sequences to produce contextual representations, while the decoder can generate output sequences conditioned on those representations. This architecture is particularly valuable for tasks that require sequence generation, such as protein design or sequence completion.\nProtXLNet explores permutation language modeling based on XLNet, capturing bidirectional context without the artificial [MASK] token that BERT-style models require during training (Yang et al. 2020). By training on all possible token orderings, XLNet-style models learn to predict each token from any subset of context tokens, potentially capturing richer dependencies.\nThese architectural variants demonstrate that the protein language modeling paradigm generalizes across architectures. The choice between encoder-only (BERT-style) and encoder-decoder (T5-style) models depends on the downstream application: encoders excel at classification and embedding tasks, while encoder-decoders enable sequence generation.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#zero-shot-variant-effect-prediction",
    "href": "p3-ch13-plm.html#zero-shot-variant-effect-prediction",
    "title": "13  Protein Language Models",
    "section": "13.3 Zero-Shot Variant Effect Prediction",
    "text": "13.3 Zero-Shot Variant Effect Prediction\nA critical application of protein language models is predicting the effects of amino acid substitutions. Missense variants are the most common type of protein-coding mutation, and clinical genetics pipelines must routinely assess whether specific substitutions are likely to be pathogenic or benign. Traditionally, this required either direct experimental characterization or computational methods trained on labeled pathogenicity data.\n\n13.3.1 The Zero-Shot Paradigm\nESM-1v demonstrated that PLMs can predict variant effects without any training on variant labels (Meier et al. 2021). The approach exploits the masked language modeling objective: for a variant at position \\(i\\) changing amino acid \\(a\\) to amino acid \\(b\\), compute the log-likelihood ratio:\n\\[\\Delta \\text{score} = \\log P(b \\mid \\text{context}) - \\log P(a \\mid \\text{context})\\]\nIf the model assigns higher probability to the mutant amino acid than the wild-type, the variant is predicted benign; if lower, deleterious. This zero-shot prediction requires no labeled training data. The model’s evolutionary knowledge, learned from sequence databases, directly informs variant interpretation.\nThe intuition is straightforward. If evolution has shaped protein sequences such that certain positions strongly prefer certain amino acids, substitutions that violate these preferences are likely to disrupt function. The language model captures these preferences through its training on millions of evolutionarily successful sequences. Variants that the model finds surprising, in the sense of assigning low probability, are more likely to be functionally disruptive.\n\n\n13.3.2 Genome-Wide Application\nBrandes and colleagues applied ESM-1b to predict effects for all approximately 450 million possible missense variants in the human genome (Brandes et al. 2023). This comprehensive annotation covers every position in every human protein multiplied by every possible amino acid substitution, providing precomputed effect scores that can be queried for any missense variant without running the model.\nOn ClinVar, the database of clinically annotated variants, ESM-1b outperformed existing methods in classifying approximately 150,000 missense variants as pathogenic or benign. The model achieved strong correlation with experimental measurements across 28 deep mutational scanning datasets, demonstrating that PLM predictions capture genuine functional information rather than merely correlating with annotation artifacts.\nThe analysis also identified approximately 2 million variants annotated as damaging only in specific protein isoforms, highlighting the importance of considering alternative splicing when interpreting variant effects. A variant that disrupts function in one isoform may have no effect if that isoform is not expressed in relevant tissues, underscoring the need to integrate PLM predictions with expression context.\n\n\n13.3.3 The ProteinGym Benchmark\nProteinGym provides a comprehensive benchmark for variant effect predictors, aggregating 217 deep mutational scanning assays covering diverse proteins (Notin et al. 2023). Deep mutational scanning experiments systematically measure the functional effects of thousands of variants in a protein, providing ground truth for computational method evaluation.\n\nPerformance of protein language models and traditional methods on the ProteinGym deep mutational scanning benchmark (Notin et al. 2023). Shown are mean Spearman correlations between predicted and experimentally measured variant effects across 217 assays (Meier et al. 2021; Frazer et al. 2021; Riesselman, Ingraham, and Marks 2018; Ng and Henikoff 2003; Adzhubei et al. 2010).\n\n\nMethod\nMean Spearman ρ\nInformation Sources\n\n\n\n\nESM-1v\n0.48\nSingle sequence (PLM)\n\n\nEVE (evolutionary model)\n0.46\nMSA (generative model)\n\n\nDeepSequence\n0.44\nMSA (VAE)\n\n\nPolyPhen-2\n0.32\nConservation + structure\n\n\nSIFT\n0.30\nConservation\n\n\n\nPLMs achieve competitive or superior performance to methods that explicitly model evolutionary conservation from multiple sequence alignments, despite using only single sequences as input. This suggests that transformer attention over large sequence databases captures similar information to traditional alignment-based approaches, but in a form that generalizes more readily to novel sequence contexts.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#esmfold-structure-from-sequence",
    "href": "p3-ch13-plm.html#esmfold-structure-from-sequence",
    "title": "13  Protein Language Models",
    "section": "13.4 ESMFold: Structure from Sequence",
    "text": "13.4 ESMFold: Structure from Sequence\n\n13.4.1 Eliminating the Alignment Bottleneck\nThe most dramatic demonstration of PLM capabilities came with ESMFold, which predicts protein 3D structure directly from ESM-2 embeddings (Lin et al. 2022). Traditional structure prediction, including AlphaFold2, relies heavily on multiple sequence alignments (MSAs). These computationally expensive searches against sequence databases can take hours per protein, and the quality of predictions depends critically on finding informative homologs.\nESMFold eliminates this requirement entirely. The architecture couples ESM-2 (15 billion parameters) with a structure module adapted from AlphaFold2. The language model embeddings replace MSA-derived features, providing the evolutionary context that the structure module needs to predict atomic coordinates.\nThe computational speedup is substantial: approximately 60-fold faster than AlphaFold2 for typical proteins, enabling metagenomic-scale structure prediction. This speed advantage makes it feasible to predict structures for the millions of protein sequences emerging from environmental sequencing projects, where computing MSAs would be prohibitively expensive.\nESMFold achieves atomic-level accuracy for many proteins, though slightly below AlphaFold2 for proteins that benefit from MSA information. The accuracy gap is largest for proteins with sparse evolutionary sampling, where MSAs provide information that single-sequence analysis cannot recover. For well-represented protein families, ESMFold approaches AlphaFold2 accuracy at a fraction of the computational cost.\n\n\n13.4.2 What ESMFold Reveals About PLMs\nESMFold’s success demonstrates that ESM-2’s internal representations encode sufficient information to determine 3D structure. The language model has learned not just local sequence patterns but global folding principles, capturing what makes a sequence fold into a particular shape.\nThis has profound implications for understanding what PLMs learn. The attention that transformers pay to distant sequence positions during masked prediction is, in some sense, learning the physics of protein folding. Residues that need to be close in 3D space attend to each other in the transformer’s attention matrices. The statistical patterns in protein sequences, shaped by billions of years of evolution and the physical constraints of protein folding, encode structural information that sufficiently powerful language models can decode.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#integration-into-variant-interpretation-pipelines",
    "href": "p3-ch13-plm.html#integration-into-variant-interpretation-pipelines",
    "title": "13  Protein Language Models",
    "section": "13.5 Integration into Variant Interpretation Pipelines",
    "text": "13.5 Integration into Variant Interpretation Pipelines\n\n13.5.1 CADD v1.7: PLM Features for Ensemble Methods\nThe Combined Annotation Dependent Depletion (CADD) framework integrates diverse annotations to score variant deleteriousness (Chapter 4). CADD v1.7 incorporated ESM-1v predictions as features within its existing integrative architecture (Schubach et al. 2024).\nThe integration approach treats PLM scores as additional annotations alongside conservation scores, functional annotations, and regulatory predictions. For each missense variant, ESM-1v scores are computed and included as features in CADD’s gradient-boosted tree classifier. This allows the ensemble to learn how PLM predictions complement other evidence sources, potentially capturing cases where PLM and conservation signals provide independent information.\nPerformance gains from PLM integration are consistent across benchmarks. On ClinVar pathogenic versus common variant classification, CADD v1.7 improves from 0.94 to 0.95 AUROC. On deep mutational scanning datasets (31 assays), performance improves from 0.78 to 0.81 Spearman correlation. The PLM features particularly improve scoring for variants in regions with limited evolutionary conservation data, where traditional methods struggle but language models can still extract contextual information.\n\n\n13.5.2 AlphaMissense: Combining PLM and Structure\nAlphaMissense represents the current state-of-the-art in missense variant effect prediction, combining PLM representations with structural context (Cheng et al. 2023). Rather than treating PLMs as a feature source for an external classifier, AlphaMissense adapts AlphaFold’s architecture directly for pathogenicity prediction.\nThe model learns to predict pathogenicity by combining three information sources. Sequence embeddings from ESM-style language modeling provide evolutionary context about amino acid preferences at each position. Structural context from predicted protein structures captures whether a position is buried or exposed, in a secondary structure element or loop, near active sites or binding interfaces. Evolutionary information from cross-species comparisons supplements the single-sequence PLM signal with explicit alignment-derived conservation.\nThe training data comes from population frequency databases, primarily gnomAD (“The Genome Aggregation Database (gnomAD)” n.d.). Common variants, those observed frequently in healthy populations, provide weak labels for benign effects. Variants absent from large population databases, particularly those in constrained positions, provide weak labels for deleterious effects. Critically, AlphaMissense never trains on clinical pathogenicity labels from ClinVar, yet achieves state-of-the-art performance on clinical benchmarks. This demonstrates that the combination of PLM representations, structural context, and population genetics signals captures genuine functional information rather than memorizing clinical annotations.\nAlphaMissense provides predictions for all approximately 71 million possible single amino acid substitutions across the human proteome. Of these, 89% are classified as either likely benign or likely pathogenic with sufficient confidence to be actionable, providing interpretable predictions for the vast majority of possible missense variants.\n\nComparative performance of missense variant effect predictors on clinical (ClinVar) and experimental (deep mutational scanning) benchmarks (Ng and Henikoff 2003; Adzhubei et al. 2010; Schubach et al. 2024; Meier et al. 2021; Cheng et al. 2023).\n\n\nMethod\nClinVar AUC\nDMS Correlation\nInformation Sources\n\n\n\n\nSIFT\n0.78\n0.30\nConservation\n\n\nPolyPhen-2\n0.82\n0.32\nConservation + structure\n\n\nCADD v1.7\n0.95\n0.81\nMulti-feature integration\n\n\nESM-1v\n0.89\n0.48\nSequence only (zero-shot)\n\n\nAlphaMissense\n0.94\n0.52\nPLM + structure + population\n\n\n\nAlphaMissense achieves top performance by integrating the strengths of multiple approaches: PLM-derived sequence understanding, AlphaFold-derived structural context, and population genetics-derived evolutionary constraint signals.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#lessons-for-genomic-foundation-models",
    "href": "p3-ch13-plm.html#lessons-for-genomic-foundation-models",
    "title": "13  Protein Language Models",
    "section": "13.6 Lessons for Genomic Foundation Models",
    "text": "13.6 Lessons for Genomic Foundation Models\nThe success of protein language models established several principles that inform genomic foundation modeling. These lessons transfer, with appropriate modifications, to the DNA language models covered in subsequent chapters.\n\n13.6.1 Self-Supervision Works\nPLMs demonstrated that massive amounts of biological knowledge can be learned from unlabeled sequences. The same evolutionary pressures that shape proteins also shape DNA. Purifying selection removes deleterious variants, leaving statistical signatures in sequence databases that self-supervised models can learn to exploit. This principle underlies the entire foundation model paradigm: if sufficiently large models are trained on sufficiently large datasets with appropriate self-supervised objectives, they will learn representations that capture biological function.\n\n\n13.6.2 Scale Matters\nPerformance improves predictably with model size, motivating the development of larger genomic models. The progression from 8 million to 15 billion parameters in ESM-2 showed consistent gains across structure prediction, contact prediction, and variant effect tasks. While the relationship between scale and performance is not linear indefinitely, current models remain in a regime where additional capacity yields reliable improvements. This scaling relationship justifies the substantial computational investment required to train genomic foundation models.\n\n\n13.6.3 Transfer Learning is Effective\nRepresentations learned for one task (masked token prediction) transfer to other tasks (structure prediction, variant effects). This suggests that self-supervised pretraining captures fundamental biological knowledge rather than task-specific shortcuts. A model trained to predict masked amino acids is simultaneously learning about protein structure, function, evolutionary constraint, and disease relevance, even though none of these properties appear in the training objective. The same principle applies to genomic sequences: models trained to predict masked nucleotides may simultaneously learn about regulatory elements, evolutionary conservation, and variant effects.\n\n\n13.6.4 Architecture Choices Matter\nThe BERT-style bidirectional encoder proved highly effective for proteins, where the entire sequence context is typically available. However, genomic sequences present different challenges: much longer lengths spanning kilobases to megabases, different information density with proteins being information-dense while intergenic regions are less so, and different symmetries including the reverse-complement structure absent in proteins. These differences motivate architectural adaptations in genomic language models, including hybrid architectures that combine convolutional and attention mechanisms, longer context windows, and specialized tokenization schemes.\n\n\n13.6.5 Integration with Other Modalities\nAlphaMissense showed that PLM embeddings combine effectively with structural information. Similarly, genomic models benefit from integration with epigenomic data, gene annotations, and other biological context. The most powerful variant effect predictors combine multiple information sources, using PLMs as one component of larger systems. This principle extends to genomic foundation models, where sequence-based representations complement rather than replace other genomic annotations.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#limitations-and-ongoing-challenges",
    "href": "p3-ch13-plm.html#limitations-and-ongoing-challenges",
    "title": "13  Protein Language Models",
    "section": "13.7 Limitations and Ongoing Challenges",
    "text": "13.7 Limitations and Ongoing Challenges\nDespite their success, protein language models face several limitations that inform the development of genomic models.\n\n13.7.1 Sequence Length Constraints\nMost PLMs handle sequences up to 1,000 to 2,000 amino acids. While sufficient for most individual protein domains, this limits modeling of large protein complexes and does not directly transfer to the much longer sequences in genomics. Genomic language models must handle sequences spanning millions of bases, requiring architectural innovations beyond simple scaling of transformer attention.\n\n\n13.7.2 Orphan Proteins\nPLMs struggle with proteins that have few homologs in training databases. Orphan or dark proteins, those unique to specific lineages, lack the evolutionary signal that PLMs exploit. For these proteins, the statistical patterns learned from diverse sequence families provide less informative context. This limitation is less severe for genomic models trained on reference genomes, where even unique sequences exist in the context of conserved flanking regions.\n\n\n13.7.3 Epistasis\nMost variant effect predictions assume independence: the effect of mutation A does not depend on whether mutation B is present. Real proteins exhibit epistasis, where variant effects depend on sequence context. Two individually benign variants may be jointly deleterious if they disrupt compensatory interactions. Current PLM-based predictors do not explicitly model these interaction effects, though the contextual embeddings may capture some epistatic relationships implicitly.\n\n\n13.7.4 Interpretability\nWhile attention patterns correlate with biological features, understanding exactly what PLMs learn remains challenging. The field is developing interpretation methods (Chapter 22), but PLMs remain partially opaque. For clinical applications where explanations are valued, this interpretability gap limits adoption. Future work must balance the accuracy gains from complex models against the transparency required for clinical decision-making.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#beyond-language-models-structure-prediction-and-design",
    "href": "p3-ch13-plm.html#beyond-language-models-structure-prediction-and-design",
    "title": "13  Protein Language Models",
    "section": "13.8 Beyond Language Models: Structure Prediction and Design",
    "text": "13.8 Beyond Language Models: Structure Prediction and Design\nWhile protein language models demonstrate the power of self-supervised learning on sequences alone, the broader protein modeling landscape encompasses methods that explicitly incorporate structural information, evolutionary constraints, and physical principles. These approaches complement PLMs by addressing tasks where three-dimensional geometry, binding interactions, or design objectives are central.\n\n13.8.1 Structure Prediction Systems\nAlphaFold2 revolutionized protein structure prediction by combining learned representations with explicit modeling of protein geometry (Jumper et al. 2021). Unlike pure sequence models, AlphaFold2 processes both sequence information through embeddings and structural information through an iterative refinement process that directly predicts atomic coordinates. The system requires multiple sequence alignments as input, using evolutionary information to infer residue-residue contacts and structural constraints. AlphaFold2 searches for homologous sequences using computationally expensive tools including HHblits against the BFD and Jackhmmer against other databases, a process that can take hours per protein.\nAlphaFold3 extends this framework to model protein complexes, nucleic acids, and small molecules (Abramson et al. 2024). The architecture incorporates diffusion-based structure generation, allowing it to predict not only protein structures but also their interactions with other biomolecules. This expansion from single proteins to molecular complexes represents a shift toward modeling entire biological systems rather than isolated components.\nColabFold democratized access to AlphaFold-quality predictions by replacing the slow MSA search with MMseqs2, reducing search time from hours to minutes while maintaining prediction accuracy (Mirdita et al. 2022). The system uses precomputed databases and optimized search algorithms to make structure prediction accessible through free cloud computing resources. ColabFold’s efficiency enabled large-scale structural proteomics, with researchers generating predictions for entire proteomes in practical time frames.\nOpenFold provides an open-source reimplementation of AlphaFold2, enabling researchers to modify and extend the architecture for specialized applications (Ahdritz et al. 2024). By making the full training and inference pipeline accessible, OpenFold supports development of domain-specific variants optimized for particular protein families or prediction tasks.\nRosettaFold emerged as an alternative to AlphaFold2, demonstrating that similar accuracy could be achieved through different architectural choices (Baek et al. 2021). The three-track neural network architecture processes sequence, distance, and coordinate information simultaneously, with each track informing the others through carefully designed information exchange. RosettaFold’s modular design facilitated subsequent extensions including RoseTTAFold2 for protein-protein interactions and RoseTTAFoldNA for nucleic acid modeling.\nESMFold, discussed earlier in this chapter, represents a distinct approach by eliminating MSA requirements entirely (Lin et al. 2022). The model achieves AlphaFold2-level accuracy for many proteins while being orders of magnitude faster, enabling structural annotation of metagenomic sequences where traditional MSA construction fails due to lack of homologs.\n\n\n13.8.2 Generative Design Methods\nProteinMPNN applies message-passing neural networks to the inverse folding problem: designing sequences that fold into specified backbone structures (Dauparas et al. 2022). Given a target structure, the model learns to generate amino acid sequences likely to adopt that fold. ProteinMPNN’s success at designing stable, functional proteins demonstrates that neural networks can capture the sequence-structure relationship in both directions, complementing the structure prediction capabilities of AlphaFold and ESM.\nRFDiffusion extends diffusion models to protein backbone generation, enabling de novo design of proteins with specified functions (Watson et al. 2023). Rather than predicting structure from sequence or sequence from structure, RFDiffusion generates entirely novel protein backbones conditioned on design objectives such as binding a target molecule or forming particular geometric shapes. The method has been used to design proteins with enzymatic activity, binding specificity, and novel folds not found in nature.\nBoltz-1 introduced a unified framework for predicting structures of protein-ligand, protein-protein, and protein-nucleic acid complexes using a diffusion-based approach (Wohlwend et al. 2025). Boltz-2 builds on this foundation with improved accuracy and broader applicability across different types of biomolecular interactions. These methods address the critical challenge of predicting not just individual protein structures but how proteins interact with other molecules in cellular contexts.\n\n\n13.8.3 Molecular Docking and Binding\nDiffDock applies diffusion models to molecular docking, predicting how small molecules bind to protein targets (Corso et al. 2022). Traditional docking methods rely on physics-based scoring functions and extensive sampling, often requiring hours of computation per ligand-protein pair. DiffDock learns to generate binding poses directly, achieving comparable or better accuracy in a fraction of the time. This capability is particularly valuable for drug discovery, where thousands of potential compounds must be evaluated against protein targets.\n\n\n13.8.4 Infrastructure and Search Methods\nThe MSA construction pipeline underlying AlphaFold2 represents substantial engineering beyond the neural network architecture itself. HHblits performs iterative profile-profile searches to identify remote homologs, building deep alignments that capture evolutionary constraints (Remmert et al. 2012). Jackhmmer provides complementary sensitivity using hidden Markov model searches (Finn, Clements, and Eddy 2011). These tools process multiple sequence databases including UniRef, BFD, and MGnify, each optimized for different coverage-redundancy tradeoffs.\nMMseqs2 revolutionized sequence search by achieving BLAST-level sensitivity at hundreds of times the speed through careful algorithmic optimization and parallelization (Steinegger and Söding 2017). ColabFold’s adoption of MMseqs2 for MSA construction demonstrated that the computational bottleneck in structure prediction lay not in the neural network but in the database search, motivating the development of faster search algorithms as a critical infrastructure problem.\n\n\n13.8.5 Integration with Protein Language Models\nThese structure-focused methods increasingly incorporate PLM representations as complementary information sources. AlphaFold3 integrates sequence embeddings from language models with its structure prediction network. RFDiffusion can condition generation on ESM embeddings to guide designs toward particular sequence properties. ProteinMPNN benefits from PLM-derived features when designing sequences for challenging structural targets. This trend toward hybrid architectures suggests that the future of protein modeling lies not in choosing between sequence models and structure models, but in intelligently combining their complementary strengths.\nThe protein modeling ecosystem thus spans a continuum from pure sequence models like ESM that never explicitly represent structure, through hybrid systems like AlphaFold that combine learned sequence representations with geometric constraints, to physics-based methods that emphasize structural principles. Each approach offers distinct advantages: PLMs provide fast, broadly applicable predictions without MSA construction; structure prediction systems achieve atomic-level accuracy when sufficient evolutionary data exists; generative methods enable design of novel proteins with specified functions. Understanding this landscape helps position genomic foundation models, which face analogous tradeoffs between sequence-only and structure-aware approaches.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch13-plm.html#significance",
    "href": "p3-ch13-plm.html#significance",
    "title": "13  Protein Language Models",
    "section": "13.9 Significance",
    "text": "13.9 Significance\nProtein language models established that transformer architectures can learn deep biological knowledge from sequence data alone. ESM’s ability to predict structure, function, and variant effects without explicit labels demonstrated the power of self-supervised learning on evolutionary data. This success directly motivated the development of genomic language models. If proteins constitute a language that transformers can learn, perhaps DNA does too.\nThe genomic language models covered in Chapter 11 adapt PLM architectures and training strategies to the distinct challenges of DNA sequences: longer contexts, different alphabets, and the full complexity of gene regulation. The integration path continues as well: just as CADD v1.7 and AlphaMissense incorporate PLM predictions, future models will integrate genomic and proteomic language models into unified frameworks for variant interpretation (Chapter 20) and multi-omic modeling (Chapter 17).\n\n\n\n\nAbramson, Josh, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, et al. 2024. “[AlphaFold3] Accurate Structure Prediction of Biomolecular Interactions with AlphaFold 3.” Nature 630 (8016): 493–500. https://doi.org/10.1038/s41586-024-07487-w.\n\n\nAdzhubei, Ivan A., Steffen Schmidt, Leonid Peshkin, Vasily E. Ramensky, Anna Gerasimova, Peer Bork, Alexey S. Kondrashov, and Shamil R. Sunyaev. 2010. “A Method and Server for Predicting Damaging Missense Mutations.” Nature Methods 7 (4): 248–49. https://doi.org/10.1038/nmeth0410-248.\n\n\nAhdritz, Gustaf, Nazim Bouatta, Christina Floristean, Sachin Kadyan, Qinghui Xia, William Gerecke, Timothy J. O’Donnell, et al. 2024. “OpenFold: Retraining AlphaFold2 Yields New Insights into Its Learning Mechanisms and Capacity for Generalization.” Nature Methods 21 (8): 1514–24. https://doi.org/10.1038/s41592-024-02272-z.\n\n\nBaek, Minkyung, Frank DiMaio, Ivan Anishchenko, Justas Dauparas, Sergey Ovchinnikov, Gyu Rie Lee, Jue Wang, et al. 2021. “Accurate Prediction of Protein Structures and Interactions Using a Three-Track Neural Network.” Science 373 (6557): 871–76. https://doi.org/10.1126/science.abj8754.\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.” Nature Genetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nCorso, Gabriele, Hannes Stärk, Bowen Jing, Regina Barzilay, and Tommi Jaakkola. 2022. “DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking.” arXiv.org. https://arxiv.org/abs/2210.01776v2.\n\n\nDauparas, J., I. Anishchenko, N. Bennett, H. Bai, R. J. Ragotte, L. F. Milles, B. I. M. Wicky, et al. 2022. “Robust Deep Learning–Based Protein Sequence Design Using ProteinMPNN.” Science 378 (6615): 49–56. https://doi.org/10.1126/science.add2187.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding.” arXiv. https://doi.org/10.48550/arXiv.1810.04805.\n\n\nElnaggar, Ahmed, Michael Heinzinger, Christian Dallago, Ghalia Rihawi, Yu Wang, Llion Jones, Tom Gibbs, et al. 2021. “ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Deep Learning and High Performance Computing.” arXiv. https://doi.org/10.48550/arXiv.2007.06225.\n\n\nFinn, Robert D., Jody Clements, and Sean R. Eddy. 2011. “HMMER Web Server: Interactive Sequence Similarity Searching.” Nucleic Acids Research 39 (suppl_2): W29–37. https://doi.org/10.1093/nar/gkr367.\n\n\nFrazer, Jonathan, Pascal Notin, Mafalda Dias, Aidan Gomez, Joseph K. Min, Kelly Brock, Yarin Gal, and Debora S. Marks. 2021. “[EVE] Disease Variant Prediction with Deep Generative Models of Evolutionary Data.” Nature 599 (7883): 91–95. https://doi.org/10.1038/s41586-021-04043-8.\n\n\nJumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. “[AlphaFold2] Highly Accurate Protein Structure Prediction with AlphaFold.” Nature 596 (7873): 583–89. https://doi.org/10.1038/s41586-021-03819-2.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, et al. 2022. “[ESM-2] Language Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction.” bioRxiv. https://doi.org/10.1101/2022.07.20.500902.\n\n\nMeier, Joshua, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu, and Alexander Rives. 2021. “[ESM-1v] Language Models Enable Zero-Shot Prediction of the Effects of Mutations on Protein Function.” bioRxiv. https://doi.org/10.1101/2021.07.09.450648.\n\n\nMirdita, Milot, Konstantin Schütze, Yoshitaka Moriwaki, Lim Heo, Sergey Ovchinnikov, and Martin Steinegger. 2022. “ColabFold: Making Protein Folding Accessible to All.” Nature Methods 19 (6): 679–82. https://doi.org/10.1038/s41592-022-01488-1.\n\n\nNg, Pauline C., and Steven Henikoff. 2003. “SIFT: Predicting Amino Acid Changes That Affect Protein Function.” Nucleic Acids Research 31 (13): 3812–14. https://doi.org/10.1093/nar/gkg509.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. “ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design.” Advances in Neural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nRaffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2019. “Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.” arXiv. https://doi.org/10.48550/arXiv.1910.10683.\n\n\nRemmert, Michael, Andreas Biegert, Andreas Hauser, and Johannes Söding. 2012. “HHblits: Lightning-Fast Iterative Protein Sequence Searching by HMM-HMM Alignment.” Nature Methods 9 (2): 173–75. https://doi.org/10.1038/nmeth.1818.\n\n\nRiesselman, Adam J., John B. Ingraham, and Debora S. Marks. 2018. “Deep Generative Models of Genetic Variation Capture the Effects of Mutations.” Nature Methods 15 (10): 816–22. https://doi.org/10.1038/s41592-018-0138-4.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. “[ESM-1b] Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.” Proceedings of the National Academy of Sciences of the United States of America 118 (15): e2016239118. https://doi.org/10.1073/pnas.2016239118.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nSteinegger, Martin, and Johannes Söding. 2017. “MMseqs2 Enables Sensitive Protein Sequence Searching for the Analysis of Massive Data Sets.” Nature Biotechnology 35 (11): 1026–28. https://doi.org/10.1038/nbt.3988.\n\n\nSuzek, Baris E., Hongzhan Huang, Peter McGarvey, Raja Mazumder, and Cathy H. Wu. 2007. “UniRef: Comprehensive and Non-Redundant UniProt Reference Clusters.” Bioinformatics 23 (10): 1282–88. https://doi.org/10.1093/bioinformatics/btm098.\n\n\n“The Genome Aggregation Database (gnomAD).” n.d. Accessed July 3, 2025. https://www.nature.com/immersive/d42859-020-00002-x/index.html.\n\n\nWatson, Joseph L., David Juergens, Nathaniel R. Bennett, Brian L. Trippe, Jason Yim, Helen E. Eisenach, Woody Ahern, et al. 2023. “De Novo Design of Protein Structure and Function with RFdiffusion.” Nature 620 (7976): 1089–1100. https://doi.org/10.1038/s41586-023-06415-8.\n\n\nWohlwend, Jeremy, Gabriele Corso, Saro Passaro, Noah Getz, Mateo Reveiz, Ken Leidal, Wojtek Swiderski, et al. 2025. “Boltz-1 Democratizing Biomolecular Interaction Modeling.” bioRxiv. https://doi.org/10.1101/2024.11.19.624167.\n\n\nYang, Zhilin, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2020. “XLNet: Generalized Autoregressive Pretraining for Language Understanding.” arXiv. https://doi.org/10.48550/arXiv.1906.08237.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Protein Language Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html",
    "href": "p3-ch14-hybrid.html",
    "title": "14  Long-range Hybrid Models",
    "section": "",
    "text": "14.1 Why Expression Needs Long-Range Models\nHybrid convolution–transformer architectures such as Enformer and Borzoi were developed to tackle one of the hardest supervised problems in regulatory genomics: predicting gene expression and other functional readouts directly from long stretches of DNA sequence. By combining the locality and efficiency of convolutions with the expressiveness of attention, these models extend the effective receptive field from a few kilobases to hundreds of kilobases or more, while still training end-to-end on large functional genomics compendia.\nIn this chapter, we focus on long-range hybrid models for expression and related tasks. We start with the motivation for long-range context, formalize the problem setting, and then discuss three representative models:\nWe then briefly survey alternative long-range architectures such as hierarchical and windowed attention (Genomic Interpreter) (Li et al. 2023), discuss what these models changed relative to earlier CNN-only architectures, and highlight their limitations and role within the broader genomic foundation model landscape.\nEarly sequence-based models like DeepSEA (Zhou and Troyanskaya 2015) and Expecto (Zhou et al. 2018) demonstrated that local chromatin features and gene expression can be predicted ab initio from relatively short windows of DNA around promoters and candidate regulatory elements. These models showed that motif content, nucleosome positioning signals, and short-range sequence context carry substantial information about chromatin accessibility, histone marks, and transcriptional activity.\nHowever, gene regulation in higher eukaryotes is a long-range, three-dimensional phenomenon. Enhancers and silencers can act over hundreds of kilobases or more, often skipping over nearby genes to regulate more distant targets. Chromatin looping and topologically associating domains (TADs) bring promoters into physical proximity with distal regulatory elements. Many disease-associated variants discovered by GWAS sit far from gene bodies and promoters, but still influence gene expression via such long-range interactions.\nShort-context models inevitably treat distal sequence as noise. They can capture promoter-proximal elements, but may miss key enhancers, silencers, and insulators that fall outside their receptive field. As a result, they can misattribute regulatory effects or underestimate the impact of variants that act through distal elements.\nAs functional genomics datasets grew through ENCODE, Roadmap, FANTOM, and GTEx, and sequencing costs dropped, the field accumulated enough data to train models with substantially longer context. At the same time, improvements in hardware and optimization made deeper and wider convolutional architectures feasible. Basenji2 (Kelley et al. 2018) extended context to tens of kilobases by aggressive pooling, but purely convolutional networks still struggle to propagate information across hundreds of kilobases without very deep stacks.\nHybrid architectures like Enformer and Borzoi emerged as a compromise: use convolutions to condense local sequence into a manageable sequence of latent tokens, then apply attention to propagate information across 100–200 kb. By predicting many signals at once, including chromatin marks, transcription initiation, and RNA coverage, these models can learn a rich representation of regulatory sequence that is particularly useful for variant effect prediction.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#why-expression-needs-long-range-models",
    "href": "p3-ch14-hybrid.html#why-expression-needs-long-range-models",
    "title": "14  Long-range Hybrid Models",
    "section": "",
    "text": "Note\n\n\n\nVISUAL SUGGESTION (biological motivation)\nFigure illustrating promoter–enhancer interactions: a gene with several distal enhancers and silencers spanning ~200 kb, with cartoon 3D chromatin loops and annotated GWAS variants.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#problem-setting-sequence-to-expression-at-scale",
    "href": "p3-ch14-hybrid.html#problem-setting-sequence-to-expression-at-scale",
    "title": "14  Long-range Hybrid Models",
    "section": "14.2 Problem Setting: Sequence-to-Expression at Scale",
    "text": "14.2 Problem Setting: Sequence-to-Expression at Scale\nThe models in this chapter tackle a demanding version of the classic sequence-to-label problem. Instead of predicting a single scalar from a short sequence, they map a long DNA window to thousands of positional, multi-task outputs.\n\n14.2.1 Inputs and Outputs\nThe input is a one-hot encoded DNA sequence, typically spanning 100–200 kb for Enformer and Borzoi, and up to ~1 Mb for AlphaGenome. Most implementations use four channels for nucleotides A, C, G, and T, with ambiguous “N” positions either masked or handled by learned embeddings. A fixed reference genome (e.g., GRCh38) provides the sequence; variants are introduced during inference using in silico mutagenesis or by directly encoding alternative alleles.\nTo make attention computationally tractable, hybrid models use a convolutional front-end that progressively downsamples the sequence. For example, Enformer starts at single-base resolution, applies several convolutional and pooling layers, and ends with a latent sequence of a few thousand tokens representing the 200 kb window.\nThe outputs are multi-task, multi-position tracks:\n\nFor Enformer: per-base predictions of chromatin accessibility, histone modifications, and CAGE signal across many cell types and assays.\nFor Borzoi: base-level RNA-seq coverage and other transcriptomic signals (e.g., PRO-seq, nascent transcription) across cell types.\nFor AlphaGenome: a broader set of outputs spanning chromatin, gene expression, splicing, and 3D contacts.\n\nOutputs are typically arranged as a tensor with axes for position, task/assay, and cell type or condition. Different readouts may be predicted at different resolutions (e.g., downsampled 128 bp bins for chromatin, finer bins around promoters and splice sites).\n\n\n14.2.2 Training Objective\nThe training objective is usually a count-based likelihood or loss computed per track and per position. Common choices include:\n\nPoisson or negative binomial log-likelihood for sequencing counts, sometimes with log-link transformations and offsets for library size.\nMean squared error (MSE) or Pearson correlation objectives when predicting normalized, continuous signals (e.g., log-transformed coverage).\nClassification losses (e.g., binary cross-entropy) for presence/absence or peak/no-peak tasks.\n\nBecause models predict thousands of outputs simultaneously, losses are aggregated across positions, tasks, and cell types. Many implementations use per-track weighting to prevent abundant assays or cell types from dominating the gradient. Some models explicitly down-weight noisy tracks or use curriculum strategies to stabilize training.\nFrom a foundation model perspective, these hybrid architectures can be viewed as supervised multi-task pretraining: the model learns a shared representation of regulatory sequence by jointly optimizing against many functional genomics readouts. This representation can then be probed directly for variant effect prediction, interpreted using attribution methods, or adapted to downstream prediction tasks.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (problem formulation)\nFigure showing: 200 kb DNA window → convolutional downsampling → transformer tokens → multi-task output heads producing a stack of tracks (chromatin, CAGE, RNA-seq) across cell types.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#enformer-cnn-plus-attention-for-200-kb-context",
    "href": "p3-ch14-hybrid.html#enformer-cnn-plus-attention-for-200-kb-context",
    "title": "14  Long-range Hybrid Models",
    "section": "14.3 Enformer: CNN Plus Attention for 200 kb Context",
    "text": "14.3 Enformer: CNN Plus Attention for 200 kb Context\nEnformer (Ž. Avsec et al. 2021) is a landmark model that directly predicts chromatin and CAGE profiles from 200 kb windows of DNA. It demonstrates that long-range context and cross-species training substantially improve prediction of gene expression and regulatory activity, and it introduces a widely adopted template for hybrid genomic architectures.\n\n14.3.1 Architectural Overview\nConceptually, Enformer consists of three stages:\n\nConvolutional stem\nA stack of one-dimensional convolutions with residual connections and pooling progressively transforms base-level one-hot sequence into a shorter sequence of latent representations. This stem detects local motifs and short-range patterns, applies dilated convolutions to expand the receptive field, and uses pooling to reduce sequence length while increasing channel dimensionality.\nTransformer trunk\nThe downsampled latent sequence (on the order of 1–2k positions) is fed into a stack of multi-head self-attention blocks. These blocks use positional encodings to retain information about relative position within the 200 kb window, allow each position to attend to any other, enabling modeling of long-range dependencies across the window, and include feed-forward layers and normalization to stabilize training.\nMulti-task output heads\nAfter the transformer trunk, Enformer applies task-specific linear and convolutional layers to predict coverage tracks for many assays and cell types. Different heads share the same backbone but specialize in different modalities (e.g., DNase, histone marks, CAGE).\n\nThis design balances local pattern recognition (handled by convolutions) and global interaction modeling (handled by attention), while keeping the attention cost manageable by operating on a downsampled sequence.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (architecture)\nFigure: Enformer architecture schematic — one-hot DNA → convolutional blocks (with pooling) → transformer blocks → multi-task regression heads producing chromatin and CAGE tracks.\n\n\nEnformer differs from its predecessor Basenji2 (Kelley et al. 2018) in several key respects. It extends the input window to 200 kb and uses attention instead of relying solely on very deep dilated convolutions to carry long-range information. It unifies many assays and cell types in a single model, rather than training separate models per modality. It explicitly targets gene expression and promoter-level activity, not just local chromatin accessibility. These changes allow Enformer to capture the influence of distal elements on promoters that may be separated by tens or hundreds of kilobases.\n\n\n14.3.2 Training Data and Cross-Species Learning\nEnformer is trained on a large collection of human and mouse regulatory data, including chromatin accessibility (e.g., DNase, ATAC), histone modifications and other marks (ChIP-seq), CAGE or related measures of transcription initiation, and other functional readouts where sufficient coverage is available.\nMouse data from analogous assays enables cross-species learning: by training a single model on both human and mouse genomes, Enformer learns regulatory motifs and patterns that are conserved across mammals. This reduces overfitting to species-specific idiosyncrasies and improves generalization.\nTwo key design choices shape the training regime. First, genome-wide sampling ensures the model is trained on many windows across the genome, not just promoter-proximal regions, ensuring exposure to diverse regulatory contexts. Second, multi-task learning means all assays, cell types, and output positions contribute to the loss, which encourages the backbone to learn features useful across modalities. Cross-species and multi-task training together push Enformer toward learning biologically meaningful regulatory syntax that generalizes beyond any single dataset.\n\n\n14.3.3 Variant Effect Prediction\nLike DeepSEA and Basenji2 before it, Enformer can be used for in silico variant effect prediction. The standard approach is to select a genomic locus and extract a 200 kb window around it, encode the reference allele and compute Enformer’s predicted output tracks, encode an alternative allele (or multiple variants) and recompute predictions, and compute differences between reference and alternative predictions for each track and cell type.\nThis workflow yields per-variant effect estimates on chromatin and CAGE signals across many cell types. Changes can be summarized at the level of gene expression (by aggregating CAGE or chromatin signal around promoters and transcription start sites), regulatory features (by examining specific histone marks or accessibility tracks), and cell-type specificity (by comparing changes across cell types and conditions).\nBecause Enformer provides position-resolved, multi-task outputs, it supports rich analyses of how a variant may alter regulatory landscapes, not just a single scalar expression measure.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (variant effects)\nFigure: Heatmap of predicted log-fold change in expression across tissues for a set of variants in a gene’s promoter, with example highlighted showing a motif-disrupting variant.\n\n\n\n\n14.3.4 Validation Against GTEx eQTLs\nA crucial question is whether Enformer’s variant predictions align with observed expression quantitative trait loci (eQTLs), such as those cataloged in GTEx. In the original work (Ž. Avsec et al. 2021), Enformer’s predictions were systematically compared to GTEx eQTLs. Variants with large predicted effects on promoter CAGE often coincided with significant eQTLs. Enformer captured long-range regulation: variants located tens of kilobases away from a gene’s transcription start site still showed predictive power for expression changes when they lay in predicted enhancers.\nWhile not perfect, these analyses showed that purely sequence-based predictions from Enformer can recover a substantial fraction of eQTL signal, especially for variants in regulatory regions with strong chromatin and CAGE signals.\n\n\n14.3.5 Interpretation and Mechanistic Insight\nDespite its size, Enformer is amenable to several interpretation strategies: gradient-based attribution (e.g., saliency maps, integrated gradients) to highlight sequence positions and motifs that contribute most to predicted outputs, in silico saturation mutagenesis systematically testing all possible substitutions in a region to map functional motifs, and attention visualization examining which positions attend to promoters in the transformer layers, providing hints about promoter–enhancer interactions.\nThese tools have been used to map candidate long-range regulatory interactions, generate hypotheses about motif function, and prioritize variants for experimental follow-up. However, as discussed in Chapter Chapter 20, attribution is not foolproof; it must be interpreted carefully and combined with external evidence.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (attention / attribution)\nFigure: Side-by-side attributions showing (1) gradient-based importance scores around a promoter, and (2) attention weights connecting distal enhancers to that promoter.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#borzoi-transcriptome-centric-hybrid-modeling",
    "href": "p3-ch14-hybrid.html#borzoi-transcriptome-centric-hybrid-modeling",
    "title": "14  Long-range Hybrid Models",
    "section": "14.4 Borzoi: Transcriptome-Centric Hybrid Modeling",
    "text": "14.4 Borzoi: Transcriptome-Centric Hybrid Modeling\nEnformer is primarily trained on chromatin and transcription initiation signals (CAGE). Borzoi (Linder et al. 2025) extends this paradigm to full RNA-seq coverage, capturing splicing, alternative isoforms, and polyadenylation patterns in a unified framework. Instead of focusing on promoter activity, Borzoi treats the entire transcript lifecycle as a modeling target.\n\n14.4.1 Motivation\nRNA-seq carries richer information than a single expression value per gene: exon–intron structure and splice junction usage, alternative transcription start sites and promoter choice, alternative polyadenylation and 3′ UTR usage, and allele-specific expression in heterozygous individuals.\nThese features encode not only transcriptional regulation but also aspects of RNA processing, stability, localization, and translation efficiency. A model that predicts base-level RNA-seq coverage across the genome can therefore inform diverse downstream analyses, from variant effect prediction on splicing to interpretation of 3′ UTR variants that modulate mRNA stability.\n\n\n14.4.2 Architecture\nBorzoi builds on an Enformer-style backbone with modifications tailored to RNA readouts. A convolutional stem and transformer trunk similar in spirit to Enformer provide long-range context (hundreds of kilobases). The output heads predict stranded RNA-seq coverage across the window and additional transcriptomic signals such as PRO-seq, CAGE, and other assays when available. The model places special emphasis on splice junctions (acceptor and donor sites), promoter regions with alternative TSS usage, and 3′ ends where polyadenylation and cleavage occur.\nMulti-task learning across these signals encourages the backbone to encode regulatory information from chromatin through transcription initiation to processing and degradation.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (Borzoi architecture + outputs)\nFigure: Comparison diagram — Enformer outputs chromatin + CAGE, Borzoi outputs RNA-seq coverage with highlighted exon–intron structure and alternative 3′ UTR usage on an example gene.\n\n\n\n\n14.4.3 From Chromatin Signals to RNA Readouts\nBy predicting RNA-seq coverage instead of just promoter-proximal activity, Borzoi supports several analyses not easily addressed by chromatin-only models.\nSplicing variant effects can be evaluated by comparing predicted coverage at exons and junctions under reference and alternative alleles. Large changes in junction usage suggest splicing disruption, complementing specialized models like SpliceAI.\nAlternative promoter and TSS usage becomes visible through coverage predictions. Promoter-proximal variants may alter initiation at alternative TSSs. Borzoi’s coverage predictions reveal shifts in the relative usage of upstream versus downstream promoters.\nAlternative polyadenylation and 3′ UTR regulation can be assessed by measuring shifts in predicted coverage around alternative polyA sites. Variants in 3′ UTRs and downstream regulatory regions may affect mRNA stability and microRNA targeting.\nVariant effect prediction follows similar steps as with Enformer (in silico mutagenesis or allelic substitution), but the outputs now span the entire gene body and flanks, enabling a unified view of how sequence changes affect transcription, splicing, and polyadenylation simultaneously.\nFrom a foundation model perspective, Borzoi moves closer to modeling a full transcriptome readout from sequence. It provides a rich, supervised training signal for representations that encode both regulatory and post-transcriptional features.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (RNA coverage example)\nFigure: Real vs predicted RNA-seq coverage across a gene with an alternative exon and alternative 3′ UTR. Show how a splice-site variant alters predicted exon inclusion.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#alphagenome-unified-megabase-scale-regulatory-modeling",
    "href": "p3-ch14-hybrid.html#alphagenome-unified-megabase-scale-regulatory-modeling",
    "title": "14  Long-range Hybrid Models",
    "section": "14.5 AlphaGenome: Unified Megabase-Scale Regulatory Modeling",
    "text": "14.5 AlphaGenome: Unified Megabase-Scale Regulatory Modeling\nAlphaGenome (Z. Avsec, Latysheva, and Cheng 2025) pushes the hybrid modeling paradigm further by expanding context to roughly a megabase and unifying multiple regulatory, transcriptional, and structural readouts in a single model. Instead of focusing on specific modalities like chromatin or RNA, AlphaGenome aims to serve as a general-purpose regulatory model of the human genome.\n\n14.5.1 Motivation: From Specialized Models to Unified Prediction\nEnformer and Borzoi demonstrate that long-range, multi-task models can predict chromatin and transcriptional features, respectively. However, variant interpretation and mechanistic understanding often require integrating multiple modalities: chromatin accessibility and histone marks (regulatory potential), promoter activity and gene expression (transcription), splicing outcomes (isoform composition), and three-dimensional contacts (which distal elements can act on which genes).\nRunning separate models for each modality complicates interpretation and can introduce inconsistencies. AlphaGenome’s goal is to unify these tasks within a single architecture, so that the backbone representation is informed by data across modalities, variant effect predictions are coherent across chromatin, expression, splicing, and 3D structure, and one can query the model for many types of effects without juggling multiple systems.\n\n\n14.5.2 Architecture\nAt a high level, AlphaGenome follows the hybrid template but at larger scale. The input window spans roughly 1 Mb of DNA sequence, encoded at single-base resolution and then downsampled by a convolutional stem into a sequence of latent tokens. The convolutional stem, similar in spirit to DeepSEA/Basenji lineages, uses stacked convolutions with pooling and nonlinearities to extract local motifs and patterns while reducing sequence length.\nA deep stack of self-attention layers (the transformer trunk) operates on the condensed sequence, enabling modeling of interactions across the full megabase window. Positional encodings and architectural choices are tuned to handle the longer context without prohibitive memory use.\nSeparate output heads predict chromatin signals (accessibility, histone marks), transcriptional readouts (including gene-level expression and promoter activity), splicing-related features (e.g., exon inclusion, splice junction usage), and structural features such as Hi-C or Micro-C contact maps.\nThe model is trained in a multi-task manner, leveraging large compendia of human functional genomics data. Compared to Enformer and Borzoi, AlphaGenome emphasizes human data and multi-modal integration, rather than cross-species training.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (AlphaGenome schematic)\nFigure: 1 Mb DNA window with icons for outputs: chromatin tracks, expression values per gene, splicing metrics per exon, and a 2D contact map, all predicted from a shared backbone.\n\n\n\n\n14.5.3 Access and Practical Use\nAt the time of writing, AlphaGenome is primarily available through an API interface, rather than as an openly downloadable model. This has several practical consequences. Users can score large sets of variants without running training or heavy inference infrastructure locally. The API abstracts away model complexity but limits fine-grained customization (e.g., domain-specific fine-tuning). Data privacy and regulatory requirements may restrict which genomic datasets can be sent to a cloud-hosted API, especially in clinical contexts.\nIn practice, AlphaGenome can be used to score candidate regulatory variants identified from GWAS or sequencing studies, generate multi-modal hypotheses about how a variant acts (e.g., altered chromatin plus splicing disruption), and provide large-scale annotations for variant effect prioritization pipelines, complementing specialized models and statistical fine-mapping.\n\n\n14.5.4 Positioning in the Landscape\nAlphaGenome sits at the intersection of long-range hybrid architectures and multi-modal genomic foundation models. Compared to Enformer and Borzoi, it extends context from 200 kb to ~1 Mb, broadens outputs from chromatin/RNA to include splicing and 3D structure, and emphasizes a unified, human-centric regulatory model.\nRelative to emerging cross-species sequence models such as Evo 2 (Brixi et al. 2025), AlphaGenome is more task-specific and supervised, using labeled functional genomics datasets. Evo 2 focuses on self-supervised pretraining across diverse genomes, potentially providing more general sequence representations but less direct mechanistic interpretability.\nRelative to self-supervised DNA language models and efficient long-context architectures (Hyena, Mamba; see Chapter 7), AlphaGenome can be seen as a bridge between specialized supervised models and broad foundation models, offering rich, multi-modal supervision within a long-range hybrid backbone.\nFrom a practical standpoint, AlphaGenome’s API and multi-modal outputs make it an attractive candidate for variant interpretation pipelines, particularly where a single system that integrates chromatin, expression, splicing, and contacts is desirable.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (positioning figure)\nTable or figure comparing Enformer, Borzoi, and AlphaGenome on axes: context length, modalities predicted, training regime, access (open model vs API).",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#alternative-architectures-hierarchical-attention",
    "href": "p3-ch14-hybrid.html#alternative-architectures-hierarchical-attention",
    "title": "14  Long-range Hybrid Models",
    "section": "14.6 Alternative Architectures: Hierarchical Attention",
    "text": "14.6 Alternative Architectures: Hierarchical Attention\nWhile Enformer, Borzoi, and AlphaGenome use standard self-attention over a condensed sequence, long-range modeling can also be approached through hierarchical or windowed attention mechanisms that reduce computational cost and impose additional inductive biases.\n\n14.6.1 Genomic Interpreter and 1D-Swin Transformers\nGenomic Interpreter (Li et al. 2023) adapts the shifted window (Swin) transformer paradigm to one-dimensional genomic sequences. The core idea is to partition the downsampled sequence into local windows, apply self-attention within each window (which is cheaper than full-sequence attention), use shifted windows in alternating layers so that information can propagate across window boundaries over depth, and merge representations hierarchically, allowing the model to build progressively more global features.\nThe 1D-Swin block operates in two alternating phases. First, standard windowed attention where each position attends only to positions within its local window. Second, shifted-window attention where windows are shifted relative to the original partition so that tokens at window boundaries can attend to neighbors in adjacent windows.\nBy stacking these layers, Genomic Interpreter achieves effective long-range dependency modeling while limiting the quadratic cost of attention to smaller windows. This yields better scaling to longer input sequences than full self-attention at the same resolution and an inductive bias toward local-to-global aggregation, which may align with hierarchical aspects of regulatory architecture (e.g., motifs to enhancers to domains).\nGenomic Interpreter has been evaluated on long-range chromatin and expression prediction tasks, often matching or surpassing Enformer-style baselines at similar compute budgets, especially when pushing context lengths beyond a few hundred kilobases.\n\n\n14.6.2 Computational Trade-offs\nThe choice between full attention and hierarchical/windowed attention involves several trade-offs.\nFull attention (Enformer-style) offers flexibility and expressiveness (any position can attend to any other in a single layer) but has quadratic cost in sequence length, becoming expensive at longer context or higher resolution.\nHierarchical/windowed attention (Genomic Interpreter, 1D-Swin) scales better with sequence length and can handle longer inputs at similar compute budgets. However, some long-range interactions require multiple layers to propagate, and the inductive bias may or may not match specific regulatory architectures.\nAlternative efficient mechanisms (e.g., Hyena, state-space models, Mamba; see Chapter 7) replace attention entirely with architectures that have sub-quadratic or linear scaling and strong long-range memory. These are still being actively explored and benchmarked on genomic tasks; integration with multi-task hybrid setups is an open area.\nIn practice, hybrid models are likely to incorporate a mix of these ideas: convolutional stems for motif-scale features, efficient long-range mechanisms for context propagation, and multi-task heads for rich outputs. The frontier is moving from “Can we model 200 kb?” to “Can we model megabase-scale or chromosomal segments with biologically meaningful inductive biases?”\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (architectural comparison)\nFigure: Side-by-side schematic comparing full self-attention vs windowed/shifted attention vs a generic efficient long-range mechanism, with curves showing theoretical compute vs context length.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#what-hybrid-models-changed",
    "href": "p3-ch14-hybrid.html#what-hybrid-models-changed",
    "title": "14  Long-range Hybrid Models",
    "section": "14.7 What Hybrid Models Changed",
    "text": "14.7 What Hybrid Models Changed\nHybrid CNN–transformer sequence models like Enformer and Borzoi introduced several conceptual advances over earlier architectures.\n\n14.7.1 Explicit Long-Range Modeling\nBy combining convolutional downsampling with attention over latent tokens, hybrid models explicitly model long-range interactions within windows of 100–200 kb or more. This enables better representation of enhancer–promoter and enhancer–enhancer interactions, modeling of promoter competition and insulator effects within regulatory neighborhoods, and capture of regulatory context spanning multiple genes and non-coding regions.\nEarlier CNN-only models such as DeepSEA and Basenji2 could expand their receptive fields through deeper stacks and dilated convolutions, but the path length between distal positions remained long. Attention shortens this path, making it easier to learn dependencies between distant positions given enough data and capacity.\n\n\n14.7.2 Unified Multi-Task Learning Across Modalities\nHybrid models jointly predict multiple modalities (chromatin, transcription initiation, RNA coverage, and more) from a shared backbone. This multi-task setup encourages the model to learn representations that are consistent across modalities (e.g., open chromatin plus active histone marks plus high transcription), allows implicit modeling of relationships between assays (e.g., chromatin changes that precede expression changes), and provides a form of regularization, as the model must simultaneously fit many related outputs.\nFrom a foundation model perspective, this is a supervised analog of multi-modal pretraining: a single model learns from heterogeneous signals, which can then be probed or adapted for downstream tasks.\n\n\n14.7.3 Improved Variant Effect Prediction for Expression\nCompared to earlier CNN-only models like DeepSEA, Beluga, and Expecto, hybrid models substantially improve variant effect prediction for expression-related outcomes. Longer context allows them to capture the effects of distal regulatory variants that would be invisible to short-window models. Multi-modal outputs provide richer evidence for how a variant acts (via chromatin, promoter activity, splicing, or polyadenylation) rather than a single scalar change. Cross-species and multi-task training help filter out noise and emphasize conserved regulatory mechanisms.\nBorzoi further extends this by connecting sequence changes to the full RNA life cycle, offering predictions about splicing, isoform ratios, and 3′ UTR usage. This is particularly valuable for interpreting variants in non-coding regions that regulate isoform-specific expression rather than total gene expression.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (before vs after)\nFigure: Conceptual diagram comparing “pre-hybrid” vs “hybrid” landscapes for variant effect prediction: short-range scalar outputs vs long-range, multi-modal outputs informing expression, splicing, and chromatin.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#limitations-and-failure-modes",
    "href": "p3-ch14-hybrid.html#limitations-and-failure-modes",
    "title": "14  Long-range Hybrid Models",
    "section": "14.8 Limitations and Failure Modes",
    "text": "14.8 Limitations and Failure Modes\nDespite their power, hybrid long-range models are not omniscient and introduce new challenges alongside their capabilities.\n\n14.8.1 Data and Label Limitations\nTraining data still imposes strong constraints. Functional genomics assays are biased toward certain cell types and conditions, often over-representing well-studied tissues and cancer lines. Many loci, particularly in non-European ancestries, are underrepresented or absent from training data. Assays are noisy, with batch effects, sequencing artifacts, and experimental variability.\nAs a result, models may underperform in underrepresented cell types or ancestries, and their predictions should be treated with caution in those settings. Rare regulatory phenomena, such as cell-state-specific enhancers or context-dependent chromatin changes, may be only partially captured. Predictions can reflect technical artifacts in training data, not just biology (a theme revisited in the chapters on evaluation, Chapter 19, and confounders, Chapter 21).\n\n\n14.8.2 Sequence Context and Generalization\nEnformer, Borzoi, and AlphaGenome are trained on fixed window sizes around annotated loci or genome-wide tiles. This introduces several limitations. Even a 1 Mb window (finite context) does not capture whole-chromosome or trans-chromosomal interactions, which can matter for some regulatory events. Models implicitly assume that the relevant information for a readout lies within the chosen window (assumption of local causality). Structural variants, long-range rearrangements, or trans-regulatory effects that fall outside the window are not modeled. Training windows are typically sampled from a reference genome (reference-centric view); complex haplotypes and structural variation are underrepresented.\nThese constraints mean that predictions are most trustworthy for cis-acting variants whose effects are captured within the window and training distribution. Out-of-distribution scenarios (novel structural variants, unusual haplotypes, or highly divergent backgrounds) require special care and, ideally, experimental validation.\n\n\n14.8.3 Interpretability and Trust\nAlthough attribution and interpretation methods exist and have yielded biologically plausible insights, several caveats remain. Attribution maps can be sensitive to model architecture and noise, and may highlight correlated but non-causal sequence features. Attention weights are not guaranteed to be faithful explanations of the model’s reasoning. Multi-modal outputs increase the complexity of interpretation, as one must reconcile changes across many tracks.\nAs discussed in the chapters on evaluation (Chapter 19) and confounders (Chapter 21), hybrid models must be evaluated not only on predictive performance but also on their robustness, calibration, and susceptibility to dataset biases. Interpretability tools should be treated as hypothesis-generating, not as definitive proofs of mechanism.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (failure modes)\nFigure: Cartoon panel showing several failure modes — missing data for some cell types, misinterpreted attribution maps, structural variant outside model context, ancestry mismatch.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#role-in-the-genomic-foundation-model-landscape",
    "href": "p3-ch14-hybrid.html#role-in-the-genomic-foundation-model-landscape",
    "title": "14  Long-range Hybrid Models",
    "section": "14.9 Role in the Genomic Foundation Model Landscape",
    "text": "14.9 Role in the Genomic Foundation Model Landscape\nHybrid architectures like Enformer, Borzoi, and AlphaGenome occupy an interesting niche in the broader genomic foundation model landscape. They are high-capacity models trained on large, heterogeneous datasets, much like foundation models in NLP and vision. However, they are strongly supervised by specific assays and tasks, rather than being pre-trained purely self-supervised on raw DNA.\nIn practice, hybrid models serve multiple roles:\n\nAs task models: directly predicting chromatin, expression, RNA coverage, and variant effects from sequence.\nAs feature extractors: their internal representations can be used as embeddings for downstream models, fine-tuned for specific tasks or cell types.\nAs benchmarks and baselines: they set a high bar for supervised performance on regulatory tasks, against which newer architectures (state-space models, Hyena, Mamba, and large self-supervised DNA language models) must be compared (Chapter 7).\n\nAs the field moves toward large, multi-modal genomic foundation models, hybrid long-range architectures are likely to remain important as specialized, mechanistically grounded models for variant effect prediction, provide training curricula and evaluation tasks for more general sequence models, and influence the design of future architectures that blend supervised multi-task learning with self-supervised pretraining on large-scale genomic data.\nIn other words, hybrid models sit between early CNN-based predictors and fully general genomic foundation models, providing both a stepping stone and a practical tool for current applications.\n\n\n\n\n\n\nNote\n\n\n\nVISUAL SUGGESTION (ecosystem diagram)\nFigure: Ecosystem diagram placing hybrid models alongside self-supervised DNA language models, multi-modal GFMs, and downstream clinical models, with arrows showing how representations and predictions flow between them.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p3-ch14-hybrid.html#summary",
    "href": "p3-ch14-hybrid.html#summary",
    "title": "14  Long-range Hybrid Models",
    "section": "14.10 Summary",
    "text": "14.10 Summary\nThis chapter examined hybrid CNN–transformer architectures designed for long-range genomic prediction, focusing on Enformer, Borzoi, and AlphaGenome as representative examples.\nEnformer combines a convolutional stem with transformer blocks to predict chromatin and CAGE profiles from 200 kb windows, enabling explicit modeling of long-range regulatory interactions and improving variant effect prediction for expression (Ž. Avsec et al. 2021). Borzoi extends this paradigm to RNA-seq coverage and related transcriptomic signals, providing a unified view of how sequence variation affects transcription, splicing, and polyadenylation (Linder et al. 2025). AlphaGenome pushes context to megabase scale and unifies multiple modalities (chromatin, expression, splicing, and 3D contacts) within a single hybrid model, currently accessible primarily via API (Z. Avsec, Latysheva, and Cheng 2025). Hierarchical and efficient attention architectures such as Genomic Interpreter’s 1D-Swin transformer offer alternative ways to scale long-range modeling while controlling compute (Li et al. 2023).\nThe key lessons from this chapter are that long-range context substantially improves our ability to predict expression and regulatory activity from sequence alone, multi-task and multi-modal supervision helps models learn representations that connect chromatin, transcription, and RNA processing, hybrid models are powerful tools for variant effect prediction but remain limited by data biases, finite context, and interpretability challenges, and in the broader genomic foundation model ecosystem, hybrid long-range architectures act as both state-of-the-art task models and stepping stones toward more general, multi-modal genomic foundation models.\nIn Chapter 7, we step back to consider what makes a model a “genomic foundation model” and how hybrid architectures, self-supervised sequence models, and efficient long-context mechanisms fit together in this rapidly evolving space.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. “[Evo 2] Genome Modeling and Design Across All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nKelley, David R., Yakir A. Reshef, Maxwell Bileschi, David Belanger, Cory Y. McLean, and Jasper Snoek. 2018. “[Basenji2] Sequential Regulatory Activity Prediction Across Chromosomes with Convolutional Neural Networks.” Genome Research 28 (5): 739–50. https://doi.org/10.1101/gr.227819.117.\n\n\nLi, Zehui, Akashaditya Das, William A. V. Beardall, Yiren Zhao, and Guy-Bart Stan. 2023. “Genomic Interpreter: A Hierarchical Genomic Deep Neural Network with 1D Shifted Window Transformer.” arXiv. https://doi.org/10.48550/arXiv.2306.05143.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part II: Deep Learning Architectures",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Long-range Hybrid Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html",
    "href": "p4-ch15-sc-epi.html",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "",
    "text": "15.1 CpGPT: A Foundation Model for DNA Methylation\nThe preceding chapters traced how genomic foundation models evolved from early convolutional networks for local regulatory elements to large transformers that operate directly on DNA, RNA, and protein sequences. Those models treat the genome primarily as a one-dimensional string and learn how sequence encodes local biochemical activities and variant effects.\nSingle-cell and epigenomic assays add a different perspective. Rather than asking “what does this sequence do in isolation?”, they capture the state of cells and tissues as they develop, respond to environment, and progress toward disease. DNA methylation, chromatin accessibility, histone marks, and three-dimensional genome folding provide multi-scale readouts of regulatory state that sequence-only models cannot fully capture. Single-cell RNA-seq and multi-omics further reveal how this state varies across individual cells, rather than in bulk averages.\nThis chapter surveys foundation models at three interconnected levels. First, we examine CpGPT, which treats DNA methylation as a sequence-like object amenable to transformer-based pretraining. Second, we explore cellular language models including Geneformer, scGPT, and TranscriptFormer that learn from massive single-cell transcriptomic corpora. Third, we examine GLUE and SCGLUE, which enable integration across modalities when different omics are measured in different cells. Finally, we survey models like Akita that predict three-dimensional chromatin contacts from DNA sequence alone. Throughout, a recurring theme is that these models treat high-dimensional, noisy measurements as tokens in a learned “language” of cellular state, then leverage large pretraining corpora to transfer across tasks, tissues, species, and technologies.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html#cpgpt-a-foundation-model-for-dna-methylation",
    "href": "p4-ch15-sc-epi.html#cpgpt-a-foundation-model-for-dna-methylation",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "",
    "text": "15.1.1 Methylation as a Systems Hub\nDNA methylation occupies a privileged position in the regulatory hierarchy, sitting at a junction between genotype, environment, and phenotype. Methylation patterns integrate genetic influences, since sequence context affects which CpG sites can be methylated and polymorphisms can create or destroy CpG dinucleotides. They also integrate developmental programs, since methylation landscapes are extensively remodeled during differentiation and establish cell-type-specific regulatory states. Environmental exposures including diet, smoking, toxins, and stress leave lasting methylation signatures that persist long after the exposure ends.\nBeyond serving as an integrative readout, methylation encodes rich information about cellular identity and state. Cell types can be distinguished by their methylation profiles, and within a cell type, methylation captures information about age, health status, and disease risk. Epigenetic clocks built from methylation data predict chronological age with remarkable accuracy, and deviations from predicted age correlate with mortality risk and disease burden (Camillo et al. 2024).\nTraditional methylation models have been task-specific: one model for age prediction, another for mortality risk, another for tissue classification. Each model is trained from scratch on labeled data for its particular task, learning whatever methylation patterns happen to be predictive without necessarily capturing general structure. CpGPT reframes methylation as a foundation modeling problem, using large-scale pretraining to learn representations that transfer across tasks.\n\n\n15.1.2 Architecture and Pretraining\nCpGPT, the Cytosine-phosphate-Guanine Pretrained Transformer, treats methylomes as sequences or sets of CpG sites and uses transformer-style self-attention to model their structure (Camillo et al. 2024). The model was pretrained on over 1,500 DNA methylation datasets encompassing more than 100,000 samples from diverse tissues and conditions.\nSeveral aspects of methylation structure make it amenable to transformer modeling. Local CpG correlations arise because nearby CpG sites tend to share methylation status, particularly within CpG islands. Long-range coordination reflects the fact that methylation patterns at distant genomic regions can be correlated through shared regulatory programs or chromatin compartmentalization. Global sample-level variation captures the systematic differences between samples that reflect tissue identity, age, disease status, and other biological variables.\nThe input representation tokenizes each methylation sample as a sequence of CpG sites with probe or genomic position identifiers, methylation beta values (often transformed or discretized), and optional metadata such as platform or tissue. The model combines local sequence context around each CpG with relative position along the genome and global sample-level embeddings representing tissue and condition.\nCpGPT uses masked modeling objectives analogous to BERT-style language model pretraining. During training, a fraction of CpG methylation values are masked, and the model learns to predict the masked values from the surrounding context. This objective encourages the model to learn both local correlations between neighboring CpG sites and global patterns that distinguish different tissues or conditions.\nThe resulting embeddings capture sample-level representations that summarize methylation state. These embeddings can serve as inputs to downstream predictors, providing rich methylation features for risk scores, prognosis models, or treatment response prediction. They can function as one modality in a shared latent space that also includes expression, proteomics, and other data types. They can inject epigenetic state information into otherwise sequence-centric genomic foundation models, providing context about cellular identity and regulatory status.\n\n\n15.1.3 Downstream Applications and Transfer Learning\nOnce pretrained, CpGPT supports several capabilities with minimal or no additional supervised training. The model can impute methylation levels at CpG sites not directly measured on a given array platform, effectively enabling array conversion between platforms such as EPIC and 450K by leveraging sequence context and co-methylation structure (Camillo et al. 2024). This addresses a persistent challenge in methylation research where different studies use different array technologies.\nFor biological age prediction, fine-tuned CpGPT models match or exceed the performance of purpose-built epigenetic clocks while using a more general architecture. The learned embeddings cluster by tissue type without explicit supervision during pretraining, suggesting that the model captures biologically meaningful variation. For disease-associated methylation patterns, CpGPT can be adapted to distinguish cases from controls across multiple disease contexts through transfer learning.\nThe foundation model paradigm offers several advantages over task-specific methylation models. New tasks can be addressed through fine-tuning or linear probing rather than training from scratch. Representations learned from diverse tissues and conditions may generalize better than those learned from narrow disease-specific cohorts. The model provides a unified framework for understanding methylation variation across biological contexts.\nBecause CpGPT is transformer-based, its attention patterns and learned embeddings can be probed to rank CpGs by their contribution to specific predictions. This offers a route toward mechanistic insight, complementing purely statistical epigenetic clocks. However, important limitations remain. Most training data are bulk methylation, so cell-type-specific signals may be entangled. Methylation is a downstream readout of regulatory processes, so CpGPT captures associations but not necessarily causal mechanisms. Training remains constrained by the coverage and diversity of available cohorts in terms of ancestry, tissue types, and environmental exposures.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html#single-cell-foundation-models",
    "href": "p4-ch15-sc-epi.html#single-cell-foundation-models",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "15.2 Single-Cell Foundation Models",
    "text": "15.2 Single-Cell Foundation Models\n\n15.2.1 The Promise of Cellular Language Models\nThe explosion of single-cell sequencing data has created training corpora of unprecedented scale for modeling cellular biology. Public repositories now contain tens of millions of single-cell transcriptomes spanning diverse tissues, developmental stages, disease states, and species. This scale approaches the data volumes that enabled large language models, motivating researchers to ask whether similar foundation model approaches could work for cellular data.\nThe analogy between language and single-cell biology runs deeper than dataset scale. In language, words combine according to grammatical rules to form sentences that convey meaning. In cells, genes combine according to regulatory programs to form expression profiles that define cellular identity and function. Just as language models learn syntax and semantics by predicting masked words, single-cell foundation models might learn regulatory logic by predicting masked genes.\nSeveral groups have pursued this vision, producing models with different architectures, pretraining objectives, and downstream applications. The resulting cellular language models treat cells as documents or sentences, genes or features as tokens, and expression levels as token attributes. If a model can learn the “grammar” of which genes co-occur and how their expression levels vary across contexts, it may provide context-aware embeddings of genes and cells, support zero-shot or few-shot transfer to new datasets, and enable in silico perturbations where the model predicts how changing one gene or pathway affects the rest of the transcriptome.\n\n\n15.2.2 Geneformer: Network Biology Through Pretraining\nGeneformer was developed as a context-aware, attention-based model pretrained on approximately 30 million single-cell transcriptomes to enable context-specific predictions in network biology (Theodoris et al. 2023). The model’s key insight is that during pretraining, it gained a fundamental understanding of network dynamics, encoding network hierarchy in attention weights in a completely self-supervised manner.\nThe architecture treats each cell as a sentence, with genes serving as tokens. Rather than using raw expression counts, Geneformer ranks genes by their expression level relative to their typical expression across the training corpus. This rank-based encoding emphasizes which genes are unusually active or silent in each cell, capturing the contextual information that defines cell state. The representation discards absolute counts but preserves relative ordering, which is often more stable across datasets and platforms.\nPretraining uses a masked gene prediction objective. A fraction of genes are masked in each cell, and the model learns to predict which genes were masked based on the remaining expression context. This forces the model to learn co-expression patterns, regulatory relationships, and the gene combinations that characterize different cell states. The objective encourages learning of which genes tend to co-occur at particular ranks in specific cellular contexts, implicitly capturing regulatory modules and pathways.\nAfter pretraining, Geneformer can be fine-tuned for diverse downstream tasks. Cell type annotation achieves high accuracy even with limited labeled examples, leveraging the general biological knowledge acquired during pretraining. Multi-batch integration benefits from representations that capture biological variation while being robust to technical artifacts. Perturbation response prediction uses the model’s implicit understanding of gene networks to anticipate how cells will respond to genetic or chemical perturbations. The model can also prioritize genes according to their influence on specific cell states or disease-relevant phenotypes.\nApplied to disease modeling with limited patient data, Geneformer identified candidate therapeutic targets for cardiomyopathy by analyzing how disease-associated genes fit within the learned network structure (Theodoris et al. 2023). This demonstrates the potential for foundation models to accelerate discovery in rare diseases where large datasets are unavailable. Because the model encodes context-aware network information, it can often perform well in data-scarce settings.\n\n\n15.2.3 scGPT: Generative Pretraining for Multi-Omics\nscGPT extends the foundation model paradigm to single-cell multi-omics, training a generative pretrained transformer on over 33 million cells to learn representations useful across diverse downstream applications (Cui et al. 2024). The model is designed as a generalist backbone for single-cell analysis pipelines, analogous to how general-purpose language models serve text applications.\nThe model architecture includes several innovations tailored to single-cell data. Gene tokens are embedded using both learnable embeddings and position encodings that capture genomic location. Expression values are discretized into bins to handle the wide dynamic range and zero-inflation characteristic of single-cell data. Special tokens mark cell boundaries and indicate modality when multi-omic data are available. Attention masks and positional encodings are adapted so that the model can handle the unordered nature of gene sets while still benefiting from sequence-like inductive biases.\nscGPT uses multiple pretraining objectives simultaneously. Masked gene prediction, analogous to BERT, encourages learning of co-expression patterns. Autoregressive generation predicts expression of one set of genes conditioned on others, enabling sampling and imputation. Contrastive objectives encourage cells from the same type or condition to cluster in embedding space while separating different types. These objectives are applied across diverse datasets to learn shared gene and cell embeddings that are reusable across tasks and modalities (Cui et al. 2024).\nThe combination of objectives and the scale of pretraining enable scGPT to excel across multiple downstream applications. Cell type annotation benefits from the rich representations learned during pretraining, including fine-grained subtypes. Multi-batch integration aligns cells from different experiments while preserving biological variation, addressing the pervasive batch effects in single-cell data. Multi-omic integration learns joint representations when cells have both RNA-seq and ATAC-seq measurements. Perturbation response prediction anticipates transcriptional changes following CRISPR knockouts or drug treatments. Gene network inference extracts regulatory relationships from attention patterns.\n\n\n15.2.4 TranscriptFormer and Cross-Species Modeling\nTranscriptFormer extends single-cell foundation models across evolutionary time, training on over 112 million cells spanning 1.5 billion years of evolution across 12 species (Pearce et al. 2025). This cross-species approach tests whether foundation models can learn regulatory principles that generalize beyond individual organisms.\nThe model uses a novel generative architecture that jointly models genes and transcripts, with specialized heads and attention mechanisms to capture their relationships. The autoregressive objective predicts genes and their expression levels in a causal fashion, enabling it to generate synthetic cells conditioned on prompts such as species, tissue, or cell type. Because the vocabulary spans multiple species, the model functions as a virtual instrument for probing cellular biology.\nIn zero-shot settings, TranscriptFormer demonstrates superior performance on both in-distribution and out-of-distribution cell type classification, with robust performance even for species separated by over 685 million years of evolutionary distance. This cross-species perspective reveals that core principles of cellular regulation are deeply conserved.\nCross-species transfer enables several applications not possible with single-species models. Cell type annotations can be transferred across species boundaries, accelerating atlas construction for less-studied organisms. Disease state identification in human cells benefits from regulatory patterns conserved across evolution. Gene-gene interactions predicted by the model align with independent experimental observations across species. The model can suggest conserved transcription factors and regulatory logic that operate across phylogeny.\nThe success of cross-species foundation models suggests that models trained on diverse organisms can capture universal patterns more effectively than models trained on any single species. This has implications for understanding both evolution and disease, as conserved regulatory programs often represent the most fundamental aspects of cellular function.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html#glue-graph-linked-unified-embedding-for-single-cell-multi-omics",
    "href": "p4-ch15-sc-epi.html#glue-graph-linked-unified-embedding-for-single-cell-multi-omics",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "15.3 GLUE: Graph-Linked Unified Embedding for Single-Cell Multi-Omics",
    "text": "15.3 GLUE: Graph-Linked Unified Embedding for Single-Cell Multi-Omics\n\n15.3.1 The Unpaired Integration Challenge\nSingle-cell experiments often profile different modalities in different cells. A typical study might include scRNA-seq data from one set of cells, scATAC-seq data from another set, and perhaps a small subset with both modalities measured simultaneously through multiome protocols. The central challenge is building a unified atlas that aligns these cells in a common space, recovers cell types and trajectories, and infers regulatory networks connecting chromatin to expression (Cao and Gao 2022).\nThis problem is harder than standard data integration because the feature spaces are entirely different. RNA-seq measures gene expression across roughly 20,000 genes. ATAC-seq measures chromatin accessibility across hundreds of thousands of peaks. There is no direct correspondence between features: a gene is not the same object as a peak. Aligning cells across modalities requires reasoning about how features in one modality relate to features in another.\nPrevious approaches addressed this through explicit feature conversion, for example by assigning ATAC-seq peaks to nearby genes and treating the resulting gene-level accessibility as comparable to expression. This conversion is straightforward but loses information, since the detailed structure of chromatin accessibility within a gene’s regulatory region is collapsed into a single number. It also introduces arbitrary choices about how to define gene-peak assignments.\nGLUE, Graph-Linked Unified Embedding, addresses this problem by combining modality-specific encoders with a graph of biological prior knowledge linking features across omics. Rather than converting features, GLUE explicitly encodes regulatory relationships into a guidance graph and learns cell embeddings that are consistent with this graph.\n\n\n15.3.2 Architecture and Training\nGLUE consists of three key components that work together to align cells across modalities while respecting biological relationships between features (Cao and Gao 2022).\nModality-specific variational autoencoders provide the foundation. Each omic has its own encoder-decoder pair. Encoders map cells to a low-dimensional latent embedding, and decoders reconstruct modality-specific features from these embeddings. The variational structure encourages smooth, interpretable latent spaces. Generative distributions differ by modality to match data characteristics: negative binomial for count data, Bernoulli or Gaussian for others.\nThe feature graph encodes biological prior knowledge about relationships between features across modalities. Nodes represent genes, peaks, regulatory elements, and other genomic features. Edges connect ATAC peaks to the genes they might regulate based on genomic proximity or evidence from chromatin conformation capture experiments. Edges connect genes to the transcription factors that bind their promoters. The graph structure is provided as input rather than learned, allowing incorporation of external biological knowledge from databases, literature, and prior experiments.\nA graph variational autoencoder learns feature embeddings from this guidance graph. These feature embeddings are then used in the decoders of the modality-specific VAEs, tying them to a common regulatory backbone. This ensures that biologically related features have similar representations and helps align the latent spaces of different modalities.\nAdversarial alignment ensures that the latent embeddings from different modalities are truly integrated rather than merely correlated. A discriminator tries to distinguish which modality produced each latent embedding, and the encoders are trained to fool the discriminator. This adversarial objective forces the encoders to produce embeddings that are indistinguishable across modalities, creating a unified cell embedding space where cells from different modalities occupy a shared manifold.\n\n\n15.3.3 Applications and Extensions\nGLUE enables several applications beyond basic integration. Triple-omics integration combines gene expression, chromatin accessibility, and DNA methylation measured in different cells from the same tissue, producing unified cell type annotations that leverage all three data types. Regulatory inference uses the learned feature embeddings to identify candidate enhancer-gene links that can be validated against chromatin conformation capture data or eQTL evidence. The guidance graph and learned embeddings provide a regularized view of peak-gene-TF relationships that is more principled than simple distance-based assignment.\nCross-modal prediction becomes possible when cells are aligned in a common space. The model can predict chromatin accessibility from expression or vice versa, enabling imputation of missing modalities. Atlas construction at scale handles millions of cells across many batches and datasets, with the graph structure helping to distinguish biological variation from technical artifacts.\nSCGLUE extends the framework specifically for single-cell applications, with optimizations for the scale and sparsity of single-cell data (Cao and Gao 2022). The adversarial alignment is refined to handle the batch effects common in single-cell experiments, and the graph structure is expanded to include tissue-specific regulatory relationships. SCGLUE scales to millions of cells while maintaining the biological grounding provided by the guidance graph.\nThe success of GLUE demonstrates that graph-guided integration, where biological prior knowledge structures the alignment objective, provides a more principled approach than feature conversion or purely data-driven alignment. The feature graph allows the model to learn biologically meaningful relationships while the adversarial objective ensures genuine integration across modalities. This pattern of combining learned representations with structured biological knowledge recurs throughout foundation models for genomics.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html#d-genome-prediction-models",
    "href": "p4-ch15-sc-epi.html#d-genome-prediction-models",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "15.4 3D Genome Prediction Models",
    "text": "15.4 3D Genome Prediction Models\n\n15.4.1 The Structural Dimension of Gene Regulation\nThe linear genome folds into a complex three-dimensional structure that brings distant regulatory elements into spatial proximity with their target genes. This folding is not random: specific sequence features, particularly CTCF binding sites with their characteristic orientation dependence, organize the genome into topologically associating domains (TADs) and create specific chromatin contacts between enhancers and promoters.\nUnderstanding how sequence encodes 3D structure is crucial for interpreting regulatory variants. A variant might sit far from any gene in linear distance but be brought into contact with a promoter through chromatin looping. Sequence-to-structure models that predict chromatin contacts from DNA sequence can identify such variants and predict how structural variants, which may create or disrupt loops, affect gene regulation. From a modeling perspective, 3D genome structure matters because many regulatory elements act over tens to hundreds of kilobases, disrupting chromatin loops can misregulate genes even when local sequence motifs remain intact, and structural variation and rearrangements are often key drivers of cancer and developmental disorders.\nHi-C, Micro-C, and related assays measure chromatin contacts but are expensive and typically low-resolution. Predictive models of 3D structure from sequence promise to infer structural consequences of non-coding SNVs and SVs, provide structural priors to sequence-to-expression models, and enable in silico mutagenesis of regulatory landscapes at scale.\n\n\n15.4.2 Akita: Sequence-to-Contact Prediction\nAkita demonstrated that convolutional neural networks can accurately predict genome folding from DNA sequence alone (Fudenberg, Kelley, and Pollard 2020). The model takes megabase-scale sequence as input and outputs predicted Hi-C contact maps, capturing the spatial proximity relationships between all pairs of positions in the input window.\nThe architecture uses an encoder-decoder structure. The input is a one-hot encoded DNA sequence of fixed length, typically around 1 megabase, centered on the region of interest. Deep convolutional blocks in the encoder extract hierarchical sequence features at multiple scales, capturing both the local motifs (particularly CTCF sites) that anchor chromatin loops and the broader sequence context that influences compartmentalization. Dilated convolutions and pooling expand receptive fields to capture long-range dependencies. The decoder reconstructs the two-dimensional contact matrix from the encoded sequence representation, typically at around 2 kilobase resolution.\nAkita is trained on Hi-C and Micro-C contact maps from specific cell types, optimizing a loss function over predicted versus observed contact matrices. The model’s representations underscore the importance of an orientation-specific grammar for CTCF binding sites. Akita learns that CTCF sites pointing toward each other tend to anchor chromatin loops, while sites pointing away do not. This orientation dependence, known from molecular biology, emerges automatically from training on Hi-C data without explicit supervision.\nOnce trained, Akita enables rapid in silico predictions. Saturation mutagenesis experiments, prohibitively expensive to perform experimentally across megabase regions, can be simulated computationally by predicting the effect of every possible single-nucleotide change on chromatin structure. This reveals which positions are most critical for maintaining normal genome folding and which mutations might cause structural disruption.\nApplications include interpreting eQTLs through the lens of 3D structure, making predictions for structural variants that create or delete CTCF sites, and probing species-specific genome folding by applying models trained on one species to sequences from another. The model can score the impact of every possible SNV or small indel on local contact patterns, suggesting which non-coding variants perturb loop structures relevant to gene expression (Fudenberg, Kelley, and Pollard 2020).\n\n\n15.4.3 Extensions and Related Models\nSeveral models have extended Akita’s sequence-to-structure paradigm. Orca scales to longer input contexts and higher resolution outputs, enabling prediction of finer structural features. DeepC uses transfer learning to predict 3D folding at megabase scales across different cell types. C.Origami incorporates additional training data and architectural refinements.\nSubsequent work has also developed hierarchical and multi-scale models that predict contact maps at multiple resolutions and genomic scales. Architectures that better handle structural variants, including large deletions, inversions, and translocations, explicitly model rearranged sequence segments. Integration of 3D structure with expression predictors has emerged as a natural direction, where 3D models provide features or inductive biases to sequence-to-expression networks.\nHiCDiffusion addresses a limitation of encoder-decoder architectures: the tendency to produce blurred contact maps that lack the sharp features of experimental Hi-C data. By combining the encoder-decoder with a diffusion model, HiCDiffusion produces high-resolution matrices that better resemble experimental results while maintaining similar correlation with ground truth.\nThese models collectively establish that 3D genome structure can be predicted from sequence, opening new possibilities for understanding how variants affect gene regulation through structural mechanisms that sequence-to-expression models like Enformer capture only indirectly. The mapping from sequence to 3D structure is sufficiently regular that deep learning can decode aspects of the structural grammar of the genome.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html#design-patterns-and-practical-considerations",
    "href": "p4-ch15-sc-epi.html#design-patterns-and-practical-considerations",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "15.5 Design Patterns and Practical Considerations",
    "text": "15.5 Design Patterns and Practical Considerations\nSeveral design patterns recur across the models surveyed in this chapter, revealing common strategies for handling cellular and epigenomic data.\nTokenization strategies for cellular data require careful consideration. Geneformer’s rank-based encoding emphasizes relative expression and is stable across datasets and platforms. scGPT’s discretization handles the dynamic range of count data while enabling discrete prediction objectives. CpGPT tokenizes CpG sites with their methylation values and genomic positions. 3D genome models operate on fixed-length sequence windows. The choice of tokenization affects what biological signals the model can capture and how well representations transfer across datasets with different technical characteristics.\nPretraining objectives shape what models learn and which downstream tasks they support. Masked prediction encourages learning of co-occurrence patterns and local dependencies. Generative objectives enable sampling and imputation. Contrastive objectives emphasize discriminative features that separate cell types or conditions. Multi-task pretraining can combine benefits of multiple objectives, as demonstrated by scGPT’s simultaneous use of masked prediction, autoregressive generation, and contrastive learning. The choice of objective reflects assumptions about which aspects of biological structure are most important.\nGraph structure provides biological grounding that can regularize learning and improve interpretability. GLUE’s feature graph encodes regulatory relationships that guide integration across modalities. Similar graph structures could incorporate protein-protein interactions, pathway membership, or other biological networks to constrain what models learn. This pattern of combining learned representations with structured biological knowledge helps ensure that models respect known biology while discovering new patterns.\nScale of pretraining enables generalization across contexts. Models trained on tens of millions of cells or hundreds of thousands of samples learn representations that transfer to new contexts better than models trained on smaller datasets. This argues for continued investment in large-scale data generation and aggregation. However, scale alone does not guarantee utility: the diversity of training data (across tissues, species, conditions, and platforms) matters as much as raw sample count.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html#practical-challenges",
    "href": "p4-ch15-sc-epi.html#practical-challenges",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "15.6 Practical Challenges",
    "text": "15.6 Practical Challenges\nSeveral challenges complicate the application of single-cell and epigenomic foundation models in practice.\nBatch effects remain pervasive in single-cell data. Technical differences between experiments, protocols, and platforms can dominate biological signal. Foundation models that are robust to batch effects in their training data may struggle when applied to new batches not represented during pretraining. The field continues to grapple with distinguishing genuine biological variation from technical artifacts.\nCell type imbalance affects what models learn. Common cell types are overrepresented in training corpora, while rare populations may be poorly captured. Models may excel at identifying well-represented cell types while struggling with rare or novel populations. This has equity implications when rare cell types are disease-relevant or when certain tissues or conditions are systematically undersampled.\nEvaluation complexity increases when ground truth is uncertain. Cell type labels in training data reflect current annotations that may be incomplete or inconsistent. Performance metrics on held-out data conflate model quality with annotation quality. Regulatory network predictions face similar challenges, as gold standard interaction sets are incomplete and context-dependent. Evaluation protocols must acknowledge these uncertainties rather than treating benchmarks as definitive.\nData imbalance and coverage biases extend beyond cell types. Common ancestries dominate current corpora, as do certain tissues and experimental protocols. Rare cell types, underrepresented populations, and less-studied organisms may be poorly modeled, with consequences for equity and generalizability. The field must invest in diverse data generation while developing methods that can generalize despite limited training examples.\nComputational requirements for training and inference remain substantial. While smaller than the largest language models, single-cell foundation models still require significant GPU resources that may limit accessibility. Techniques such as distillation, quantization, and parameter-efficient fine-tuning are essential for broader adoption. Making models accessible to researchers without extensive computational infrastructure remains an important goal.\nDomain shift between training and deployment contexts poses persistent challenges. Models trained on one technology platform, tissue type, or species may not transfer well to others. Even when transfer is possible, performance may degrade in ways that are difficult to predict or diagnose. Understanding the boundaries of model applicability requires careful characterization of both training data and deployment contexts.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch15-sc-epi.html#summary",
    "href": "p4-ch15-sc-epi.html#summary",
    "title": "15  Single-Cell & Epigenomic Models",
    "section": "15.7 Summary",
    "text": "15.7 Summary\nThis chapter has surveyed foundation models that operate on epigenomic and single-cell readouts rather than primary DNA sequence alone. CpGPT demonstrates that methylation can be modeled as a sequence-like object amenable to transformer-based pretraining, with applications spanning biological age prediction, tissue classification, disease association, and platform conversion. Single-cell foundation models including Geneformer, scGPT, and TranscriptFormer learn cellular representations from massive transcriptomic corpora that transfer to diverse downstream tasks including cell type annotation, perturbation response prediction, gene network inference, and cross-species analysis. GLUE shows how graph-linked embeddings can align cells across modalities when different omics are measured in different cells, using biological prior knowledge to guide integration. 3D genome prediction models including Akita and its successors predict chromatin contacts from sequence, revealing how variants affect gene regulation through structural mechanisms.\nThese models extend the foundation model paradigm from sequence-only representations to the rich landscape of cellular identity and genome organization. They demonstrate that the principles enabling language models (large-scale pretraining, transfer learning, context-aware representations) can be adapted to biological domains where tokens represent genes, CpG sites, or genomic positions rather than words. The success of these adaptations depends critically on choosing appropriate tokenization strategies, pretraining objectives, and architectural inductive biases that reflect the structure of biological data.\nLooking forward, several directions promise to enhance these models’ utility. Integration across levels of organization (sequence, epigenome, 3D structure, cellular state) could yield multi-scale representations that capture regulatory logic more completely than any single modality. Cross-species pretraining can reveal conserved principles while highlighting evolutionary innovations. Incorporation of temporal dynamics through developmental trajectories or disease progression could better capture how cellular states transition over time. The evaluation and interpretability principles developed in later chapters become especially important for these models, where ground truth is often uncertain and deployment stakes are high.\n\n\n\n\nCamillo, Lucas Paulo de Lima, Raghav Sehgal, Jenel Armstrong, Albert T. Higgins-Chen, Steve Horvath, and Bo Wang. 2024. “CpGPT: A Foundation Model for DNA Methylation.” bioRxiv. https://doi.org/10.1101/2024.10.24.619766.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nCui, Haotian, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan Duan, and Bo Wang. 2024. “scGPT: Toward Building a Foundation Model for Single-Cell Multi-Omics Using Generative AI.” Nature Methods 21 (8): 1470–80. https://doi.org/10.1038/s41592-024-02201-0.\n\n\nFudenberg, Geoff, David R. Kelley, and Katherine S. Pollard. 2020. “[Akita] Predicting 3D Genome Folding from DNA Sequence with Akita.” Nature Methods 17 (11): 1111–17. https://doi.org/10.1038/s41592-020-0958-x.\n\n\nPearce, James D., Sara E. Simmonds, Gita Mahmoudabadi, Lakshmi Krishnan, Giovanni Palla, Ana-Maria Istrate, Alexander Tarashansky, et al. 2025. “[TranscriptFormer] Cross-Species Generative Cell Atlas Across 1.5 Billion Years of Evolution: The TranscriptFormer Single-Cell Model.” bioRxiv. https://doi.org/10.1101/2025.04.25.650731.\n\n\nTheodoris, Christina V., Ling Xiao, Anant Chopra, Mark D. Chaffin, Zeina R. Al Sayed, Matthew C. Hill, Helene Mantineo, et al. 2023. “[Geneformer] Transfer Learning Enables Predictions in Network Biology.” Nature 618 (7965): 616–24. https://doi.org/10.1038/s41586-023-06139-9.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Single-Cell & Epigenomic Models</span>"
    ]
  },
  {
    "objectID": "p4-ch16-networks.html",
    "href": "p4-ch16-networks.html",
    "title": "16  Graphs, Networks, and Biology",
    "section": "",
    "text": "16.1 Graph Neural Network Fundamentals\nThe foundation models explored in earlier chapters treat genomic data as sequences: DNA bases arranged in chromosomal order, amino acids forming protein chains, or RNA transcripts as linear strings of nucleotides. This sequential view has proven remarkably powerful for tasks ranging from variant effect prediction to protein structure modeling. Yet biology is fundamentally relational. Genes regulate one another through transcription factor networks, proteins assemble into functional complexes, metabolites flow through biochemical pathways, and cells coordinate across tissues through spatial signaling. These relationships are not well captured by sequences alone.\nGraphs provide a natural mathematical framework for representing such relational structure. In a graph, biological entities become nodes and their interactions become edges. A protein-protein interaction network represents proteins as nodes with edges denoting physical binding or functional association. A gene regulatory network encodes transcription factors and their targets with directed edges indicating regulatory control. Spatial transcriptomics data can be modeled as a graph where cells are nodes and edges capture physical proximity or inferred cell-cell communication. This graph perspective allows us to ask questions that sequence models cannot easily address: How does a perturbation in one gene propagate through regulatory cascades? Which protein complexes are enriched in disease-associated genes? How do spatial neighborhoods of cells influence tissue-level phenotypes?\nGraph neural networks (GNNs) extend deep learning to operate directly on graph-structured data. Rather than sliding convolutional filters across a regular grid or attending over a fixed-length sequence, GNNs perform message passing along edges: each node iteratively aggregates information from its neighbors to refine its representation. This allows models to incorporate both node-level features (such as gene expression or sequence embeddings) and edge-level structure (such as known interactions or spatial relationships) in a unified framework. GNNs have achieved state-of-the-art results across diverse domains including molecular property prediction, recommendation systems, and social network analysis, and are increasingly central to genomic and multi-omic applications.\nThis chapter introduces graphs and graph neural networks as tools for genomic foundation modeling. We begin by reviewing core GNN concepts and architectures, then survey major classes of biological graphs, from protein interaction networks to spatial cell graphs to variant-gene-phenotype hierarchies. We discuss how GNNs can be integrated with sequence-based foundation models, highlight key applications in disease gene prioritization and pathway analysis, and examine practical challenges in graph construction, scalability, and interpretability. This chapter establishes foundational concepts that will be extended in Chapter 17, where we consider multi-omics integration and systems-level modeling, and connects to evaluation themes in Chapter 18 and Chapter 19 regarding robustness and generalization on graph-structured tasks.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Graphs, Networks, and Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch16-networks.html#graph-neural-network-fundamentals",
    "href": "p4-ch16-networks.html#graph-neural-network-fundamentals",
    "title": "16  Graphs, Networks, and Biology",
    "section": "",
    "text": "16.1.1 Graphs as Data Structures\nA graph \\(G = (V, E)\\) consists of a set of nodes (or vertices) \\(V\\) and a set of edges \\(E\\) connecting pairs of nodes. In biological contexts, nodes typically represent molecular or cellular entities such as genes, proteins, metabolites, regulatory elements, cells, or even higher-level abstractions like pathways or phenotypes. Edges encode relationships between these entities: physical binding between proteins, regulatory influence from a transcription factor to a target gene, metabolic reactions linking substrates to products, spatial proximity between cells, or co-expression patterns across conditions.\nEdges may be undirected when the relationship is symmetric (such as physical protein-protein interactions or mutual co-expression) or directed when the relationship is asymmetric (such as transcriptional regulation where a factor activates or represses a target). Edges can also carry weights representing interaction strength, confidence scores, or distances. In many biological applications, graphs are heterogeneous, meaning they contain multiple node types (genes, proteins, cells) and multiple edge types (physical interaction, regulation, co-localization), each potentially requiring different treatment by the model.\nBoth nodes and edges can be associated with features. Node features might include gene expression levels, protein sequence embeddings from foundation models (Chapter 13), chromatin accessibility scores, or cell type annotations. Edge features could encode binding affinities, tissue specificity, or experimental evidence codes. These features provide the raw material that GNNs will integrate with graph structure to produce task-relevant representations.\nTraditional graph algorithms operate directly on this structure to compute properties such as shortest paths, centrality measures, or network communities. While these classical methods remain valuable for exploratory analysis, they typically require hand-crafted features and do not learn from data in an end-to-end fashion. Graph neural networks instead learn task-specific transformations of graph structure and features, enabling more flexible and powerful modeling.\n\n\n16.1.2 Message Passing and Neighborhood Aggregation\nThe core operation in modern GNNs is message passing, a local information exchange mechanism where each node updates its representation by aggregating information from its neighbors. At layer \\(\\ell\\), each node \\(i\\) maintains a hidden state \\(\\mathbf{h}_i^{(\\ell)}\\). A generic message passing layer proceeds in two conceptual steps.\nFirst, for each edge \\((i, j)\\) connecting node \\(i\\) to its neighbor \\(j\\), the model computes a message from \\(j\\) to \\(i\\): \\[\n\\mathbf{m}_{ij}^{(\\ell)} = \\phi_m\\left(\\mathbf{h}_i^{(\\ell)}, \\mathbf{h}_j^{(\\ell)}, \\mathbf{e}_{ij}\\right),\n\\] where \\(\\phi_m\\) is a learned function (typically a small neural network) and \\(\\mathbf{e}_{ij}\\) represents edge features. This message captures how neighbor \\(j\\) should influence node \\(i\\) given their current states and their relationship.\nSecond, node \\(i\\) aggregates messages from all its neighbors and updates its own state: \\[\n\\mathbf{h}_i^{(\\ell+1)} = \\phi_h\\left(\\mathbf{h}_i^{(\\ell)}, \\square_{j \\in \\mathcal{N}(i)} \\mathbf{m}_{ij}^{(\\ell)}\\right),\n\\] where \\(\\mathcal{N}(i)\\) denotes the neighbors of node \\(i\\), \\(\\square\\) is a permutation-invariant aggregation operation (such as summation, mean, max, or attention-weighted sum), and \\(\\phi_h\\) is an update function that combines the aggregated messages with the node’s previous state.\nBy stacking multiple message passing layers, information can propagate across multiple hops in the graph. A node’s representation at layer \\(\\ell\\) incorporates information from all nodes within \\(\\ell\\) hops. For biological networks, this means that a gene’s learned representation can reflect not only its own features but also signals from its immediate interaction partners, their partners, and so on. This multi-hop aggregation allows the model to capture pathways, cascades, and communities that influence downstream tasks.\nThe aggregation function \\(\\square\\) must be permutation-invariant because the set of neighbors has no inherent ordering. Simple choices like summation or averaging work well in many settings, while more sophisticated options like attention mechanisms allow the model to weight neighbors differentially based on their relevance. The expressiveness of a GNN is closely tied to the expressiveness of these aggregation and update functions, with connections to the Weisfeiler-Lehman graph isomorphism test suggesting inherent limitations for certain graph structures.\n\n\n16.1.3 Canonical GNN Architectures\nSeveral standard GNN architectures have emerged as workhorses for biological applications, each with distinct design choices for message passing and aggregation.\nGraph Convolutional Networks (GCN) (Kipf and Welling 2017) perform a simple neighborhood averaging operation, where each node’s new representation is a normalized weighted sum of its neighbors’ representations followed by a linear transformation and nonlinearity. GCNs are conceptually straightforward and computationally efficient, making them popular for initial explorations. However, they can suffer from over-smoothing when many layers are stacked, as repeated averaging causes node representations to become increasingly similar regardless of their position in the graph.\nGraphSAGE (Hamilton, Ying, and Leskovec 2017) addresses scalability by learning aggregation functions that operate on sampled neighborhoods rather than the full set of neighbors. This enables mini-batch training on large graphs where full-batch methods would be infeasible. GraphSAGE supports multiple aggregation strategies including mean pooling, max pooling, and LSTM-based aggregation, and can generalize to unseen nodes by applying learned aggregators to new neighborhoods. This inductive capability is particularly valuable for biological networks that grow over time as new genes or proteins are characterized.\nGraph Attention Networks (GAT) (Veličković et al. 2018) introduce attention mechanisms to weight neighbors differently based on their relevance to the target node. Rather than treating all neighbors equally, GAT computes attention coefficients for each edge using a learned compatibility function, allowing the model to focus on the most informative interactions. In biological contexts, attention weights are often interpreted as highlighting key regulatory relationships, critical protein partners, or important cell-cell communications, providing a degree of interpretability beyond black-box aggregation.\nGraph Transformers extend the transformer architecture to graphs by replacing local message passing with global or structured attention over nodes. Some variants use full attention over all nodes with structural encodings (such as shortest path distances or Laplacian eigenvectors) injected as positional information. Others restrict attention to k-hop neighborhoods or learned sparse patterns. Graph transformers blur the boundary between sequence models and GNNs, and are increasingly applied to large heterogeneous biological graphs where capturing long-range dependencies is important.\nBeyond these canonical architectures, many specialized variants exist for specific graph properties. Heterogeneous GNNs handle multiple node and edge types with type-specific parameters. Temporal GNNs model dynamic graphs where edges appear or disappear over time, relevant for modeling development or disease progression. Hierarchical GNNs incorporate multi-scale structure through pooling operations that coarsen graphs into super-nodes representing modules or communities. The choice of architecture depends on the structure of the biological graph, the nature of the task, and computational constraints.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Graphs, Networks, and Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch16-networks.html#biological-graph-types",
    "href": "p4-ch16-networks.html#biological-graph-types",
    "title": "16  Graphs, Networks, and Biology",
    "section": "16.2 Biological Graph Types",
    "text": "16.2 Biological Graph Types\nBiological systems can be represented as graphs at multiple scales and with diverse semantics. This section surveys major classes of biological graphs encountered in genomic foundation modeling, highlighting their structure, typical applications, and connections to other chapters.\n\n16.2.1 Protein-Protein Interaction Networks\nProtein-protein interaction (PPI) networks represent one of the most extensively studied biological graph types. Nodes correspond to proteins, and edges denote physical binding or stable complex formation. Interactions are typically derived from curated databases such as BioGRID, STRING, or IntAct, which aggregate evidence from yeast two-hybrid screens, affinity purification mass spectrometry, co-crystallization studies, and computational predictions. Edges may be weighted by confidence scores reflecting the strength and reliability of experimental evidence.\nPPI networks provide a natural substrate for disease gene prioritization. The premise is that genes causing similar diseases or participating in related biological processes tend to cluster in network neighborhoods. Graph neural networks trained on PPI networks can learn to propagate disease labels or expression signatures across the interactome, identifying candidate disease genes whose neighbors exhibit characteristic patterns even if the genes themselves lack direct annotations. This approach has been applied to prioritize cancer drivers, Mendelian disease genes, and drug targets.\nPPI networks also support function prediction tasks. By training GNNs to predict Gene Ontology terms, KEGG pathways, or subcellular localizations from network context, models can transfer functional knowledge from well-studied proteins to poorly characterized ones. This is particularly valuable for non-model organisms or tissue-specific contexts where experimental annotations are sparse. The learned embeddings often reveal modular structure corresponding to protein complexes, signaling cascades, or metabolic pathways, providing interpretable intermediate representations.\nA common pattern is to initialize node features using protein sequence foundation models such as ESM (Chapter 13), then refine these embeddings with GNN layers that incorporate interaction context. This two-stage approach leverages the strong inductive bias of sequence models while allowing network structure to adjust representations for relational tasks. The resulting embeddings can be used for downstream applications ranging from variant effect prediction to drug-target interaction screening.\n\n\n16.2.2 Gene Regulatory Networks\nGene regulatory networks (GRNs) encode the control logic of gene expression. Nodes represent genes or regulatory elements, and directed edges indicate regulatory relationships such as transcription factor binding to target promoters, enhancer-promoter loops, or microRNA-mediated silencing. Unlike PPI networks, GRNs are inherently directed and often context-specific, varying across cell types, developmental stages, and environmental conditions.\nConstructing GRNs typically involves integrating multiple data sources. Chromatin immunoprecipitation followed by sequencing (ChIP-seq) identifies direct transcription factor binding sites. Chromatin accessibility assays (ATAC-seq, DNase-seq) reveal open regulatory regions likely to be active. Chromosome conformation capture techniques (Hi-C, promoter capture Hi-C) map physical contacts between enhancers and promoters. Single-cell RNA-seq provides expression correlations that can suggest regulatory relationships. Computational tools combine these signals with sequence motifs and conservation to infer GRN edges, though the resulting networks remain incomplete and noisy.\nGraph neural networks applied to GRNs can learn to predict context-specific gene expression from regulatory architecture and chromatin state. For example, a GNN might take as input a graph where nodes represent genes with features from chromatin accessibility models (Chapter 15) and edges represent inferred regulatory connections, then predict cell-type-specific expression levels. By training across many cell types, the model can learn which regulatory motifs and network motifs are associated with active or repressed states.\nGRNs are also valuable for modeling perturbation effects. Given a CRISPR knockout or transcription factor overexpression, one can simulate how signals propagate through the regulatory network to predict changes in downstream targets. This connects to the perturbation prediction models discussed in Chapter 15 and provides a systems-level complement to sequence-based variant effect prediction (Chapter 20).\n\n\n16.2.3 Pathway and Metabolic Networks\nBiochemical pathways represent chains of enzymatic reactions, where metabolites are converted from substrates to products through catalysis by proteins. Pathway databases such as KEGG, Reactome, and BioCyc organize this knowledge into hierarchical graphs where nodes can represent genes, proteins, metabolites, or reactions, and edges denote substrate-product relationships, catalytic roles, or regulatory influences.\nGraph neural networks on pathway networks enable several applications. One is pathway activity inference: given gene expression or proteomic measurements, a GNN can propagate signals through the pathway graph to estimate activity levels of metabolic or signaling pathways. This provides more robust and interpretable summaries than gene set enrichment approaches that treat pathways as flat lists of members. Another application is drug mechanism prediction, where GNNs trained on compound-target-pathway graphs can predict off-target effects or suggest repurposing opportunities by identifying drugs that modulate similar network neighborhoods.\nPathway graphs also support mechanistic interpretation of genome-wide association studies (GWAS). Rather than treating associated variants independently, one can map variants to genes, genes to pathways, and train GNNs to identify which pathway modules are enriched for risk variants. This network-based view can reveal convergent effects of multiple low-frequency variants that would be missed by single-variant tests.\nHierarchical pathway graphs, such as the Reactome hierarchy, provide multi-scale structure where higher-level nodes represent broad processes (such as metabolism or immune response) and lower-level nodes represent specific reactions. GNNs with hierarchical pooling (Chapter 17) can learn representations at multiple levels of granularity, aligning with biological intuition that complex traits involve perturbations at multiple scales.\n\n\n16.2.4 Spatial and Cell-Cell Interaction Graphs\nSpatial transcriptomics and multiplexed imaging assays measure gene expression or protein abundance while preserving spatial coordinates in tissue sections. These data naturally give rise to spatial graphs where nodes represent cells or spatial spots and edges encode physical proximity, shared boundaries, or inferred cell-cell communication.\nConstructing spatial graphs typically involves first segmenting cells or tiles from imaging data, then connecting nodes based on distance thresholds, Delaunay triangulation, or k-nearest neighbors in spatial coordinates. Node features can include gene expression profiles, morphological descriptors from imaging, or embeddings from single-cell foundation models (Chapter 15). Edge features might encode distances, shared membrane area, or predicted ligand-receptor interactions inferred from expression of known communication pairs.\nGraph neural networks on spatial graphs have been applied to diverse tasks. One is tissue region classification, where the goal is to label regions as tumor, stroma, immune-infiltrated, or necrotic based on the spatial organization of cells. Another is cell state prediction, where spatial context (such as proximity to blood vessels or immune cells) influences cell behavior in ways not captured by expression alone. Spatial GNNs have also been used to identify tissue niches, such as tertiary lymphoid structures in tumors or stem cell niches in developmental systems, by learning embeddings that cluster spatially coherent functional regions.\nA key advantage of spatial graphs over purely expression-based models is the ability to capture emergent tissue-level properties. For example, a tumor’s response to immunotherapy may depend not just on the abundance of immune cells but on their spatial distribution and proximity to tumor cells. GNNs can integrate expression and spatial signals to predict such higher-order phenotypes.\nSpatial graphs connect naturally to other graph types: cells can be linked not only by physical proximity but also by shared pathways (constructing a hybrid spatial-molecular graph) or by temporal trajectories (linking spatial snapshots across developmental time or disease progression). This multi-graph view is explored further in Chapter 17.\n\n\n16.2.5 Molecular Association Graphs\nBeyond protein-coding genes, many studies construct graphs over non-coding RNAs (microRNAs, long non-coding RNAs, circular RNAs) and their associations with diseases, drugs, or other molecular entities. In a typical molecular association graph, nodes represent molecules and diseases, and edges indicate known associations or similarities. For example, a microRNA-disease graph might connect miRNAs to diseases they regulate, with additional edges connecting similar miRNAs (based on sequence or target overlap) or related diseases (based on phenotypic similarity or shared genetic architecture).\nGraph neural networks on these heterogeneous molecular association graphs have become a popular approach for predicting novel associations. The premise is that if a miRNA is connected to diseases A and B, and disease B shares many associations with disease C, then the miRNA is a plausible candidate for disease C. GNNs formalize this transitive reasoning by propagating embeddings across the graph, learning to weigh different paths and evidence types.\nHowever, molecular association graphs also illustrate important pitfalls. If similarity edges are constructed using features derived from the same data used for training (such as sequence similarity computed from sequences also used as node features), this can introduce information leakage where the model exploits shortcuts rather than learning generalizable patterns. Additionally, if train-test splits are performed naively without accounting for graph connectivity, the model may have indirect access to test labels through neighboring nodes. These issues are discussed extensively in Chapter 21 regarding confounding and leakage, and underscore the importance of careful experimental design when evaluating GNNs on biological graphs.\n\n\n16.2.6 Variant-Gene-Phenotype Graphs\nClinical variant interpretation often relies on structured knowledge linking variants to genes, genes to pathways or protein complexes, and genes to phenotypes. Resources such as the Gene2Phenotype (G2P) database curate variant-gene-phenotype relationships for Mendelian disorders, providing a graph backbone for diagnostic filtering. More broadly, one can construct graphs where nodes represent variants (or haplotypes), genes, molecular functions, tissue contexts, and clinical phenotypes, with edges encoding relationships like “variant disrupts gene,” “gene participates in pathway,” or “pathway perturbation causes phenotype.”\nGraph neural networks on such hierarchical graphs enable several applications. One is variant prioritization: given a patient’s genotype and clinical phenotype (represented as a set of Human Phenotype Ontology terms), a GNN can propagate phenotype information backward through the gene and pathway layers to score which variants are most likely causal. This connects to variant effect prediction (Chapter 20) but extends it to consider not just the molecular impact of each variant in isolation but also how variants interact through shared genes, pathways, or phenotypic consequences.\nAnother application is phenotype prediction from genotype: given a set of variants, propagate their effects forward through genes and pathways to predict clinical outcomes. This is related to polygenic risk scores (Chapter 3) but leverages network structure to model non-additive effects and pathway-level perturbations. Hierarchical graphs provide natural interpretability, as attention weights or activation patterns at each layer can highlight which genes, pathways, or tissues mediate risk.\nVariant-gene-phenotype graphs also support knowledge graph completion: predicting missing edges such as uncharacterized gene-disease associations or novel variant-phenotype links. This is particularly valuable in rare diseases where direct evidence is limited but indirect evidence from related genes or pathways can guide discovery.\nThese applications illustrate a general pattern where GNNs bridge molecular and clinical scales by reasoning over multi-level biological graphs. This theme is expanded in Chapter 17, where we consider how such graphs integrate with multi-omic data, and in Chapter 23, where we discuss deployment in diagnostic workflows.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Graphs, Networks, and Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch16-networks.html#key-applications",
    "href": "p4-ch16-networks.html#key-applications",
    "title": "16  Graphs, Networks, and Biology",
    "section": "16.3 Key Applications",
    "text": "16.3 Key Applications\n\n16.3.1 Disease Gene Prioritization\nOne of the earliest and most successful applications of GNNs in genomics is disease gene prioritization. The task is to rank genes by their likelihood of being involved in a disease, given known disease-associated genes and features such as expression, sequence, and network context. Traditional approaches relied on guilt-by-association heuristics: genes connected to known disease genes in PPI or co-expression networks were ranked higher. GNNs formalize and extend this intuition by learning how to propagate and weight signals across networks.\nA typical workflow involves constructing a PPI or multi-omic network, initializing node features with gene expression or sequence embeddings, labeling known disease genes as positive examples, and training a GNN to classify nodes as disease-associated or not. The trained model can then score genes lacking direct annotations. Early studies demonstrated that GNN-based prioritization outperforms simpler network diffusion methods and can identify candidate genes that are later validated experimentally.\nMore sophisticated variants use heterogeneous graphs that integrate multiple evidence types. For example, one might combine PPI networks, gene co-expression networks, shared pathway membership, and sequence similarity into a multi-layer graph, then train a heterogeneous GNN that learns type-specific transformations for each edge type. This allows the model to flexibly combine complementary signals: expression correlations might be most informative for regulatory relationships, while physical interactions are key for complex membership.\nDisease gene prioritization connects to variant effect prediction by providing a complementary lens. While variant effect models (Chapter 20) score the impact of individual genetic changes, disease gene prioritization scores whether a gene, if perturbed, is likely to contribute to disease. Integrating both can improve clinical interpretation: a variant with a high deleteriousness score in a highly prioritized disease gene is a stronger candidate than one in a gene with no network or functional support.\n\n\n16.3.2 Pathway and Module Discovery\nUnderstanding complex diseases often requires moving beyond individual genes to identify dysregulated pathways, modules, or processes. Graph neural networks provide a natural framework for learning such modular structure. By training GNNs with regularization that encourages sparsity or community structure, one can extract subgraphs or clusters of nodes that coherently contribute to a phenotype.\nFor example, consider a GNN trained to predict cancer subtype from multi-omic node features on a pathway graph. After training, attention weights or gradient-based attribution can highlight edges and nodes that are most informative for the classification. These may correspond to known cancer pathways (such as cell cycle or apoptosis) or novel modules whose coherence was not previously appreciated. Hierarchical GNNs that pool nodes into super-nodes at intermediate layers provide an explicit mechanism for discovering such modules.\nAnother approach is unsupervised or self-supervised training, where GNNs are trained to reconstruct graph structure, predict masked node features, or align multi-omic embeddings (as in GLUE; Chapter 15). The learned embeddings can then be clustered to identify modules. This has been applied to single-cell data to discover cell types and states, to spatial data to identify tissue niches, and to molecular networks to find functional modules that are perturbed in disease.\nPathway and module discovery is particularly valuable for rare diseases and precision medicine, where patient-specific perturbations may affect unique combinations of pathways. Rather than relying solely on population-level pathway enrichment, GNN-based methods can score pathway activity for individual patients, enabling more personalized interpretation of multi-omic profiles.\n\n\n16.3.3 Integration with Sequence Foundation Models\nA recurring theme in biological GNN applications is the integration of sequence-based foundation models with graph structure. Sequence models such as protein language models (Chapter 13), DNA foundation models (Chapter 11), or single-cell foundation models (Chapter 15) provide rich, context-aware embeddings of biological sequences. However, these models typically operate on individual sequences without explicit relational information. Graph neural networks provide a natural way to augment sequence embeddings with network context.\nThe typical workflow is a two-stage process. First, a sequence foundation model is applied to each entity in the graph (such as proteins in a PPI network or genes in a regulatory network) to generate node features. These embeddings already capture a wealth of information, such as protein structure propensity, regulatory motifs, or cell type-specific expression patterns. Second, a GNN is trained on top of these embeddings, using the graph structure to propagate and refine information. The GNN layers are often relatively shallow (two to four layers), as the heavy lifting of feature extraction has already been done by the sequence model.\nThis approach yields several benefits. It improves sample efficiency, as the sequence model is pretrained on large datasets and transfers to the graph task with limited labeled examples. It provides modularity, allowing practitioners to swap in better sequence models as they become available without retraining the entire pipeline. It also enhances interpretability, as one can separately analyze what the sequence model captures versus what the graph structure adds.\nFor example, in variant effect prediction, one might use a DNA foundation model to embed sequence context around a variant, then use a GNN over a variant-gene-regulatory element graph to aggregate effects across multiple variants or regulatory sites. In protein function prediction, one might use ESM embeddings as initial node features in a PPI network GNN, allowing the model to reason about both intrinsic sequence properties and extrinsic network roles.\nThis integration strategy connects to the multi-modal foundation models discussed in Chapter 17, where sequence, network, and other data types are jointly modeled. It also illustrates a broader principle: foundation models need not be monolithic end-to-end systems but can serve as modular components in larger pipelines that incorporate structured biological knowledge.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Graphs, Networks, and Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch16-networks.html#architecture-patterns-for-biological-gnns",
    "href": "p4-ch16-networks.html#architecture-patterns-for-biological-gnns",
    "title": "16  Graphs, Networks, and Biology",
    "section": "16.4 Architecture Patterns for Biological GNNs",
    "text": "16.4 Architecture Patterns for Biological GNNs\n\n16.4.1 Heterogeneous and Multi-Relational Graphs\nMost biological systems involve multiple types of entities and relationships. A gene regulatory network might include nodes for transcription factors, target genes, enhancers, and chromatin loops, with edges representing binding, activation, repression, and physical contact. A disease network might include nodes for genes, variants, pathways, and phenotypes, with edges encoding causal relationships, pathway membership, and phenotypic associations. Standard GNNs that treat all nodes and edges homogeneously may miss important distinctions between these types.\nHeterogeneous GNNs address this by maintaining type-specific parameters. For each node type, there is a separate embedding lookup or encoder. For each edge type, there is a separate message function. Aggregation functions may also be type-aware, combining messages from different relation types using learned weights or hierarchical attention. This allows the model to learn, for example, that physical protein interactions should be aggregated differently from co-expression correlations, or that activating regulatory edges should have opposite effects from repressing edges.\nMulti-relational graph convolutional networks and relational GCNs provide canonical architectures for this setting. These models extend message passing to operate separately on each edge type, then combine the resulting embeddings. Attention-based variants learn to weight different relation types dynamically based on the task and node context. Heterogeneous graph transformers further generalize this by allowing cross-type attention, enabling reasoning about indirect relationships (such as a variant affecting a gene that participates in a pathway that influences a phenotype).\nDesigning heterogeneous GNNs requires careful thought about which distinctions matter. Too many node or edge types can fragment training data and lead to overfitting, while too few can obscure important biological differences. Domain knowledge and exploratory analysis are essential for choosing an appropriate level of granularity.\n\n\n16.4.2 Hierarchical Pooling and Coarsening\nMany biological questions involve reasoning at multiple scales. Individual proteins assemble into complexes, complexes participate in pathways, and pathways coordinate in tissues to produce organismal phenotypes. Similarly, cells cluster into tissue regions, regions into organs, and organs into systems. Hierarchical GNNs provide a natural way to model such multi-scale structure.\nThe core idea is to iteratively coarsen the graph by grouping nodes into super-nodes. At each level of the hierarchy, a pooling operation selects which nodes to merge, and a readout operation computes features for the new super-nodes. The resulting coarser graph becomes the input to the next layer, allowing the model to reason at progressively higher levels of abstraction.\nSeveral pooling strategies exist. Top-k pooling selects the most important nodes based on learned scores, discarding the rest. Differentiable pooling learns soft cluster assignments and produces super-nodes as weighted combinations of original nodes. Graph U-Net architectures alternate between coarsening (pooling) and refining (unpooling), enabling information to flow both bottom-up and top-down.\nIn biological applications, pooling often incorporates prior knowledge. For example, in a gene-pathway-disease graph, one might pool genes into their annotated pathways, then pathways into broader biological processes, creating a hierarchy aligned with Gene Ontology or Reactome. In spatial transcriptomics, cells might be pooled into tissue regions based on spatial clustering, then regions into anatomical structures. This biologically informed pooling provides both computational efficiency and interpretability, as each level of the hierarchy corresponds to a meaningful biological unit.\nHierarchical models connect naturally to the multi-omics integration strategies discussed in Chapter 17, where molecular measurements at different scales (variants, genes, pathways, phenotypes) need to be coherently combined.\n\n\n16.4.3 Dynamic and Temporal Graphs\nBiological systems are dynamic. Gene regulatory networks change during development and in response to stimuli. Protein-protein interactions are context-dependent and temporally regulated. Disease progression involves evolving states of cells and tissues. Static graph models that assume a fixed topology may miss crucial temporal dynamics.\nDynamic GNNs extend standard architectures to handle time-varying graphs. One approach is to snapshot the graph at different time points, train independent GNNs on each snapshot, and link them through recurrent connections or temporal smoothing. Another is to explicitly model edge appearance and disappearance, treating the graph as a temporal point process. Continuous-time dynamic graphs use neural ODEs or other differential equation solvers to model smooth trajectories of node embeddings over time.\nIn genomics, dynamic GNNs have been applied to model cell state transitions during differentiation, cancer progression through treatment and relapse, and longitudinal disease trajectories in patients. For example, one might model patient health records as a temporal graph where nodes represent clinical events (diagnoses, treatments, lab results) and edges represent temporal dependencies, then train a dynamic GNN to predict future outcomes or treatment responses.\nTemporal modeling is particularly relevant for integrating multi-omic snapshots (such as baseline and post-treatment biopsies) or longitudinal single-cell data. The combination of single-cell foundation models (Chapter 15) for embedding cell states and dynamic GNNs for modeling trajectories is an active area of development.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Graphs, Networks, and Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch16-networks.html#practical-considerations",
    "href": "p4-ch16-networks.html#practical-considerations",
    "title": "16  Graphs, Networks, and Biology",
    "section": "16.5 Practical Considerations",
    "text": "16.5 Practical Considerations\n\n16.5.1 Graph Construction and Quality\nConstructing the graph is often the most consequential modeling choice, as it encodes strong inductive biases about what relationships matter. Several considerations arise.\nSource selection: Biological networks can be derived from curated databases, computational predictions, or data-driven inference. Curated databases (such as STRING for PPIs or Reactome for pathways) provide high-confidence interactions but are incomplete and biased toward well-studied genes. Computational predictions (such as co-expression networks or sequence-based interaction predictions) are more comprehensive but noisy. The choice depends on the task: high-precision curated networks may be preferable for disease gene prioritization, while high-recall predicted networks may be better for exploratory analysis.\nThresholding: Many potential edges have associated confidence scores or distances. Choosing a threshold determines the graph’s density and structure. Too sparse a graph may fragment the network and prevent information propagation. Too dense a graph may introduce noise and obscure meaningful structure. Cross-validation or principled selection criteria (such as targeting a specific edge density or ensuring graph connectivity) are typically needed.\nDirectionality and symmetry: Whether to treat edges as directed or undirected affects both model architecture and interpretation. Gene regulatory networks are inherently directed (transcription factors regulate targets, not vice versa), while PPI networks are often treated as undirected. In practice, many biological relationships have asymmetric strength even if conceptually bidirectional, and directed models can capture this nuance.\nHandling missing data: Biological networks are incomplete. Important interactions may be unmeasured, especially in less-studied contexts or organisms. Models should be robust to missing edges, which can be encouraged through edge dropout during training or by treating the graph as partially observed and jointly learning to predict missing edges alongside the primary task.\nGraph construction often requires domain expertise and iterative refinement. Exploratory analyses of graph statistics (degree distributions, clustering coefficients, shortest path lengths) can reveal issues such as disconnected components or implausibly dense hubs that suggest artifacts.\n\n\n16.5.2 Scalability and Efficiency\nBiological graphs can be enormous: millions of cells in spatial transcriptomics datasets, hundreds of thousands of genomic bins in 3D genome contact maps, or comprehensive multi-omic patient cohorts. Full-batch training on such graphs is often infeasible due to memory constraints and computational cost.\nSeveral strategies address scalability. Neighborhood sampling (as in GraphSAGE) restricts message passing to a fixed-size sample of neighbors per node, enabling mini-batch training. The sampling can be uniform or biased toward high-degree or high-confidence edges. Subgraph sampling trains on induced subgraphs corresponding to biologically meaningful units (such as patients, tissues, or pathways), then combines predictions or embeddings across subgraphs. Cluster-based training partitions the graph into clusters, trains on each cluster independently, and uses cross-cluster edges only for fine-tuning.\nEfficient implementations matter. Sparse matrix operations, GPU-accelerated GNN libraries (such as PyTorch Geometric or DGL), and specialized kernels for graph operations can provide significant speedups. For extremely large graphs, distributed training or pre-aggregation of neighborhood features may be necessary.\nAn orthogonal consideration is whether the graph structure is static or needs to be learned or updated during training. Learning sparse or adaptive graphs via differentiable graph structure learning can improve performance but adds computational overhead. For many biological applications, using a fixed graph derived from prior knowledge is a reasonable and efficient starting point.\n\n\n16.5.3 Robustness to Noise and Incompleteness\nAll biological networks are noisy and incomplete. Experimental methods for detecting interactions (such as yeast two-hybrid or co-immunoprecipitation for PPIs) have false positive and false negative rates. Computational predictions rely on proxies (such as co-expression or sequence similarity) that imperfectly reflect true biological relationships. Even curated databases are biased toward well-studied genes and processes.\nGNNs must be robust to these imperfections. Several strategies help:\n\nEdge dropout: Randomly dropping edges during training forces the model to not rely on any single edge, improving robustness to missing or false interactions.\nNode dropout: Randomly masking node features or entire nodes similarly encourages robustness and prevents overfitting to well-connected hubs.\nAdversarial training: Perturbing edge weights or adding noise to node features during training, then optimizing worst-case performance, can improve robustness.\nUncertainty quantification: Using Bayesian GNNs or ensembles to estimate prediction uncertainty allows the model to flag low-confidence predictions for manual review.\nMulti-view graphs: Constructing multiple graphs from different data sources and training models that reason over all of them can compensate for noise in any single view.\n\nEvaluation on nodes or edges with varying connectivity and annotation quality is essential. Models should not simply perform well on highly connected, well-studied hubs but also generalize to peripheral and novel nodes.\n\n\n16.5.4 Interpretability and Biological Insight\nA key advantage of graph-based models is interpretability: the graph structure itself provides a scaffold for understanding model predictions. Several techniques extract biological insight from trained GNNs:\nAttention weight analysis: When using attention-based GNNs (such as GAT), attention coefficients indicate which neighbors most influenced each node’s prediction. Aggregating attention across nodes and predictions can highlight critical edges or subgraphs.\nGradient-based attribution: Computing gradients of predictions with respect to node or edge features identifies which parts of the graph are most important. Integrated gradients or GradCAM-style methods extend this to provide smoother, more reliable attributions.\nCounterfactual interventions: Systematically removing edges, masking nodes, or perturbing features and observing changes in predictions reveals which parts of the graph are necessary or sufficient for a prediction. This can identify vulnerabilities in network structure or suggest therapeutic targets.\nEmbedding analysis: Visualizing learned node or edge embeddings (via dimensionality reduction) can reveal clusters or gradients corresponding to biological categories such as pathways, cell types, or disease subtypes. Comparing embeddings across conditions or perturbations can identify context-specific rewiring.\nModule extraction: For hierarchical models, examining intermediate-layer representations or pooled super-nodes can identify emergent modules. These modules often correspond to known pathways or complexes but can also suggest novel functional groupings.\nInterpretability is not an afterthought but a central goal for biological GNN applications. The most impactful models are those that not only improve predictions but also generate testable hypotheses and reveal new biological relationships.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Graphs, Networks, and Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch16-networks.html#summary",
    "href": "p4-ch16-networks.html#summary",
    "title": "16  Graphs, Networks, and Biology",
    "section": "16.6 Summary",
    "text": "16.6 Summary\nGraphs provide a powerful and natural representation for the relational structure of biological systems. By encoding entities as nodes and their interactions as edges, graph representations enable us to reason about how perturbations propagate through networks, how pathways coordinate to produce phenotypes, and how spatial organization influences cell behavior. Graph neural networks extend deep learning to these irregular structures through message passing and neighborhood aggregation, learning task-specific transformations that integrate node features with topological context.\nThis chapter introduced core GNN concepts and architectures, surveyed major classes of biological graphs (protein-protein interactions, gene regulatory networks, pathways, spatial cell graphs, molecular association networks, and variant-gene-phenotype hierarchies), and examined key applications including disease gene prioritization, pathway discovery, and integration with sequence foundation models. We discussed practical considerations around graph construction, scalability, robustness to noise, and interpretability.\nGraphs and GNNs form a complementary perspective to the sequence-based foundation models explored in earlier chapters. While sequence models excel at learning from the linear structure of DNA, RNA, and proteins, GNNs excel at learning from the relational structure of interactions, regulation, and spatial organization. The most powerful approaches often combine both: using sequence models to generate rich node features and GNNs to refine these features based on network context. This integration pattern recurs throughout the book and is central to the multi-omics and systems-level models discussed in Chapter 17.\nThe graph-based methods introduced here provide essential building blocks for moving beyond single-gene or single-sequence analysis toward systems-level understanding. As genomic foundation models continue to mature, the integration of sequence, structure, and network information promises to yield increasingly comprehensive and biologically grounded representations of complex traits and diseases.\n\n\n\n\nHamilton, William L., Rex Ying, and Jure Leskovec. 2017. “[GraphSAGE] Inductive Representation Learning on Large Graphs.” arXiv.org. https://arxiv.org/abs/1706.02216v4.\n\n\nKipf, Thomas N., and Max Welling. 2017. “Semi-Supervised Classification with Graph Convolutional Networks.” arXiv. https://doi.org/10.48550/arXiv.1609.02907.\n\n\nVeličković, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. “Graph Attention Networks.” arXiv. https://doi.org/10.48550/arXiv.1710.10903.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Graphs, Networks, and Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html",
    "href": "p4-ch17-systems.html",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "",
    "text": "17.1 Why Single-Omics Models Are Not Enough\nThe preceding chapter examined foundation models for individual data types: single-cell transcriptomics, DNA methylation, and three-dimensional genome structure. Real biological systems, however, do not respect these modality boundaries. Complex traits arise from systems-level interactions where genetic variants perturb molecular networks, networks span multiple omics layers, and these layers interact with environment, development, and clinical context. A model that sees only one layer rarely captures the full story.\nThis chapter surveys how deep learning extends beyond single-omics to integrate multiple data types into unified representations. We examine integration strategies that differ in when and how modalities are combined. We explore graph neural network approaches that use patient similarity networks and gene-level graphs for cancer subtyping and biomarker discovery. We address rare variants and epistasis through set-based architectures and hierarchical modeling that capture effects linear polygenic scores miss. We consider deep learning frameworks for polygenic risk and fine-mapping that extend the traditional PGS paradigm with nonlinear architectures and foundation model features. Throughout, the emphasis is on design patterns that recur across methods and on the trajectory toward whole-patient foundation models that jointly encode multiple omics and clinical data.\nEarlier chapters emphasized how sequence-based models can predict variant effects from local DNA or protein context. These models already improve causal variant prioritization and polygenic risk scoring. However, they typically assume a narrow view of biology.\nMost sequence models operate on a single molecular layer. A convolutional network or transformer may see only DNA sequence, or only expression values, without access to the other layers that mediate the flow of genetic information. Even when multiple outputs are predicted simultaneously, as in multi-task models like Enformer, the input remains a single modality.\nMany downstream uses treat variant effects as additively summing across loci. The PGS framework from Chapter 3 exemplifies this assumption: effects of individual variants are estimated independently and combined through weighted sums. While linear models have well-understood statistical properties and interpretability, they cannot capture interactions between variants or between molecular layers.\nModels rarely account for dynamic cellular state. The same sequence may have different regulatory consequences depending on cell type, developmental stage, or environmental exposure. Static sequence-to-function models provide context-averaged predictions that may not reflect biology in any particular condition.\nReal diseases violate all three of these assumptions. Regulation is inherently multi-layered: genetic variants alter chromatin accessibility and DNA methylation, which modulate transcription, which affects splicing and translation, which determines protein levels and modifications. A variant’s consequences propagate through this cascade in ways that single-layer models cannot fully capture.\nEffects are context-dependent. A variant might be benign in one tissue and pathogenic in another, depending on which genes are expressed, which transcription factors are present, and how the local chromatin environment is configured.\nInteractions between variants can be biologically important. Epistasis, where the effect of one variant depends on genotypes at other loci, is theoretically expected from network biology and has been documented empirically for many traits. Models that ignore interactions may miss important biology and underperform for individual-level prediction.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#multi-omics-integration-strategies",
    "href": "p4-ch17-systems.html#multi-omics-integration-strategies",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.2 Multi-Omics Integration Strategies",
    "text": "17.2 Multi-Omics Integration Strategies\nHow should multiple data types be combined? Three broad strategies have emerged, each with distinct tradeoffs.\n\n17.2.1 Early Fusion\nEarly fusion, also called feature-level integration, concatenates normalized features from multiple omics and feeds them into a single model. This approach is straightforward to implement and allows the model to learn arbitrary interactions between features. However, early fusion is sensitive to differences in scale and dimensionality between modalities, handles missing data poorly since any sample lacking one modality must be imputed or excluded, and can be dominated by whichever modality has the most features or highest signal-to-noise ratio.\n\n\n17.2.2 Intermediate Fusion\nIntermediate fusion, also called shared latent space integration, learns modality-specific encoders that map each omic into a common embedding space. Alignment between modalities is encouraged through reconstruction losses that require each encoder’s latent representation to support decoding back to its original features, contrastive terms that pull together representations of the same biological entity across modalities, or graph constraints that enforce consistency with known biological relationships.\nIntermediate fusion is the dominant design in modern multi-omics deep learning because it handles missing modalities gracefully (only the available encoder needs to fire), allows modality-specific preprocessing and architectures, and can incorporate biological prior knowledge through the alignment objectives. GLUE and related methods from Chapter 15 exemplify this approach.\n\n\n17.2.3 Late Fusion\nLate fusion, also called prediction-level integration, trains separate models for each modality and combines their outputs through ensemble methods or a meta-model. This approach is robust to missing modalities since each sub-model operates independently, and it allows each modality to use whatever architecture works best for its data type. However, late fusion may underutilize cross-omic structure that could inform predictions, since interactions between modalities can only be captured at the final combination stage.\n\n\n17.2.4 Graph-Guided Integration\nModern frameworks like GLUE and multi-omics graph neural networks predominantly adopt intermediate fusion, often augmented with graphs that encode known or inferred biological relationships. Gene-peak edges in single-cell multi-omics link chromatin accessibility peaks to the genes they regulate. Gene-transcription factor edges connect genes to the factors that bind their promoters and enhancers. Protein-protein interaction edges capture physical and functional relationships. Sample similarity edges connect patients or cells with similar molecular profiles.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#graph-neural-networks-for-cancer-subtyping",
    "href": "p4-ch17-systems.html#graph-neural-networks-for-cancer-subtyping",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.3 Graph Neural Networks for Cancer Subtyping",
    "text": "17.3 Graph Neural Networks for Cancer Subtyping\nCancer classification provides a compelling use case for multi-omics integration. Tumors are characterized by complex molecular alterations spanning mutations, copy number changes, epigenetic modifications, and expression programs. Different subtypes may require different treatments, and identifying the molecular basis of subtypes can reveal therapeutic targets.\n\n17.3.1 MoGCN: Patient Similarity Networks\nMoGCN, a multi-omics integration model based on graph convolutional networks, was developed for cancer subtype classification and analysis (X. Li et al. 2022). The approach constructs patient similarity networks from multi-omic data and applies graph convolutions to learn subtype-discriminative representations.\nThe architecture proceeds in several stages. First, autoencoders reduce dimensionality for each omic layer, producing compressed representations of genomic, transcriptomic, and proteomic profiles. Second, similarity network fusion constructs a patient similarity network (PSN) from these reduced representations, connecting patients whose molecular profiles are similar across modalities. Third, the compressed features and the PSN are input to a graph convolutional network for subtype classification.\nIn analysis of multi-dimensional omics data for breast invasive carcinoma (BRCA) samples from TCGA, MoGCN achieved the highest accuracy in cancer subtype classification compared with several popular algorithms. Beyond classification, MoGCN can extract the most significant features of each omics layer and provide candidate functional molecules for further analysis. Network visualization showed that MoGCN could support clinically intuitive diagnosis by revealing the molecular relationships underlying subtype distinctions.\n\n\n17.3.2 CGMega: Gene-Level Modules\nWhile MoGCN operates at the patient level, connecting samples with similar profiles, CGMega takes a complementary approach by constructing gene-level graphs that capture multi-omic relationships among genes (H. Li et al. 2024). This gene-centric view enables identification of gene modules that drive subtype differences and provides more mechanistically interpretable results.\nThe architecture builds graphs where nodes represent genes and edges capture relationships across omics layers: co-expression from transcriptomics, co-methylation from epigenomics, and protein interactions from proteomics. Graph neural network layers learn gene embeddings that integrate information across these different relationship types. Gene-level importance scores derived from the model identify candidate biomarkers and therapeutic targets.\n\n\n17.3.3 Design Themes in Cancer Subtyping\nCommon themes emerge across these methods. Modality-specific encoders with shared latent spaces appear repeatedly, allowing flexible handling of missing modalities while enabling cross-modal interactions. Graphs capturing patient-patient or gene-gene relationships structure the learning problem and provide interpretability. Emphasis on biological interpretability through clusters, modules, or attention patterns helps translate model outputs into biological hypotheses.\nThese cancer subtyping models illustrate how multi-omics integration naturally leads to graph-structured genomic foundation models. Sequences, epigenetics, and expression become nodes in learned biological networks, and the models learn to reason over these networks rather than treating each measurement in isolation.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#rare-variants-and-epistasis-in-systems-context",
    "href": "p4-ch17-systems.html#rare-variants-and-epistasis-in-systems-context",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.4 Rare Variants and Epistasis in Systems Context",
    "text": "17.4 Rare Variants and Epistasis in Systems Context\nChapter 3 discussed how standard PGS methods largely ignore rare variants and epistatic interactions, despite their importance for individual-level risk and disease mechanism. Rare variants, though individually uncommon, collectively explain substantial phenotypic variance and often have larger effect sizes than common variants. Epistasis, the non-additive interaction between variants, is theoretically expected from network biology and has been documented empirically for many traits. Multi-omics and systems models offer a framework to incorporate these effects more effectively than linear approaches.\n\n17.4.1 DeepRVAT: Set-Based Rare Variant Burden Modeling\nDeepRVAT, Deep Rare Variant Association Testing, addresses a fundamental statistical challenge: rare variants have too few carriers to achieve individual statistical significance, yet collectively they carry important phenotypic information (Clarke et al. 2024). Traditional burden tests collapse all rare variants in a gene into a single count, losing information about variant severity. DeepRVAT instead learns gene-level impairment scores from variant annotations using set neural networks.\nThe architecture treats each gene’s rare variants as an unordered set, reflecting the biological reality that the order of variants along a gene is not informative for their combined effect. Each variant is characterized by a vector of annotations including predicted functional impact, conservation, and structural features. A permutation-invariant neural network aggregates these annotations into a gene-level impairment score.\nCrucially, DeepRVAT learns trait-agnostic representations. The gene impairment scores are trained to be predictive across multiple phenotypes simultaneously, which provides regularization and enables transfer to new traits. This multi-task learning encourages the model to learn biologically meaningful notions of gene damage rather than overfitting to any single phenotype.\nThe result improves both gene discovery and risk prediction. For gene discovery, DeepRVAT identifies more significant gene-trait associations than linear burden tests, particularly for genes where variant effects are heterogeneous. For risk prediction, the learned impairment scores identify individuals with high rare variant burden across multiple genes, enabling personalized risk assessment that linear PGS cannot capture.\nDeepRVAT bridges the gap between variant-level annotations and gene-level burden, making it naturally compatible with sequence-based variant effect models from earlier chapters. Annotations from models like SpliceAI, AlphaMissense, or DNA foundation models can serve as input features, and the set neural network learns how to combine them into predictive gene-level scores.\n\n\n17.4.2 NeEDL: Network-Based Epistasis Detection\nNeEDL, Network-based Epistasis Detection via Local search, addresses the complementary challenge of identifying epistatic interactions among variants (Hoffmann et al. 2024). The search space for epistasis is enormous: even considering only pairwise interactions among a million variants yields approximately 500 billion pairs to test. NeEDL uses network structure and optimization algorithms to make this search tractable.\nThe approach builds on network medicine principles. Genes and variants are embedded in a network based on biological prior knowledge, including protein-protein interactions, pathway membership, and co-expression relationships, as well as GWAS signals that suggest which variants influence the trait. Local search strategies explore combinations of variants that are close in this network and that jointly influence disease.\nThe optimization uses algorithms that efficiently explore the combinatorial space of variant combinations. Rather than exhaustively testing all pairs or higher-order combinations, the search focuses on biologically plausible interaction sets defined by network proximity.\nNeEDL does not operate as a full genomic foundation model, but it points toward systems-level combinatorial reasoning that future models will need to support. The network structure provides biological constraints that make the epistasis search feasible, and the discovered interactions map onto interpretable pathways and cellular processes.\n\n\n17.4.3 G2PT: Hierarchical Genotype-to-Phenotype Transformers\nG2PT, Genotype-to-Phenotype Transformer, explicitly models the hierarchical structure connecting variants to phenotypes (Lee et al. 2025). Rather than treating variants as independent features to be weighted and summed, G2PT organizes variants into genes, genes into systems such as pathways and tissues, and systems into phenotype predictions.\nThe architecture uses transformer blocks at each level of this hierarchy. Variant-level attention captures interactions between variants within a gene. Gene-level attention captures interactions between genes within a system. System-level attention captures how different pathways and tissues contribute to phenotype risk.\nPrior biological knowledge structures these attention patterns. Gene-pathway membership from databases like KEGG and Reactome defines which genes belong to which systems. Tissue expression patterns from GTEx indicate where each gene is active. These priors constrain the attention patterns, ensuring that the model learns biologically plausible interaction structures rather than arbitrary statistical correlations.\nThe hierarchical structure provides interpretability. After training, attention weights can be examined to understand which variants, genes, and systems most strongly contribute to risk for a given individual. This enables explanations like “high risk is driven by variants in genes A and B that together perturb pathway X in tissue Y.”\nAs proof-of-concept, G2PT was applied to model the genetics of the triglycerides to high-density lipoprotein cholesterol ratio (TG/HDL), an indicator of metabolic health. G2PT predicted this trait via attention to 1,395 variants underlying at least 20 systems, including immune response and cholesterol transport, with accuracy exceeding state-of-the-art methods. It implicated 40 epistatic interactions, including epistasis between APOA4 and CETP in phospholipid transfer, a target pathway for cholesterol modification.\nG2PT can be viewed as an early example of a systems-aware genomic foundation model for genotype data. It unifies additive and interaction effects within a single deep architecture, using prior knowledge to guide learning toward biologically meaningful structure.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#deep-learning-enhanced-polygenic-risk-and-fine-mapping",
    "href": "p4-ch17-systems.html#deep-learning-enhanced-polygenic-risk-and-fine-mapping",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.5 Deep Learning-Enhanced Polygenic Risk and Fine-Mapping",
    "text": "17.5 Deep Learning-Enhanced Polygenic Risk and Fine-Mapping\nChapter 3 framed polygenic scores as linear weighted sums of variant effects. This approach has attractive statistical properties including interpretability, efficiency, and well-characterized uncertainty. However, it misses nonlinear effects, cannot incorporate rich sequence-based features, and struggles with rare variants and cross-ancestry generalization. Deep learning extends the PGS paradigm along each of these dimensions.\n\n17.5.1 Deep-Learning PGS Frameworks\nDeep-learning PGS frameworks like Delphi replace the linear combination of variant effects with flexible neural networks that learn complex functions of genotype and covariates (Georgantas, Kutalik, and Richiardi 2024).\nThe key technical contribution is enabling neural networks to handle genome-wide inputs. A typical GWAS includes hundreds of thousands to millions of variants, far more than can be naively input to a neural network. Delphi addresses this through efficient architectures that can process hundreds of thousands of variants while remaining computationally tractable.\nThe resulting models can capture dominance effects where heterozygotes differ from the midpoint of homozygotes, epistatic interactions where variant effects depend on genetic background, and gene-environment interactions where variant effects depend on non-genetic covariates. These effects are learned from data rather than specified a priori, allowing the model to discover whatever structure best predicts the phenotype.\nEmpirical evaluations demonstrate improved discrimination compared to linear PGS across several traits, with the gains being largest for traits where nonlinear effects are most important. Delphi showed relative increases in percentage variance explained of 11.4% for body mass index, 18.9% for systolic blood pressure, 7.5% for LDL cholesterol, 35% for C-reactive protein, 16.2% for height, and 29.6% for pulse rate compared to state-of-the-art linear methods.\nImportantly, Delphi also shows improved cross-ancestry generalization: the learned representations transfer more effectively than linear weights to populations not well represented in training data. This suggests that deep learning can partially address the well-documented portability problem of polygenic scores.\nFrom a systems perspective, deep-learning PGS frameworks represent a move toward whole-patient risk modeling. While still primarily based on genotype plus covariates without explicit multi-omics integration, they demonstrate that the linear PGS paradigm can be extended to capture more biological complexity.\n\n\n17.5.2 MIFM and Multi-Ancestry Fine-Mapping\nFine-mapping addresses a fundamental challenge in human genetics: GWAS identifies loci but cannot usually pinpoint causal variants. Within each associated locus, linkage disequilibrium means that many variants are correlated with the causal variant and show similar association signals. Fine-mapping methods attempt to distinguish causal variants from these correlated passengers.\nMultiple-instance fine-mapping frameworks like MIFM address the key bottleneck that per-variant causal labels are rarely available (Rakowski and Lippert 2025). Instead, we typically know only that some variant or variants within a locus are causal. MIFM treats this as a multiple-instance learning problem where each locus is a “bag” of variants, only some of which are causal.\nThe framework learns to score variants based on sequence-derived features from genomic foundation models, conservation, and functional annotations. The training objective encourages the model to identify variants that distinguish causal loci from matched control regions, without requiring explicit labels for individual variants.\nBy incorporating foundation model embeddings, MIFM can leverage the rich sequence representations learned from large-scale pretraining. Variants in similar regulatory contexts receive similar scores, even if they have not been directly observed in fine-mapping studies. This enables transfer to new loci and populations where fine-mapping data are limited.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#design-patterns-across-multi-omics-models",
    "href": "p4-ch17-systems.html#design-patterns-across-multi-omics-models",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.6 Design Patterns Across Multi-Omics Models",
    "text": "17.6 Design Patterns Across Multi-Omics Models\nSeveral design patterns provide conceptual vocabulary for understanding existing methods and designing new ones.\nModality-specific encoders with shared latent spaces appear in GLUE, CpGPT, and many multi-omics subtyping models. Each omic has its own encoder architecture tailored to its data characteristics, whether that involves treating methylation as a sequence, using variational autoencoders for scRNA-seq, or applying graph convolutions to patient similarity networks. These modality-specific encoders map into a common embedding space where downstream tasks operate. This design supports flexible inference with missing modalities, since only the available encoders need to fire, and allows incremental addition of new data types by training new encoders without retraining existing components.\nGraph-guided integration structures learning through biological prior knowledge. GLUE’s feature graph links peaks to genes and transcription factors. CGMega’s gene-level graphs encode multi-omic relationships. NeEDL’s epistasis networks capture pathway structure and protein interactions. Graph neural networks, graph transformers, and attention mechanisms over graph edges provide natural tools for encoding these biological networks and learning representations that respect network structure.\nHierarchical modeling captures the organization of biological systems across scales. G2PT formalizes the hierarchy from variants to genes to systems to phenotypes. Similar hierarchies can be defined for omics layers: sequence gives rise to chromatin state, which influences methylation patterns, which affect transcription, which determines protein levels, which ultimately connect to clinical traits. Architectures that respect this hierarchy can learn more interpretable and generalizable representations than flat models that treat all features equivalently.\nSet-based and bag-based learning handles collections of variants or features that lack natural ordering. DeepRVAT treats variants within a gene as an unordered set, using permutation-invariant architectures to aggregate them into gene-level scores. MIFM treats variants within a fine-mapping locus as a bag, learning to identify causal variants without explicit per-variant labels. This pattern is crucial when sample sizes are large, labels are sparse, and biological order is meaningless.\nFoundation pretraining with task-specific adaptation follows the broader paradigm that defines foundation models. CpGPT is pretrained on massive methylation datasets covering diverse tissues and conditions, then adapted through fine-tuning or linear probing to specific tasks like age prediction or mortality risk. This pattern could extend to multi-omics pretraining, where models learn joint representations of sequence, chromatin, methylation, expression, and clinical data before specialization for particular applications.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#practical-challenges",
    "href": "p4-ch17-systems.html#practical-challenges",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.7 Practical Challenges",
    "text": "17.7 Practical Challenges\nMulti-omics foundation models introduce additional practical challenges beyond those facing single-modality approaches.\nBatch effects multiply when combining data from multiple platforms, laboratories, and time points. Each modality may have its own batch structure, and batch effects can correlate with biological signals in complex ways. Harmonization methods must address batch effects within each modality while preserving cross-modal relationships.\nSample size limitations become more severe when requiring samples with measurements across all modalities. While imputation can address missing modalities, the reliability of imputed values depends on how well the relationship between modalities is captured by training data.\nMost large multi-omics datasets come from European-ancestry populations in high-resource healthcare systems. Models trained on these data may perform poorly or behave differently in other populations. Multi-omics models risk amplifying disparities if trained primarily on non-representative cohorts, since the richer feature sets provide more opportunity for overfitting to population-specific patterns.\nEvaluation complexity increases with the number of modalities and the breadth of potential applications. Multi-omics models can be evaluated at many levels: predictive performance on held-out data, biological consistency of learned representations with known biology, plausibility of inferred networks compared to experimental validation, and clinical utility when deployed in real-world settings. Overfitting to proxy metrics that are easy to compute may not translate to performance on the metrics that ultimately matter.\nInterpretability and causal inference remain challenging. Attention scores and feature importance values provide some insight into model behavior, but they are not guarantees of causal mechanism. A model might attend to a feature because that feature is causal, or because it is correlated with something causal, or for spurious reasons related to batch effects or data collection. Integrating deep models with perturbation data from CRISPR screens and gene knockouts, and with robust causal inference frameworks, remains an open frontier.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#outlook-toward-whole-patient-foundation-models",
    "href": "p4-ch17-systems.html#outlook-toward-whole-patient-foundation-models",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.8 Outlook: Toward Whole-Patient Foundation Models",
    "text": "17.8 Outlook: Toward Whole-Patient Foundation Models\nThe methods in this chapter sketch an endgame for genomic deep learning that extends far beyond sequence-only models. The trajectory moves through several stages that the book has traced across its chapters.\nGenome-wide variant and sequence representation through hybrid CNN, transformer, and state-space model architectures established the foundation in earlier chapters. These models learn rich representations of sequence that capture regulatory grammar, variant effects, and long-range dependencies.\nSingle-cell and epigenomic foundation models from Chapter 15 bring methylation, cellular identity, and 3D genome structure into the picture. CpGPT treats methylation as a foundation modeling problem. scGPT and Geneformer learn cellular representations from massive transcriptomic corpora. GLUE enables integration across modalities measured in different cells.\nMulti-omics integration through graph-guided latent spaces adds new dimensions. MoGCN and CGMega demonstrate how graph neural networks can integrate patient-level or gene-level multi-omic data for cancer subtyping and biomarker discovery.\nSystems-level reasoning about rare variants and epistasis addresses effects that linear models miss. DeepRVAT learns gene-level impairment from rare variant sets. NeEDL searches for epistatic interactions guided by network structure. G2PT provides hierarchical models that explicitly represent the flow from variants through genes and pathways to phenotypes.\nClinically oriented risk modeling with deep PGS and fine-mapping connects genomic representations to patient outcomes. Delphi-like frameworks extend PGS to capture nonlinear effects and improve cross-ancestry generalization. MIFM-like methods integrate sequence-based variant features with GWAS evidence for more accurate fine-mapping.\nA future whole-patient foundation model might unify all these threads. Such a model would jointly encode genotype, methylome, chromatin state, expression, proteomics, imaging, and electronic health record data. It would provide unified representations across tissues, cell types, and time points, capturing the dynamic nature of biological state. It would offer calibrated, equitable predictions of disease risk and treatment response across diverse populations. It would support mechanistic queries like “which pathways mediate this variant’s effect in this tissue?” or “which interventions might counteract rare variant burden in this patient?”\nRealizing this vision will require advances across multiple fronts. Data sharing and privacy-preserving learning must enable training on sensitive multi-omic and clinical data at scale. Scalable architecture design must handle the computational demands of truly multi-modal foundation models. Causal validation must distinguish correlative patterns from mechanistic understanding. Equity and fairness considerations must guide data collection and model development from the outset.\nThe methods surveyed here show that moving beyond single-omics is not merely incremental improvement but a qualitative change in what kinds of questions genomic models can address. The path from isolated sequence models to systems-level, clinically actionable genomics is becoming visible, even if substantial work remains to traverse it.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p4-ch17-systems.html#summary",
    "href": "p4-ch17-systems.html#summary",
    "title": "17  Multi-Omics & Systems Biology",
    "section": "17.9 Summary",
    "text": "17.9 Summary\nThis chapter has surveyed how deep learning extends beyond single-omics to integrate multiple data types into unified representations. We examined integration strategies spanning early, intermediate, and late fusion, with intermediate fusion augmented by graph structure emerging as the dominant approach. Graph neural network methods including MoGCN and CGMega showed how patient-level and gene-level graphs can integrate genomics, transcriptomics, and proteomics for cancer subtyping. DeepRVAT, NeEDL, and G2PT addressed rare variants and epistasis through set-based architectures and hierarchical modeling. Deep learning frameworks for polygenic risk (Delphi) and fine-mapping (MIFM) extended the PGS paradigm with nonlinear architectures and foundation model features.\nSeveral design patterns emerged as common threads: modality-specific encoders with shared latent spaces, graph-guided integration, hierarchical modeling, set-based learning, and foundation pretraining with task-specific adaptation. These patterns provide conceptual vocabulary for understanding existing methods and designing new ones.\nPractical challenges including batch effects, sample size limitations, population diversity, and evaluation complexity require careful attention. But the trajectory toward whole-patient foundation models that jointly encode multiple omics and clinical data is becoming clear.\nThe remaining chapters will address cross-cutting issues of evaluation, confounding, and interpretability that apply across all the models surveyed in this book, then explore how genomic foundation models translate into clinical practice.\n\n\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus Wahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024. “[DeepRVAT] Integration of Variant Annotations Using Deep Set Networks Boosts Rare Variant Association Testing.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nHoffmann, Markus, Julian M Poschenrieder, Massimiliano Incudini, Sylvie Baier, Amelie Fritz, Andreas Maier, Michael Hartung, et al. 2024. “[NeEDL] Network Medicine-Based Epistasis Detection in Complex Diseases: Ready for Quantum Computing.” Nucleic Acids Research 52 (17): 10144–60. https://doi.org/10.1093/nar/gkae697.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam, Amit R. Majithia, and Trey Ideker. 2025. “[G2PT] A Genotype-Phenotype Transformer to Assess and Explain Polygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai, et al. 2024. “CGMega: Explainable Graph Neural Network Framework with Attention Mechanisms for Cancer Gene Module Dissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and Yunping Zhu. 2022. “MoGCN: A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Analysis.” Frontiers in Genetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.",
    "crumbs": [
      "p4--multi-modal_multi-scale.qmd",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Multi-Omics & Systems Biology</span>"
    ]
  },
  {
    "objectID": "p5--eval-interp.html",
    "href": "p5--eval-interp.html",
    "title": "Part V: Evaluation and Reliability",
    "section": "",
    "text": "The preceding sections have surveyed an impressive landscape of genomic foundation models, from convolutional architectures that learn regulatory grammar to transformer-based systems that capture long-range chromatin interactions. Yet the enthusiasm surrounding these advances must be tempered by rigorous assessment. A model’s utility in genomics depends not merely on its architectural sophistication but on whether it genuinely captures biological signal, generalizes beyond its training distribution, and provides insights that translate to clinical or experimental settings. Part V addresses these critical questions, examining the frameworks, methodologies, and potential pitfalls that determine whether genomic AI models deliver on their promises.\nEvaluating genomic models presents unique challenges that distinguish this domain from natural language processing or computer vision. Biological sequences contain nested hierarchies of functional elements, population-stratified variation, and evolutionary constraints that can masquerade as predictive signal. Standard machine learning metrics may obscure fundamental problems: a variant effect predictor might achieve impressive aggregate performance while systematically failing on clinically actionable mutations, or a regulatory model might exploit sequence artifacts rather than genuine enhancer logic. The chapters that follow develop a comprehensive framework for understanding what benchmarks actually measure, how evaluation methodology shapes conclusions, what confounders threaten validity, and how interpretability methods can distinguish genuine biological insight from spurious pattern matching.\nWe begin in 18  Benchmarks for Genomic Models with a survey of established benchmarks in genomic deep learning, examining their construction, scope, and limitations. 19  Evaluation of Models then develops principles for rigorous evaluation methodology, addressing issues of train-test contamination, metric selection, and clinical relevance that frequently compromise published comparisons. 21  Confounders in Model Training confronts the systematic biases and data leakage pathways that pervade genomic datasets, with particular attention to population stratification and linkage disequilibrium. Finally, 22  Interpretability & Mechanisms explores interpretability methods that move beyond black-box prediction toward mechanistic understanding, examining both the promise and limitations of attribution approaches in the genomic context.",
    "crumbs": [
      "Part V: Evaluation and Reliability"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html",
    "href": "p5-ch18-benchmarks.html",
    "title": "18  Benchmarks for Genomic Models",
    "section": "",
    "text": "18.1 Chapter Overview\nFoundation models do not exist in a vacuum. Whether a model is perceived as “good” in practice is determined almost entirely by the benchmarks the community chooses to report. In genomics, these benchmarks range from classic transcription factor (TF) binding prediction tasks to multi-phenotype cohort analyses, from single-assay classification to multi-modal, multi-task evaluations spanning species and cellular contexts.\nThis chapter surveys the landscape of existing benchmarks for genomic models and documents how they are commonly used. In contrast, Chapter 17 (Chapter 19) focuses on evaluation principles and methodology: how to design experiments, choose metrics, quantify uncertainty, and interpret results. Here we concentrate on the empirical landscape itself, cataloging datasets, tasks, and leaderboards that structure the incentives of model developers.\nThe benchmark ecosystem is evolving quickly. Early deep learning work focused on small numbers of hand-curated tasks derived from ENCODE-style assays. More recent efforts introduce benchmark suites that attempt to cover many assays, tissues, or variant types, and to standardize splits and metrics. Even so, substantial gaps remain, especially around structural variation, non-European populations, and clinically meaningful endpoints.\nBy the end of this chapter you should have:",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#chapter-overview",
    "href": "p5-ch18-benchmarks.html#chapter-overview",
    "title": "18  Benchmarks for Genomic Models",
    "section": "",
    "text": "A mental map of the main benchmark families used for genomic models.\nAn understanding of what these benchmarks actually measure, and what they miss.\nAn appreciation for benchmark staleness, leakage, and distribution shift, which are elaborated in Chapter 19 and Chapter 21.\n\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (overview table): A 1–2 page table listing major benchmark suites. Columns could include: “Name”, “Assays/modalities”, “Primary task(s)”, “Typical metrics”, “Scale (loci / peaks / cohort size)”, “Intended use (pretraining, fine-tuning, zero-shot)”.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#molecular-and-regulatory-benchmarks",
    "href": "p5-ch18-benchmarks.html#molecular-and-regulatory-benchmarks",
    "title": "18  Benchmarks for Genomic Models",
    "section": "18.2 Molecular and Regulatory Benchmarks",
    "text": "18.2 Molecular and Regulatory Benchmarks\nMost genomic benchmarks originate from molecular assays that measure regulatory activity, chromatin state, or gene expression. These tasks were the first to be adopted by deep learning in genomics and remain core metrics for many new models.\n\n18.2.1 Classical Sequence-Level Classification Tasks\nThe earliest deep learning benchmarks for genomics framed regulatory prediction as a binary classification problem at short sequence windows. Typical examples include:\n\nTF binding prediction: Given a sequence of approximately 1 kb, predict whether a specific TF ChIP-seq peak overlaps that window in a given cell type.\nOpen chromatin and accessibility: Predict DNase-seq or ATAC-seq peaks, labeling regions as “open” or “closed”.\nHistone marks: Predict the presence or absence of a histone mark peak (for example, H3K27ac or H3K4me1) in each window.\nPromoter and enhancer classification: Distinguish promoter, enhancer, and background sequences based on curated annotations.\n\nThese tasks are usually constructed from consortia like ENCODE or Roadmap Epigenomics. Benchmarks derived from them often share a common structure: fixed-length input sequences (for example, 1,000 bp centered on peaks), one label per assay or assay times cell-type combination, and random genomic train/validation/test splits, sometimes with held-out chromosomes.\nModels such as DeepSEA, Basset, and ExPecto were evaluated primarily on such tasks. Modern foundation models still report AUROC or average precision on similar benchmarks, often as a first sanity check before moving to more complex evaluations.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (task cartoon): A cartoon panel illustrating how raw tracks (for example, ChIP-seq, DNase-seq) are converted into binary labels over fixed windows, feeding a sequence model.\n\n\n\n\n18.2.2 Quantitative Prediction of Regulatory Readouts\nBeyond binary classification, many benchmarks require prediction of quantitative readouts:\n\nSignal regression: Predict the per-base or per-bin signal of a ChIP-seq or ATAC-seq experiment from sequence alone.\nGene expression prediction: Predict gene-level expression (for example, TPM or counts) from promoters, enhancers, or larger genomic contexts.\nReporter assays and MPRA: Predict continuous activity of synthetic or genomic sequences tested in massively parallel reporter assays.\n\nHybrid architectures like Enformer and related models (see Chapter 9, Chapter 14) popularized benchmarks that combine large receptive fields with dense quantitative targets. Here, metrics often include Pearson or Spearman correlation, coefficient of determination (\\(R^2\\)), or distance-dependent correlation decay curves between predicted and observed profiles.\nThese tasks better reflect the continuous nature of regulatory activity but also introduce challenges around heterogeneous noise across different assays and laboratories, replicates and uncertainty (some benchmarks now report performance relative to replicate concordance, but this is not universal), and cell-type diversity (evaluations may include dozens or hundreds of cell types, raising questions about how to aggregate performance).\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (multi-task regression): A figure showing a multi-task model predicting many regulatory tracks at once, with example predicted versus observed profiles for several assays.\n\n\n\n\n18.2.3 Benchmark Suites and Leaderboards for Regulatory Genomics\nTo facilitate more standardized comparison, several efforts have curated suites of regulatory tasks and established leaderboards or challenge settings. Examples include:\n\nTF binding and accessibility leaderboards derived from ENCODE-style assays.\nDREAM Challenges focusing on TF binding, gene expression prediction, or network inference from multi-omics data.\nCommunity-maintained benchmark collections of DNA sequence classification tasks. The Genomic Benchmarks resource by Grešová et al. (2023) compiles a variety of classification datasets in a unified format, covering tasks such as enhancer identification, promoter recognition, and splice site detection across multiple species. This resource facilitates direct comparison of sequence models on standardized splits and evaluation protocols.\n\nThese suites define canonical train/validation/test splits, metrics, and baseline models, making it easier to compare new architectures. However, they are still heavily skewed toward short-range, single-variant or single-element tasks and often focus on a small number of well-studied cell types and assays.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#dna-language-model-benchmark-suites",
    "href": "p5-ch18-benchmarks.html#dna-language-model-benchmark-suites",
    "title": "18  Benchmarks for Genomic Models",
    "section": "18.3 DNA Language Model Benchmark Suites",
    "text": "18.3 DNA Language Model Benchmark Suites\nAs genomic language models have matured (see Chapter 11 and Chapter 7), dedicated benchmark suites have emerged to assess their representation quality and task performance in a more comprehensive and standardized manner.\n\n18.3.1 BEND (Benchmark for DNA Language Models)\nBEND provides a diverse set of biologically meaningful tasks on the human genome. Task composition includes gene finding, enhancer annotation, chromatin accessibility prediction, histone mark classification, and CpG methylation status. The design philosophy emphasizes biologically relevant evaluation rather than synthetic or contrived benchmarks.\nKey findings from models evaluated on BEND include limited capture of long-range features in current architectures, highlighting an important gap between model receptive fields and the genomic distances over which regulatory interactions occur.\n\n\n18.3.2 Genomics Long-Range Benchmark (LRB)\nDeveloped alongside the Nucleotide Transformer and related work by InstaDeep, the LRB focuses explicitly on tasks requiring extended context. These tasks include enhancer-promoter linking, expression prediction over long genomic windows, and regulatory variant effect prediction at distances beyond what typical convolutional models can capture.\nThe LRB also explores fine-tuning recipes and their impact on evaluation. Performance gaps are often observed: models tend to perform better on annotation tasks (chromatin marks, binding) than on variant effect and expression prediction, which require more integrated understanding of regulatory logic.\n\n\n18.3.3 DNALongBench\nDNALongBench extends the evaluation of long-range dependencies even further, with five tasks operating on sequences up to 1 Mb in length. These tasks include enhancer-target gene assignment, eQTL identification, 3D genome organization prediction, regulatory activity modeling, and transcription initiation site prediction.\nBaseline comparisons across CNNs, HyenaDNA, and Caduceus variants reveal that different architectures have different strengths: some handle local features well but struggle with megabase-scale patterns, while others sacrifice local precision for better long-range coherence. The benchmark is designed for standardized assessment of long-range dependency modeling.\n\n\n18.3.4 GenBench\nGenBench offers a modular framework for genomic foundation model evaluation, stratifying tasks by short-range versus long-range dependencies and examining architecture-task interactions. For example, attention-based models may excel at tasks requiring integration over long distances, while convolutional models may be better suited for motif-centric predictions.\nThe benchmark emphasizes reproducibility, providing clear documentation of data splits, preprocessing, and evaluation protocols. This emphasis addresses a common concern in the field: that minor differences in data preparation or hyperparameter tuning can produce large swings in reported performance.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#variant-effect-prediction-benchmarks",
    "href": "p5-ch18-benchmarks.html#variant-effect-prediction-benchmarks",
    "title": "18  Benchmarks for Genomic Models",
    "section": "18.4 Variant Effect Prediction Benchmarks",
    "text": "18.4 Variant Effect Prediction Benchmarks\nFrom a clinical perspective, the most important question is often not “what is the regulatory activity here?” but “what happens if this variant is present?” Variant effect prediction (VEP) benchmarks try to connect sequence changes to molecular or phenotypic consequences.\n\n18.4.1 Clinical Annotation Databases\nA common class of benchmarks uses curated variant databases to define classification tasks. ClinVar is the most widely used resource, providing pathogenic, likely pathogenic, benign, and likely benign annotations for variants across the genome. However, ClinVar has well-documented biases: submission heterogeneity (annotations come from diverse submitters with varying standards), version sensitivity (classifications are updated regularly as evidence accumulates), and ancestry and gene coverage biases (variants in well-studied populations and disease genes are overrepresented).\nHGMD (Human Gene Mutation Database) offers another source of disease-associated variants, but access limitations and similar biases apply. Expert-curated panels such as those from ClinGen and disease-specific consortia provide higher confidence labels for subsets of genes, but at much smaller scale.\nLabels from these resources are closer to clinical decisions than molecular assay readouts, but subject to ascertainment bias (well-studied genes and variant types are overrepresented), historical annotation bias (older annotations may not reflect current clinical guidelines), and context dependence (pathogenicity can depend on ancestry, environment, and genetic background, which benchmarks often ignore).\nModels that score variants (as discussed in Chapter 20) are commonly assessed on such benchmarks using metrics like AUROC, AUPRC, and calibration diagnostics.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (variant effect flow): A schematic showing the flow from raw variant call to variant effect predictor to benchmark labels (for example, ClinVar categories), including possible sources of noise and bias.\n\n\n\n\n18.4.2 Multiplexed Assays of Variant Effect (MAVEs)\nAnother important family of variant effect benchmarks comes from high-throughput perturbation experiments. Deep mutational scanning (DMS) provides systematic measurements of functional consequences for many single amino acid or nucleotide changes in a gene or regulatory element. These datasets are aggregated in resources like MaveDB, offering dense maps of sequence-to-function relationships.\nSuch assays serve as attractive gold standards for predicting variant effects because they provide quantitative, experimentally determined readouts. However, they come with their own biases: the reporter context may differ from native genomic settings, selection stringency in the assay affects which variants appear deleterious, and gene coverage remains sparse (only a small fraction of genes and regulatory elements have been subjected to comprehensive DMS).\nBenchmarks derived from MAVEs typically ask: How well does a model’s predicted effect size correlate with experimental measurements? Can the model correctly prioritize variants that strongly disrupt function? Does performance generalize to unseen sequences or contexts?\n\n\n18.4.3 Noncoding Variant Benchmarks\nNoncoding variants present distinct challenges and require specialized benchmarks. MPRA datasets for regulatory variants test whether models can predict the quantitative effect of variants on enhancer or promoter activity. eQTL-based evaluation approaches leverage naturally occurring variants associated with expression changes, treating the statistical evidence for eQTL status as a proxy for functional impact. GWAS fine-mapped variant sets identify putatively causal variants in associated loci, providing another source of functional labels.\nThe open challenge in noncoding benchmarks is linking molecular effects to trait effects. A variant may alter chromatin accessibility without affecting disease risk, or affect risk through pathways unrelated to the molecular phenotype being measured. This gap complicates interpretation of noncoding variant benchmarks.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#protein-language-model-benchmarks",
    "href": "p5-ch18-benchmarks.html#protein-language-model-benchmarks",
    "title": "18  Benchmarks for Genomic Models",
    "section": "18.5 Protein Language Model Benchmarks",
    "text": "18.5 Protein Language Model Benchmarks\nProtein language models (Chapter 6, Chapter 13) have their own rich benchmarking traditions that intersect with genomic modeling when variants affect protein-coding sequences.\n\n18.5.1 ProteinGym\nProteinGym has emerged as a comprehensive benchmark for protein variant effect prediction. It compiles 217 deep mutational scanning assays covering diverse protein families and uses Spearman correlation as the primary metric for comparing predicted and observed fitness effects. This benchmark provides standardized evaluation across a wide range of proteins, enabling fair comparison of different modeling approaches.\nHowever, the reliance on Spearman correlation as the primary metric has limitations. It measures rank correlation but does not directly assess calibration or absolute effect size prediction, both of which may matter for clinical interpretation. Moreover, the benchmark reflects the biases of available DMS datasets: over-representation of well-studied proteins and specific functional classes, limited coverage of variants in disordered regions or regulatory domains, and assay-specific artifacts.\n\n\n18.5.2 Structure Prediction Benchmarks\nStructure prediction benchmarks derive from the CASP (Critical Assessment of protein Structure Prediction) tradition and the evaluations established for models like ESMFold and AlphaFold2. Metrics include TM-score (template modeling score) and GDT-TS (global distance test, total score), which measure structural similarity between predicted and experimentally determined structures.\nBenchmarks distinguish between single-sequence and MSA-based evaluation regimes. Protein language models are typically evaluated in the single-sequence setting, where predictions rely only on the target sequence without multiple sequence alignments. This tests whether the model has internalized evolutionary and biophysical constraints from pretraining alone.\n\n\n18.5.3 Clinical Variant Benchmarks for Proteins\nBenchmarks that evaluate protein models on clinical variant classification often use ClinVar pathogenic versus benign discrimination as the primary task. Models like AlphaMissense, ESM-1v, and integrated tools like CADD have been benchmarked on this task. However, circularity concerns arise when models are trained on features derived from resources that also contribute to ClinVar labels, creating feedback loops that inflate apparent performance without genuine predictive power.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#trait-and-individual-level-benchmarks",
    "href": "p5-ch18-benchmarks.html#trait-and-individual-level-benchmarks",
    "title": "18  Benchmarks for Genomic Models",
    "section": "18.6 Trait and Individual-Level Benchmarks",
    "text": "18.6 Trait and Individual-Level Benchmarks\nAt the trait and individual level, benchmarks assess models on cohort-level or population genetics tasks.\n\n18.6.1 Polygenic Score Benchmarks\nPolygenic score benchmarks evaluate how well genotype-derived scores predict disease risk or quantitative traits. Common evaluation settings include UK Biobank held-out evaluation (partitioning individuals into training and test sets within a single large biobank), cross-biobank transferability (training in one biobank and testing in another to assess robustness), and ancestry-specific performance gaps (reporting results stratified by ancestry to identify differential utility).\nThese benchmarks typically report \\(R^2\\) for quantitative traits, AUROC or AUPRC for binary disease outcomes, and incremental predictive value over clinical covariates. The portability of polygenic scores across populations remains a major concern, as discussed in Chapter 3.\n\n\n18.6.2 TraitGym\nTraitGym provides a framework specifically for assessing complex trait prediction from genomic features. It evaluates GFM-augmented polygenic scores, testing whether foundation model embeddings or variant scorings improve prediction over traditional polygenic score methods. Ancestry stratification in evaluation is built into the benchmark design, highlighting performance disparities across populations.\nThis benchmark is particularly relevant for assessing whether genomic foundation models deliver on their promise to improve phenotype prediction beyond what classical statistical genetics methods already achieve.\n\n\n18.6.3 EmbedGEM Framework\nMukherjee et al. (2024) introduced EmbedGEM, a framework to evaluate multivariate traits or machine learning-derived embeddings specifically for genetic discovery along two complementary axes. The first axis measures heritability through the number of LD-clumped genome-wide significant hits and the mean or median chi-squared statistic at those loci, quantifying how much genetic signal is captured. The second axis measures disease relevance through polygenic risk scores built from embedding-associated variants and their incremental predictive value for a downstream trait in an independent cohort.\nTechnically, EmbedGEM orthogonalizes multivariate traits or embedding dimensions using principal component analysis, then runs univariate GWAS on each principal component. Wald Z-statistics are combined into a multivariate chi-squared test for each SNP, followed by LD-based clumping to identify independent loci. For each principal component, polygenic risk scores are constructed and compared against full models (PRS plus covariates) versus reduced models (covariates only) using AUROC or AUPRC for binary traits and \\(R^2\\) or MAE for continuous traits. Permutation and bootstrap procedures provide p-values for statistical inference.\nThis framework is particularly useful for evaluating whether embeddings learned by genomic foundation models are enriched for biologically meaningful genetic signal rather than technical artifacts or confounders. It addresses a key gap in foundation model evaluation: demonstrating that representations are not only predictive of downstream phenotypes but also discover novel genetic associations.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#cross-cutting-issues",
    "href": "p5-ch18-benchmarks.html#cross-cutting-issues",
    "title": "18  Benchmarks for Genomic Models",
    "section": "18.7 Cross-Cutting Issues",
    "text": "18.7 Cross-Cutting Issues\nSeveral issues cut across multiple benchmark families and warrant explicit discussion.\n\n18.7.1 Benchmark Suite Proliferation\nThe rapid proliferation of benchmark suites creates both opportunities and challenges. On one hand, diverse benchmarks test different aspects of model capability and reduce the risk that a single benchmark becomes an unrepresentative target for optimization. On the other hand, fragmentation and inconsistent evaluation make it difficult to compare models evaluated on different suites. Calls for unified evaluation frameworks recur in the literature, but tension persists between standardization (which enables comparison) and task-specific validity (which requires domain-appropriate design choices).\n\n\n18.7.2 What Benchmarks Miss\nDespite the breadth of existing tasks, there are systematic blind spots in the genomic benchmark landscape.\nTasks underrepresented: Structural variants, inversions, copy number variants, and other complex rearrangements are rarely evaluated, even though they account for substantial genomic variation and disease burden. Repeat regions, including tandem repeats, transposable elements, and segmental duplications, are often excluded or down-weighted in benchmarks. Multi-variant effects, epistasis, and haplotype-specific phenomena receive minimal attention, even though real genomes exhibit dense, correlated variation.\nPopulations underrepresented: Non-European ancestry groups are systematically underrepresented in benchmark cohorts, limiting the assessment of model robustness and equity. Environmental diversity (diet, exposures, comorbidities, treatment histories) that shapes phenotypic expression is rarely incorporated into benchmarks. These biases mean that models appearing to perform well on benchmarks may fail in diverse real-world populations.\nModalities underrepresented: Long-read sequencing data, which resolves structural variants and phasing more effectively than short reads, is scarce in benchmarks. Single-cell contexts, where cell-type heterogeneity and rare cell states matter, are underrepresented. Spatial transcriptomics, epigenetic aging measures, and other emerging modalities have minimal benchmark coverage.\nClinical endpoints versus molecular surrogates: Most benchmarks rely on molecular surrogates (chromatin accessibility, TF binding, expression) rather than hard clinical endpoints like disease incidence, progression, severity, treatment response, or patient-reported outcomes. While molecular surrogates are easier to obtain at scale, they do not directly measure what matters most for clinical translation.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (coverage heatmap): A heatmap with rows representing benchmark suites and columns representing “variant types”, “ancestry groups”, “modalities”, and “clinical endpoints”. Shaded cells indicate coverage, visually emphasizing systematic gaps.\n\n\n\n\n18.7.3 Benchmark Leakage and Staleness\nBenchmarks derive their value from being both representative and unseen. As foundation models scale, both properties are under pressure.\nTraining-test overlap: Modern genomic foundation models may be pretrained on enormous corpora that include almost all publicly available sequencing and assay data. This creates several leakage risks. Assay-level overlap occurs when the exact experiments used in a benchmark are also present, explicitly or implicitly, in the pretraining data. Individual-level overlap arises when the same individuals appear in both pretraining and evaluation sets if care is not taken to exclude them. Task-level overlap happens when a foundation model has been fine-tuned on tasks nearly identical to those used for evaluation, blurring the line between pretraining and test performance.\nLeakage can inflate reported metrics, obscure true generalization capacity, and make comparisons between models unfair. Where possible, benchmark designers should explicitly document which public datasets were used to construct benchmarks, provide tools or hashes to help model developers identify potential overlaps, and encourage evaluations on held-out consortia or data collections reserved specifically for assessment.\nTemporal drift: Genomic technology and clinical practice evolve rapidly. Assays change as new sequencing platforms, library preparations, or protocols alter noise profiles and data distributions. Annotations improve as variant classifications, gene annotations, and regulatory element maps are continuously updated. Clinical practice shifts as treatment guidelines and diagnostic criteria evolve, changing the meaning of historical labels.\nA benchmark constructed from assays and annotations circa 2013 may no longer reflect current practice. Over time, models may effectively “overfit the literature,” optimizing for performance on legacy benchmarks that no longer capture the most relevant questions.\nTo mitigate staleness, communities can periodically refresh benchmark datasets, splits, and labels; maintain versioned benchmarks with clear documentation about changes; and establish ongoing evaluation consortia that curate new cohorts and assays specifically for benchmarking.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (timeline): A timeline showing benchmark introductions over time, overlaid with major assay and technology changes (for example, short-read to long-read, bulk to single-cell). Highlight how older benchmarks drift away from current practice.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch18-benchmarks.html#chapter-summary",
    "href": "p5-ch18-benchmarks.html#chapter-summary",
    "title": "18  Benchmarks for Genomic Models",
    "section": "18.8 Chapter Summary",
    "text": "18.8 Chapter Summary\nGenomic benchmarks are the lenses through which we view foundation model progress. This chapter surveyed the main components of the current landscape:\n\nMolecular and regulatory benchmarks based on TF binding, chromatin state, expression, and quantitative assay signals, which remain foundational for evaluating sequence-level prediction.\nDNA language model benchmark suites such as BEND, LRB, DNALongBench, and GenBench, which provide standardized evaluation for genomic foundation models across diverse tasks and context lengths.\nVariant effect and disease-relevant benchmarks that connect sequence variation to functional changes and clinical phenotypes, including clinical variant databases, perturbation experiments, and noncoding variant evaluations.\nProtein language model benchmarks including ProteinGym, structure prediction tasks, and clinical variant classification, which intersect with genomics when evaluating coding variants.\nTrait and individual-level benchmarks such as polygenic score evaluations, TraitGym, and the EmbedGEM framework, which assess prediction of complex phenotypes and genetic discovery from foundation model representations.\n\nWe also highlighted systematic gaps: underrepresented variant types, populations, modalities, and clinical endpoints; and the growing challenges of benchmark leakage and staleness as models and datasets scale.\nIn the next chapter (Chapter 19), we step back from specific benchmarks to discuss evaluation principles and methodology. While this chapter cataloged what benchmarks exist, Chapter 17 explains how to use them properly: designing experiments, choosing metrics, quantifying uncertainty, and interpreting results responsibly when deploying genomic foundation models in research and clinical settings.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion (summary diagram): A final “roadmap” figure connecting this chapter’s benchmark types to the methodological topics in Chapter 19 and the downstream applications in the translation part of the book (Chapter 23, Chapter 24, Chapter 25, Chapter 26).\n\n\n\n\n\n\nGrešová, Katarína, Vlastimil Martinek, David Čechák, Petr Šimeček, and Panagiotis Alexiou. 2023. “Genomic Benchmarks: A Collection of Datasets for Genomic Sequence Classification.” BMC Genomic Data 24 (1): 25. https://doi.org/10.1186/s12863-023-01123-8.\n\n\nMukherjee, Sumit, Zachary R. McCaw, Jingwen Pei, Anna Merkoulovitch, Tom Soare, Raghav Tandon, David Amar, et al. 2024. “EmbedGEM: A Framework to Evaluate the Utility of Embeddings for Genetic Discovery.” Bioinformatics Advances 4 (1). https://doi.org/10.1093/bioadv/vbae135.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Benchmarks for Genomic Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html",
    "href": "p5-ch19-eval.html",
    "title": "19  Evaluation of Models",
    "section": "",
    "text": "19.1 Evaluation as a Multi-Scale Problem\nBy this point in the book, we have seen genomic models deployed at almost every scale. Variant calling from NGS reads (Chapter 1), polygenic scores and GWAS (Chapter 3), deleteriousness scores and variant effect predictors (Chapter 4, Chapter 20), CNN-based sequence-to-function models (Section 10.1 through Section 10.3), and genomic language models and foundation models (Chapter 11, Chapter 7) have each introduced their own metrics and benchmarks. Clinical risk prediction and pathogenic variant discovery (Chapter 23, Chapter 24) add still more evaluation considerations. What has been missing is a single place to answer a deceptively simple question: what does it mean for a genomic model to work, and how should we systematically evaluate it?\nThis chapter provides that unifying view. We describe the major families of evaluation metrics and show how they map to typical genomic tasks. We organize evaluation across four levels, from molecular readouts through variant-level predictions to trait-level risk scores and finally to clinical decisions. We discuss data splitting, leakage, and robustness, the mechanics that make or break benchmarks regardless of how sophisticated the underlying architecture may be. We explain how to evaluate foundation models across different usage regimes, from zero-shot scoring through linear probing to full fine-tuning. Finally, we connect evaluation to the broader theme of reliability, linking forward to the detailed treatments of confounders in Chapter 21 and interpretability in Chapter 22.\nThroughout, the theme is that architecture and scale matter, but evaluation choices often matter more. A state-of-the-art model evaluated on a leaky benchmark tells us less than a modest model evaluated on a clean one. A foundation model that achieves impressive perplexity but fails to improve downstream variant interpretation has not demonstrated clinical utility. Getting evaluation right is prerequisite to knowing whether any of the sophisticated methods covered in this book actually work.\nGenomic models are deployed at very different scales, and understanding this hierarchy is essential for designing appropriate evaluations. It helps to keep a simple mental pyramid in mind, with molecular readouts at the base and clinical decisions at the apex.\nAt the molecular and regulatory level, models take local sequence and epigenomic context as input and predict outputs such as chromatin accessibility, histone marks, transcription factor binding, splicing outcomes, or expression levels. Representative models at this level include DeepSEA-style chromatin predictors, SpliceAI for splice site prediction, and Enformer for long-range regulatory modeling. Evaluation here typically involves comparing predicted tracks or binary annotations against experimental measurements.\nAt the variant level, models take a specific variant (whether SNV, indel, or structural variant) and its surrounding context as input, producing outputs such as pathogenicity scores, predicted molecular impact, or fine-mapping posterior probabilities. Examples include CADD-style deleteriousness scores, AlphaMissense-like variant effect predictors, and Bayesian fine-mapping methods. Evaluation focuses on concordance with clinical annotations, allele frequency patterns, or experimental measurements of variant effects.\nAt the trait and individual level, models take a person’s genotype or sequence along with other features as input and produce risk scores for complex traits, predicted phenotypes, or endophenotypes. Classical polygenic scores and GFM-augmented risk models (Chapter 3, Chapter 23) operate at this level. Evaluation compares predicted risk against observed outcomes in held-out cohorts, often with attention to calibration and discrimination across ancestry groups.\nAt the clinical and decision level, the inputs are model predictions combined with contextual factors such as guidelines, utility assumptions, and patient preferences. The outputs are actual decisions: whether to treat or not treat, screen or not screen, include a patient in a trial or exclude them. Examples include screening strategies, clinical decision support tools, and trial enrichment protocols. Evaluation at this level requires moving beyond accuracy metrics to consider decision curves, net benefit, and prospective validation.\nGood evaluation starts from the intended level of action. If the goal is variant prioritization in a rare disease pipeline, improvement in AUROC on a chromatin benchmark is only indirectly relevant. If the goal is clinical risk stratification, better perplexity on a DNA language model test set is useful only insofar as it leads to more discriminative, better calibrated risk scores. The rest of the chapter climbs this pyramid while keeping a few core metric families in view.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#metric-families-across-genomic-tasks",
    "href": "p5-ch19-eval.html#metric-families-across-genomic-tasks",
    "title": "19  Evaluation of Models",
    "section": "19.2 Metric Families Across Genomic Tasks",
    "text": "19.2 Metric Families Across Genomic Tasks\nMost evaluation in this book falls into four broad metric families, each suited to different types of predictions and scientific questions.\n\n19.2.1 Classification Metrics\nFor binary or multi-class outputs such as pathogenic versus benign, open versus closed chromatin, or presence versus absence of a histone mark, the standard metrics derive from the confusion matrix. The area under the receiver operating characteristic curve (AUROC or simply AUC) measures the probability that a randomly chosen positive example is ranked above a randomly chosen negative example, providing a threshold-independent summary of discrimination. The area under the precision-recall curve (AUPRC) is more informative when positives are rare, as is typically the case when identifying pathogenic variants among many benign ones or causal variants among many correlated candidates. Simple metrics like accuracy, sensitivity, and specificity are intuitive but sensitive to class imbalance and require choosing specific decision thresholds.\nIn practice, variant effect predictors and clinical risk models typically report AUROC and AUPRC for prioritization tasks. Regulatory prediction models often report per-task AUROC averaged over hundreds of chromatin assays, sometimes with weighting schemes that emphasize difficult or clinically relevant targets.\n\n\n19.2.2 Regression and Correlation Metrics\nFor continuous outputs such as expression levels, log-odds of accessibility, or quantitative traits, the standard metrics measure association between predicted and observed values. Pearson correlation measures linear association, while Spearman correlation measures rank-based association and is robust to monotone transformations of the data. The coefficient of determination (\\(R^2\\)) measures the fraction of variance explained, often computed against a simple baseline such as a mean-only model. Mean-squared error and root mean-squared error provide absolute measures of prediction error in the original units.\nSequence-to-expression models and multi-omics integrations frequently use correlation between predicted and observed tracks, as in Enformer-style evaluations that compare predicted and measured gene expression across cell types. Polygenic score performance is often reported as incremental \\(R^2\\), the additional variance explained by genomic features over and above clinical covariates.\n\n\n19.2.3 Ranking and Prioritization Metrics\nMany genomics workflows are fundamentally about ranking rather than absolute prediction. The goal may be to prioritize variants in a locus for follow-up, rank genes or targets for experimental validation, or select individuals at highest risk for screening. While AUROC and AUPRC capture some aspects of ranking quality, additional metrics can be more directly relevant.\nTop-k recall or enrichment measures the fraction of true positives captured in the top k predictions, directly addressing questions like “how many real causal variants would land in our top 20 candidates?” Enrichment over baseline measures how much more likely a high-scoring bucket is to contain true positives compared to random expectation. Normalized discounted cumulative gain (NDCG) emphasizes getting highly relevant items near the top of the ranked list, with diminishing returns for items placed lower. These metrics often align better with practical questions about how predictions will actually be used in experimental workflows where resources limit validation efforts to a small number of top candidates.\n\n\n19.2.4 Generative and Language Model Metrics\nSelf-supervised genomic language models (Chapter 11) introduce their own metrics related to the pretraining objective. Perplexity and cross-entropy on masked-token reconstruction tasks measure how well the model predicts held-out sequence content. Bits-per-base for next-token prediction or compression-style objectives provides a related measure of the model’s ability to capture sequence statistics.\nThese metrics are important for assessing representation quality and for comparing pretraining runs, but they come with important caveats. They are distribution-specific, tied to the particular pretraining corpus and task, which limits comparability across models trained on different data. More importantly, improvements in perplexity do not automatically translate into better variant or trait predictions. A model might achieve excellent perplexity by capturing abundant patterns in the genome, such as repetitive elements and sequence composition, that are largely irrelevant for functional prediction. As a result, generative metrics should always be paired with downstream task metrics to assess real utility.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#levels-of-evaluation-from-base-pairs-to-bedside",
    "href": "p5-ch19-eval.html#levels-of-evaluation-from-base-pairs-to-bedside",
    "title": "19  Evaluation of Models",
    "section": "19.3 Levels of Evaluation: From Base Pairs to Bedside",
    "text": "19.3 Levels of Evaluation: From Base Pairs to Bedside\nWe now walk through the pyramid from molecular readouts to clinical decisions, focusing on what good evaluation looks like at each level and the common pitfalls that can undermine it.\n\n19.3.1 Molecular and Regulatory-Level Evaluation\nAt the molecular level, the core tasks include predicting chromatin accessibility, histone marks, and transcription factor binding profiles; predicting splicing outcomes such as percent spliced in (PSI) values or transcription start and termination sites; and predicting readouts from functional assays like massively parallel reporter assays (MPRAs) or CRISPR perturbation screens.\nCommon evaluation setups involve multi-task classification, where AUROC or AUPRC is computed for each assay and then averaged with or without weighting across assays. Track-wise regression computes Pearson or Spearman correlation between predicted and observed signal profiles across genomic positions. Out-of-cell-type prediction trains on some cell types and tests on others to assess generalization beyond the training distribution.\nSeveral design choices shape the meaning of reported metrics. The granularity of labels matters: base-resolution predictions present a different challenge than predictions averaged over 128-base-pair bins. The size of context windows determines whether the evaluation tests local sequence features or long-range regulatory architecture. The definition of held-out biology, whether new transcription factors, new cell types, or entirely new genomic loci, determines what kind of generalization is actually being tested.\nCommon pitfalls include overfitting to specific assays or idiosyncratic lab protocols and inadvertent leakage when nearby genomic regions or replicate experiments are split across train and test sets. A model might appear to generalize to new regions while actually leveraging sequence similarity or chromatin context shared with training examples.\nFor noisy assays, reporting performance relative to replicate concordance provides important context. If technical replicates of the same experiment correlate at \\(r = 0.85\\), a model achieving \\(r = 0.80\\) may be approaching the practical ceiling imposed by measurement noise. Reporting fraction of explainable variance, computed as the ratio of model performance to replicate concordance, can be more informative than raw correlation values.\n\n\n19.3.2 Variant-Level Evaluation\nAt the variant level, tasks include classifying variants as pathogenic versus benign or damaging versus tolerated, predicting functional impact such as effects on splicing, expression, or protein stability, and fine-mapping to assign posterior probabilities of causality to variants in associated loci.\nCommon benchmarks derive from clinical labels in resources like ClinVar and HGMD, from curated variant sets assembled by diagnostic laboratories, from population-based labels using allele frequency strata in gnomAD-like resources, and from functional assays including saturation mutagenesis, MPRAs, and deep mutational scanning experiments. The choice of benchmark profoundly shapes what the evaluation measures, as discussed extensively in Chapter 18.\nMetrics typically include AUROC and AUPRC on binary labels, correlation or rank metrics against experimental effect sizes, and calibration-style metrics for probabilistic outputs. Reliability diagrams for pathogenicity probabilities or fine-mapping posteriors assess whether variants scored at 80% pathogenic are truly pathogenic about 80% of the time.\nSeveral design questions deserve careful attention. The definition of the negative class matters enormously: common and presumably benign variants, frequency-matched controls, synonymous variants, or synthetic negatives as in CADD (Chapter 4) each create different evaluation contexts with different biases. The choice of what is held out determines the kind of generalization being tested. Holding out entire genes tests whether the model has learned general principles about variant effects versus gene-specific patterns. Holding out specific loci tests whether the model can extrapolate to new genomic contexts. Holding out particular variant types (for example, only evaluating on frameshifts or splice-disrupting variants) tests whether the model has learned type-specific consequences.\nFor fine-mapping and similar tasks where multiple variants per locus compete for causal status, evaluating top-k recall of causal variants per risk locus is often more informative than global AUC across all variants. In practice, researchers follow up only a handful of variants per locus, so knowing that the causal variant consistently ranks in the top three is more valuable than knowing the model achieves high genome-wide discrimination.\nThis level is also where issues of circularity become especially acute. Scores trained on ClinVar and then evaluated on overlapping or highly correlated variants create feedback loops that inflate apparent performance without demonstrating real predictive power. Similarly, models that incorporate features derived from the same underlying data as the evaluation labels can appear to work well while providing no incremental utility beyond what those features already captured. We return to these problems in detail in Chapter 21.\n\n\n19.3.3 Trait- and Individual-Level Evaluation\nAt the trait and individual level, tasks include predicting quantitative traits such as LDL cholesterol, height, or estimated glomerular filtration rate from genotypes and other features, case-control risk prediction for complex diseases like coronary artery disease or type 2 diabetes, and multi-trait and multi-task risk modeling that jointly predicts related phenotypes.\nFor quantitative traits, incremental \\(R^2\\) measures the variance explained by genomic features over and above clinical covariates, directly quantifying what genetics adds to prediction. For binary or time-to-event outcomes, AUROC, AUPRC, and the concordance index (C-index) measure discrimination. Net reclassification improvement (NRI) asks how often individuals are moved across clinically meaningful risk thresholds in the correct direction, a metric more directly tied to clinical utility than discrimination alone.\nImportant evaluation settings include within-ancestry versus cross-ancestry performance, building on the portability issues discussed in Chapter 3. Models trained predominantly on European ancestry cohorts often show substantial performance degradation when applied to African, East Asian, or admixed populations. Reporting ancestry-stratified metrics is now considered essential for polygenic score evaluations.\nWithin-cohort versus external validation compares models trained and tested in the same biobank against models validated in entirely separate cohorts with different recruitment, sequencing, and clinical practices. External validation provides stronger evidence of generalizability but is often not feasible until after model publication. When external validation is not possible, careful documentation of the training cohort’s characteristics and explicit caveats about likely performance in other settings become especially important.\nJoint versus marginal contribution of genetics examines how much predictive information comes from genomic features when combined with electronic health records and other multi-omic data (Chapter 17). A model that achieves high absolute performance might contribute little beyond what clinical variables already provide. Reporting both absolute metrics and incremental gains over strong non-genomic baselines is essential for understanding real impact.\nEven for purely research models, reporting absolute performance alongside incremental gain over strong baselines is essential for understanding real impact. A polygenic score that achieves 0.65 AUROC for a disease sounds moderately impressive until one learns that clinical variables alone achieve 0.63 AUROC. The incremental value may still be scientifically interesting, but the practical utility for clinical decision-making is limited.\n\n\n19.3.4 Clinical and Decision-Level Evaluation\nClinical risk models, treatment response predictors, and trial enrichment models (Chapter 23) ultimately need to be evaluated in terms of decisions, not just scores. Beyond discrimination and calibration, several additional concepts become important.\nDecision curves and net benefit compare different decision thresholds or policies by weighting true positives versus false positives according to clinical utilities. A model that achieves high AUROC but offers no net benefit at clinically relevant thresholds has not demonstrated clinical value. The net benefit framework explicitly incorporates the relative costs of false positives versus false negatives, allowing evaluation to reflect real-world trade-offs in screening, diagnosis, or treatment decisions.\nCost-sensitive and utility-aware evaluation explicitly models different misclassification costs, recognizing that missing a high-risk patient has different consequences than unnecessary screening. For cancer screening, a false negative might delay diagnosis by years with substantial mortality consequences, while a false positive leads to additional imaging or biopsy. These asymmetric costs should be reflected in evaluation metrics and decision thresholds.\nProspective and interventional evaluation through randomized trials, pragmatic trials, and observational implementations with careful monitoring provides the strongest evidence for clinical utility but is expensive and time-consuming. Retrospective validation on historical data can identify promising models but cannot fully account for how clinician behavior, patient adherence, or health system workflows will change in response to model predictions. The gap between retrospective performance and prospective impact is often substantial.\nThis chapter provides only a high-level overview of clinical evaluation. Chapter 23 goes deeper into clinical metrics and deployment considerations, while Chapter 24 discusses evaluation of variant-centric discovery workflows in rare disease and oncology settings.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#data-splits-leakage-and-robustness",
    "href": "p5-ch19-eval.html#data-splits-leakage-and-robustness",
    "title": "19  Evaluation of Models",
    "section": "19.4 Data Splits, Leakage, and Robustness",
    "text": "19.4 Data Splits, Leakage, and Robustness\nMetrics mean little without well-designed data splits. In genomics, the usual approach of randomly assigning 80% of examples to training, 10% to validation, and 10% to testing often fails to test the kind of generalization we actually care about. The structure of genomic data, with its hierarchical organization from bases to variants to individuals to populations, creates many opportunities for subtle information leakage.\n\n19.4.1 Axes of Splitting\nSeveral axes exist along which we can and often should split data. Splitting by individual ensures that genomes from the same person or family do not appear in both training and test sets, preventing models from memorizing individual-specific patterns. This is essential for trait prediction and clinical risk modeling but may be less relevant for purely sequence-based regulatory models that do not use individual-level labels.\nSplitting by locus or region holds out contiguous genomic segments such as specific chromosomes or megabase windows, testing whether models can generalize to entirely new genomic contexts. Chromosome-based splits are common in regulatory genomics, where models trained on chromosomes 1 through 16 are tested on chromosomes 17 through 22. This approach reduces sequence similarity between train and test sets and forces models to rely on general principles rather than memorizing local patterns.\nSplitting by gene or target holds out entire genes or protein families for variant effect and protein models, testing whether the model has learned general principles versus gene-specific idiosyncrasies. For example, a protein model evaluated on entirely held-out protein families provides stronger evidence of biological understanding than a model evaluated on random variants across all proteins, some of which may have close homologs in the training set.\nSplitting by assay, cell type, or tissue trains on some experimental contexts and tests on unseen ones, assessing whether learned regulatory logic transfers across biological conditions. This is particularly relevant for multi-task models like Enformer that predict regulatory readouts across many cell types. Holding out entire cell types or tissue contexts tests whether the model has learned general regulatory principles or has simply memorized cell-type-specific patterns.\nSplitting by ancestry or cohort trains in one population or recruitment setting and evaluates in others, testing whether models generalize across human diversity. This is essential for assessing model fairness and for understanding performance degradation in underrepresented populations. As discussed in Chapter 3 and Chapter 21, ancestry-aware evaluation has become a standard requirement for genomic risk prediction.\nDifferent scientific questions imply different splitting strategies. The question “Can this model generalize to new loci in the same cell type?” calls for locus or chromosome-based splits. The question “Can it generalize to new cell types?” requires cell-type splits. The question “Can it generalize to different populations or clinical settings?” demands ancestry and cohort splits. Matching the split to the intended use case is essential for meaningful evaluation.\n\n\n19.4.2 Types of Leakage\nLeakage arises when information about the test set sneaks into training, inflating apparent performance without improving real-world generalization. Several forms of leakage are common in genomics.\nDuplicate or near-duplicate sequences across splits can occur when overlapping windows around the same variant appear in both training and test sets. In regulatory genomics, if training windows overlap with test windows by even 100 base pairs, sequence similarity may allow models to effectively memorize test examples through their training neighbors. Careful attention to window boundaries and minimum separation distances between train and test regions is required.\nShared individuals or families across train and test can happen when different cohorts containing related individuals are combined without careful deduplication. Even distant relatives share genomic segments identical by descent, and models can exploit this structure if related individuals appear in both training and test partitions. Pedigree-aware splitting or explicit removal of relatives below a kinship threshold is necessary to prevent this leakage.\nBenchmark construction leakage occurs when evaluation labels are derived from resources that also guided model design or pretraining. For example, if a foundation model is pretrained on all publicly available chromatin data including ENCODE, and then evaluated on ENCODE-derived benchmarks, the pretraining has seen information about the test distribution even if the exact test examples were held out. This subtle form of leakage is difficult to avoid entirely but should at least be acknowledged and quantified when possible.\nHyperparameter tuning leakage results from repeatedly evaluating on the test set while choosing checkpoints or model configurations, gradually overfitting to the test distribution. Best practice maintains a completely untouched final test set, using only training and validation data for all model development decisions. When iterative model development requires feedback, the validation set should be used for intermediate decisions, with the test set reserved for final reporting only.\nThe practical takeaway is straightforward in principle but demanding in practice: always define the split to match the generalization you care about, then audit carefully for potential linkage and dataset overlap. This often requires detailed provenance tracking of where every training and test example originated and whether any pathways exist for information to flow from test back to training.\n\n\n19.4.3 Robustness and Distribution Shift\nRobustness is evaluated by deliberately shifting the data distribution beyond what the model encountered during training. Technical shifts involve new sequencing platforms, different coverage levels, or altered assay protocols. A model trained on Illumina short-read data may perform poorly on PacBio long-read data if it has learned platform-specific artifacts. Similarly, models trained on high-coverage whole genome sequencing may degrade substantially when applied to lower-coverage exome sequencing.\nBiological shifts involve new species, tissues, disease subtypes, or ancestry groups not represented in training. Cross-species evaluation tests whether regulatory logic learned from human data transfers to mouse or other model organisms. Cross-tissue evaluation tests whether a model trained on blood and brain can generalize to liver or kidney. Cross-ancestry evaluation tests whether patterns learned predominantly from European populations apply to African, East Asian, or admixed individuals.\nClinical shifts involve new hospitals, different care patterns, or later time periods with evolving patient populations and medical practices. A risk model trained on academic medical center data may perform differently in community hospitals with different patient demographics and care protocols. Temporal validation, where models trained on earlier time periods are evaluated on later ones, can reveal degradation due to changes in diagnostic coding, treatment guidelines, or population health trends.\nRobustness evaluations typically involve training on one platform or cohort and testing on another, comparing performance across subgroups such as ancestry-stratified AUROC, and stress-testing models under label noise or missing data. These experiments often reveal that performance on curated, independently and identically distributed benchmarks overestimates usefulness in messy real-world settings, especially for high-stakes clinical decisions.\nA model that performs well on curated benchmarks may still struggle in real-world deployment for several reasons. Population diversity issues arise when training corpora underrepresent certain ancestries, leading to biased variant scoring (Chapter 2, Chapter 21). Assay heterogeneity means that experimental conditions, laboratories, and technologies in deployment differ from the curated datasets used in training. Different labs use different antibodies for ChIP-seq, different enzymes for ATAC-seq, and different sequencing depths, all of which can affect the mapping between sequence and measured regulatory activity. Phenotypic complexity reflects the reality that many clinically relevant phenotypes involve long causal chains from variant to molecular consequence to tissue-level effect to disease, and models may capture only part of this cascade.\nFor these reasons, genomic model evaluation increasingly includes cross-population robustness testing, out-of-distribution evaluation on new tissues, cell types, or species, and end-to-end assessments on clinically relevant endpoints often combined with traditional statistical genetics tools. Reporting performance stratified by potential sources of distribution shift has become expected practice, particularly for models intended for clinical deployment.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#evaluating-foundation-models-zero-shot-probing-and-fine-tuning",
    "href": "p5-ch19-eval.html#evaluating-foundation-models-zero-shot-probing-and-fine-tuning",
    "title": "19  Evaluation of Models",
    "section": "19.5 Evaluating Foundation Models: Zero-Shot, Probing, and Fine-Tuning",
    "text": "19.5 Evaluating Foundation Models: Zero-Shot, Probing, and Fine-Tuning\nGenomic foundation models (Chapter 7) complicate evaluation because there are multiple ways to use them, each testing different aspects of the learned representations. The appropriate evaluation regime depends on the downstream application and available resources.\n\n19.5.1 Zero-Shot and Few-Shot Evaluation\nIn zero-shot settings, we apply the pretrained model without any task-specific training. Examples include using masked-token probabilities to rank variants by predicted deleteriousness and using embedding similarities to cluster sequences or annotate motifs. Evaluation in this regime focuses on how well these raw scores correlate with functional or clinical labels and whether few-shot adaptation with small linear heads trained on limited labeled data already yields strong performance.\nZero-shot performance serves as a stress test of representation quality and inductive biases. Strong zero-shot performance suggests that the pretraining objective has captured biologically relevant structure that transfers without explicit supervision. For example, if masked language model probabilities on sequence variations correlate strongly with experimentally measured variant effects without any fine-tuning, this indicates that the model has internalized functional constraints during pretraining.\nWeak zero-shot performance combined with strong fine-tuned performance suggests that pretraining provides useful initialization but the learned representations are not directly interpretable for the task. This pattern is common when the pretraining objective (for example, next-token prediction) differs substantially from the downstream task (for example, clinical pathogenicity classification). The representations may still be useful as features for subsequent learning, but they do not encode the target concept directly.\nFew-shot evaluation examines how quickly models can adapt to new tasks with minimal labeled data. This is particularly relevant for rare diseases, underrepresented populations, or novel assays where large labeled datasets are impractical. If a foundation model can achieve competitive performance with 100 labeled examples while a model trained from scratch requires 10,000 examples, this demonstrates substantial practical value even if the final saturated performance is similar.\n\n\n19.5.2 Probing and Linear Evaluation\nA common evaluation pattern freezes the foundation model, extracts embeddings for sequences, variants, or loci, and trains simple probes such as linear models or shallow MLPs on downstream labels. This approach isolates the usefulness of learned representations from the model’s capacity to adapt during fine-tuning.\nKey evaluation questions in the probing regime include how much label efficiency is gained compared to training from scratch, how stable probe results are across random seeds and small dataset variations, and whether probes perform well across diverse tasks or only on those similar to the pretraining objectives. Linear probing provides a clean measure of how much useful information is linearly decodable from model representations.\nLayer-wise probing analysis can reveal how information is organized within the model. Early layers of a genomic transformer might encode local motifs and k-mer statistics, while deeper layers encode more abstract patterns like regulatory grammar or evolutionary constraints. Observing which layers are most informative for which tasks provides insight into the model’s internal representations and can guide feature extraction for downstream applications.\nProbing also enables diagnosing failure modes. If a task requires information that should be present in the training data but probes fail to decode it, this suggests either that the pretraining objective did not incentivize learning that information or that it is encoded in a non-linear or distributed way that simple probes cannot access. This diagnostic capability makes probing valuable both for understanding models and for improving them.\n\n\n19.5.3 Full Fine-Tuning and Task-Specific Heads\nFor high-value tasks, practitioners often fine-tune the foundation model end-to-end, adding task-specific heads for classification, regression, or ranking and adapting to new modalities or clinical contexts. Evaluation then looks similar to classic deep model evaluation but with additional questions specific to the foundation model paradigm.\nTransfer versus from-scratch baselines ask whether fine-tuning a foundation model meaningfully outperforms training a comparable architecture from scratch on the same downstream data. If the fine-tuned foundation model and from-scratch baseline converge to similar performance given sufficient data, the primary benefit of pretraining is data efficiency rather than improved final performance. This distinction matters for resource allocation: if labeled data are abundant, pretraining may offer limited advantage, but if labeled data are scarce, pretraining can be essential.\nCatastrophic forgetting asks whether fine-tuning degrades performance on other tasks, and whether that degradation matters for the intended use. A model fine-tuned aggressively on pathogenicity prediction might lose the ability to predict splicing effects or regulatory activity. If the deployment scenario requires multi-task performance, techniques to mitigate forgetting such as multi-task fine-tuning or parameter-efficient adaptation become important.\nRobustness and fairness ask whether foundation model features inherit or amplify biases present in the pretraining data or introduced during fine-tuning. If pretraining data are dominated by European ancestry samples, fine-tuning on a more diverse dataset may not fully overcome the ancestral imbalance in the learned representations. Explicit evaluation of performance across demographic groups is necessary to detect and mitigate these issues.\nAcross all evaluation regimes, it is helpful to report absolute performance, the delta compared to strong baselines, and data efficiency curves showing how performance varies with the amount of labeled data. This comprehensive reporting reveals whether pretraining provides genuine benefit or merely matches well-tuned task-specific models. Data efficiency curves are particularly informative: plotting performance as a function of training set size often shows that foundation models achieve with 1% of the data what from-scratch models require 10% or more to achieve, even when both eventually converge to similar asymptotic performance.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#uncertainty-calibration-and-reliability",
    "href": "p5-ch19-eval.html#uncertainty-calibration-and-reliability",
    "title": "19  Evaluation of Models",
    "section": "19.6 Uncertainty, Calibration, and Reliability",
    "text": "19.6 Uncertainty, Calibration, and Reliability\nMetrics like AUROC summarize ranking quality but say little about how trustworthy individual predictions are. For many applications, especially those involving clinical decisions, we care not only about whether the model is correct on average but also about whether its confidence estimates are meaningful.\nCalibration refers to the property that predicted probabilities match observed frequencies. A variant scored at 0.8 probability of being pathogenic should truly be pathogenic about 80% of the time. Well-calibrated models support rational decision-making because the probability scores can be interpreted at face value. Poorly calibrated models, even if they rank examples correctly, provide misleading confidence estimates that can lead to inappropriate decisions.\nThe distinction between epistemic and aleatoric uncertainty is also important. Epistemic uncertainty arises from limited data and could in principle be reduced by gathering more training examples. A model might express high epistemic uncertainty about variants in an underrepresented ancestral population simply because the training data contained few similar examples. Aleatoric uncertainty reflects inherent noise in the problem and cannot be reduced by additional data. Measurement noise in assays, stochastic biological processes, and incomplete penetrance of genetic variants all contribute to aleatoric uncertainty.\nModels that can distinguish these uncertainty types provide more actionable predictions, flagging cases where more data might help versus cases where uncertainty is irreducible. Ensemble methods, Bayesian neural networks, and other uncertainty quantification techniques can decompose total predictive uncertainty into epistemic and aleatoric components, though these decompositions are approximate and depend on modeling assumptions.\nSelective prediction or abstention allows models to say “I don’t know” when confidence is low, focusing predictions on cases where the model is reliable. This capability is particularly valuable in clinical settings where the cost of errors is high. A variant interpretation tool that abstains on 20% of variants but achieves 99% accuracy on the remaining 80% may be more useful than a tool that attempts to classify all variants at 90% accuracy, because the high-confidence predictions can be trusted while the abstained cases are flagged for manual review.\nEvaluation tools for uncertainty and calibration include reliability diagrams that plot predicted probabilities against observed frequencies, Brier scores that combine calibration and discrimination in a single metric, and calibration curves stratified by subgroup to identify differential calibration across ancestry, sex, or clinical site. Coverage versus accuracy curves for selective prediction show how accuracy changes as the model restricts predictions to increasingly confident cases: if the model predicts only on the 50% most confident samples, how accurate is it?\nReliability diagrams are constructed by binning predictions into intervals (for example, 0 to 0.1, 0.1 to 0.2, and so on), computing the mean predicted probability and empirical frequency within each bin, and plotting one against the other. A perfectly calibrated model produces points along the diagonal. Systematic deviations reveal patterns of over-confidence (predictions above the diagonal) or under-confidence (predictions below the diagonal).\nExpected calibration error (ECE) provides a scalar summary by computing the weighted average absolute difference between predicted probabilities and empirical frequencies across bins. Lower ECE indicates better calibration. However, ECE is sensitive to bin size and binning strategy, so it should be reported alongside reliability diagrams for interpretability.\nFor clinical risk models, Chapter 23 covers calibration and uncertainty in more depth. For variant-centric tasks, similar tools apply to pathogenicity probabilities or fine-mapping posteriors, which must be interpreted cautiously in light of confounders discussed in Chapter 21. Even well-calibrated models can give misleading risk estimates if the training data systematically differ from the deployment population in ways that affect the relationship between features and outcomes.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#benchmarks-leaderboards-and-their-limits",
    "href": "p5-ch19-eval.html#benchmarks-leaderboards-and-their-limits",
    "title": "19  Evaluation of Models",
    "section": "19.7 Benchmarks, Leaderboards, and Their Limits",
    "text": "19.7 Benchmarks, Leaderboards, and Their Limits\nBenchmark suites such as those introduced for Nucleotide Transformer and related genomic language models (see Chapter 18) serve important roles in the field. They provide standardized datasets, metrics, and splits that enable apples-to-apples comparisons between architectures. They encourage reproducibility by defining shared baselines against which progress can be measured. Well-designed benchmarks can accelerate progress by focusing community effort on common challenges and facilitating rapid iteration on model architectures.\nHowever, benchmark-centric culture has well-documented pitfalls. Overfitting to the benchmark can occur when models are tuned aggressively on a small panel of tasks, achieving impressive headline numbers while degrading on tasks outside the benchmark. This is particularly problematic when the same benchmark is used for both model development and final evaluation, creating incentives to optimize for benchmark-specific quirks rather than general capability.\nNarrow task coverage is common. Many existing suites focus on chromatin and transcription factor binding while underrepresenting splicing, structural variation, or clinical endpoints. A model that achieves state-of-the-art performance on chromatin benchmarks may perform no better than baselines on splice site prediction or pathogenicity classification. Relying solely on benchmark rankings without examining task-specific performance can give a misleading picture of model capabilities.\nMisaligned incentives can emerge when the community prizes fractional improvements in AUROC over more important but harder-to-measure gains in robustness, calibration, or fairness. A model that improves AUROC from 0.89 to 0.90 on a saturated benchmark may receive more attention than a model that maintains 0.88 AUROC while dramatically improving calibration, cross-ancestry performance, and uncertainty quantification. Yet the latter may be far more valuable for real-world deployment.\nGood practice treats benchmark scores as necessary but not sufficient evidence of model quality. They should be complemented with task-specific evaluations that mirror the intended downstream usage. Benchmarks should be periodically refreshed to include new assays, ancestries, and edge cases that stress-test models in new ways. The goal is to use benchmarks as a starting point for evaluation rather than as the final word on model quality.\nBenchmark deprecation should also be considered when performance saturates or when evaluation becomes dominated by optimization tricks rather than scientific advances. The computer vision community has grappled with this issue as models have saturated classic benchmarks like ImageNet, leading to the introduction of more challenging variants and out-of-distribution evaluation protocols. Genomics may face similar needs as foundation models mature.\nWhen reporting benchmark results, providing confidence intervals, reporting performance on multiple random seeds, and conducting ablation studies that isolate the contribution of different model components all strengthen the evidence for genuine progress. Transparency about what was and was not tuned on the benchmark helps readers interpret results critically.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#putting-it-all-together-an-evaluation-checklist",
    "href": "p5-ch19-eval.html#putting-it-all-together-an-evaluation-checklist",
    "title": "19  Evaluation of Models",
    "section": "19.8 Putting It All Together: An Evaluation Checklist",
    "text": "19.8 Putting It All Together: An Evaluation Checklist\nWhen designing or reviewing an evaluation for a genomic model, walking through a systematic checklist can help identify gaps and potential problems.\nThe first question concerns the level of decision. Is the model intended for molecular assay design, variant prioritization, patient risk stratification, or clinical action? The answer should determine which metrics are reported and how they are interpreted. Enrichment metrics make sense for variant ranking. Net benefit matters for clinical decisions. Choosing metrics aligned with the actual decision context ensures that evaluation measures what matters.\nThe second question concerns baselines. What are the comparison points? Strong non-deep baselines like logistic regression and classical polygenic scores establish floors that any sophisticated model should exceed. Prior deep models such as DeepSEA, SpliceAI, Enformer, and earlier foundation models establish the relevant state of the art. Reporting both absolute performance and gains over these baselines provides necessary context. A model achieving 0.85 AUROC might represent substantial progress if baselines are at 0.70, or minimal progress if baselines are at 0.83.\nThe third question concerns split design. Are individuals, loci, genes, assays, and ancestries appropriately separated between training and test sets? Is there any plausible path for leakage or circularity? These questions require careful auditing of data provenance and split construction. Documenting exactly how splits were constructed and what overlap checks were performed builds confidence in evaluation validity.\nThe fourth question concerns robustness. How does performance vary across cohorts, ancestries, platforms, and time? How does the model behave under label noise or missing data? Robustness evaluations reveal whether benchmark performance translates to real-world utility. Reporting stratified metrics by subgroup and evaluating on external datasets from different sources tests whether apparent performance generalizes beyond the specific training distribution.\nThe fifth question concerns uncertainty and calibration. For probabilistic outputs, are calibration and decision-level trade-offs reported? Are subgroup-specific metrics examined to identify differential performance across populations? Models deployed in high-stakes settings require not just good average performance but reliable confidence estimates that support appropriate action.\nThe sixth question concerns usage regimes for foundation models. How does the model perform in zero-shot, probing, and fine-tuning settings? Does pretraining help when labeled data are scarce, as measured by data efficiency curves? Understanding where the value of pretraining comes from (better final performance, faster convergence, improved data efficiency) helps determine whether the investment in large-scale pretraining is justified.\nThe seventh question concerns the story beyond the benchmark. Does improved performance actually change downstream decisions or experimental design? For models intended for clinical deployment, are there plans for prospective or interventional evaluation? The ultimate test of model utility is whether it enables better science or better care, not just higher numbers on a leaderboard.\nThis checklist is not exhaustive but covers the most common evaluation pitfalls in genomics. Working through it systematically at the design stage can prevent problems that are difficult or impossible to fix after the fact. Reviewers and readers can use the same checklist to critically evaluate published work.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch19-eval.html#looking-forward",
    "href": "p5-ch19-eval.html#looking-forward",
    "title": "19  Evaluation of Models",
    "section": "19.9 Looking Forward",
    "text": "19.9 Looking Forward\nThis chapter has provided a framework for thinking about evaluation across the full range of genomic models. The subsequent chapters flesh out specific aspects of reliability that evaluation alone cannot address.\nChapter 21 examines confounders, bias, and fairness in detail, showing how evaluation can mislead when data are structured in problematic ways. Population stratification, batch effects, label circularity, and benchmark leakage can all create illusions of performance that evaporate in deployment. Understanding these failure modes is essential for interpreting evaluation results critically.\nChapter 22 focuses on interpretability and mechanisms, turning models from black boxes into sources of testable biological hypotheses. When evaluation shows that a model works, interpretability helps us understand why it works and whether the reasons are biologically meaningful or artifacts of confounded data.\nTogether, these chapters aim to equip readers with the critical perspective needed to engage with the emerging literature on genomic foundation models. The question is never simply “what is the AUROC?” but rather “what has really been demonstrated, and how much should we trust it?” With careful attention to evaluation design, data splitting, robustness testing, and calibration assessment, we can distinguish models that represent genuine advances from those that merely perform well on convenient benchmarks.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Evaluation of Models</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html",
    "href": "p5-ch20-vep.html",
    "title": "20  Variant Effect Prediction",
    "section": "",
    "text": "20.1 From Handcrafted Scores to Foundation Models\nVariant effect prediction sits at the heart of modern genomics. Most variants discovered in clinical sequencing are rare and lack direct experimental evidence, yet clinicians must still decide whether a change is likely benign, pathogenic, or uncertain. The goal of variant effect prediction (VEP) is to map a variant and its context to a quantitative estimate of functional impact or disease risk that can support this decision.\nEarly computational approaches relied on hand-engineered features and relatively simple models. Conservation and heuristic-based scores such as SIFT and PolyPhen combine information about amino acid properties, sequence conservation, and protein domains to estimate whether a missense variant is damaging (Ng and Henikoff 2003; Adzhubei et al. 2010). CADD extends this idea to genome-wide scoring, integrating many annotations (e.g., conservation, regulatory marks, local sequence context) into a single pathogenicity score , Chapter 4. These methods were a major step forward, but they are fundamentally limited by the expressiveness of the hand-crafted features and by biases in the labeled data they use (Chapter 21).\nDeep learning methods widened the scope of VEP. Convolutional models like DeepSEA and ExPecto learn regulatory sequence features directly from raw DNA; splicing-focused models such as SpliceAI target specific molecular mechanisms, predicting how sequence changes alter splice donor/acceptor usage (Section 10.3). Protein language models (Chapter 13) learn high-dimensional representations of protein sequences that can be adapted for missense variant effect prediction, often outperforming feature-based scores.\nThe current frontier is defined by foundation models that treat DNA, RNA, and protein as languages, learning rich sequence representations from massive unlabeled corpora and then reusing those representations for variant interpretation. These models differ in their input modalities (protein vs DNA vs multi-species alignments), architectural choices (CNNs, transformers, state-space models), and training objectives (masked language modeling, autoregressive modeling, multi-task prediction), but they all aim to capture the evolutionary and regulatory constraints that shape observed variation.\nThis chapter focuses on four landmark systems that illustrate what modern foundation models look like when specialized for variant interpretation: AlphaMissense, a proteome-wide missense pathogenicity predictor that combines protein language models with structural context (Cheng et al. 2023); GPN-MSA, an alignment-based DNA language model that scores variants using multi-species sequence constraint (Benegas et al. 2024); Evo 2, a generalist genomic language model trained across species and modalities, providing zero-shot variant scores (Brixi et al. 2025; Manzo, Borkowski, and Ovcharenko 2025); and AlphaGenome, a unified 1 Mb context model that predicts multi-omic readouts and regulatory effects, enabling end-to-end noncoding VEP (Avsec, Latysheva, and Cheng 2025).\nWe first revisit zero-shot protein language model approaches, then dive into these four systems, compare their design choices, and close with open challenges for future VEP models.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#from-handcrafted-scores-to-foundation-models",
    "href": "p5-ch20-vep.html#from-handcrafted-scores-to-foundation-models",
    "title": "20  Variant Effect Prediction",
    "section": "",
    "text": "Warning\n\n\n\nVisual suggestion – big-picture overview\nAdd a small schematic showing the progression from: 1. Handcrafted scores (SIFT/PolyPhen/CADD) →\n2. Task-specific deep models (SpliceAI, regulatory CNNs) →\n3. Foundation-model-based VEP (protein LMs, Evo 2, AlphaGenome).\nThis could be a left-to-right timeline with example inputs (protein, DNA, MSA) and outputs (pathogenicity, regulatory effect, multi-omic profiles).",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#zero-shot-protein-language-models-for-variant-scoring",
    "href": "p5-ch20-vep.html#zero-shot-protein-language-models-for-variant-scoring",
    "title": "20  Variant Effect Prediction",
    "section": "20.2 Zero-Shot Protein Language Models for Variant Scoring",
    "text": "20.2 Zero-Shot Protein Language Models for Variant Scoring\nBefore specialized systems like AlphaMissense, a key development was the realization that unsupervised protein sequence models can already provide useful variant effect scores with no task-specific training.\n\n20.2.1 Evolutionary Models Over MSAs: EVE and popEVE\nEVE (Evolutionary model of Variant Effect) fits a generative model to a multiple sequence alignment (MSA) of homologs for a single protein (Frazer et al. 2021). The model learns a probability distribution over sequences such that variants that strongly violate evolutionary constraints (e.g., breaking conserved motifs or co-evolution patterns) receive low probability.\nVariant effect scores are derived from log-likelihood differences: the change in sequence log-probability under the model when a reference amino acid is replaced by an alternative. These raw scores are then calibrated against labeled variants (e.g., ClinVar) to produce categorical calls and confidence levels analogous to ACMG evidence.\npopEVE extends the approach by training models across many proteins and incorporating population allele frequencies, enabling proteome-wide scoring and better calibration across genes (Orenbuch et al. 2025). Together, these methods showed that strong performance is possible with purely unsupervised training on evolutionary data, MSA quality and depth critically influence performance and coverage, and calibration against clinical labels is essential for practical use (Chapter 19).\n\n\n20.2.2 Large Protein LMs: ESM-1v and Related Models\nESM-1v and related protein language models push beyond MSAs by training transformers on large corpora of unaligned protein sequences (Meier et al. 2021). These models use masked language modeling: given a sequence with masked amino acids, the model predicts the masked tokens, implicitly learning structural and functional constraints.\nZero-shot variant scoring follows the same principle as in EVE. The model computes the log-probability of the wild-type amino acid at a position, computes the log-probability of the mutant amino acid, and uses the difference as a variant effect score (often aggregated over both directions and context windows).\nCompared to MSA-based models, large protein LMs provide much broader coverage since they do not require explicit MSAs per protein, capture global patterns such as secondary/tertiary structure and remote homology (Chapter 13), and still require calibration and interpretation to be clinically useful.\n\n\n20.2.3 Cross-Protein Transfer from Deep Mutational Scanning\nDespite their success, zero-shot approaches face a persistent challenge: the gap between experimental fitness assays and clinical labels. Deep mutational scanning (DMS) experiments measure the functional effects of thousands of variants in a single protein, but only for a small subset of proteins. Conversely, clinical variant databases span many genes but are sparse and biased.\nCPT-1 (Cross-Protein Transfer 1) is a recent approach that tries to bridge this gap (Jagota et al. 2023). The key idea is to leverage cross-protein transfer. For a subset of proteins with DMS data, the model extracts features from protein language models (e.g., ESM-derived embeddings), structure (experimental or AlphaFold2-predicted), and conservation and other biologically motivated descriptors. A shared predictor is trained that maps these features to DMS-measured effects, then this predictor is transferred to new proteins by feeding in the same feature types, even when no DMS data exist for that protein.\nCPT-1 demonstrates substantial gains in high-sensitivity recall and ranking of pathogenic variants compared to purely zero-shot methods, complementarity between foundation model features and task-specific experimental supervision, and a template for systematically using DMS data as a bridge between large-scale representations and clinically relevant outcomes.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestions – zero-shot protein VEP\n\nSmall cartoon comparing EVE vs ESM-1v:\n\nEVE: MSA stack, generative model, Δ log-likelihood score.\nESM-1v: single sequence, transformer, masked token prediction.\n\nSchematic for CPT-1:\n\nDMS assays (per-protein fitness landscapes) → feature extraction (LM embeddings, structure) → shared predictor → transfer to new proteins.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#alphamissense-proteome-wide-missense-pathogenicity",
    "href": "p5-ch20-vep.html#alphamissense-proteome-wide-missense-pathogenicity",
    "title": "20  Variant Effect Prediction",
    "section": "20.3 AlphaMissense: Proteome-Wide Missense Pathogenicity",
    "text": "20.3 AlphaMissense: Proteome-Wide Missense Pathogenicity\nAlphaMissense, developed by DeepMind, is a large-scale system that provides precomputed pathogenicity scores for essentially all possible missense variants in the human proteome (Cheng et al. 2023). It combines the strengths of protein language models and structural information from AlphaFold2 to produce calibrated probability scores interpretable as “pathogenic” vs “benign”.\n\n20.3.1 Combining Sequence and Structure\nAlphaMissense rests on two main pillars. First, sequence-based representations. A protein language model is used to encode the wild-type amino acid sequence and the position-specific context of a mutation. The model learns evolutionary constraints from massive protein sequence databases and captures subtle patterns such as remote homology, local structural motifs, and co-evolution across residues.\nSecond, structure-based representations. Structural information is derived from AlphaFold2 predictions, providing a 3D context around each residue. Features include local geometry (e.g., solvent exposure, secondary structure, packing density) and longer-range contacts. Mutations at buried sites or within critical interaction interfaces can be distinguished from those in flexible, solvent-exposed regions.\nFor a proposed missense variant, AlphaMissense integrates the wild-type sequence, the mutant amino acid at a specific position, and local structural features from AlphaFold2 into a neural network that outputs a continuous pathogenicity probability between 0 and 1.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion – AlphaMissense architecture\nInsert an architecture schematic showing: - Input: protein sequence + AlphaFold2 structure, - Encoding: protein LM and structural feature extraction, - Fusion: joint network combining sequence and structure, - Output: pathogenicity probability.\nA zoom-in panel could highlight how local 3D neighborhood (e.g., proximity to active site) modulates the score.\n\n\n\n\n20.3.2 Training and Calibration\nAlphaMissense uses a hybrid training strategy. Self-supervised pretraining on protein sequences and structures ensures that representations capture generic biophysical and evolutionary constraints. Supervised fine-tuning on labeled clinical and population data uses pathogenic and benign missense variants from ClinVar and other curated resources, along with high-frequency variants from population databases such as gnomAD, treated as likely benign under standard assumptions (Chapter 21).\nRaw model outputs are then calibrated so that scores near 0 correspond to variants observed to behave like benign in curated sets, scores near 1 correspond to variants consistently observed as pathogenic, and intermediate scores are interpretable as uncertain or conflicting evidence, which can be integrated into ACMG-like decision frameworks (Chapter 19).\n\n\n20.3.3 Performance and Clinical Utility\nAcross diverse benchmarks including ClinVar, expert-curated panels, and deep mutational scanning datasets, AlphaMissense achieves higher AUC and precision–recall than many prior missense predictors, strong correlation with experimental functional readouts, and robustness across different genes and variant spectra.\nIts precomputed proteome-wide score release makes it particularly attractive in practice: users can simply look up scores instead of running heavy inference per variant. This facilitates downstream tasks such as prioritizing variants of uncertain significance (VUS), supporting gene discovery and burden tests, and annotating large sequencing cohorts.\n\n\n20.3.4 Limitations and Caveats\nDespite its strengths, AlphaMissense has several important limitations. It only handles missense variants; other coding and noncoding variant types require separate tools. Calibration depends on existing clinical and population labels, which are themselves biased by ascertainment and ancestry (Chapter 21). The model is largely opaque: it provides a scalar score but limited mechanistic explanations (Chapter 22). Structural features rely on predicted rather than experimentally determined structures for most proteins; errors or uncertainties in AlphaFold2 predictions can propagate into scores.\nGuidelines thus recommend using AlphaMissense as a strong supporting line of evidence, but not as a standalone decision-maker. Scores are best interpreted in combination with segregation data, population frequencies, functional assays, and gene-level context (Section 10.2).",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#gpn-msa-alignment-based-dna-language-modeling",
    "href": "p5-ch20-vep.html#gpn-msa-alignment-based-dna-language-modeling",
    "title": "20  Variant Effect Prediction",
    "section": "20.4 GPN-MSA: Alignment-Based DNA Language Modeling",
    "text": "20.4 GPN-MSA: Alignment-Based DNA Language Modeling\nNoncoding variants present a different challenge: there is no straightforward notion of a “protein structure” to rely on, and the relevant functional constraints are often encoded in subtle motifs and long-range regulatory elements. GPN-MSA (Genomic Pre-trained Network with Multi-Species Alignments) addresses this by combining raw DNA sequence with multi-species conservation in a language modeling framework (Benegas et al. 2024).\n\n20.4.1 Alignment-Based DNA Language Model\nGPN-MSA extends earlier GPN models by ingesting multi-species sequence alignments over kilobase-scale genomic windows. For each genomic position, the input includes the reference DNA base in the focal species (e.g., human), the aligned bases (or gaps) from multiple other species, and masking patterns to indicate which positions and species are visible.\nThe model is trained with a masked language modeling objective analogous to BERT. The training procedure randomly masks bases across the alignment and predicts the masked bases given surrounding context across positions and species. Through this objective, GPN-MSA learns which bases are strongly constrained across evolution (highly predictable) and which positions tolerate more variability.\n\n\n20.4.2 Variant Scoring Strategies\nSeveral strategies map GPN-MSA outputs to variant effect scores. Likelihood-based scoring compares the log-likelihood of reference and alternative alleles at a position, capturing how much the variant deviates from conservation patterns. Contextual perturbation assesses how a variant perturbs model predictions or hidden representations across a window, capturing disruption of local motifs or multi-base patterns. Embedding-based features use learned representations as features in downstream supervised models for pathogenicity or specific regulatory phenotypes.\nBecause GPN-MSA directly uses multi-species alignments, it excels at capturing deep evolutionary constraint in genomic regions that are noncoding but functionally important, such as enhancers, promoters, and untranslated regions.\n\n\n20.4.3 Benchmarking and Applications\nOn genome-wide variant pathogenicity benchmarks and regulatory variant datasets (e.g., from high-throughput reporter assays), GPN-MSA outperforms simpler conservation scores (e.g., phyloP, phastCons) when evaluated fairly, offers strong prefiltering ability by enriching for likely functional variants out of large candidate sets, and provides a principled way to combine alignment information with learned sequence features.\nIts limitations include dependence on high-quality multi-species alignments, which may be missing or unreliable in repetitive regions, and coverage gaps for species or loci with poor comparative genomics resources.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion – GPN-MSA input and objective\nAdd a figure showing: - A stack of aligned sequences (species × position), - Masked tokens highlighted, - The model predicting masked bases across positions and species.\nA side panel can illustrate how a single nucleotide variant changes the alignment column and how that translates into a Δ log-likelihood score.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#evo-2-a-generalist-genomic-language-model",
    "href": "p5-ch20-vep.html#evo-2-a-generalist-genomic-language-model",
    "title": "20  Variant Effect Prediction",
    "section": "20.5 Evo 2: A Generalist Genomic Language Model",
    "text": "20.5 Evo 2: A Generalist Genomic Language Model\nEvo 2 pushes the foundation model paradigm further by acting as a generalist genomic language model: a single model trained across species and genomic contexts with very long input sequences (Brixi et al. 2025; Manzo, Borkowski, and Ovcharenko 2025). Conceptually, Evo 2 for genomes plays a similar role to large language models for text.\n\n20.5.1 Scale and Architecture\nEvo 2 introduces several distinctive features. Long context length is enabled by the StripedHyena 2 architecture, which efficiently handles context lengths up to approximately 1 Mb, enabling it to model both local motifs and long-range dependencies (e.g., enhancer-promoter links). The model is trained on a diverse corpus: OpenGenome2, a large collection of genomes spanning many branches of the tree of life. This cross-species training encourages learning general principles of genomic organization and constraint. Flexible tokenization strategies range from single nucleotides to longer k-mer or hybrid schemes, balancing resolution and efficiency (Chapter 5).\nThe training objective is primarily autoregressive or masked language modeling on raw DNA, learning to predict bases or tokens given the surrounding context.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion – Evo 2 architecture\nInsert a high-level diagram of Evo 2: - Input: 1 Mb genomic window, - Backbone: StripedHyena 2 blocks (recurrent/state-space-like) enabling long-range context, - Output: per-position token probabilities.\nA small inset could compare Evo 2’s context length to earlier CNN/transformer models (e.g., 1–10 kb vs 1 Mb).\n\n\n\n\n20.5.2 Zero-Shot Variant Effect Scoring\nVariant scoring with Evo 2 mirrors the logic of zero-shot protein LMs. The model computes token-level log-probabilities for the reference sequence, substitutes the variant allele in context, recomputes log-probabilities, and derives a score based on the log-likelihood change.\nBecause Evo 2 sees long genomic neighborhoods, its scores implicitly capture local motif disruption (e.g., TF binding sites), altered higher-order patterns (e.g., CpG content, nucleosome positioning signals), and constraints arising from interactions between multiple elements within the window. This makes Evo 2 particularly suited for noncoding and regulatory variants, where context far beyond the immediate base often matters.\n\n\n20.5.3 Fine-Tuning and Task-Specific Heads\nWhile zero-shot scores are already competitive, Evo 2 can be fine-tuned or paired with task-specific heads for regulatory prediction (e.g., chromatin accessibility, histone marks), splicing outcomes, and gene expression levels. Such adapters reuse Evo 2’s representations as a generic backbone, mirroring how text LLMs are adapted via lightweight fine-tuning and prompting (Chapter 7).",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#alphagenome-unified-multi-omic-vep-at-1-mb-context",
    "href": "p5-ch20-vep.html#alphagenome-unified-multi-omic-vep-at-1-mb-context",
    "title": "20  Variant Effect Prediction",
    "section": "20.6 AlphaGenome: Unified Multi-Omic VEP at 1 Mb Context",
    "text": "20.6 AlphaGenome: Unified Multi-Omic VEP at 1 Mb Context\nAlphaGenome is a unified model that takes a 1 Mb DNA sequence as input and jointly predicts a wide panel of multi-omic readouts: chromatin accessibility, histone modifications, TF binding, 3D contacts, and splicing features (Avsec, Latysheva, and Cheng 2025). It can then be used to estimate how variants perturb these readouts, providing a mechanistic view of noncoding variant effects.\n\n20.6.1 Architecture and Training\nThe AlphaGenome architecture combines multiple components. Convolutional front-ends extract local motif-level features (akin to models like DeepSEA and Enformer). Long-range attention or state-space blocks propagate information across hundreds of kilobases (Chapter 14). Multi-task prediction heads handle different assay types (e.g., ATAC-seq, ChIP-seq marks, Hi-C contact maps, splice junction usage).\nTraining relies on large-scale functional genomics data from many cell types and assays (Section 10.1). The model is optimized to jointly predict 1D tracks (e.g., coverage profiles), 2D contact maps (e.g., Hi-C), and sequence-derived splicing features (e.g., junction usage, splice site scores).\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion – AlphaGenome unified architecture\nAdd a block diagram showing: - Input: 1 Mb DNA sequence, - Layers: convolutional encoder → long-range blocks → multi-task heads, - Outputs: example tracks (ATAC, H3K27ac), a 3D contact map panel, and splicing predictions.\nHighlight that the same backbone supports all these modalities.\n\n\n\n\n20.6.2 Variant Effect Prediction Across Modalities\nFor VEP, AlphaGenome compares predictions for the reference and alternate sequences. Regulatory impact is captured through changes in predicted chromatin accessibility or histone marks at enhancers/promoters. 3D genome structure effects appear as shifts in predicted contact maps, particularly enhancer-promoter interactions that may be weakened or strengthened. Splicing effects manifest as altered splice junction usage or cryptic splice site activation.\nThis enables multi-modal variant effect scores that unify many previously separate tools (e.g., promoter/enhancer predictors, splicing models, TAD-perturbation models). On benchmarks spanning regulatory MPRAs, splicing assays, and disease-associated noncoding variants, AlphaGenome achieves state-of-the-art performance while providing mechanistically interpretable outputs.\nIts main challenges include heavy computational cost (1 Mb windows with many outputs), potential brittleness when extrapolating beyond the training distribution (e.g., rare tissues, extreme cell states), and the difficulty of calibrating multi-omic changes into clinical pathogenicity categories.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#comparing-design-choices-across-modern-vep-models",
    "href": "p5-ch20-vep.html#comparing-design-choices-across-modern-vep-models",
    "title": "20  Variant Effect Prediction",
    "section": "20.7 Comparing Design Choices Across Modern VEP Models",
    "text": "20.7 Comparing Design Choices Across Modern VEP Models\nThe models surveyed in this chapter span different points in a multidimensional design space. The table below summarizes some of the key axes:\n\n\n\n\n\n\n\n\n\n\n\nModel\nInput Modality\nContext Length\nPretraining Data\nVariant Types\nPrimary Outputs\n\n\n\n\nAlphaMissense\nProtein sequence + structure\nProtein-length\nProtein sequence corpora + AlphaFold2 structures\nMissense only\nPathogenicity probability\n\n\nGPN-MSA\nMulti-species DNA alignments\nkb-scale windows\nWhole-genome MSAs across many species\nCoding + noncoding\nLikelihood / embedding-based scores\n\n\nEvo 2\nRaw DNA sequence\nUp to ~1 Mb\nOpenGenome2 (multi-species genomes)\nAll variant types\nZero-shot likelihood-based scores + representations\n\n\nAlphaGenome\nRaw DNA sequence\n1 Mb\nHuman genome + multi-omic tracks across cell types\nAll variant types\nMulti-omic tracks + delta effects\n\n\n\nSeveral key contrasts emerge. AlphaMissense focuses on proteins and missense variants, while GPN-MSA, Evo 2, and AlphaGenome operate directly on DNA, with varying emphasis on coding vs noncoding variants. Shorter context models (e.g., GPN-MSA) excel at capturing local conservation, whereas Evo 2 and AlphaGenome can model long-range regulatory interactions. AlphaMissense outputs a single pathogenicity probability; Evo 2 primarily offers likelihood-based scores and representations; AlphaGenome produces rich multi-omic profiles that can support mechanistic hypotheses (Chapter 22). AlphaMissense and GPN-MSA emphasize evolutionary constraints; Evo 2 adds cross-species genomic syntax; AlphaGenome emphasizes functional genomics.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestions – comparative performance and design\n\nA bar chart or ROC/AUPRC plot comparing model performance on ClinVar (missense), MAVE/DMS datasets, and regulatory MPRA datasets.\nA schematic table (expanded from the one above) highlighting modality, context length, training data types, output types, and example use cases (clinical vs research).\n\n\n\n\n20.7.1 Specialized vs General Regulatory Models\nA recurring tension in regulatory VEP is whether to build specialized models for a specific tissue/assay or general models that span many contexts. TREDNet exemplifies the specialized strategy: it is trained to predict regulatory activity (e.g., TF binding, chromatin marks) for a specific cell type and assay configuration (Hudaiberdiev et al. 2023). Such specialization concentrates model capacity on a well-defined biological context, often yields strong performance for that context, and facilitates interpretation in terms of a particular regulatory program.\nIn contrast, models like AlphaGenome and Evo 2 are generalist backbones that can be adapted across many contexts via multi-task heads or fine-tuning. Generalist models provide a single representation that can be reused across tasks (Chapter 7), enable transfer to cell types or assays with limited data, and support unified analyses that integrate multiple regulatory modalities.\nIn practice, specialized vs general models are complementary. Specialized models may be preferable when the disease mechanism is tightly linked to a particular cell type and high-quality matched functional data exist for that context. Generalist backbones are more attractive when data are sparse or heterogeneous and we wish to systematically explore variant effects across many cell types and assays (Section 10.1).\n\n\n20.7.2 Combining Predictors in Practice\nNo single VEP model is universally optimal. Practical workflows often combine multiple predictors. For example, use GPN-MSA or Evo 2 for initial genome-wide filtering, prioritizing variants under strong evolutionary or language-model-derived constraint. Use AlphaMissense for missense variants in protein-coding regions, especially when strong structural context is available. Use AlphaGenome (or similar regulatory models) to evaluate noncoding variants affecting enhancers, promoters, or splicing.\nThese combinations are typically integrated with population allele frequencies (e.g., gnomAD), gene-level constraint metrics, clinical and segregation data, and task-specific experimental assays when available (Chapter 19; Section 10.2).\nA key challenge is to avoid overcounting correlated signals (e.g., multiple scores derived from similar evolutionary data) and to calibrate evidence contributions within frameworks like ACMG, as discussed further in Chapters 17 and 18 (Chapter 19; Chapter 21).\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion – practical VEP workflow\nAdd a workflow diagram showing: 1. Input: variant list from sequencing, 2. Branches by variant type (missense, synonymous, noncoding), 3. Tools used per branch (AlphaMissense, Evo 2, AlphaGenome, GPN-MSA, TREDNet), 4. Integration with population, gene-level, and clinical data, 5. Output: prioritized variant set and evidence summary.\nThis could be reused across later translation chapters.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch20-vep.html#open-challenges-and-future-directions",
    "href": "p5-ch20-vep.html#open-challenges-and-future-directions",
    "title": "20  Variant Effect Prediction",
    "section": "20.8 Open Challenges and Future Directions",
    "text": "20.8 Open Challenges and Future Directions\nEven state-of-the-art systems like AlphaMissense, GPN-MSA, Evo 2, and AlphaGenome leave major gaps. These open challenges define the frontier of variant effect prediction research.\n\n20.8.1 Ancestry and Population Bias\nTraining data and labels remain skewed toward certain ancestries, genes, and disease phenotypes. ClinVar submissions are dominated by variants from individuals of European ancestry, population databases underrepresent many global populations, and functional assays are concentrated on a limited set of genes and pathways. These biases can distort both calibration and ranking of variants across ancestries (Chapter 21). Future VEP models will need more diverse training datasets, explicit modeling of population structure, and evaluation frameworks that surface ancestry-specific performance disparities (Chapter 18).\n\n\n20.8.2 Complex Variant Patterns\nMost current models focus on single-nucleotide variants (SNVs) or single amino acid substitutions. However, real genomes contain indels and frameshifts, structural variants (SVs), haplotypes involving multiple nearby variants, and compound heterozygosity and gene-gene interactions. Extending models to capture combinatorial variant patterns is challenging: the space of possible multi-variant configurations is enormous, training data for interactions are sparse, and long-range and higher-order epistasis can be hard to represent even in large models. Foundation models with long contexts (like Evo 2 and AlphaGenome) provide a promising substrate, but new objectives and datasets will be needed to robustly model multi-variant effects.\n\n\n20.8.3 Integrating Multi-Omics and Longitudinal Data\nAlphaGenome takes a first step toward unified multi-omic prediction, but real tissues and organisms exhibit dynamic regulatory programs across development and aging, responses to environmental perturbations, and cell-type heterogeneity and spatial organization. Integrating single-cell, spatial, and longitudinal omics into VEP frameworks will be crucial for capturing context-specific variant effects (Chapter 17). This will likely require new multi-scale architectures that span from sequence to cell states, careful treatment of batch effects and confounders, and benchmarks that explicitly evaluate context-specific predictions (Chapter 18).\n\n\n20.8.4 Interpretability and Clinical Communication\nAs models grow more complex, interpretability becomes a central concern (Chapter 22). Clinicians need explanations that connect model scores to mechanism (e.g., “disrupts a conserved splice acceptor, predicted to cause exon skipping”). Researchers need tools to trace predictions back to motifs, domains, or 3D contacts that can be experimentally tested. Future work will involve model-based attribution methods adapted to sequence and structure, counterfactual reasoning over variant sets, and interfaces that present model outputs in clinically meaningful formats.\n\n\n20.8.5 Safe Deployment and Continual Learning\nFinally, VEP systems are increasingly deployed in clinical and research pipelines that continuously generate new data. This raises questions about continual learning (how to integrate new functional and clinical labels without destabilizing existing predictions), versioning and reproducibility (how to ensure that changes in models and training data are tracked and interpretable to downstream users), and safety and governance (how to prevent misuse, ensure transparency about limitations, and embed these tools within responsible clinical workflows) (Section 10.2; Chapter 19).\nIn subsequent chapters, we connect these VEP systems to broader end-to-end frameworks for variant interpretation, including risk prediction, rare disease diagnosis, and therapeutic target discovery. Together with careful evaluation and interpretation, foundation-model-based VEP promises to transform how we understand and act on genomic variation.\n\n\n\n\nAdzhubei, Ivan A., Steffen Schmidt, Leonid Peshkin, Vasily E. Ramensky, Anna Gerasimova, Peer Bork, Alexey S. Kondrashov, and Shamil R. Sunyaev. 2010. “A Method and Server for Predicting Damaging Missense Mutations.” Nature Methods 7 (4): 248–49. https://doi.org/10.1038/nmeth0410-248.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. “[Evo 2] Genome Modeling and Design Across All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nFrazer, Jonathan, Pascal Notin, Mafalda Dias, Aidan Gomez, Joseph K. Min, Kelly Brock, Yarin Gal, and Debora S. Marks. 2021. “[EVE] Disease Variant Prediction with Deep Generative Models of Evolutionary Data.” Nature 599 (7883): 91–95. https://doi.org/10.1038/s41586-021-04043-8.\n\n\nHudaiberdiev, Sanjarbek, D. Leland Taylor, Wei Song, Narisu Narisu, Redwan M. Bhuiyan, Henry J. Taylor, Xuming Tang, et al. 2023. “[TREDNet] Modeling Islet Enhancers Using Deep Learning Identifies Candidate Causal Variants at Loci Associated with T2D and Glycemic Traits.” Proceedings of the National Academy of Sciences 120 (35): e2206612120. https://doi.org/10.1073/pnas.2206612120.\n\n\nJagota, Milind, Chengzhong Ye, Carlos Albors, Ruchir Rastogi, Antoine Koehl, Nilah Ioannidis, and Yun S. Song. 2023. “Cross-Protein Transfer Learning Substantially Improves Disease Variant Prediction.” Genome Biology 24 (1): 182. https://doi.org/10.1186/s13059-023-03024-6.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025. “Comparative Analysis of Deep Learning Models for Predicting Causative Regulatory Variants.” bioRxiv: The Preprint Server for Biology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nMeier, Joshua, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu, and Alexander Rives. 2021. “[ESM-1v] Language Models Enable Zero-Shot Prediction of the Effects of Mutations on Protein Function.” bioRxiv. https://doi.org/10.1101/2021.07.09.450648.\n\n\nNg, Pauline C., and Steven Henikoff. 2003. “SIFT: Predicting Amino Acid Changes That Affect Protein Function.” Nucleic Acids Research 31 (13): 3812–14. https://doi.org/10.1093/nar/gkg509.\n\n\nOrenbuch, Rose, Courtney A. Shearer, Aaron W. Kollasch, Aviv D. Spinner, Thomas Hopf, Lood van Niekerk, Dinko Franceschi, Mafalda Dias, Jonathan Frazer, and Debora S. Marks. 2025. “[popEVE] Proteome-Wide Model for Human Disease Genetics.” Nature Genetics, November, 1–10. https://doi.org/10.1038/s41588-025-02400-1.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Variant Effect Prediction</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html",
    "href": "p5-ch21-confound.html",
    "title": "21  Confounders in Model Training",
    "section": "",
    "text": "21.1 Definitions: Confounding, Bias, and Leakage\nIn previous chapters, we have largely treated model performance curves and ROC plots as if they faithfully reflected how well a model captured biology. Under that view, higher AUC or lower loss is always better, and improvements on a benchmark mean real progress.\nThis chapter interrogates that assumption.\nGenomic datasets are riddled with hidden structure: ancestry, family relatedness, sequencing center, capture kit, hospital system, recruitment year, label curation protocol, and more. These factors correlate with both the features (genotypes, readouts, gene expression, epigenomic marks) and the labels (disease status, variant pathogenicity, expression levels). When such confounders are not explicitly controlled, models, especially large, flexible foundation models, can easily learn shortcuts that exploit them.\nPopulation structure, technical batch effects, benchmark leakage, and label bias are not unique to deep learning; they affect linear regression and logistic models just as much. What makes them particularly dangerous in the foundation model era is scale: larger datasets and more expressive architectures make it easier for models to discover subtle shortcuts that are invisible in standard diagnostics but dramatically hurt out-of-distribution performance.\nOur goal in this chapter is not to provide a complete causal inference textbook. Instead, we offer a practical guide for genomic modelers. We examine how to recognize common confounders in genomic and clinical datasets, how these confounders show up in benchmarks and cross-cohort evaluation, how to design splits and experiments that probe real generalization rather than memorization or shortcut learning, how to mitigate confounding via study design, modeling choices, and post-hoc analysis, and how to report results transparently so that readers can assess robustness and fairness.\nWe will repeatedly cross-reference the benchmark-focused discussion in Chapter 18 and the methodological guidance in Chapter 19. Here, the emphasis is on pitfalls: ways models can look impressive on paper while failing to learn the desired biology.\nBefore diving into genomics-specific examples, it is helpful to clarify terminology.\nA confounder is a variable that influences both the input features and the label. For example, ancestry affects allele frequencies across the genome and disease risk via environmental and socioeconomic pathways. If ancestry is not explicitly modeled or controlled, a model trained to predict disease may in fact be learning ancestry.\nBias refers to a systematic deviation from the quantity we intend to estimate or predict. Bias can result from confounding, but also from measurement error, label definitions, sampling procedures, or deployment differences (for instance, different prevalence in clinical practice versus a case–control study).\nLeakage occurs when information about the test set inadvertently influences model training or selection. Leakage can occur through overlapping individuals or variants, shared families, duplicated samples, or indirect channels such as pretraining on a resource that is later used as a benchmark.\nDistribution shift is a mismatch between the data distribution used for training and the distribution encountered during evaluation or deployment. Shift can be driven by changes in ancestry composition, sequencing technology, clinical coding practices, or temporal trends in care.\nThese phenomena are intertwined. Confounders create biases in estimated effects and predictions. Leakage can hide those biases by making held-out performance look better than it should. Distribution shifts then cause performance to collapse when a model is deployed outside the environment in which its shortcuts were learned.\nFor genomic foundation models, these risks are magnified by three features. First, high-dimensional structure means that genomes encode ancestry, relatedness, and assay conditions in thousands of subtle ways, even if we never explicitly provide those labels. Second, powerful pattern detection means that shallow models might miss some shortcuts, but large transformers will find them if they help optimize the training objective. Third, complex training regimes involving pretraining on biobank-scale data, followed by fine-tuning on curated labels and evaluation on community benchmarks, create many opportunities for direct and indirect leakage.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#a-taxonomy-of-confounders-in-genomic-data",
    "href": "p5-ch21-confound.html#a-taxonomy-of-confounders-in-genomic-data",
    "title": "21  Confounders in Model Training",
    "section": "21.2 A Taxonomy of Confounders in Genomic Data",
    "text": "21.2 A Taxonomy of Confounders in Genomic Data\nConfounders in genomic modeling can be grouped into several broad categories. The same variable, say recruitment site, may simultaneously induce ancestry differences, batch effects, and label bias.\nPopulation structure and relatedness includes continental and sub-continental ancestry, family relatedness (siblings, parent–offspring, cryptic relatedness), and founder effects with local haplotype structure.\nTechnical batch and platform effects arise from sequencing center, instrument, capture kit, and library preparation protocol. Different read lengths, coverage patterns, aligners, and variant callers introduce systematic differences. Distinct assay chemistries for DNA, RNA, or epigenomic profiling further complicate matters.\nCohort and institution effects reflect hospital systems with different patient populations and coding practices, biobank-specific inclusion and exclusion criteria, and ascertainment patterns (referral centers versus population-based studies).\nLabel and curation bias stems from clinical labels derived from billing codes, problem lists, or registry entries. Variant pathogenicity labels from ClinVar and similar databases reflect expert curation, test panels, and past literature biases (Landrum et al. 2018). Expression, regulatory, or splicing labels derived from specific tissues or cell lines carry their own limitations (The GTEx Consortium 2020; Kagda et al. 2025).\nTemporal drift includes changes in clinical practice, diagnostic criteria, or coding over time, evolving sequencing technologies and QC pipelines, and shifts in population behavior or environment.\nKnowledge-base and benchmark leakage involves using resources like gnomAD (Karczewski et al. 2020) or UK Biobank (Bycroft et al. 2018) in both model training and evaluation, or reusing curated variant sets across multiple publications and tasks.\nMany of these factors are present simultaneously in large-scale genomic resources and biobanks. Ignoring them leads to deceptively strong benchmark performance and brittle behavior when models are deployed in new contexts.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A comprehensive table summarizing confounder categories (population, technical, cohort, label, temporal, knowledge-base leakage) with columns for “Example variables”, “Common manifestations in genomic data”, “Diagnostics”, and “Mitigation strategies” would provide readers with a practical reference.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#population-structure-and-ancestry-as-shortcuts",
    "href": "p5-ch21-confound.html#population-structure-and-ancestry-as-shortcuts",
    "title": "21  Confounders in Model Training",
    "section": "21.3 Population Structure and Ancestry as Shortcuts",
    "text": "21.3 Population Structure and Ancestry as Shortcuts\n\n21.3.1 How Ancestry Becomes a Confounder\nHuman genetic variation is structured by ancestry: allele frequencies, haplotype blocks, and linkage disequilibrium patterns differ across populations. Principal components (PCs) computed from genome-wide genotypes provide a low-dimensional summary of this structure and are now standard in genome-wide association studies (GWAS) to correct for stratification (Patterson, Price, and Reich 2006; Price et al. 2006).\nAncestry, however, is not just a convenient statistical nuisance. It is intertwined with geography, environment, socioeconomic status, and access to healthcare. These factors directly impact disease risk, phenotyping, and the likelihood of receiving genetic testing. Thus, ancestry influences both features (the genome) and labels (phenotypes and clinical annotations), creating classic confounding.\nFor example, a rare disease clinic serving primarily individuals of European ancestry may contribute most pathogenic variants in ClinVar, while variants observed predominantly in other ancestries remain labelled as variants of uncertain significance (VUS) (Landrum et al. 2018). Biobanks enriched for particular ancestries, birth cohorts, or health systems introduce subtle differences in both genotype and phenotype distributions (Bycroft et al. 2018).\nA model trained on such data may appear to excel at predicting disease risk or variant pathogenicity, while in reality it has learned to infer ancestry and exploit its correlation with label definitions and clinical practice.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A causal diagram or schematic showing ancestry influencing both genotype and environment/clinical practice, which in turn influence disease labels, would clarify where a model might pick up shortcuts (predicting ancestry instead of biology).\n\n\n\n\n21.3.2 Ancestry and Foundation Models\nFoundation models trained directly on nucleotide sequences or variant streams clearly see ancestry information: the distribution of k-mers and haplotypes differs by population (He et al. 2023). When such models are fine-tuned to predict disease risk, expression, or pathogenicity, they may leverage this ancestry signal as an easy shortcut.\nMulti-ancestry GWAS and polygenic score studies underscore the magnitude of these issues. Risk scores derived from primarily European cohorts often transfer poorly to other ancestries, with attenuated performance and systematic miscalibration (Ishigaki et al. 2022). Similar pitfalls arise when genomic foundation models are trained or validated in ancestry-skewed datasets.\nCrucially, increasing model capacity does not automatically solve ancestry bias; it can make it worse by making it easier to detect and exploit subtle ancestry-linked features. Robust evaluation must therefore probe performance within and across ancestry groups, not just overall metrics.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#technical-batch-and-platform-effects",
    "href": "p5-ch21-confound.html#technical-batch-and-platform-effects",
    "title": "21  Confounders in Model Training",
    "section": "21.4 Technical Batch and Platform Effects",
    "text": "21.4 Technical Batch and Platform Effects\nTechnical pipelines are complex. Each step from sample collection through library preparation, sequencing, alignment, and variant calling can introduce systematic differences that act as confounders.\nDifferent sequencing centers use distinct instruments, reagents, and QC thresholds. Library preparation protocols vary in GC bias and coverage profiles. Capture kits and read lengths change the probability of calling variants in specific genomic regions. Assay platforms for epigenomics, expression, or chromatin conformation have distinct noise and bias characteristics.\nWhen samples from a particular batch or platform are disproportionately drawn from a specific label class (say, cases sequenced at one center and controls at another), models can learn to distinguish batches rather than biology. In high-dimensional feature spaces, even subtle batch-specific artifacts (coverage dips, variant density patterns, adapter content) can be exploited.\nFoundation models are particularly sensitive: pretraining on raw reads, read piles, or coverage tracks makes it easy to detect batch signatures unless preprocessing and normalization are carefully handled.\nCommon patterns include clustering by batch or sequencing center when embedding outputs or PCs are visualized, strong predictive performance that collapses when evaluated on data from a new center, instrument, or protocol, and models that can nearly perfectly predict batch ID, platform, or capture kit from the inputs alone.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A PCA or UMAP of sample embeddings colored by batch or sequencing center (left panel) versus labeled phenotype (right panel) would illustrate strong batch structure relative to signal-of-interest.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#cohort-institution-and-label-bias",
    "href": "p5-ch21-confound.html#cohort-institution-and-label-bias",
    "title": "21  Confounders in Model Training",
    "section": "21.5 Cohort, Institution, and Label Bias",
    "text": "21.5 Cohort, Institution, and Label Bias\nBeyond ancestry and technical factors, cohort and institution choices introduce additional confounding.\nCohort effects arise because population-based cohorts differ from hospital-based or referral cohorts in terms of disease prevalence, comorbidities, and socio-demographic composition.\nInstitutional practices vary across hospitals and clinics, which use distinct coding practices, diagnostic thresholds, and follow-up schedules. These alter labels derived from electronic health records.\nAscertainment and testing bias means that individuals who receive genome sequencing or panel testing may be more severely affected, more affluent, or preferentially from particular ancestry groups.\nLabel sources further complicate matters. Claims-based phenotypes and ICD codes can be noisy and incomplete. Registries and expert-curated variant databases may lag behind current knowledge and reflect historical focus areas (Landrum et al. 2018). Functional assay readouts often depend on specific cell lines, overexpression systems, or environmental conditions, which may not generalize.\nFor genomic foundation models that aspire to downstream clinical utility, these biases can dominate the training signal. Without careful design, models may simply reproduce institutional practices and historical biases rather than underlying biology.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#data-splitting-and-benchmark-leakage",
    "href": "p5-ch21-confound.html#data-splitting-and-benchmark-leakage",
    "title": "21  Confounders in Model Training",
    "section": "21.6 Data Splitting and Benchmark Leakage",
    "text": "21.6 Data Splitting and Benchmark Leakage\nData splitting is one of the primary tools we have to assess generalization. However, naive splits can silently allow leakage and confounding.\n\n21.6.1 Types of Splits\nCommon splitting strategies include several approaches. Random individual-level splits assign individuals randomly to train, validation, and test sets. Family-aware splits keep families together to avoid relatedness leakage across splits. Locus-level splits keep variants at the same genomic position, and often in close proximity, within the same split to prevent models from memorizing site-specific patterns. Region or chromosome splits hold out entire genomic regions or chromosomes to assess long-range generalization. Cohort or site splits hold out entire cohorts, sequencing centers, or hospitals to probe robustness across institutions. Time-based splits use earlier data for training and hold out later data to simulate prospective performance and account for temporal drift.\nEach strategy targets specific forms of leakage and confounding. Unfortunately, many benchmarks rely on random individual-level splits that allow information leakage across families, loci, or cohorts.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A figure comparing different splitting strategies (random individual, family-aware, locus-level, chromosome, cohort, time-based) and highlighting which leakage pathways each prevents would be instructive. Consider a timeline or schematic genome diagram with color-coded splits.\n\n\n\n\n21.6.2 Overlap and Indirect Leakage\nLeakage need not be explicit. A few common patterns in variant effect prediction and risk modeling include variant overlap across resources, where variants used for training may also appear in external benchmarking datasets (for instance, ClinVar variants used during model development, then again in downstream evaluation), even if the exact label is not reused. Relatedness across splits allows close relatives of test individuals to appear in the training set, letting models memorize segments of the genome and inflate apparent performance on rare variants. Knowledge-base pretraining occurs when models pre-trained on resources like gnomAD allele frequencies or UK Biobank genotype–phenotype associations (Karczewski et al. 2020; Bycroft et al. 2018) are later evaluated on benchmarks built from the same data without explicitly acknowledging that this constitutes leakage.\nThese issues are particularly acute for community benchmarks that reuse widely popular variant sets. Without rigorous deduplication and splitting at the locus or individual level, performance may primarily reflect memorization.\n\n\n\n\n\n\nNote\n\n\n\nCase study suggestion: An example of benchmark leakage in a variant effect prediction task, illustrating how deduplicating variants across training and benchmark sets causes a noticeable drop in AUC, would reveal prior over-optimism and make the concept concrete.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#manifestations-of-confounding-in-genomic-models",
    "href": "p5-ch21-confound.html#manifestations-of-confounding-in-genomic-models",
    "title": "21  Confounders in Model Training",
    "section": "21.7 Manifestations of Confounding in Genomic Models",
    "text": "21.7 Manifestations of Confounding in Genomic Models\nHow can we tell when confounding is driving performance?\nSome common signatures include performance gaps across subgroups, where models exhibit high overall performance but much worse metrics in under-represented ancestry groups, sequencing centers, or time periods. Prediction–confounder correlation occurs when model outputs are strongly correlated with ancestry PCs, batch indicators, or recruitment site, even after conditioning on the label. Performance collapse under cohort or time-based splits happens when models that perform well under random splits show sharp degradation when evaluated on held-out cohorts or later time windows. Simple confounder-only baselines performing comparably means that logistic regression on ancestry PCs, batch IDs, or site indicators alone achieves performance close to that of a complex model.\nThese signatures are not proofs of confounding, but they are red flags that should trigger deeper investigation.\nFor genomic foundation models, additional manifestations include token and embedding structure dominated by confounders, where sequence or variant embeddings cluster by ancestry or batch rather than by biological similarity. Contextual embeddings may track institutional labels, with models fine-tuned on EHR-linked genomics encoding institutional coding practices more strongly than underlying phenotypes.\nThe key lesson is that good performance on a single benchmark, especially with random splits and without subgroup analysis, is insufficient evidence that a model has learned robust, biologically meaningful patterns.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#diagnostics-and-sanity-checks",
    "href": "p5-ch21-confound.html#diagnostics-and-sanity-checks",
    "title": "21  Confounders in Model Training",
    "section": "21.8 Diagnostics and Sanity Checks",
    "text": "21.8 Diagnostics and Sanity Checks\nBecause confounding is often subtle, we need systematic diagnostics.\n\n21.8.1 Baseline Models Using Confounders Only\nAn essential check is to train simple models using only potential confounders. This includes logistic regression on ancestry PCs and basic covariates, gradient boosting trees on technical variables (batch, sequencing center, capture kit), and models using only cohort or site indicators.\nIf these baselines approach the performance of complex genomic models, a substantial portion of the signal is likely driven by confounding. Reporting these baselines alongside genomic models makes hidden shortcuts more visible.\n\n\n21.8.2 Subgroup Performance and Calibration\nPerformance should be reported stratified by ancestry or population group, sequencing center or platform, cohort, institution, or country, and time period.\nThis includes both discrimination metrics (AUC, precision–recall) and calibration diagnostics. Poor calibration or systematic over- or under-prediction in specific subgroups often reveals confounding or distribution shift.\n\n\n21.8.3 Prediction–Confounder Association\nPlotting model predictions against potential confounders can be revealing. Look for correlations between predicted risk and ancestry PCs after adjusting for true status, differences in mean predicted risk across batches, sites, or time periods within the same label class, and association tests using regression or mutual information between predictions and confounders.\nStrong residual associations indicate that the model is encoding confounders beyond what is needed to predict the label.\n\n\n21.8.4 Split Sensitivity Analyses\nVarying the splitting strategy is a powerful diagnostic. Re-evaluate performance under locus-level or chromosome-level splits, hold out entire cohorts, sites, or time windows, and exclude families or closely related individuals from test sets.\nLarge drops in performance under stricter splits suggest that initial results were inflated by leakage or confounding.\n\n\n21.8.5 Negative Controls and Perturbations\nFinally, negative controls and simple perturbations can help. Use outcome labels known to be unrelated to genomics as negative controls; good performance suggests confounding. Randomize labels within batches or ancestry strata and confirm that models cannot achieve meaningful performance. Remove suspected confounder variables (when explicitly present) or residualize features and compare performance.\nThese diagnostics do not remove confounding, but they help quantify its impact and guide mitigation efforts.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#mitigation-strategies",
    "href": "p5-ch21-confound.html#mitigation-strategies",
    "title": "21  Confounders in Model Training",
    "section": "21.9 Mitigation Strategies",
    "text": "21.9 Mitigation Strategies\nNo mitigation strategy is perfect, and trade-offs between bias, variance, and coverage are inevitable. Nonetheless, several practical approaches can substantially reduce confounding.\n\n21.9.1 Study Design and Cohort Construction\nGood design beats clever modeling. Match cases and controls on age, sex, ancestry PCs, and recruitment site where possible to reduce confounding by these factors. Use balanced sampling to down-sample dominant groups or up-sample under-represented groups within mini-batches to prevent models from over-relying on majority patterns. For new studies, plan recruitment prospectively to ensure diversity across ancestries, institutions, and environments.\nMatched designs and balanced sampling reduce the incentive for models to use confounders, though they may limit effective sample size.\n\n\n21.9.2 Covariate Adjustment and Residualization\nExplicitly modeling confounders can help. Include ancestry PCs, batch indicators, or site variables as covariates in regression or generalized linear models. Residualize phenotypes with respect to known confounders before training genetic models, while being cautious not to remove genuine biological signal. Use mixed models or hierarchical structures to model institution or batch as random effects.\nThese approaches are well-established in GWAS and can be adapted to genomic foundation model pipelines.\n\n\n21.9.3 Domain Adaptation and Invariance\nMore advanced approaches aim to learn representations that are invariant to confounders. Adversarial training involves training a feature extractor such that a discriminator cannot recover batch, site, or ancestry labels from the learned representation, promoting invariance. Domain adaptation uses techniques such as domain adversarial networks or importance weighting to align distributions across batches or cohorts. Group-robust optimization optimizes worst-group performance (for instance, worst-ancestry AUC) rather than average performance, encouraging robust models.\nThese methods are not a substitute for careful design, but they can reduce reliance on confounders when distribution alignment is feasible.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A small schematic illustrating adversarial domain adaptation for batch correction (encoder → predictor and encoder → batch discriminator, with gradient reversal on the discriminator branch) would clarify this technique.\n\n\n\n\n21.9.4 Data Curation and Benchmark Design\nMitigation also depends on how we build benchmarks and curate datasets. Deduplicate individuals, families, and variants across training, validation, and benchmark sets. Use locus-level or chromosome-level splits in variant effect prediction to avoid memorization of sites. Construct benchmarks that explicitly include diverse ancestries, cohorts, and platforms, rather than reusing a single dominant dataset. Document known overlaps or shared resources between training data and benchmarks, clearly flagging potential leakage.\nThese principles complement the methodological guidance in Chapter 18 and Chapter 19, focusing them on confounding and bias.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#fairness-external-validity-and-causal-thinking",
    "href": "p5-ch21-confound.html#fairness-external-validity-and-causal-thinking",
    "title": "21  Confounders in Model Training",
    "section": "21.10 Fairness, External Validity, and Causal Thinking",
    "text": "21.10 Fairness, External Validity, and Causal Thinking\nConfounding and bias are intimately connected to questions of fairness and external validity.\nModels that primarily serve majority ancestry groups exacerbate health disparities, even if they show excellent overall performance. Biases in ClinVar-like resources and biobank recruitment can lock in historical inequities, with pathogenic variants in under-studied groups remaining poorly characterized (Landrum et al. 2018; Karczewski et al. 2020). Multi-ancestry GWAS and polygenic score studies highlight both the need for broad representation and the difficulty of building models that generalize across ancestries (Ishigaki et al. 2022).\nCausal representation learning aims to separate invariant mechanisms from spurious correlations (Chen 2025). While still an active research area, this perspective is useful: robust genomic foundation models should capture relationships that hold across ancestries, cohorts, and technical platforms, rather than those specific to a single dataset.\nIn practice, this means prioritizing cross-cohort and cross-ancestry evaluation, designing objectives and benchmarks that emphasize out-of-distribution robustness, and being explicit about which populations and settings a model is expected to work in, and where uncertainty remains.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch21-confound.html#a-practical-checklist",
    "href": "p5-ch21-confound.html#a-practical-checklist",
    "title": "21  Confounders in Model Training",
    "section": "21.11 A Practical Checklist",
    "text": "21.11 A Practical Checklist\nTo close, here is a concise checklist to apply when designing, training, and evaluating genomic models.\nPopulation structure and relatedness\n\nQuantify ancestry and relatedness via PCs, kinship estimates, or other appropriate methods.\nDecide whether to match, stratify, or adjust for ancestry and relatedness, and justify that choice.\nReport performance stratified by ancestry and, when relevant, by family structure (for instance, presence of close relatives in the training data).\n\nData splits and leakage\n\nEnsure that individuals, families, and loci do not cross the train–validation–test boundaries for the target tasks.\nConsider stricter splits (locus-level, chromosome-level, cohort- or time-based) to probe for leakage.\nCheck for overlap with external databases or benchmarks used in evaluation and clearly document any shared resources.\n\nBatch, platform, and cohort effects\n\nCatalog technical variables (center, instrument, protocol, assay) and cohort or institution identifiers.\nEvaluate whether these variables align with labels or subgroups of interest.\nUse diagnostics (embeddings, PCs, simple classifiers) to detect batch or cohort signatures and mitigate via design, adjustment, or domain adaptation.\n\nLabel quality and curation bias\n\nUnderstand how labels were defined and what processes (billing codes, expert review, registry inclusion) produced them.\nQuantify label noise where possible, and consider robust training strategies when labels are noisy.\nBe explicit about how curated resources (for instance, ClinVar, functional assay datasets) may reflect historical biases.\n\nCross-group performance and fairness\n\nReport metrics for each major subgroup (ancestry, sex, age, cohort, platform) rather than only overall metrics.\nExamine calibration and error patterns across groups, not just discrimination metrics.\nDiscuss the ethical and clinical implications of residual performance gaps, including whether deployment might exacerbate existing disparities.\n\nReproducibility and transparency\n\nFully document dataset construction, inclusion criteria, and all splitting strategies used.\nRelease code and configuration files for preprocessing, model training, and evaluation where feasible.\nClearly describe which confounders were measured, how they were handled, and what limitations remain.\n\nBy systematically addressing these points, we can move beyond models that merely perform well on convenient benchmarks to models that reveal genuine biology and behave reliably in diverse clinical and scientific settings.\n\n\n\n\nBycroft, Clare, Colin Freeman, Desislava Petkova, Gavin Band, Lloyd T. Elliott, Kevin Sharp, Allan Motyer, et al. 2018. “The UK Biobank Resource with Deep Phenotyping and Genomic Data.” Nature 562 (7726): 203–9. https://doi.org/10.1038/s41586-018-0579-z.\n\n\nChen, Liyin. 2025. “Causal Genomics in the Deep Learning Era.” MDPI AG. https://doi.org/10.20944/preprints202503.2081.v1.\n\n\nHe, Shujun, Baizhen Gao, Rushant Sabnis, and Qing Sun. 2023. “Nucleic Transformer: Classifying DNA Sequences with Self-Attention and Convolutions.” ACS Synthetic Biology 12 (11): 3205–14. https://doi.org/10.1021/acssynbio.3c00154.\n\n\nIshigaki, Kazuyoshi, Saori Sakaue, Chikashi Terao, Yang Luo, Kyuto Sonehara, Kensuke Yamaguchi, Tiffany Amariuta, et al. 2022. “Multi-Ancestry Genome-Wide Association Analyses Identify Novel Genetic Mechanisms in Rheumatoid Arthritis.” Nature Genetics 54 (11): 1640–51. https://doi.org/10.1038/s41588-022-01213-w.\n\n\nKagda, Meenakshi S., Bonita Lam, Casey Litton, Corinn Small, Cricket A. Sloan, Emma Spragins, Forrest Tanaka, et al. 2025. “Data Navigation on the ENCODE Portal.” Nature Communications 16 (1): 9592. https://doi.org/10.1038/s41467-025-64343-9.\n\n\nKarczewski, Konrad J., Laurent C. Francioli, Grace Tiao, Beryl B. Cummings, Jessica Alföldi, Qingbo Wang, Ryan L. Collins, et al. 2020. “The Mutational Constraint Spectrum Quantified from Variation in 141,456 Humans.” Nature 581 (7809): 434–43. https://doi.org/10.1038/s41586-020-2308-7.\n\n\nLandrum, Melissa J, Jennifer M Lee, Mark Benson, Garth R Brown, Chen Chao, Shanmuga Chitipiralla, Baoshan Gu, et al. 2018. “ClinVar: Improving Access to Variant Interpretations and Supporting Evidence.” Nucleic Acids Research 46 (D1): D1062–67. https://doi.org/10.1093/nar/gkx1153.\n\n\nPatterson, Nick, Alkes L. Price, and David Reich. 2006. “Population Structure and Eigenanalysis.” PLOS Genetics 2 (12): e190. https://doi.org/10.1371/journal.pgen.0020190.\n\n\nPrice, Alkes L., Nick J. Patterson, Robert M. Plenge, Michael E. Weinblatt, Nancy A. Shadick, and David Reich. 2006. “Principal Components Analysis Corrects for Stratification in Genome-Wide Association Studies.” Nature Genetics 38 (8): 904–9. https://doi.org/10.1038/ng1847.\n\n\nThe GTEx Consortium. 2020. “The GTEx Consortium Atlas of Genetic Regulatory Effects Across Human Tissues.” Science 369 (6509): 1318–30. https://doi.org/10.1126/science.aaz1776.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Confounders in Model Training</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html",
    "href": "p5-ch22-interp.html",
    "title": "22  Interpretability & Mechanisms",
    "section": "",
    "text": "22.1 Why Interpretability Matters for Genomic Models\nDeep learning models in genomics increasingly operate as systems-level surrogates for biology. They predict chromatin features, gene expression, and variant effects directly from sequence, achieving accuracy that would have seemed implausible a decade ago. When such models drive mechanistic hypotheses or inform clinical decisions, understanding how they make predictions becomes as important as understanding how well they perform.\nInterpretability in this context serves several distinct but interconnected roles. The most scientifically compelling is mechanistic insight: extracting sequence motifs, regulatory grammars, and long-range interaction patterns directly from trained models. A well-designed interpretability analysis can turn a black-box predictor into a source of candidate mechanisms that can be tested experimentally. When a model trained to predict chromatin accessibility learns filters that match known transcription factor binding motifs, this validates that the model has discovered biologically meaningful patterns. When the same analysis reveals novel motif variants or unexpected spacing constraints, it generates hypotheses that extend beyond what was known before training.\nInterpretability also serves as a tool for model debugging and confounder detection. Deep networks can achieve high benchmark accuracy by learning spurious correlations rather than genuine regulatory signals. A model might learn that certain k-mers correlate with peak calls because of batch effects in the training data, or that GC content predicts chromatin accessibility because GC-rich regions tend to be more mappable and thus better covered by sequencing. Interpretability methods can reveal such shortcuts by showing what features the model actually relies upon. This diagnostic function complements the data-level confounder analyses discussed in Chapter 21 by interrogating model internals directly.\nIn clinical and translational settings, interpretability supports variant interpretation workflows by explaining why specific rare or de novo variants are predicted to be damaging. A pathogenicity score alone may be insufficient for clinical decision-making; knowing that a variant disrupts a specific transcription factor binding motif in a disease-relevant enhancer provides interpretable evidence that can be combined with family history, functional assays, and literature review. These adoption barriers extend beyond clinical genomics. A systematic review of machine learning in agricultural genomics found that despite promising benchmark performance, interpretability concerns remain a primary obstacle to real-world deployment in livestock breeding programs, where traditional statistical methods continue to dominate despite their theoretical limitations (Chafai et al. 2023).\nFinally, interpretability enables scientific communication by condensing high-dimensional latent representations into human-readable abstractions. Motifs, regulatory sequence classes, and interaction graphs can be shared across laboratories and applications in ways that raw model weights cannot. A published motif vocabulary derived from a foundation model becomes a reusable resource for the community, even if the original model is computationally expensive to run or subject to access restrictions.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#why-interpretability-matters-for-genomic-models",
    "href": "p5-ch22-interp.html#why-interpretability-matters-for-genomic-models",
    "title": "22  Interpretability & Mechanisms",
    "section": "",
    "text": "Note\n\n\n\nVisual suggestion: Four pillars of interpretability\nA conceptual figure showing four pillars of interpretability for genomics: (1) Mechanistic insight (illustrated with motif discovery), (2) Debugging and confound detection (showing artifact identification), (3) Reliability and clinical translation (variant prioritization workflow), and (4) Scientific communication (motif vocabulary and grammar diagrams). Each pillar could include a small vignette demonstrating its application.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#interpreting-convolutional-filters-as-motifs",
    "href": "p5-ch22-interp.html#interpreting-convolutional-filters-as-motifs",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.2 Interpreting Convolutional Filters as Motifs",
    "text": "22.2 Interpreting Convolutional Filters as Motifs\nConvolutional neural networks remain a workhorse for modeling cis-regulatory sequence, as described in earlier chapters. In many of these models, first-layer convolutional filters act as motif detectors. A filter slides along the one-hot encoded sequence, computing a dot product between its learned weights and the local sequence window at each position. High activation indicates that the subsequence closely matches the filter’s preferred pattern.\n\n22.2.1 From Filters to Motif Logos\nConverting learned filters into interpretable motifs follows a standard workflow. The trained model is run on a large sequence set, typically the training data or genome-wide tiles, and for each filter the positions where its activation exceeds a threshold are recorded. The fixed-length windows around these high-activation positions are then extracted and aligned, and base frequencies at each position are computed to build a position weight matrix. This PWM can be visualized as a sequence logo, where letter heights reflect information content, and compared to known motif databases like JASPAR or HOCOMOCO using similarity scores. Filters that produce PWMs resembling characterized transcription factors can be annotated with candidate TF identities.\nThis procedure has been applied extensively to models like DeepSEA and its successors, demonstrating that early convolutional layers learn motifs for canonical transcription factors and chromatin-associated patterns. Such validation confirms that models are discovering biologically meaningful sequence features rather than arbitrary patterns that happen to correlate with training labels.\nSeveral practical considerations affect filter interpretation. DNA is double-stranded, and filters may learn forward and reverse-complement versions of the same motif. Architectures and analysis pipelines should account for this RC symmetry. Some filters capture technical artifacts such as homopolymer runs or general sequence composition like GC-rich regions. These can be biologically meaningful in contexts such as nucleosome positioning, or purely artifactual. Interpretability must distinguish between them.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Filter-to-motif workflow\nA multi-panel figure showing: (1) A convolutional filter as a small weight matrix, (2) Its activation track along a sequence, (3) Extracted high-activation hits aligned into a PWM, (4) A resulting motif logo aligned against a canonical TF motif from JASPAR. This visualization demonstrates the complete pipeline from learned weights to biological annotation.\n\n\n\n\n22.2.2 Beyond First-Layer Filters\nDeeper convolutional layers aggregate lower-level motifs into more complex representations. These layers can encode combinatorial motifs that respond to pairs or clusters of transcription factor binding sites, grammar patterns involving distance or orientation constraints, and contextual preferences that depend on surrounding sequence composition. However, directly interpreting deeper layers becomes increasingly difficult because receptive fields expand and nonlinearities accumulate. The activation of a deep-layer filter depends on intricate combinations of early-layer patterns, making it hard to summarize what the filter means in simple biological terms.\nIn practice, deeper filters are often interpreted indirectly by examining attribution maps for specific sequences, clustering high-importance subsequences discovered by attribution methods, or analyzing in silico perturbation experiments that probe combinatorial effects of motifs. This motivates the attribution-based approaches described in the next section.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Deeper filter grammar\nA small panel showing: (1) A first-layer motif logo, (2) A deeper-layer grammar filter that responds to pairs of motifs with fixed spacing, (3) A cartoon of how these patterns map to regulatory architecture such as TF cooperativity at enhancers. This could be reused in case study sections to illustrate compositional learning.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#attribution-methods-connecting-bases-to-predictions",
    "href": "p5-ch22-interp.html#attribution-methods-connecting-bases-to-predictions",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.3 Attribution Methods: Connecting Bases to Predictions",
    "text": "22.3 Attribution Methods: Connecting Bases to Predictions\nAttribution methods assign an importance score to each input base, reflecting how much that position contributes to a prediction for a specific task and sequence. If a model \\(f(x)\\) predicts some output from sequence \\(x\\), attribution methods estimate the contribution of each base \\(x_i\\) to \\(f(x)\\), typically for a specific output neuron such as chromatin accessibility in a particular cell type. The resulting attribution maps can reveal which sequence positions drive a prediction, highlighting candidate motifs and regulatory elements.\n\n22.3.1 In Silico Mutagenesis\nIn silico mutagenesis (ISM) is conceptually the most straightforward attribution method and works with any model, regardless of architecture. For each position \\(i\\) and alternative base \\(b\\), ISM creates a mutated sequence \\(x^{(i \\rightarrow b)}\\) and computes the change in prediction: \\(\\Delta f_{i,b} = f(x^{(i \\rightarrow b)}) - f(x)\\). These changes can be aggregated across non-reference alleles to obtain a per-base importance score, typically by taking the maximum or mean absolute change.\nISM provides true counterfactual information about how the model responds to sequence perturbations. Unlike gradient-based methods that estimate local sensitivity, ISM directly measures what happens when a base is changed. This makes ISM the gold standard for faithfulness: if ISM shows that mutating a position changes the prediction, that is a direct observation rather than an approximation.\nThe primary limitation of ISM is computational cost. Scoring all possible single-nucleotide substitutions requires \\(L \\times 3\\) forward passes for a sequence of length \\(L\\), which becomes expensive for long sequences or large models. Variants of ISM can reduce this cost by focusing on specific regions of interest or by using saturation mutagenesis only in targeted windows. For variant effect prediction specifically, ISM reduces to computing the difference between reference and alternative allele predictions, which requires only two forward passes per variant.\n\n\n\n\n\n\nNote\n\n\n\nCode suggestion: Minimal ISM implementation\n# Pseudocode: in silico mutagenesis for a single sequence and output\nref_pred = model(seq)[task_idx]\nism_scores = np.zeros_like(seq_onehot)  # shape: L × 4\n\nfor i in range(L):\n    for b in range(4):\n        if b == np.argmax(seq_onehot[i]):  # skip original base\n            continue\n        seq_mut = seq_onehot.copy()\n        seq_mut[i, :] = 0.0\n        seq_mut[i, b] = 1.0\n        pred_mut = model(seq_mut)[task_idx]\n        ism_scores[i, b] = pred_mut - ref_pred\nThis snippet demonstrates the core ISM loop and can be adapted to any framework.\n\n\n\n\n22.3.2 Gradient-Based Methods\nGradient-based methods approximate how much the prediction would change if each input base were perturbed, using backpropagation rather than explicit perturbation. The simplest approach computes the gradient of the output with respect to the input: \\(s_i = \\partial f(x) / \\partial x_i\\). With one-hot encoding, this gradient can be interpreted as the sensitivity to changing the nucleotide at position \\(i\\). A common variant multiplies the gradient by the input to focus on positions where the current nucleotide (rather than hypothetical alternatives) is important.\nVanilla gradients require only a single backward pass per sequence, making them computationally efficient. However, they are susceptible to gradient saturation, where gradients vanish in regions where the model is already confident. Saturated regions may be functionally important but show near-zero gradients because small perturbations do not change the prediction.\nDeepLIFT (Deep Learning Important FeaTures) addresses saturation by comparing neuron activations between an input and a reference sequence, distributing differences back to inputs using layer-wise rules rather than raw gradients. This approach avoids gradient saturation and enforces a consistency constraint: the sum of input contributions matches the difference in output between input and reference. DeepLIFT has been widely used for genomic models, particularly in conjunction with TF-MoDISco, where its base-level importance scores serve as inputs for motif discovery.\nIntegrated gradients (IG) compute the path integral of gradients along a linear interpolation from a reference sequence \\(x'\\) to the input \\(x\\): \\[\\text{IG}_i(x) = (x_i - x'_i) \\int_{\\alpha=0}^1 \\frac{\\partial f\\left(x' + \\alpha(x - x')\\right)}{\\partial x_i} d\\alpha.\\] This integral is approximated via a Riemann sum over discrete interpolation steps. Integrated gradients satisfy desirable theoretical properties including sensitivity (if changing an input changes the output, that input receives nonzero attribution) and implementation invariance (functionally equivalent networks produce identical attributions). In practice, IG tends to be less noisy than raw gradients.\nAll gradient-based methods require choosing a reference sequence, which significantly affects the resulting attributions. Common choices include random genomic sequence, dinucleotide-shuffled versions of the input that preserve local composition, or an average non-functional sequence. Different references emphasize different aspects of the signal. A shuffled reference highlights features that differ from random sequence with matched composition, while a zero reference treats any informative position as important.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Attribution method comparison\nA multi-panel figure and accompanying table showing: (A) A sequence with a known CTCF motif and its ground-truth binding track, (B) Base-level ISM scores, (C) Gradient × input scores, (D) Integrated gradients scores. The table compares methods across dimensions: computational cost, reference dependency, sensitivity to saturation, robustness to noise, and typical use cases. This provides practitioners with guidance on method selection.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#from-attributions-to-motifs-tf-modisco",
    "href": "p5-ch22-interp.html#from-attributions-to-motifs-tf-modisco",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.4 From Attributions to Motifs: TF-MoDISco",
    "text": "22.4 From Attributions to Motifs: TF-MoDISco\nAttribution maps highlight where the model focuses, but they do not automatically yield consistent motifs or regulatory grammars. A DeepLIFT attribution track might show high importance at scattered positions throughout a sequence without revealing that those positions collectively form instances of the same transcription factor binding site. TF-MoDISco (Transcription Factor Motif Discovery from Importance Scores) was developed to bridge this gap by discovering motifs from attribution scores rather than from raw sequences.\nThe core insight of TF-MoDISco is that operating on importance-weighted sequences rather than raw sequences focuses motif discovery on positions the model actually uses. Traditional motif discovery algorithms applied to regulatory sequences must contend with the fact that most positions are not part of functional motifs. By extracting seqlets (short windows where total importance exceeds a threshold) and clustering them based on both sequence and importance profiles, TF-MoDISco identifies the specific patterns that drive model predictions.\nThe workflow begins by computing importance scores for many sequences using DeepLIFT, ISM, or integrated gradients. Local windows where total importance exceeds a threshold are extracted as seqlets, each representing a candidate motif instance. These seqlets are then compared using similarity metrics that consider both sequence content and the importance score profile, and clustered into groups corresponding to putative motifs. Within each cluster, seqlets are aligned and consolidated into position weight matrices and importance-weighted logos. The resulting motifs can be matched to known transcription factor binding sites or flagged as novel patterns.\nBeyond individual motifs, TF-MoDISco enables grammar inference by analyzing how motifs co-occur within sequences. Mapping motif instances back onto the genome reveals patterns of co-occurrence, characteristic spacing between motif pairs, and orientation preferences. These grammatical rules can be validated through in silico experiments: inserting or removing motifs in synthetic sequences and observing whether predictions change as expected.\nWhen applied to models like BPNet trained on ChIP-seq data, TF-MoDISco has recovered known transcription factor motifs, discovered novel sequence variants, and revealed grammars such as directional spacing constraints that have been validated with synthetic reporter assays. In the context of genomic foundation models, an analogous workflow applies: use the model to produce base-level attributions for a downstream task, run TF-MoDISco to extract a task-specific motif vocabulary, and analyze how motif usage varies across cell types, conditions, or species.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: TF-MoDISco pipeline\nA schematic showing the following stages: (1) Base-level attribution map for a sequence, (2) Highlighted high-importance windows (seqlets), (3) Clustering of seqlets into motif families, (4) Motif logos representing each cluster, (5) A simple grammar diagram showing motif A followed by motif B with preferred spacing. This can be referenced in motif discovery sections elsewhere in the book.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#interpreting-attention-and-long-range-context",
    "href": "p5-ch22-interp.html#interpreting-attention-and-long-range-context",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.5 Interpreting Attention and Long-Range Context",
    "text": "22.5 Interpreting Attention and Long-Range Context\nTransformer-based models use self-attention to mix information across long genomic contexts, enabling them to capture distal regulatory interactions and genomic organization that are invisible to models with narrow receptive fields. Interpretability for these models often centers on attention patterns and long-range attribution, asking which distant positions influence predictions at a given location.\n\n22.5.1 Attention in Genomic Language Models\nGenomic language models (gLMs) trained on prokaryotic genomes treat genes or genomic tokens as elements of a sequence and learn to predict masked tokens, analogous to protein or text language models. Work on gLMs trained on millions of metagenomic scaffolds has shown that these models learn non-trivial genomic structure that can be read out from attention patterns.\nCertain attention heads specialize in connecting genes that are part of the same operon or functional module. When attention weights are visualized as edges between gene positions, they reveal networks of co-regulated genes that often align with known operon boundaries. Other heads capture functional semantics, with attention patterns that cluster genes by enzymatic function or gene ontology category. Still others encode taxonomic signals, separating clades and capturing clade-specific gene neighborhood patterns.\nThese findings suggest that the model has inferred a syntax of gene neighborhoods: which genes tend to co-occur, in what order, and conditioned on phylogenetic context. While attention weights are not universally faithful explanations of model decisions (high attention need not correspond to large causal influence on predictions), attention analysis in genomic language models reveals emergent mechanistic structure that is consistent with known biological organization.\nA critical methodological note: raw attention weights should be interpreted with caution. Work on transformer interpretability in other domains (Consens et al. 2023) has articulated why raw attention maps are not inherently interpretable. Issues include layer mixing effects, value vectors being ignored, and head averaging problems. More robust alternatives include attention rollout (which propagates attention across layers), attention flow (tracking information movement), layer-wise relevance propagation, and SHAP-based methods. For genomic applications, combining attention visualization with attribution methods or perturbation experiments provides more reliable mechanistic insights.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Attention head patterns\nA figure consisting of: (1) A genomic sequence with annotated features such as promoter, enhancer, or operon structure, (2) One or two attention maps for individual heads showing strong, structured connectivity between regulatory elements, (3) A small inset summarizing head specialization statistics (fraction of attention mass connecting enhancer to promoter). This can be cross-referenced in Chapter 17 when discussing multi-omic integration and regulatory networks.\n\n\n\n\n22.5.2 Distal Regulatory Elements in Enformer-Like Models\nEnformer and related architectures (Avsec et al. 2021; Cheng et al. 2024) use convolutional layers and attention to aggregate information over long genomic regions (such as 200 kb windows) and predict many regulatory outputs. Long-range interpretability focuses on questions such as: Which distal regions contribute most to a gene’s predicted expression? Are known enhancers, super-enhancers, or CTCF-mediated loops reflected in contribution scores? How robust are these patterns across cell types and tasks?\nPractical tools include contribution tracks that aggregate base-level or region-level attributions across the input window and visualize them as tracks aligned to genomic coordinates. Peaks in contribution tracks often correspond to putative enhancers or insulators that drive predictions. Region-level perturbations perform in silico deletions of candidate enhancers or CTCF sites and measure the effect on target gene predictions, validating whether long-range connections are actually used by the model. Integration with experimental data compares model-derived contribution tracks to Hi-C, ChIP-seq, and reporter assay data. Concordance suggests that the model’s internal representation aligns with known regulatory architecture; discordance can point to either model failure or previously unannotated elements.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Long-range contributions\nA multi-track genome browser-style figure showing: (1) Input sequence with gene and regulatory annotations, (2) Experimental tracks such as ATAC-seq and ChIP-seq, (3) Model prediction track for a target gene, (4) A contribution track highlighting distal regions whose deletion strongly alters the prediction. This figure can be cross-referenced in Chapter 17 as an example of how single-sequence interpretability interfaces with 3D regulatory models.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#global-regulatory-vocabularies-sei-sequence-classes",
    "href": "p5-ch22-interp.html#global-regulatory-vocabularies-sei-sequence-classes",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.6 Global Regulatory Vocabularies: Sei Sequence Classes",
    "text": "22.6 Global Regulatory Vocabularies: Sei Sequence Classes\nMost motif-based interpretation operates at the local level, asking which motifs appear in a particular sequence and how they contribute to a specific prediction. Sei takes a complementary global approach by learning a vocabulary of regulatory sequence classes that summarize the vast diversity of chromatin profiles across the genome.\nSei trains a deep sequence model to predict tens of thousands of chromatin profiles covering transcription factor binding, histone modifications, and chromatin accessibility across many cell types. The key interpretability step is to compress these thousands of outputs into a few dozen sequence classes, each representing a characteristic regulatory activity pattern.\nSequence classes are derived by clustering genome-wide predictions. For each of millions of genomic positions, Sei computes predicted chromatin profiles and projects them into a lower-dimensional space using principal component analysis. These projections are then clustered to identify recurrent patterns of regulatory activity. The resulting classes include promoter-like patterns enriched for H3K4me3 and TSS proximity, enhancer-like patterns with H3K27ac and H3K4me1, repressive patterns dominated by H3K27me3 or H3K9me3, and cell-type-specific modules corresponding to neuronal, immune, or other lineage-specific regulatory programs.\nEach input sequence or variant can be scored against all sequence classes, effectively mapping it to a point in a low-dimensional regulatory activity space. This representation has several interpretability advantages. Instead of reasoning about thousands of raw chromatin predictions, one can describe a sequence in terms of human-interpretable categories. Variants can be summarized by their shifts in sequence-class scores, yielding concise functional descriptions. GWAS loci can be enriched for specific sequence classes, revealing which tissues and regulatory programs are most relevant to a disease.\nThis notion of a regulatory vocabulary parallels word embeddings or topic models in natural language processing. It provides a bridge between highly multivariate model outputs and mechanistically interpretable axes of variation that can be communicated across studies and applications.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Sequence-class embedding\nA figure showing: (1) A UMAP or t-SNE of sequence features or loci colored by regulatory class (promoter, enhancer, insulator, repressed), (2) Example genomic loci annotated with their class assignments, (3) Example variants mapped as arrows showing movement between classes (such as enhancer to promoter-like). This can be cross-linked to variant interpretation chapters and to Chapter 17 to emphasize multi-scale regulatory modeling.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#a-case-study-from-base-pair-attributions-to-regulatory-grammar",
    "href": "p5-ch22-interp.html#a-case-study-from-base-pair-attributions-to-regulatory-grammar",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.7 A Case Study: From Base-Pair Attributions to Regulatory Grammar",
    "text": "22.7 A Case Study: From Base-Pair Attributions to Regulatory Grammar\nPutting the pieces together, a typical mechanistic interpretability pipeline for a CNN or transformer-based regulatory model proceeds through several connected stages.\nThe starting point is a trained predictive model, for example one that predicts chromatin accessibility or transcription factor ChIP-seq tracks from sequence. For sequences where the model makes confident predictions in a target cell type, base-level attributions are computed using DeepLIFT or integrated gradients. These attributions are fed into TF-MoDISco, which extracts seqlets from high-attribution regions, clusters them, and derives motifs. The resulting motifs are matched to known transcription factors where possible, and novel motifs are flagged for further investigation.\nGrammar inference follows from analyzing motif instances across the full set of high-confidence predictions. Motif co-occurrence patterns reveal which factors tend to operate together. Spacing distributions between motif pairs identify characteristic distances that may reflect cooperative binding or nucleosome constraints. Orientation analysis determines whether certain motif pairs require specific relative orientations to function. In silico knock-in and knock-out experiments confirm these grammatical dependencies: if the model predicts that two motifs must co-occur for high accessibility, deleting either motif from a sequence should reduce the prediction, while inserting both into a neutral background should increase it.\nThe local motif grammar can then be connected to global regulatory context. Motif-rich regions can be mapped to Sei sequence classes to understand what broader regulatory programs they participate in. For transformer-based models, attention patterns or long-range attributions can link local motif clusters to distal elements, revealing enhancer-promoter architectures or chromatin domain boundaries.\nValidation closes the loop by connecting model-derived hypotheses to external evidence. Do motif disruptions align with reporter assay effects or allelic imbalance measured in functional genomics experiments? Do inferred enhancer-promoter links correspond to contacts observed in Hi-C or to effects measured in CRISPR perturbation screens? This integrated approach moves beyond descriptive saliency maps toward testable hypotheses about regulatory logic.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: End-to-end case study\nA multi-panel figure that: (1) Shows an input sequence and predicted TF binding profile, (2) Displays base-level attribution scores, (3) Summarizes discovered motifs as logos, (4) Depicts an inferred regulatory grammar (motif combinations with spacing), (5) Presents a schematic of experimental validation such as mutated motif in a reporter assay. This figure can be referenced whenever the book discusses mechanistic discovery from models, including in later translation chapters.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#evaluating-interpretations-faithfulness-versus-plausibility",
    "href": "p5-ch22-interp.html#evaluating-interpretations-faithfulness-versus-plausibility",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.8 Evaluating Interpretations: Faithfulness versus Plausibility",
    "text": "22.8 Evaluating Interpretations: Faithfulness versus Plausibility\nNot all explanations are equally trustworthy. Effective interpretability work must grapple with the distinction between plausibility (does the explanation look biological?) and faithfulness (does the explanation accurately reflect the internal computation of the model?).\nAn explanation is plausible if it matches prior biological knowledge. Discovering a motif that resembles CTCF is plausible because CTCF is a well-characterized chromatin organizer. Plausibility provides reassuring sanity checks but does not guarantee that the model actually uses the plausible feature. An explanation is faithful if perturbing the identified features changes the model’s output as predicted. If removing a putative CTCF site from a sequence causes the model’s chromatin accessibility prediction to drop, the explanation has some degree of faithfulness.\nSeveral pitfalls complicate the relationship between plausibility and faithfulness:\n\nAttention weights in transformer models need not correspond to large changes in output. High attention may reflect information routing rather than causal influence on predictions. A model might attend strongly to certain positions for bookkeeping purposes without those positions driving the final output.\nGradient-based attribution methods can produce noisy maps or miss important features in saturated regions where gradients are near zero. Comparing multiple methods (ISM, DeepLIFT, integrated gradients) and checking for consistency helps identify robust signals.\nModels may learn shortcut features that produce clean, plausible-looking motifs but are not mechanistically meaningful. A model might learn that certain k-mers correlate with peak calls because of barcode sequences in the training data, or that GC content predicts accessibility because of mappability biases.\n\nRecommended practices for validating interpretations include sanity checks where model weights are randomized (attributions should degrade to noise) or training labels are scrambled (derived motifs should disappear or lose predictive power). Counterfactual tests delete or scramble high-attribution regions to confirm that predictions drop accordingly, or insert discovered motifs into neutral backgrounds to test gain-of-function effects. Benchmarking on synthetic datasets with known ground-truth grammar provides controlled settings where the ability of interpretability methods to recover planted motifs and interactions can be quantified.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Faithfulness versus plausibility\nA simple illustration with: (Left) An attribution map that looks biologically plausible (highlighting a canonical motif) but fails deletion tests (removing highlighted bases barely changes predictions). (Right) An attribution map that passes deletion tests (removing highlighted bases strongly changes predictions), possibly uncovering a less obvious secondary motif. Label the two panels as “plausible but unfaithful” and “faithful explanation” to reinforce the distinction.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#a-practical-interpretability-toolbox",
    "href": "p5-ch22-interp.html#a-practical-interpretability-toolbox",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.9 A Practical Interpretability Toolbox",
    "text": "22.9 A Practical Interpretability Toolbox\nFor practitioners working with genomic foundation models and their fine-tuned derivatives, several interpretability strategies form a practical toolbox.\nLocal effect estimation focuses on individual variants or short sequence windows. For variant effect prediction, comparing reference and alternative allele scores provides direct effect estimates, while small-window ISM around variants reveals which nearby positions modulate the effect. Per-base attributions can be aggregated into per-variant or per-motif scores for summary statistics.\nMotif and grammar discovery begins with computing base-level attributions for sequences where the model makes high-confidence predictions. Running TF-MoDISco or similar algorithms builds a motif vocabulary that can be compared across tasks, cell types, or training conditions. Grammar analysis examines motif co-occurrence, spacing, and orientation to infer combinatorial rules.\nGlobal context visualization applies to transformer-based models, where attention patterns can reveal which distant positions the model considers when making predictions at a given location. For hybrid architectures like Enformer, combining long-range attributions with contact maps helps hypothesize regulatory architectures that span tens to hundreds of kilobases.\nRegulatory vocabularies and embeddings use frameworks like Sei to project sequences into interpretable regulatory activity spaces. Clustering variants, enhancers, or genomic regions by their sequence-class profiles reveals shared regulatory programs and enables compact summaries of complex predictions.\nModel and dataset auditing uses interpretability tools to identify reliance on confounded or undesirable features. Cross-referencing with the confounder taxonomy from Chapter 21 helps design deconfounded training and evaluation schemes. If interpretability reveals that a model relies heavily on GC content or batch-specific signals, this diagnoses a problem that evaluation metrics alone might miss.\nHuman-in-the-loop analysis integrates motif and sequence-class outputs into visualization tools such as genome browsers with attribution tracks, motif annotations, and class scores. Domain experts can then iteratively refine hypotheses, identifying patterns that merit experimental follow-up and flagging predictions that seem biologically implausible.\n\n\n\n\n\n\nNote\n\n\n\nTable suggestion: Interpretability toolbox summary\nA compact reference table with rows for common tasks (Variant effect prediction, TF motif discovery, Long-range regulation, Model debugging) and columns for: recommended attribution method(s), global summarization approach, and key evaluation tests. This provides practitioners with a quick-start guide for method selection.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p5-ch22-interp.html#outlook-from-explanations-to-mechanistic-models",
    "href": "p5-ch22-interp.html#outlook-from-explanations-to-mechanistic-models",
    "title": "22  Interpretability & Mechanisms",
    "section": "22.10 Outlook: From Explanations to Mechanistic Models",
    "text": "22.10 Outlook: From Explanations to Mechanistic Models\nInterpretability in genomic deep learning is evolving from post hoc explanation toward model-assisted mechanistic discovery. Foundation models provide rich latent spaces and long-range context that capture regulatory information at unprecedented scale. Attribution and motif discovery tools translate those representations into candidate regulatory grammars that can be tested experimentally. Global vocabularies like Sei’s sequence classes offer interpretable axes spanning thousands of assays, enabling systematic characterization of regulatory programs across the genome.\nAttention analysis in genomic language models reveals emergent gene-level organization, suggesting that models trained on raw sequence implicitly learn operon structure, co-regulation patterns, and phylogenetic context. These findings hint at scalable ways to capture systems-level biology from sequence alone, complementing the multi-omic integration approaches discussed in Chapter 17.\nThe next frontier is to close the loop between interpretability and model development. Insights from interpretability (motifs, grammars, sequence classes) can inform better architectures and training objectives. Experimentally validated grammars can be fed back into models as inductive biases, constraining the hypothesis space to biologically plausible solutions. Evaluation frameworks can measure not only predictive accuracy but also mechanistic fidelity: how well do model-derived hypotheses align with the causal structure of regulatory biology revealed by perturbation experiments?\nSeveral trends point toward this integration:\n\nInterpretability-guided experimental design uses model-derived motifs and grammars to prioritize which sequences to perturb, reducing experimental search space and accelerating mechanistic discovery.\nMulti-scale integration combines attention heads and long-range contribution patterns in Enformer-like models (Avsec et al. 2021; Cheng et al. 2024) with network and systems-level analyses in Chapter 17 to move from single-sequence explanations to global regulatory circuitry.\nFoundation models and emergent structure reveal that genomic language models and multimodal models (sequence plus epigenomics plus 3D structure) encode increasingly sophisticated representations, shifting interpretability from individual features to representation geometry.\nStandardized benchmarks for interpretability will complement predictive performance benchmarks (Chapter 19) by measuring faithfulness and biological utility of explanations through shared tasks and datasets.\n\nIn this sense, interpretability is not merely a diagnostic for black-box models. It is a central tool for turning genomic foundation models into engines of biological discovery, capable of bridging the gap between sequence-level predictions and the mechanistic understanding that underpins robust clinical translation. When a model’s explanations match experimental observations and generate validated predictions, it becomes more than a predictor: it becomes a hypothesis-generating system that accelerates the scientific enterprise.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nChafai, Narjice, Ichrak Hayah, Isidore Houaga, and Bouabid Badaoui. 2023. “A Review of Machine Learning Models Applied to Genomic Prediction in Animal Breeding.” Frontiers in Genetics 14 (September). https://doi.org/10.3389/fgene.2023.1150596.\n\n\nCheng, Wenduo, Zhenqiao Song, Yang Zhang, Shike Wang, Danqing Wang, Muyu Yang, Lei Li, and Jian Ma. 2024. “DNALONGBENCH: A Benchmark Suite For Long-Range DNA Prediction Tasks,” October. https://openreview.net/forum?id=opv67PpqLS.\n\n\nConsens, Micaela E., Cameron Dufault, Michael Wainberg, Duncan Forster, Mehran Karimzadeh, Hani Goodarzi, Fabian J. Theis, Alan Moses, and Bo Wang. 2023. “To Transformers and Beyond: Large Language Models for the Genome.” arXiv. https://doi.org/10.48550/arXiv.2311.07621.",
    "crumbs": [
      "Part V: Evaluation and Reliability",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Interpretability & Mechanisms</span>"
    ]
  },
  {
    "objectID": "p6--translation.html",
    "href": "p6--translation.html",
    "title": "Part VI — Translation and Application",
    "section": "",
    "text": "The preceding parts of this book have traced the development of genomic foundation models from their architectural foundations through the challenges of reliable evaluation and interpretation. We have examined how convolutional networks learn sequence-to-function mappings, how transformers capture long-range dependencies and emergent representations, and how multi-omic integration extends these capabilities to systems-level biology. We have also confronted the reliability concerns that shadow this progress: confounders that inflate apparent performance, calibration failures that undermine clinical utility, and interpretability gaps that complicate mechanistic claims.\nPart VI turns from methods to practice. The question shifts from how these models work to how they are used, and from what they can predict to what they enable us to do. This transition is not merely practical but conceptual: deploying a model in a clinical or industrial setting exposes assumptions that benchmarks leave implicit and reveals failure modes that curated evaluations obscure.\nThe five chapters in this part span the major application domains where genomic foundation models are reshaping practice. 23  Clinical Risk Prediction examines clinical risk prediction, where foundation model features combine with electronic health records and traditional risk factors to stratify patients for disease, progression, and treatment response. The discussion emphasizes calibration, uncertainty quantification, and fairness considerations that are essential when predictions inform medical decisions and resource allocation. 24  Pathogenic Variant Discovery focuses on variant interpretation in rare disease and cancer, where models enter diagnostic pipelines alongside clinical geneticists and laboratory scientists, and where the stakes of misclassification are measured in missed diagnoses and inappropriate interventions. 25  Drug Discovery & Biotech explores drug discovery and biotechnology, where genomic foundation models contribute to target identification, genetic validation, biomarker development, and the broader industrial ecosystem that translates genetic insights into therapeutics. 26  Sequence Design reverses the direction of inference, moving from prediction to generation: how foundation models guide protein engineering, regulatory element design, and the emerging field of programmable biology. Finally, 27  Future Work & Ethics steps back to consider open problems and responsible development, from technical challenges in generalization and robustness to ethical questions about equity, consent, and the governance of increasingly powerful genomic AI.\nA thread running through these chapters is the gap between benchmark performance and real-world utility. Models that achieve impressive metrics on held-out test sets may falter when deployed on populations underrepresented in training data, when integrated into workflows designed around different assumptions, or when their outputs must be communicated to clinicians, patients, and regulators who lack the technical background to interpret confidence intervals and attribution scores. Closing this gap requires not only better models but also better infrastructure for validation, monitoring, and human oversight. It requires attending to the social and institutional contexts in which genomic predictions are produced and consumed.\nThe goal of Part VI is not to provide definitive protocols for each application domain, since such protocols would be obsolete before publication in a field moving this rapidly. Instead, the aim is to develop a framework for reasoning about deployment: what questions to ask when evaluating a model for clinical use, what pitfalls to anticipate when integrating foundation model outputs into existing pipelines, and what principles should guide responsible development as these tools become more powerful. Readers who have worked through the earlier parts of this book should be well positioned to engage critically with new applications as they emerge, recognizing both the genuine capabilities and the persistent limitations of genomic foundation models in practice.",
    "crumbs": [
      "Part VI — Translation and Application"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html",
    "href": "p6-ch23-clinical.html",
    "title": "23  Clinical Risk Prediction",
    "section": "",
    "text": "23.1 From Polygenic Scores to Foundation Model-Enabled Risk\nModern genomic foundation models provide increasingly rich representations of DNA, RNA, proteins, and multi-omic context. The preceding parts of this book have traced how these models learn from sequence and structure, predict molecular functions, and integrate information across biological scales. The natural next question is practical: how do we turn these representations into actionable predictions for individual patients?\nThis chapter focuses on clinical risk prediction and decision support, the task of estimating the probability, timing, or trajectory of outcomes such as incident disease, progression, recurrence, or adverse drug reactions. The discussion emphasizes how genomic foundation models and related deep learning approaches extend traditional polygenic scores with richer sequence-based features and epistatic structure through methods like Delphi, G2PT, and MIFM (Georgantas, Kutalik, and Richiardi 2024; Lee et al. 2025; Rakowski and Lippert 2025). These models combine genomic features with electronic health records and multi-omics to produce holistic patient-level risk representations, building on the systems-level integration strategies introduced in Chapter 17. Throughout, the emphasis is on evaluation, calibration, uncertainty quantification, fairness considerations, and the practical realities of clinical deployment.\nThe chapter concludes with case studies in cardiometabolic risk, oncology risk and recurrence, and pharmacogenomics, illustrating how foundation models move from computational representations to clinical utility, followed by a practical checklist for translation teams.\nClassical polygenic risk scores (PRS) aggregate the effects of many common variants into a single number for a given disease, typically derived from genome-wide association studies (GWAS) and validated in held-out cohorts. As discussed in Chapter 3, PRS have demonstrated that common variants contribute substantial risk for conditions such as coronary artery disease, breast cancer, and type 2 diabetes. However, traditional PRS face several limitations: they rely on linear models that cannot capture epistatic interactions, they perform poorly in non-European ancestries due to training data bias, and they reduce the entire genome to a single scalar that provides little mechanistic insight.\nGenomic foundation models change this landscape in several ways. First, they provide richer genomic representations beyond simple linear combinations of effect sizes. Instead of relying solely on GWAS summary statistics, foundation models can encode sequence context, chromatin state, and three-dimensional genome features into high-dimensional embeddings that capture non-linear interactions and context-dependent effects. Second, they enable task-agnostic pretraining with task-specific adaptation. A single pretrained model can support many downstream clinical tasks through fine-tuning or feature extraction, amortizing the cost of large-scale pretraining across multiple applications. Third, they facilitate multi-modal risk models that naturally integrate genomic representations with electronic health records, imaging, and environmental data through the fusion architectures discussed in Chapter 17.\nIn practice, a foundation model-enabled clinical risk system typically consists of one or more pretrained models generating variant-level or region-level embeddings, optional aggregation across the genome at the gene, pathway, or genome-wide level, and a downstream predictor that maps embeddings plus clinical covariates to risk scores or survival curves. This modular design separates the foundation model backbone from clinical prediction heads, enabling updates to either component while maintaining clear interfaces for validation and regulatory compliance.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#problem-framing-what-is-clinical-risk-prediction",
    "href": "p6-ch23-clinical.html#problem-framing-what-is-clinical-risk-prediction",
    "title": "23  Clinical Risk Prediction",
    "section": "23.2 Problem Framing: What Is Clinical Risk Prediction?",
    "text": "23.2 Problem Framing: What Is Clinical Risk Prediction?\nClinical risk prediction is the task of mapping patient data to probabilistic statements about future outcomes. Critically, these predictions must be tied to actionable decisions rather than statistical association alone. The inputs include genotypes, family history, clinical measurements, imaging, and environmental factors. The outputs are probabilities or hazard estimates that answer specific clinical questions: What is this patient’s 10-year risk of coronary artery disease if treated with standard of care? Given current tumor characteristics and therapy, what is the hazard of recurrence within two years? If we start this medication, what is the probability of a severe adverse drug reaction in the next six months?\nFor a foundation model-based risk tool to achieve clinical adoption, you must explicitly define the outcome (incident disease, exacerbation, hospitalization, mortality, or composite endpoint), the time horizon (one-year versus 10-year risk, or lifetime risk), the target population (inclusion and exclusion criteria, age range, ancestry distribution, care setting), and the intended use case (screening, triage, preventive intervention targeting, treatment selection, or prognosis). Risk models are more likely to be adopted when they map to concrete actions such as intensifying screening programs, starting preventive therapies, tailoring surveillance frequency, or prioritizing patients for genetic counseling.\nThese questions fall into several archetypes that differ in their temporal structure and clinical context. Individual-level incident risk concerns whether a currently disease-free individual will develop disease within a specified time window, such as 10-year type 2 diabetes risk. Progression and complication risk asks which patients with an existing condition will develop complications, for example nephropathy in diabetes or heart failure after myocardial infarction. Prognosis and survival involve time-from-baseline to events such as death, recurrence, or transplant, often with censoring and competing risks that complicate standard regression approaches. Treatment response and toxicity prediction concerns whether a patient will benefit from one therapy versus another and their risk of severe toxicity or adverse drug reactions.\nGenomic foundation models enter these problems as feature generators. They transform raw genomic and multi-omic data into structured embeddings, variant effect scores, or region-level functional annotations that can then be combined with clinical covariates in downstream prediction models. Real-world deployment typically requires fusing genomic features with electronic health records, imaging, and other omics, mirroring the multi-omics integration strategies discussed in Chapter 17.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#feature-sources-for-clinical-prediction",
    "href": "p6-ch23-clinical.html#feature-sources-for-clinical-prediction",
    "title": "23  Clinical Risk Prediction",
    "section": "23.3 Feature Sources for Clinical Prediction",
    "text": "23.3 Feature Sources for Clinical Prediction\nThe features that enter clinical risk models can be organized into three broad categories that draw on different parts of the foundation model landscape.\nThe first category comprises genomics and regulatory features derived from DNA-level models. Zero-shot variant scores from DNA foundation models such as Nucleotide Transformer, HyenaDNA, and GPN provide sequence-based predictions of variant deleteriousness without requiring trait-specific training (Dalla-Torre et al. 2023; Nguyen et al. 2023; Benegas, Batra, and Song 2023). Coding variant scores from protein language models, including systems similar to AlphaMissense (discussed in earlier chapters), capture the impact of missense mutations on protein structure and function. Fine-mapped causal variant probabilities from methods like MIFM provide posterior estimates of which variants within a GWAS locus are likely causal, allowing risk models to weight variants by their evidence for causality rather than treating all associated variants equally (Rakowski and Lippert 2025).\nThe second category encompasses multi-omics and systems context features. Cell-type-resolved epigenomic and transcriptomic embeddings from frameworks like GLUE, SCGLUE, and CpGPT capture regulatory state across chromatin accessibility, methylation, and expression (Cao and Gao 2022; Camillo et al. 2024). Rare-variant burden and pathway-level representations from DeepRVAT aggregate the predicted effects of multiple rare variants into gene-level or pathway-level impairment scores (Clarke et al. 2024). Tumor-level representations from models such as SetQuence and SetOmic, or from graph neural network-based cancer subtypers, encode the complex mutational landscapes of individual tumors (Jurenaite et al. 2024; X. Li et al. 2022; H. Li et al. 2024).\nThe third category includes clinical covariates and electronic health record data. Demographics, vitals, laboratory results, and medication history provide non-genomic risk factors that often have substantial predictive power. Problem lists, procedures, and imaging-derived features add diagnostic context. Time-varying trajectories of biomarkers such as estimated glomerular filtration rate, hemoglobin A1c, or tumor markers capture disease dynamics that static snapshots miss.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#fusion-architectures",
    "href": "p6-ch23-clinical.html#fusion-architectures",
    "title": "23  Clinical Risk Prediction",
    "section": "23.4 Fusion Architectures",
    "text": "23.4 Fusion Architectures\nArchitecturally, risk models that combine these feature sources typically adopt one of the fusion strategies echoed from Chapter 17, each with distinct tradeoffs.\nEarly fusion concatenates foundation model-derived genomic embeddings with static clinical covariates and feeds them into a single model such as a multilayer perceptron or survival regression. This approach is simple to implement and allows the model to learn arbitrary interactions between genomic and clinical features. However, early fusion is sensitive to differences in scale between modalities, handles missing data poorly since samples lacking one modality must be imputed or excluded, and can be dominated by whichever input has the most features or highest signal-to-noise ratio.\nIntermediate fusion trains separate encoders for genomics, electronic health records, and multi-omics that produce modality-specific embeddings. A fusion layer, which might use attention mechanisms, cross-modal transformers, or graph-based integration, then combines these embeddings into a patient-level representation that downstream prediction heads use for risk estimation. Intermediate fusion is often most attractive from a practical standpoint because it allows modularity (foundation model encoders can be swapped as new versions become available) while still enabling cross-modal interactions that can capture how genomic risk manifests differently depending on clinical context.\nLate fusion trains independent models for each modality, such as a polygenic score-only model and an electronic health record-only model, then combines their predictions through ensemble methods or a meta-model. This approach is robust to missing modalities since each sub-model operates independently, and it allows each modality to use whatever architecture works best for its data type. However, late fusion may underutilize cross-modal structure since interactions between genomic and clinical features can only be captured at the final combination stage rather than learned jointly.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Schematic comparison of early, intermediate, and late fusion architectures for combining genomic foundation model features with clinical data. Show representative inputs (genotype matrices, EHR features, multi-omic profiles), encoder blocks, fusion mechanisms, and prediction heads. Annotate each with key advantages and limitations for clinical deployment.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#evidence-standards-discrimination-calibration-and-clinical-utility",
    "href": "p6-ch23-clinical.html#evidence-standards-discrimination-calibration-and-clinical-utility",
    "title": "23  Clinical Risk Prediction",
    "section": "23.5 Evidence Standards: Discrimination, Calibration, and Clinical Utility",
    "text": "23.5 Evidence Standards: Discrimination, Calibration, and Clinical Utility\nMany genomic foundation models will initially be developed in research settings, but clinical deployment requires additional evidence beyond what is usually reported in machine learning papers. High performance on held-out test sets is necessary but not sufficient for clinical deployment. Risk models must be discriminative, well-calibrated, robust to distribution shift, and clinically useful in ways that justify the costs of implementation.\n\n23.5.1 Discrimination\nDiscrimination measures how well a model ranks individuals by risk, distinguishing those who will experience an outcome from those who will not. For binary endpoints such as disease occurrence within a fixed time window, the area under the receiver operating characteristic curve (AUROC) summarizes discrimination across all possible classification thresholds. When outcomes are rare, as is often the case for severe adverse drug reactions or specific disease subtypes, the area under the precision-recall curve (AUPRC) is more informative because it is sensitive to how well the model identifies true positives among many negatives. For survival tasks with time-to-event outcomes and censoring, the concordance index (C-index) and time-dependent AUC generalize discrimination metrics to the survival setting.\nStrong discrimination is necessary but not sufficient. A model that ranks patients correctly but systematically overestimates or underestimates absolute risks will lead to inappropriate clinical decisions. For a broader discussion of how discrimination metrics are used across molecular, variant-level, and trait-level tasks, see Chapter 19.\n\n\n23.5.2 Calibration and Risk Stratification\nCalibration asks whether predicted probabilities match observed frequencies. If a group of patients is assigned 20% risk of an event, approximately 20% of that group should actually experience it. Well-calibrated predictions can be taken at face value and used directly for clinical decision-making, whereas miscalibrated predictions mislead clinicians and patients regardless of how good the discrimination is.\nCalibration is assessed through calibration plots that compare predicted risk deciles to observed event rates, statistical tests like the Hosmer-Lemeshow test, and proper scoring rules like the Brier score that combine calibration and discrimination into a single metric. These assessments should be stratified by clinically relevant subgroups such as ancestry, sex, and age, since a model that is well-calibrated overall may be systematically miscalibrated for specific populations.\nFor polygenic score-informed models, calibration is especially important because raw polygenic scores are often centered and scaled rather than calibrated to absolute risk. Mapping a polygenic score to an absolute probability of disease typically requires post-hoc models that incorporate baseline incidence and clinical covariates. Foundation models can shift score distributions as architectures evolve, meaning that recalibration may be required when swapping or updating encoders.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Example calibration plots showing well-calibrated versus miscalibrated risk models, with stratification by ancestry group. Include observed versus predicted event rates across risk deciles, 95% confidence intervals, and annotations highlighting systematic over-prediction or under-prediction in specific subgroups.\n\n\n\n\n23.5.3 Reclassification and Net Benefit\nBeyond discrimination and calibration, clinical utility asks whether using the model will change decisions in a beneficial way. Net reclassification improvement quantifies how many patients are appropriately moved across risk thresholds compared to a baseline model. Decision curve analysis estimates net benefit across a range of risk thresholds, accounting for the relative costs of false positives and false negatives in clinical decision-making. For genomic foundation models, these analyses should demonstrate incremental value over existing tools such as traditional polygenic scores or clinical risk calculators.\n\n\n23.5.4 The Validation Hierarchy\nThe strength of evidence depends critically on validation design. Internal validation through cross-validation or temporal splits within the development cohort is useful but insufficient for clinical deployment due to potential overfitting and subtle leakage, as discussed in Chapter 21. External validation across institutions and ancestries, testing the same model in independent health systems and populations with different ancestry distributions, is essential for assessing robustness and transportability. Prospective observational validation runs the model silently in a live clinical system without influencing care, measuring real-time performance and drift over time. Prospective interventional trials use randomized or quasi-experimental designs to assess whether using the model actually improves patient outcomes, equity, and cost-effectiveness.\nFor most foundation model-based risk tools, regulators, payers, and health systems will expect at least robust external validation and, for high-stakes decisions, prospective evidence. The validation hierarchy reflects increasing confidence in clinical applicability, from internal studies that establish proof of concept to prospective trials that demonstrate real-world benefit.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Validation hierarchy ladder showing progression from internal cross-validation through external multi-site validation (with diverse ancestries) to prospective trials and post-deployment monitoring. Overlay annotations showing where most genomic foundation model research currently stops versus what is required for clinical adoption.\n\n\n\n\n23.5.5 Uncertainty Estimation\nIn high-stakes clinical settings, models should know when they do not know. Uncertainty quantification allows models to flag predictions where confidence is low, either because the input is unusual or because the model has limited evidence for its predictions.\nCommon approaches to uncertainty estimation include ensemble variance, where multiple models trained with different random seeds provide prediction intervals based on their disagreement, and Monte Carlo dropout, which approximates Bayesian uncertainty by averaging predictions across multiple stochastic forward passes. Conformal prediction provides a more principled framework for outputting risk intervals or prediction sets with guaranteed coverage under exchangeability assumptions.\nFor foundation model-based systems, uncertainty can be decomposed into genomic uncertainty (confidence in variant effect predictions, fine-mapping probabilities, or embedding reliability) and clinical uncertainty (extrapolation to new care settings, practice patterns, or patient populations). Selective prediction or abstention allows models to decline to make predictions on cases where uncertainty is high or inputs are out-of-distribution, such as patients from rare ancestries missing from training data or novel tumor subtypes that the model has not encountered. Communicating uncertainty transparently is a core component of responsible decision support.\n\n\n23.5.6 Fairness, Bias, and Health Equity\nMany genomic and electronic health record datasets reflect historical and structural inequities in who is genotyped, which populations are recruited into biobanks, and how healthcare is documented and delivered. Risk models can amplify these biases if not carefully evaluated and designed.\nAncestry and polygenic score portability remain central concerns. As discussed in Chapter 3, classical polygenic scores substantially underperform in under-represented ancestries due to the European bias in GWAS design. Foundation model-based methods such as Delphi and G2PT have the opportunity, but not the guarantee, to improve portability by leveraging functional priors and cross-ancestry information (Georgantas, Kutalik, and Richiardi 2024; Lee et al. 2025). Whether they succeed depends on training data composition, evaluation practices, and explicit attention to cross-ancestry performance.\nMeasurement and access bias affect electronic health record features. Which patients get genotyped, which laboratory tests are ordered, how diagnoses are coded, and how thoroughly clinical notes are documented all differ systematically across patient populations, care settings, and health systems. A model trained on one system’s data may encode these institutional patterns rather than underlying biology.\nHealth equity evaluation for foundation model-based tools should include disparity metrics that measure differences in AUROC, calibration, and net benefit across subgroups, along with error rates for high-stakes predictions. Access metrics assess who is eligible to receive the test and whether financial or geographic barriers exist. Outcome metrics evaluate whether clinical actions triggered by the model differ across groups and whether benefits accrue equitably or primarily to already advantaged populations.\nMitigation strategies include reweighting or resampling training data to reduce representation disparities, group-wise calibration and threshold setting to ensure equitable performance, and localized fine-tuning using data from the deployment site with careful attention to overfitting. However, technical interventions alone are insufficient. Non-technical approaches such as expanding sequencing access, subsidizing tests for underserved populations, and designing workflows that fit local constraints are equally essential.\nGroup-wise evaluation is essential. Calibration and discrimination should be assessed separately by ancestry, sex, socioeconomic proxies, and care site. A model that appears well-calibrated overall but is miscalibrated for specific groups will exacerbate rather than reduce health disparities. When necessary, fairness constraints such as equalized odds or affirmative designs targeting historically disadvantaged groups can be incorporated into model training, though such constraints involve tradeoffs with overall performance that must be navigated thoughtfully.\nEquity is not an afterthought. For foundation models, it should inform what data to pretrain on, which benchmarks to report, and how to deploy models in practice.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#clinical-integration-and-deployment",
    "href": "p6-ch23-clinical.html#clinical-integration-and-deployment",
    "title": "23  Clinical Risk Prediction",
    "section": "23.6 Clinical Integration and Deployment",
    "text": "23.6 Clinical Integration and Deployment\nEven a beautifully validated model can fail in practice if it does not integrate into clinical workflows. Clinical genomics already has established pathways for returning results through CLIA-certified laboratories, structured reports, and genetic counseling. Genomic foundation models can augment these pathways in two main ways.\nFirst, they can augment laboratory interpretation by prioritizing variants for manual review (see Chapter 20), providing richer functional annotations such as predicted impact on splicing or chromatin accessibility, and suggesting likely disease mechanisms to support differential diagnosis. Second, they can embed risk predictions directly in the electronic health record by precomputing risk scores for patients with genomic data, surfacing these scores in structured fields or dashboards, and triggering alerts or best-practice advisories when thresholds are crossed.\nDesign choices include whether to use batch versus on-demand computation. Batch computation, such as overnight processing, is often preferable for foundation models because of their computational cost and the relative infrequency of genomic changes. Synchronous alerts at order entry versus asynchronous reports in an inbox represent another choice, as does the requirement for human-in-the-loop review by genetic counselors or specialty clinics before high-impact recommendations reach front-line clinicians.\n\n23.6.1 Software Architecture and Operationalization\nFrom a systems perspective, foundation model-based tools are typically deployed as services with several key components. A secure model-serving endpoint, whether on-premises or in a regulated cloud environment, handles inference requests. Input adapters transform laboratory and electronic health record data into model-ready formats. Output adapters map model outputs to structured concepts or user-facing text. Logging and monitoring infrastructure provides auditing capabilities and drift detection.\nRegulated settings often require versioning of models, data pipelines, and reference genomes, along with audit trails for all predictions returned. Access controls and network segmentation protect genomic data, while validation environments separate from production allow safe testing of updates. For practical details about deployment patterns, hardware considerations, and monitoring stacks, see Appendix B.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: System architecture diagram showing typical hospital deployment with sequencing laboratory and variant calling pipeline on the left, foundation model service (with model registry, feature store, monitoring) in the middle, and EHR with clinician-facing applications (risk dashboards, reports, alert pop-ups) on the right. Show data flows including one-time genomic upload and periodic recomputation, along with governance and approval checkpoints.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#regulatory-and-quality-frameworks",
    "href": "p6-ch23-clinical.html#regulatory-and-quality-frameworks",
    "title": "23  Clinical Risk Prediction",
    "section": "23.7 Regulatory and Quality Frameworks",
    "text": "23.7 Regulatory and Quality Frameworks\nIt is crucial to distinguish between research-only foundation models used for discovery and hypothesis generation, clinical decision support tools that inform diagnosis or management, and in vitro diagnostic devices or laboratory-developed tests that may fall under medical device regulations. Jurisdictions differ in how they regulate AI-based clinical software, but common themes include the intended use and claims made for the tool, risk classification where high-risk tools face stricter oversight than low-risk educational reports, and change management procedures for updating models and retraining.\nRegulators increasingly expect transparent descriptions of model training data and limitations, quantitative performance evidence across relevant subgroups, and plans for post-market surveillance and incident reporting. Beyond formal regulation, health systems often require standard operating procedures for model deployment and decommissioning, model cards and datasheets describing training data and known limitations, validation reports documenting evaluation evidence, and governance structures such as AI oversight committees that review and approve new tools.\nGenomic foundation models introduce additional documentation needs including detailed descriptions of pretraining corpora (which genomes, which assays, from which populations), fine-tuning datasets and label definitions, and procedures for updating to new genome builds, reference panels, or assay types. The modular separation between pretrained encoders and clinical prediction heads can ease regulatory management by allowing updates to either component independently, but this requires clear versioning and compatibility testing.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Summary table of regulatory considerations for foundation model-based clinical decision support systems. Include columns for regulatory framework (FDA, CE marking, others), device classification criteria, validation evidence requirements, post-market surveillance obligations, and considerations for model updates. Annotate with examples of how genomic foundation models might be classified under different frameworks.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#monitoring-drift-and-continual-learning",
    "href": "p6-ch23-clinical.html#monitoring-drift-and-continual-learning",
    "title": "23  Clinical Risk Prediction",
    "section": "23.8 Monitoring, Drift, and Continual Learning",
    "text": "23.8 Monitoring, Drift, and Continual Learning\nClinical deployment is not the end of the story but the beginning of a model lifecycle. Once deployed, foundation models and downstream risk models operate in non-stationary environments. Clinical practice patterns change as new treatments and guidelines emerge. Patient populations drift as screening programs expand or contract. Laboratory assays and sequencing pipelines evolve, introducing subtle distributional shifts in input features.\nMonitoring systems should track input distributions such as genotype frequencies and electronic health record feature patterns to detect when the current patient population differs from the training population. Output distributions including risk score histograms and the fraction of patients above decision thresholds reveal whether model behavior is changing over time. Performance metrics over time, often computed via rolling windows or periodic audits, detect calibration or discrimination degradation before it becomes clinically consequential.\nWhen drift is detected, several responses are possible depending on severity and type. Recalibration may suffice if the model’s ranking behavior remains sound but the mapping from scores to probabilities has shifted. Refitting a calibration layer to current data can restore well-calibrated predictions without retraining the entire model. Partial retraining of prediction heads or fusion layers can adapt to new environments while keeping foundation model weights fixed, preserving regulatory status of the backbone while adjusting to local conditions. Full continual learning, including updating foundation model backbones, requires careful safeguards to avoid catastrophic forgetting (where the model loses performance on previously well-handled cases) and maintain regulatory compliance.\nKey components of post-deployment management include performance monitoring that tracks discrimination, calibration, and case-mix over time with separate evaluation by subgroup to detect emerging disparities. Data and concept drift monitoring watches for changes in laboratory workflows, sequencing technologies, patient populations, and the introduction of new therapies or screening programs that alter outcome incidence. Incident response processes allow clinicians to report surprising or harmful model behavior with root-cause analysis and remediation such as retraining or narrowing intended use. Governance and sunset decisions involve regular reviews by oversight committees and clear criteria for deprecating or replacing models.\nGenomic foundation models complicate this lifecycle because updates to shared encoders can affect many downstream tools simultaneously. This argues for strong versioning and compatibility testing, staged rollouts with canary deployments, and clear communication to clinicians when underlying models change. The modular design patterns from Chapter 17, with clear interfaces between foundation encoders and clinical prediction layers, are crucial for maintainable and updatable decision support systems.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: Model drift monitoring dashboard concept showing temporal trends in input distributions (allele frequencies, clinical feature distributions), output score histograms over time, and performance metrics (discrimination, calibration) with alert thresholds. Include examples of acceptable drift versus actionable degradation requiring intervention.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#interpretability-and-clinician-trust",
    "href": "p6-ch23-clinical.html#interpretability-and-clinician-trust",
    "title": "23  Clinical Risk Prediction",
    "section": "23.9 Interpretability and Clinician Trust",
    "text": "23.9 Interpretability and Clinician Trust\nGenomic foundation models are often perceived as black boxes. In clinical settings, trust depends on more than raw performance. As discussed in Chapter 22, interpretability methods range from simple feature importance to mechanistic model dissection. In clinical translation, you often need “interpretability for action” rather than comprehensive mechanistic understanding.\nFor variant-level predictions, this means highlighting specific variants, motifs, or genomic regions that drive risk. For multi-modal models, it involves showing contributions from genomic versus non-genomic features. For complex predictions, succinct rationales work best, such as “Genomic risk is high due to variants impacting LDL metabolism; clinical risk is elevated due to hypertension and smoking history.”\nCommunicating uncertainty is equally important. Clinically, you must differentiate aleatoric uncertainty (irreducible noise due to biology and measurement) from epistemic uncertainty (model uncertainty due to limited training data, especially in certain subgroups or genomic contexts). Practical strategies include reporting prediction intervals or credible intervals for risk estimates, especially near decision thresholds, flagging cases falling outside the training distribution such as ancestry extrapolation or rare variant patterns not seen during training, and using ensemble methods or Bayesian approaches to quantify epistemic uncertainty.\nHowever, interpretability tools can themselves be misleading. They should be validated for stability and robustness and used to detect model failures such as shortcut learning from ancestry proxies rather than to retroactively justify any prediction. The goal is to provide clinicians with enough transparency to make informed decisions while acknowledging the inherent limitations of post-hoc explanation methods.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#case-studies",
    "href": "p6-ch23-clinical.html#case-studies",
    "title": "23  Clinical Risk Prediction",
    "section": "23.10 Case Studies",
    "text": "23.10 Case Studies\nTo make these ideas concrete, we examine three stylized case studies that build on models and concepts from earlier chapters. Each illustrates different aspects of foundation model integration into clinical risk prediction.\n\n23.10.1 Cardiometabolic Risk Stratification\nThe goal of cardiometabolic risk stratification is to identify individuals at high risk of major adverse cardiovascular events, including myocardial infarction, stroke, and cardiovascular death, over a time horizon such as 10 years. This is among the most mature applications of genomic risk prediction, with established clinical frameworks like the Framingham Risk Score and ASCVD Risk Estimator providing baselines against which genomic augmentation can be evaluated.\nThe inputs for such a model combine genotype data from biobank-scale genotyping or whole-genome sequencing with foundation model features and clinical data. Variant effect scores from DNA foundation models like Nucleotide Transformer, HyenaDNA, and GPN provide sequence-based annotations for variants in cardiometabolic risk loci (Dalla-Torre et al. 2023; Nguyen et al. 2023; Benegas, Batra, and Song 2023). Polygenic models like Delphi or G2PT produce patient-level genomics embeddings tuned for cardiometabolic outcomes (Georgantas, Kutalik, and Richiardi 2024; Lee et al. 2025). Clinical data including age, sex, body mass index, blood pressure, lipids, smoking status, diabetes status, and current medications provide the non-genomic risk factors that drive most of the predictive signal in traditional risk scores.\nA model design for this application might proceed in several stages. First, a DNA foundation model computes variant-level annotations such as predicted enhancer disruption in cardiomyocyte or hepatocyte contexts. Second, these annotations and genotypes feed into Delphi or G2PT to obtain a patient-level genomics embedding tuned for cardiometabolic outcomes. Third, an intermediate fusion network combines the genomics embedding with electronic health record covariates. Finally, the fused representation trains to predict 10-year major adverse cardiovascular event risk using survival or discrete-time hazard losses.\nIn clinical use, such a model would stratify patients into risk categories that inform statin initiation, consideration of PCSK9 inhibitors, or intensive lifestyle intervention. Individual-level explanations, drawing on G2PT attention weights or Delphi variant contributions, would highlight which variants and pathways most contributed to risk, connecting the prediction to interpretable biology. Equity evaluation would ensure that performance and calibration hold across ancestries and care sites, avoiding the portability failures that plague traditional polygenic scores.\n\n\n23.10.2 Oncology: Risk and Recurrence Prediction\nIn oncology, the goal is often to predict recurrence risk and treatment benefit for patients with solid tumors after surgery or first-line therapy. Unlike cardiometabolic risk where germline variants dominate, oncology applications must integrate somatic mutation landscapes with germline background and multi-omic tumor characterization.\nThe inputs combine somatic landscapes from whole-exome or whole-genome tumor sequencing with tumor representations from deep set or transformer architectures such as SetQuence and SetOmic (Jurenaite et al. 2024). Multi-omics profiles of tumor expression, methylation, and chromatin can be integrated through frameworks like GLUE and CpGPT (Cao and Gao 2022; Camillo et al. 2024). Graph neural network-based subtyping from models like MoGCN and CGMega provides embeddings or cluster assignments that capture tumor subtype structure (X. Li et al. 2022; H. Li et al. 2024). Clinical features including stage, grade, performance status, and treatment regimen provide essential prognostic context.\nThe model design encodes somatic mutation sets with SetQuence or SetOmic to obtain tumor-variant embeddings. Transcriptomic and epigenomic profiles integrate via GLUE-like latent spaces and CpGPT methylation embeddings. These combine with graph neural network-based subtype embeddings to capture tumor-microenvironment and histopathological context. The fused tumor-level representations join with clinical features in a time-to-recurrence model using flexible deep survival networks.\nClinical use would provide risk estimates that guide adjuvant therapy decisions, such as intensifying chemotherapy or adding targeted agents for high-risk patients. Candidate biomarkers or pathways identified through foundation model importance scores and attention maps could inform trial stratification. Continuous monitoring would track drift as treatment standards evolve, updating models to reflect new targeted therapies and immune checkpoint inhibitors that change the baseline hazard.\n\n\n23.10.3 Pharmacogenomics and Adverse Drug Reaction Risk\nThe goal of pharmacogenomic risk prediction is to identify patients at high risk of severe adverse drug reactions before initiating therapy. Examples include myopathy on statins, severe cutaneous adverse reactions to certain antibiotics and anticonvulsants, and cardiotoxicity from oncology agents. Some pharmacogenomic associations, such as the HLA-B*5701 association with abacavir hypersensitivity, are well-established and already implemented clinically (Mallal et al. 2008). Foundation models offer the potential to extend such predictions to variants and drugs without established single-gene associations.\nThe inputs include germline variation in pharmacogenes such as the CYP family and HLA alleles, along with variants across the broader genome that might modulate drug metabolism or immune responses. Variant effect scores from both DNA and protein language models provide predictions of how coding and regulatory variants affect drug metabolism and immune genes. Clinical context including co-medications, comorbidities, organ function (particularly liver and kidney), and prior adverse reactions provides essential non-genomic risk factors.\nThe model design uses foundation models to derive mechanistically meaningful features for variants in pharmacogenes, such as predicted impact on protein stability, binding affinity, or gene regulation. These features aggregate across loci into a pharmacogenomic risk embedding, possibly using a G2PT-style transformer restricted to relevant genes (Lee et al. 2025). The genomic embedding combines with electronic health record data in a multi-task classification model that predicts adverse reaction risk for multiple drugs or drug classes simultaneously, sharing representation learning across related prediction tasks.\nClinical use would flag patients at high risk before initiating therapy, prompting genotype-guided drug choice or dose adjustment. Reports would tie risk predictions back to specific variants and pharmacogenes, aligned with existing clinical pharmacogenomics guidelines from organizations like CPIC and PharmGKB. Cross-ancestry evaluation would ensure that the model does not exacerbate existing disparities in access to safe and effective therapy, a particular concern given the European bias in pharmacogenomics research.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch23-clinical.html#practical-checklist-for-translating-foundation-model-based-risk-models",
    "href": "p6-ch23-clinical.html#practical-checklist-for-translating-foundation-model-based-risk-models",
    "title": "23  Clinical Risk Prediction",
    "section": "23.11 Practical Checklist for Translating Foundation Model-Based Risk Models",
    "text": "23.11 Practical Checklist for Translating Foundation Model-Based Risk Models\nTo close, we summarize a pragmatic checklist for teams aiming to translate foundation model-based models into clinical practice. This checklist distills the key considerations discussed throughout this chapter into actionable steps.\nDefine the clinical problem clearly. What decision will change? For whom, and in what setting? What alternative tools exist, and how will this be better? Ensure the outcome, time horizon, target population, and use case are precisely specified and tied to actionable clinical decisions.\nDesign the model with translation in mind. Choose inputs and outputs that can be reliably obtained in routine care. Plan for batch versus real-time inference based on computational constraints and clinical workflow. Consider requirements for latency, compute resources, and interpretability from the outset rather than as afterthoughts.\nBuild robust evidence across the validation hierarchy. Start with rigorous internal validation using appropriate methodology as described in Chapter 19. Progress to external, multi-site validation across diverse ancestries and demographics. Pursue prospective validation and, where feasible, interventional studies that demonstrate actual clinical benefit rather than statistical performance alone.\nAssess equity comprehensively. Evaluate performance and calibration across subgroups defined by ancestry, sex, age, and socioeconomic status. Examine who gets access to the test and who benefits from its use. Implement mitigation strategies for identified disparities and track equity metrics continuously over time.\nPrepare for regulation and governance. Clarify intended use and risk classification early in development. Create comprehensive documentation including model cards, standard operating procedures, and validation reports. Engage regulatory and institutional stakeholders before deployment rather than seeking approval as a final step.\nIntegrate into clinical workflows thoughtfully. Co-design with clinicians, laboratory staff, and patients to ensure the tool fits existing workflows. Prototype interfaces and iterate based on usability testing. Avoid alert fatigue by prioritizing high-value, actionable outputs over comprehensive but overwhelming information displays.\nPlan for monitoring and model updates. Establish metrics and dashboards for ongoing performance monitoring across relevant subgroups. Define clear triggers for investigation and potential retraining. Maintain a model registry with detailed version histories and compatibility testing procedures.\nIf genomic foundation models are to realize their promise in clinical medicine, success will depend less on ever-larger models and more on humble, rigorous translation work: careful problem selection, evidence generation, stakeholder engagement, and vigilant stewardship. The modular design patterns discussed in this chapter, treating foundation models as feature extractors with clear separation from clinical prediction heads, embracing multi-modal fusion, prioritizing calibration and fairness, bridging interpretability and mechanism, and designing for continual learning, provide a framework for responsible deployment.\nIn the broader arc of this book, clinical risk prediction and decision support represent a key translation layer that connects the representational gains of genomic foundation models to the realities of patient care. The next chapters extend these ideas to other application domains: pathogenic variant discovery in rare disease and cancer workflows (Chapter 24), and drug discovery and biotech applications (Chapter 25), further exploring how foundation models reshape translational genomics.\n\n\n\n\nBenegas, Gonzalo, Sanjit Singh Batra, and Yun S. Song. 2023. “[GPN] DNA Language Models Are Powerful Predictors of Genome-Wide Variant Effects.” Proceedings of the National Academy of Sciences 120 (44): e2311219120. https://doi.org/10.1073/pnas.2311219120.\n\n\nCamillo, Lucas Paulo de Lima, Raghav Sehgal, Jenel Armstrong, Albert T. Higgins-Chen, Steve Horvath, and Bo Wang. 2024. “CpGPT: A Foundation Model for DNA Methylation.” bioRxiv. https://doi.org/10.1101/2024.10.24.619766.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus Wahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024. “[DeepRVAT] Integration of Variant Annotations Using Deep Set Networks Boosts Rare Variant Association Testing.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nJurenaite, Neringa, Daniel León-Periñán, Veronika Donath, Sunna Torge, and René Jäkel. 2024. “SetQuence & SetOmic: Deep Set Transformers for Whole Genome and Exome Tumour Analysis.” BioSystems 235 (January): 105095. https://doi.org/10.1016/j.biosystems.2023.105095.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam, Amit R. Majithia, and Trey Ideker. 2025. “[G2PT] A Genotype-Phenotype Transformer to Assess and Explain Polygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai, et al. 2024. “CGMega: Explainable Graph Neural Network Framework with Attention Mechanisms for Cancer Gene Module Dissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and Yunping Zhu. 2022. “MoGCN: A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Analysis.” Frontiers in Genetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nMallal, Simon, Elizabeth Phillips, Giampiero Carosi, Jean-Michel Molina, Cassy Workman, Janez Tomažič, Eva Jägel-Guedes, et al. 2008. “HLA-B*5701 Screening for Hypersensitivity to Abacavir.” New England Journal of Medicine 358 (6): 568–79. https://doi.org/10.1056/NEJMoa0706135.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Clinical Risk Prediction</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html",
    "href": "p6-ch24-variants.html",
    "title": "24  Pathogenic Variant Discovery",
    "section": "",
    "text": "24.1 From Variant Effect Prediction to Prioritization\nClinical genetics ultimately cares about specific variants and genes: which change in this patient, tumor, or cohort is plausibly causal, and what should we do about it? Earlier chapters focused on learning rich sequence representations and predicting molecular readouts such as chromatin accessibility, splicing, and protein stability (Chapter 11; Chapter 12; Chapter 20). This chapter shifts the emphasis from prediction to discovery workflows: how do we move from raw variant calls to ranked lists of variants and genes for follow-up, and where do genomic foundation models (GFMs) make that process more powerful?\nThe central question is: given a huge space of possible variants, which ones should we believe and which should we act on? In practice, the answer emerges from layered pipelines that combine sequencing, population genetics, variant effect prediction, aggregation, network context, and experimental validation. GFMs appear at multiple stages: as variant effect predictors, turning raw sequence variants into functional scores (Chapter 20); as feature providers for gene- and pathway-level models, including deep set architectures for rare variant aggregation (Clarke et al. 2024); as node and edge embeddings in molecular and clinical knowledge graphs (Chandak, Huang, and Zitnik 2023); and as oracles in closed-loop discovery, guiding which variants to perturb or validate next.\nThis chapter walks through these roles, moving from locus-level variant prioritization to association testing, rare disease diagnosis, graph-based gene ranking, and closed-loop discovery systems.\nVariant effect predictors (VEPs) map a candidate variant to one or more predicted consequences: changes in transcription factor binding, chromatin accessibility, RNA abundance, splicing, protein stability, and so on (Chapter 20). GFMs greatly expand the coverage and resolution of these predictions. AlphaMissense provides proteome-wide missense effect estimates (Cheng et al. 2023), while long-range regulatory models like Enformer and Borzoi predict complex cis-regulatory outputs from sequence alone (Ž. Avsec et al. 2021; Linder et al. 2025).\nHowever, clinical and discovery tasks rarely operate on individual variant-assay pairs. Instead, they ask questions like: Which variants in this gene are likely pathogenic under a dominant model? Which regulatory elements near this locus harbor functional variants that could explain the GWAS signal? Which genes or pathways are most likely to drive this tumor subtype? Answering these questions requires several steps that transform raw VEP scores into actionable rankings.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html#from-variant-effect-prediction-to-prioritization",
    "href": "p6-ch24-variants.html#from-variant-effect-prediction-to-prioritization",
    "title": "24  Pathogenic Variant Discovery",
    "section": "",
    "text": "24.1.1 Contextualizing Variant Scores\nA raw variant effect score has very different implications depending on its genetic and clinical context. For allele frequency and constraint, rare variants (especially ultra-rare singletons in gnomAD) with high-effect predictions are much more suspicious in severe early-onset disease than common variants with similar VEP scores. Gene-level constraint metrics such as intolerance to loss-of-function or missense variation modulate how much weight we assign to damaging predictions in that gene. For inheritance models, under a dominant model (such as de novo pathogenic variants in trios), a single predicted-damaging allele may be enough to warrant attention. Under a recessive model, we seek two hits (compound heterozygous or homozygous) with consistent predicted effects. For X-linked or mitochondrial inheritance, dosage and sex-specific considerations further influence interpretation.\nClinical phenotype and penetrance also matter. The same variant effect score is interpreted very differently in a patient with a classic, highly specific phenotype versus a heterogeneous, nonspecific presentation. In complex traits, penetrance is partial and polygenic; VEP scores become one contributor among many rather than a binary decision rule. GFMs do not solve these contextual issues by themselves. Instead, they provide better candidate scores that must be embedded in downstream models explicitly accounting for frequency, inheritance, and phenotype.\n\n\n24.1.2 Aggregating to Genes and Elements\nMost discovery tasks operate at the gene, element, or locus level rather than on individual variants. This requires aggregation. Simple aggregation schemes include max pooling (taking the maximum predicted effect among variants in a gene or element, representing the single worst variant), sum or average pooling (combining effects additively, sometimes weighting by allele frequency or zygosity), and threshold-based counts (counting how many variants exceed a pathogenicity or functional effect threshold).\n\n\n\n\n\n\nNoteFigure: Deep Set Architecture for Rare Variant Aggregation\n\n\n\nA schematic showing a DeepRVAT-style architecture where multiple rare variants in one gene, each with VEP and GFM-derived features, are processed through a permutation-invariant pooling layer (deep set or attention mechanism) to produce a single gene-level risk score.\n\n\nMore sophisticated approaches use deep set and attention pooling. DeepRVAT (Clarke et al. 2024) and related methods treat the set of variants in a gene or region as a permutation-invariant set. Each variant is encoded using VEP and GFM-derived features, a shared network transforms each variant representation, pooling (sum, mean, or attention) aggregates to a gene-level embedding, and a final network outputs a gene-level risk or association score. This architecture naturally handles variable numbers of variants and allows the model to learn which variants in the set matter most.\nFor element-centric aggregation focused on regulatory elements such as enhancers, promoters, and splice junctions, we may first aggregate variants within each element, then propagate scores to target genes using contact maps, enhancer-promoter links, or model-predicted regulatory influence (Chapter 15; Chapter 16). Long-range GFMs such as Enformer and Borzoi can directly predict the change in gene expression induced by combinations of variants in cis (Ž. Avsec et al. 2021; Linder et al. 2025), effectively learning aggregation and regulatory wiring jointly.\n\n\n24.1.3 Combining VEP with Orthogonal Evidence\nVariant effect prediction is rarely used in isolation in modern discovery pipelines. Instead, VEP and GFM scores are combined with orthogonal evidence. Population and familial information includes segregation in pedigrees (de novo status, co-segregation with disease), co-occurrence with other pathogenic variants, and ancestry-matched frequency spectra. Functional genomics and expression data provide co-localization with expression or splicing QTLs, overlap with chromatin accessibility, histone modifications, or 3D genome interactions (Chapter 15), and perturbation data such as CRISPR screens and massively parallel reporter assays. Clinical and literature priors draw from known disease genes and gene-phenotype associations (such as ClinVar and OMIM) and evidence from model organisms or prior case reports.\nGFMs enhance this step by providing richer features such as expression changes across cell types and protein embeddings capturing domain-level context that can be fed into joint models. Knowledge graphs such as PrimeKG (Chandak, Huang, and Zitnik 2023) provide a natural scaffold for integrating these heterogeneous signals.\n\n\n24.1.4 Calibration and Interpretability\nIn prioritization tasks, ranking performance often matters more than perfectly calibrated probabilities: we mostly care that truly pathogenic variants or genes are near the top. Nevertheless, clinicians need approximate probabilities or evidence levels to communicate risk and decide on testing or treatment. Miscalibration can lead to overconfidence in variants with unstable predictions across ancestries or genetic backgrounds (Chapter 21).\nCalibration techniques such as isotonic regression and temperature scaling can be applied to gene- or variant-level scores, often stratified by variant class (missense versus splice versus regulatory). Interpretability matters too. Deep set models can provide attention weights over variants within a gene, highlighting which variants drive the gene-level score. Graph-based models can expose path-level importance, showing which disease-gene-pathway edges contributed most strongly.\nIn short, GFMs provide high-resolution features and predictions; prioritization frameworks turn those into calibrated, interpretable rankings that fit within clinical and experimental constraints.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html#rare-variant-association-and-complex-trait-discovery",
    "href": "p6-ch24-variants.html#rare-variant-association-and-complex-trait-discovery",
    "title": "24  Pathogenic Variant Discovery",
    "section": "24.2 Rare Variant Association and Complex Trait Discovery",
    "text": "24.2 Rare Variant Association and Complex Trait Discovery\nIn the GWAS paradigm discussed in Chapter 3, common variants are tested one at a time, often yielding loci where the actual causal variant and gene are ambiguous. Rare variant association studies (RVAS) flip the perspective: consider many rare variants within a gene or region, aggregate them into a single test statistic per gene or region, and test whether carriers of “damaging” variants are enriched among cases versus controls. Foundation models naturally plug into RVAS because they provide nuanced estimates of how damaging each variant might be.\n\n24.2.1 Burden and Kernel Tests with GFM-Derived Weights\nClassical rare variant methods include collapsing or burden tests, which collapse all “qualifying” variants in a gene into a single indicator or count (for example, does the individual carry at least one damaging variant?). This requires hand-crafted criteria for what counts as damaging (such as predicted loss-of-function or highly deleterious missense). SKAT and related kernel tests model the combined effect of multiple variants using a kernel over genotypes and allow variants to have different directions and magnitudes of effect.\n\n\n\n\n\n\nNoteTable: GFM-Based Variant Effect Prediction Tools\n\n\n\nA comparison table with columns for Method, Variant Type(s), Training Signals, Output, and Key Strengths. Example rows include AlphaMissense (Cheng et al. 2023) for missense variants, GPN-MSA (Benegas et al. 2024) for genome-wide variants, Evo 2 (Brixi et al. 2025) for long-range genomic contexts, and AlphaGenome (Z. Avsec, Latysheva, and Cheng 2025) for multi-omic regulatory predictions.\n\n\nGFMs can supply data-driven weights and qualifiers. They enable using missense or regulatory effect scores as continuous weights, rather than hard thresholds. They allow downweighting variants whose predicted effects are modest or uncertain. They help focus burden tests on variants predicted to perturb regulatory programs in relevant tissues or cell types (such as enhancers active in a disease-relevant cell population). This improves power when many observed variants are benign or mildly deleterious, and it helps harmonize analyses across cohorts with different sequencing depths.\n\n\n24.2.2 Deep Set and Multiple-Instance Models\nDeepRVAT (Clarke et al. 2024) extends traditional RVAS by learning a trait-agnostic gene impairment score from variant annotations using deep set networks. GFMs are a natural provider of such annotations. The input for each individual and gene is a set of variants with GFM-derived features (such as predicted expression changes, splicing disruptions, and protein stability shifts). The model applies a permutation-invariant network to the set, pooling to a gene-level embedding. The output is a gene-level liability or risk score that can be tested against case-control status.\nMultiple-instance learning frameworks such as MIFM (Rakowski and Lippert 2025) push this further by grouping variants into loci or instances and learning to predict which groups harbor causal regulatory variants across many GWAS signals. Here again, regulatory GFMs supply the base features that represent each candidate variant’s mechanistic plausibility.\n\n\n24.2.3 Biobank-Scale Studies and Ancestry Considerations\nAt biobank scale, rare variant association must grapple with heterogeneous ancestries and allele frequencies. Pathogenic variants may be common in one ancestry but absent in another. GFMs trained predominantly on one ancestry may misestimate effect sizes in others (Chapter 21). Coverage and technical artifacts also matter: exome versus genome sequencing, differences in capture kits, and batch effects can induce spurious associations if not carefully modeled.\nGFMs can help and hurt. They enable more precise filtering and weighting, increasing power. But if trained on biased data, they can systematically under- or over-score variants in underrepresented groups. Robust RVAS pipelines therefore treat GFM-derived scores as powerful, but fallible, covariates, and they rely on careful quality control, replication, and sensitivity analyses to ensure that discovered genes withstand scrutiny (Chapter 19; Chapter 21).",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html#mendelian-disease-gene-and-variant-discovery",
    "href": "p6-ch24-variants.html#mendelian-disease-gene-and-variant-discovery",
    "title": "24  Pathogenic Variant Discovery",
    "section": "24.3 Mendelian Disease Gene and Variant Discovery",
    "text": "24.3 Mendelian Disease Gene and Variant Discovery\nFor Mendelian disorders, the goal is often to explain the phenotype of one family or a small number of patients using rare, high-effect variants. Typical pipelines involve sequencing and variant calling (trio whole-exome or whole-genome sequencing with high-quality variant calls and strict filters for depth, quality, and artifacts), frequency and consequence filtering (removing variants too common in population datasets given the disease prevalence and mode of inheritance, focusing on predicted loss-of-function, damaging missense, canonical splice, and high-impact regulatory variants), and gene and phenotype filters (prioritizing genes with known or plausible links to the phenotype through expert-curated gene lists and HPO-based phenotype matching, cross-referencing ClinVar and other knowledge bases for previously reported variants).\nGFMs integrate primarily at the variant and gene scoring stages. Missense and protein-level GFMs such as AlphaMissense (Cheng et al. 2023) and related GFM-based VEPs provide proteome-wide estimates of missense pathogenicity. Incorporating these scores into Mendelian pipelines can de-prioritize previously misclassified variants of uncertain significance (VUS) and highlight novel missense changes with strong predicted impact in constrained genes.\nRegulatory and splicing GFMs can flag variants likely to disrupt critical regulatory elements or splice junctions in noncoding or intronic regions. In disorders with tissue-specific manifestations, cell-type-resolved regulatory predictions are especially informative. For joint scoring of multi-hit genes, some Mendelian disorders involve multiple variants in the same gene (such as compound heterozygotes). Deep set-style aggregation can combine missense and regulatory predictions across hits to estimate the overall probability of gene disruption.\n\n24.3.1 Practical Considerations in Mendelian Settings\nDespite the promise, several caveats are important. Sample size is small: individual families provide limited data, and overfitting to idiosyncratic variants is a risk. GFMs are mostly used as priors, not as stand-alone evidence of causality. Phenotypic heterogeneity is common: many Mendelian genes produce overlapping phenotypes, and relying on phenotype matching alone can mislead. Interpretations should integrate both phenotype and GFM-derived variant scores. Manual review remains essential: expert curation and multidisciplinary case conferences remain the gold standard. GFMs can triage large variant lists to a manageable subset for expert review rather than replacing human judgment.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html#graph-based-prioritization-of-disease-genes",
    "href": "p6-ch24-variants.html#graph-based-prioritization-of-disease-genes",
    "title": "24  Pathogenic Variant Discovery",
    "section": "24.4 Graph-Based Prioritization of Disease Genes",
    "text": "24.4 Graph-Based Prioritization of Disease Genes\nBeyond individual genes, many discovery tasks require reasoning over networks and knowledge graphs: genes interact in pathways; diseases share molecular mechanisms; drugs target proteins that reside in these networks.\n\n24.4.1 Knowledge Graphs and GFM-Derived Features\nResources like PrimeKG (Chandak, Huang, and Zitnik 2023) assemble multimodal knowledge graphs connecting genes and proteins, diseases and phenotypes, drugs, pathways, and molecular functions, and multi-omics signals (expression, methylation, and others).\n\n\n\n\n\n\nNoteFigure: Knowledge Graph Visualization\n\n\n\nA stylized representation of a PrimeKG-like graph structure showing gene nodes, disease associations, pathway membership, and drug-target interactions connected by edges representing protein-protein interactions, co-expression, regulatory relationships, and literature-derived associations. Highlights indicate where GFM-derived features populate node embeddings.\n\n\nGFMs enrich these graphs by providing node embeddings for genes and proteins derived from sequence, structure, or expression patterns; edge features representing interaction strengths or regulatory impacts predicted from sequence (such as variant-to-gene regulatory scores from Enformer-like models (Ž. Avsec et al. 2021; Linder et al. 2025)); and text-derived embeddings for literature and clinical notes (Chapter 7). Graph neural networks (GNNs) operating on these enriched graphs can then learn to propagate disease risk, predict novel disease-gene links, or identify candidate drug targets.\n\n\n24.4.2 Multi-Omics and Single-Cell Graph Models\nSeveral methods illustrate how graph-based approaches and GFMs can be combined. MoGCN integrates multi-omics data into a graph convolutional network to classify cancer subtypes (X. Li et al. 2022). CGMega uses an explainable GNN framework with attention to dissect cancer gene modules (H. Li et al. 2024). GLUE performs multi-omics single-cell data integration and regulatory inference with a graph-linked embedding (Cao and Gao 2022).\n\n\n\n\n\n\nNoteTable: Graph-Based Gene Prioritization Methods\n\n\n\nA comparison table with columns for Method, Graph Type, Input Features (including whether GFM-derived), Primary Task, and Example Applications. Rows include MoGCN (X. Li et al. 2022), CGMega (H. Li et al. 2024), GLUE (Cao and Gao 2022), and classical network propagation methods (without GFMs).\n\n\nIn each case, foundation models can provide initial embeddings for genes and cells (from protein or RNA GFMs) and supply variant- or region-level functional scores that feed into graph construction (such as edges between variants and genes, or between enhancers and promoters). For pathogenic variant discovery, these models allow us to move from “this variant looks damaging” to “this variant is embedded in a network of genes and pathways already implicated in this disease and points toward a specific mechanism or druggable module.”",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html#closed-loop-discovery-foundation-models-perturbation-and-iteration",
    "href": "p6-ch24-variants.html#closed-loop-discovery-foundation-models-perturbation-and-iteration",
    "title": "24  Pathogenic Variant Discovery",
    "section": "24.5 Closed-Loop Discovery: Foundation Models, Perturbation, and Iteration",
    "text": "24.5 Closed-Loop Discovery: Foundation Models, Perturbation, and Iteration\nTraditional discovery pipelines are mostly one-shot: collect data, fit models, test hypotheses, publish results. Closed-loop systems instead iterate. They use existing data to train GFMs and downstream prioritization models, use these models to propose new variants, genes, or regions to investigate, perform targeted experiments (CRISPR perturbations, saturation mutagenesis, reporter assays) to validate or refute predictions, and feed new data back into the models, refining predictions.\n\n\n\n\n\n\nNoteFigure: Closed-Loop Discovery Workflow\n\n\n\nA cycle diagram showing: (1) data flowing into GFM training and fine-tuning, (2) GFM-based variant prioritization generating hypotheses, (3) CRISPR screens, MPRA assays, and tiling screens providing experimental validation, and (4) updated training data feeding back into model refinement, creating a continuous improvement cycle.\n\n\nGFMs are particularly well-suited to this loop because they can generalize from limited experimental data to large variant spaces, incorporate new labeled examples efficiently via fine-tuning (Chapter 7), and provide uncertainty estimates or ensemble variability that can guide which variants are most informative to test next. For example, a regulatory GFM trained on MPRA data might propose noncoding variants with high predicted impact in a disease-relevant enhancer. A CRISPR tiling screen around that enhancer validates a subset of these variants. The new measurements are used to fine-tune the GFM, improving predictions near that locus and for similar regulatory architectures elsewhere in the genome. Over time, such closed loops can create self-improving discovery systems where model predictions and experimental design reinforce each other.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html#case-studies-and-practical-considerations",
    "href": "p6-ch24-variants.html#case-studies-and-practical-considerations",
    "title": "24  Pathogenic Variant Discovery",
    "section": "24.6 Case Studies and Practical Considerations",
    "text": "24.6 Case Studies and Practical Considerations\n\n24.6.1 Case Study A: GFM-Enhanced Rare Disease Diagnosis\nConsider a child with a severe neurodevelopmental disorder and no clear diagnosis after standard testing. Trio whole-genome sequencing identifies tens of thousands of variants. Filtering by quality, allele frequency, inheritance model, and gene panels reduces this to hundreds. Missense variants are scored by a proteome-wide GFM VEP (Cheng et al. 2023); noncoding variants in brain-specific enhancers are scored by a regulatory GFM (Ž. Avsec et al. 2021). A deep set model aggregates these variant scores at the gene level, emphasizing de novo and highly damaging variants in constrained genes (Clarke et al. 2024).\nThe top-ranked gene has biallelic predicted-loss-of-function variants, strong expression in developing cortex, and prior evidence from model organisms and weakly similar human cases. This candidate moves into manual review, targeted functional assays, and potentially clinical reclassification of the variants from VUS to likely pathogenic. GFMs here serve as force multipliers: they compress a large candidate list into a small, interpretable set where human expertise is most effective.\n\n\n24.6.2 Case Study B: Noncoding Driver Discovery in Cancer\nIn cancer genomics, the goal is often to distinguish driver mutations (those conferring a selective advantage) from passenger mutations in noncoding regions. Whole-genome sequencing of tumors identifies many somatic variants in promoters, enhancers, and other regulatory elements. A regulatory GFM predicts the effect of each variant on chromatin accessibility and gene expression in the relevant cancer cell type. Variants are aggregated to elements and genes, weighted by predicted regulatory impact. Graph-based models such as CGMega (H. Li et al. 2024) integrate these scores into multi-omics modules linked to tumor subtypes or outcomes. Elements with high predicted impact and module centrality become candidates for CRISPR perturbation screens.\nThis approach prioritizes noncoding mutations not just by local effect, but by their predicted position in disease-relevant regulatory programs.\n\n\n24.6.3 Practical Pitfalls and Best Practices\nAcross these settings, several practical issues recur. Confounding and batch effects represent a persistent challenge: correlations between technical variables and phenotypes can bias association and prioritization (Chapter 21). GFMs trained on confounded data may internalize and propagate these biases. Ancestry and data shift matter because performance can differ markedly across ancestries or sequencing platforms. Models should always be evaluated and, where possible, recalibrated in the target population (Chapter 19).\nOverreliance on single scores is dangerous. No single GFM score should be treated as definitive. Robust pipelines triangulate across multiple predictors, orthogonal functional data, and biological plausibility. Reproducibility and validation require that variant- and gene-level discoveries be replicated in independent cohorts when possible. Experimental validation, even at small scale (such as focused MPRA or CRISPR screens), dramatically increases confidence.\nA pragmatic view is that GFMs are tools for triage and hypothesis generation, not automatic truth machines. Used wisely, they can save enormous time and highlight non-obvious candidates; used uncritically, they can amplify biases and generate false leads.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch24-variants.html#outlook-towards-end-to-end-discovery-systems",
    "href": "p6-ch24-variants.html#outlook-towards-end-to-end-discovery-systems",
    "title": "24  Pathogenic Variant Discovery",
    "section": "24.7 Outlook: Towards End-to-End Discovery Systems",
    "text": "24.7 Outlook: Towards End-to-End Discovery Systems\nBiomedical discovery of pathogenic variants is gradually moving from manual, stepwise pipelines toward more integrated, end-to-end systems that combine GFMs for sequence, structure, and multi-omics data; aggregation and graph models for variant, gene, and pathway-level reasoning; causal inference tools for distinguishing correlation from mechanism; and active learning loops with high-throughput perturbation experiments.\nIn the long term, one can imagine systems that constantly ingest new genomic, phenotypic, and functional data, update GFM representations and prioritization models on a rolling basis, propose candidate variants and genes for follow-up in specific diseases, and integrate experimental results into improved models, closing the loop. Yet several challenges remain.\nRobustness and generalization require that models handle data shifts, rare ancestries, and out-of-distribution phenotypes without brittle failure. Calibration and uncertainty matter because overconfident but wrong predictions can be more harmful than modest but honest uncertainty. Interpretability and oversight are essential: clinicians, genetic counselors, and experimentalists need mechanisms to interrogate why a variant was prioritized. Ethical and regulatory considerations become central as automated systems play a larger role in diagnostic and therapeutic decisions, raising questions of accountability, fairness, and transparency.\nSubsequent chapters zoom out to drug discovery and target identification (Chapter 25) and then to sequence and protein design (Chapter 26), where many of the same principles reappear. Pathogenic variant discovery is an early and especially high-impact testbed for genomic foundation models. Success here will shape how these models are trusted and deployed across clinical medicine and biology.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. “[Evo 2] Genome Modeling and Design Across All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nChandak, Payal, Kexin Huang, and Marinka Zitnik. 2023. “[PrimeKG] Building a Knowledge Graph to Enable Precision Medicine.” Scientific Data 10 (1): 67. https://doi.org/10.1038/s41597-023-01960-3.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus Wahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024. “[DeepRVAT] Integration of Variant Annotations Using Deep Set Networks Boosts Rare Variant Association Testing.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai, et al. 2024. “CGMega: Explainable Graph Neural Network Framework with Attention Mechanisms for Cancer Gene Module Dissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and Yunping Zhu. 2022. “MoGCN: A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Analysis.” Frontiers in Genetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Pathogenic Variant Discovery</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html",
    "href": "p6-ch25-drugs.html",
    "title": "25  Drug Discovery & Biotech",
    "section": "",
    "text": "25.1 Why Genetics-Driven Drug Discovery?\nModern drug discovery is a race against combinatorial explosion. There are thousands of disease-associated loci, tens of thousands of potential targets, and astronomical numbers of possible molecules. Most candidates will fail, often late and expensively. At the same time, we now have human genetic and multi-omic datasets at a scale that was unimaginable even a decade ago.\nGenomic foundation models offer a way to compress this complexity into reusable representations of molecular biology, and then re-deploy those representations across the drug discovery pipeline. Rather than hand-engineering features for each project, we can increasingly ask: what does the model already know about this locus, gene, pathway, or phenotype, and how can that knowledge guide therapeutic decisions?\nThis chapter focuses on how GFMs built over genomes, transcriptomes, and related modalities connect to drug discovery and target identification. We deliberately do not cover small-molecule or protein design in depth; those are the focus of Chapter 26. Instead, we emphasize how genomic and multi-omic representations inform what to target and where to intervene, rather than how to design the molecule itself.\nPrevious chapters demonstrated how GFMs improve variant effect prediction (Chapter 20), long-range regulatory modeling (Chapter 14, Section 10.1), and disease genetics workflows (Chapter 23, Chapter 24). Here we zoom out to ask: how do these capabilities actually plug into drug discovery and biotech workflows? The focus is on four broad roles. First, target discovery and genetic validation use human genetics, variant-level scores, and gene-level evidence to prioritize safer, more effective targets. Second, network-aware approaches propagate genetic signals through protein and regulatory networks to identify modules and repurposing opportunities. Third, functional genomics and perturbation screens leverage GFMs to design, interpret, and iteratively improve large-scale experiments. Fourth, biomarkers, patient stratification, and biotech infrastructure turn model outputs into actionable signals for trial design while integrating GFMs into industrial platforms.\nThroughout, the aim is not to promise end-to-end AI drug discovery, but to show pragmatic ways that genomic foundation models can reduce risk, prioritize hypotheses, and make experiments more informative, especially when coupled to high-quality human data.\nDrug discovery is traditionally framed as a sequence of steps: target identification, hit finding, lead optimization, preclinical testing, and clinical development. Historically, target identification relied heavily on prior biology (known pathways, curated targets) and opportunistic findings (serendipitous observations, phenotypic screens). Human genetics played a role, but often as a supporting actor.\nOver the past decade, multiple analyses have shown that genetically supported targets are more likely to succeed in the clinic. Targets supported by Mendelian disease genetics, GWAS hits, or functional variants tend to have higher probabilities of success in phase II and III trials compared to targets without genetic evidence. This empirical observation motivates building pipelines where genetic architecture is a first-class input to drug discovery.\nGenomic FMs extend this logic in two ways. First, they provide richer context: instead of simple “variants near gene X,” FMs encode regulatory architecture, chromatin state, 3D genome interactions, cell-type specificity, and perturbation responses. Second, they enable transfer across diseases and modalities: a single model trained on diverse genomic and multi-omic data can be reused for multiple diseases and therapeutic areas, much like text FMs are reused across language tasks.\nThe central question of this chapter, then, is: how do we turn variant- and gene-level representations learned by genomic FMs into actionable hypotheses for targets, indications, and repurposing?",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#where-genomic-fms-plug-into-the-pipeline",
    "href": "p6-ch25-drugs.html#where-genomic-fms-plug-into-the-pipeline",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.2 Where Genomic FMs Plug Into the Pipeline",
    "text": "25.2 Where Genomic FMs Plug Into the Pipeline\nAt a high level, genomic FMs intersect with four stages of the drug discovery process.\nTarget identification and prioritization maps genetic associations to likely causal genes and pathways, then prioritizes targets with strong genetic and mechanistic support. Target validation and mechanism of action uses FMs over perturbation data (CRISPR, RNAi, small molecules) to connect targets to cellular phenotypes and identify convergent pathways and compensatory mechanisms. Indication selection and repurposing embeds diseases, genes, and drug targets in a shared representation space based on genetics, expression, and phenotypes, then matches existing drugs to new indications based on genomic similarity between diseases. Safety, off-target effects, and patient stratification predicts on-target liabilities by linking targets to broad phenotype landscapes (such as PheWAS, biobank traits) and stratifies patients based on genomic signatures that predict response or risk.\nThe canonical small-molecule or biologics pipeline is often summarized as target identification and validation, followed by hit finding and lead optimization, preclinical characterization (covering safety, pharmacokinetics, and toxicology), and finally clinical trials through post-marketing surveillance. Genomics most directly enters at three points along this trajectory. At the earliest stages, human genetic associations from GWAS, rare-variant burden analyses, and somatic mutation landscapes point to potential targets. Later in development, genetic risk scores, regulatory embeddings, and multi-omic signatures define patient subgroups and endpoints for trials. Throughout the pipeline, functional genomics screens and perturbation assays help dissect how a compound perturbs cellular networks.\nOther AI-for-drug-discovery efforts focus on molecular design, docking, or protein structure prediction; those applications are largely beyond the scope of this book. Here we stay close to the DNA- and RNA-centric capabilities developed in earlier chapters: variant effect prediction, regulatory modeling, and multi-omics integration.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A pipeline-style diagram showing the drug discovery stages (target identification, validation, lead optimization, clinical trials) with callout boxes indicating where genomic FMs contribute. Under each stage, annotate which model classes from earlier chapters appear: VEP FMs (Chapter 20), long-range sequence models (Chapter 14), single-cell and epigenomic models (Chapter 15), network models (Chapter 16), and phenotypic/systems FMs (Chapter 17). Include arrows showing information flow and feedback loops.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#target-discovery-and-genetic-validation",
    "href": "p6-ch25-drugs.html#target-discovery-and-genetic-validation",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.3 Target Discovery and Genetic Validation",
    "text": "25.3 Target Discovery and Genetic Validation\nHuman genetics provides some of the strongest evidence that modulating a particular target can safely change disease risk. GFMs do not replace classical statistical genetics, but they provide richer priors and more mechanistic features for identifying and validating targets.\n\n25.3.1 From Variant-Level Scores to Gene-Level Targets\nVariant effect prediction models provide a natural starting point for target discovery. Earlier chapters introduced genome-wide deleteriousness scores such as CADD, which integrate diverse annotations and, more recently, deep and foundation-model features (Rentzsch et al. 2019; Schubach et al. 2024). Protein-centric VEP GFMs including AlphaMissense, GPN-MSA, and AlphaGenome combine protein language models, structure, and long-range context to score coding variants (Cheng et al. 2023; Benegas, Albors, et al. 2024; Z. Avsec, Latysheva, and Cheng 2025; Brandes et al. 2023). Sequence-to-function models such as Enformer and long-context DNA language models (including Nucleic Transformer and HyenaDNA) predict regulatory outputs from large genomic windows (Ž. Avsec et al. 2021; He et al. 2023; Nguyen et al. 2023; Trop et al. 2024).\nDrug target teams rarely care about individual variants per se; they care about genes and pathways. The key move is therefore to aggregate variant-level information into gene-level evidence. A typical workflow for genetics-driven target identification using FMs might look like: start with loci from GWAS or sequencing studies, use statistical fine-mapping to obtain a credible set of variants per locus, then apply sequence-based FMs to score each candidate variant for regulatory or coding impact in relevant cell types. Next, combine FM-based regulatory scores with 3D genome contacts, promoter-capture Hi-C, and enhancer-promoter maps (Chapter 15) to assign variants to genes. Use models that learn variant-to-gene maps directly, for example by training on CRISPR perturbations or eQTL data. Represent candidate genes with embeddings that incorporate both genetic and functional context. Finally, aggregate variant-level information (effect size, FM scores, LD structure) to gene-level probabilities of causality, integrating across traits to identify pleiotropic genes, and overlay druggability features (protein family, structural information, existing ligands, tractability flags).\nFor coding variants, this means summarizing missense and predicted loss-of-function variants in each gene using VEP scores, partitioning variants by predicted functional category (likely loss-of-function versus benign missense, for example) and by allele frequency, then deriving gene-level metrics such as burden of predicted damaging variants in cases versus controls.\nFor noncoding and regulatory variants, the aggregation problem is more complex. Teams can aggregate variant effect predictions on enhancers, promoters, and splice sites that link to candidate genes via chromatin interaction maps or models like Enformer (Ž. Avsec et al. 2021; He et al. 2023). Long-range GFMs connect distal regulatory elements to target loci across distances of 100 kilobases to 1 megabase, enabling attribution of noncoding signals to specific genes.\nConstraint and intolerance metrics provide another dimension. Combining VEP-informed burden with gene constraint measures (as used implicitly in CADD and downstream tools) helps identify genes that are highly intolerant to damaging variation (Rentzsch et al. 2019; Schubach et al. 2024). Extremely constrained genes may be risky targets due to essentiality or toxicity concerns, while dose-sensitive but not lethal genes may present more attractive therapeutic opportunities.\nFrom a GFM perspective, the core idea is to treat gene-level evidence as an aggregation problem over high-dimensional variant embeddings. Instead of manually defining a handful of summary statistics, teams can feed variant embeddings or predicted functional profiles into downstream models that learn which patterns matter most for disease.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A detailed schematic of a GWAS locus showing: (1) the LD structure with multiple correlated variants in a “cloud”, (2) fine-mapping to identify credible causal variants, (3) GFMs scoring individual variants for enhancer disruption, splicing impact, and coding effects, (4) 3D chromatin loop showing enhancer-promoter contact, (5) aggregation to gene-level scores, and (6) candidate target gene with annotations (expression, protein family, existing drugs, druggability metrics). This multi-panel figure would integrate concepts from Chapter 3, Chapter 20, and Section 10.1.\n\n\n\n\n25.3.2 Linking Genetic Evidence to Target Safety and Efficacy\nClassical human genetics has established several now-standard heuristics for target selection. Human knockout individuals carrying biallelic loss-of-function variants provide natural experiments on what happens when a gene is effectively inactivated. Protective variants that reduce disease risk suggest directionality of effect, indicating that partial inhibition of a protein is beneficial rather than harmful. Pleiotropy, meaning associations with many unrelated traits, may signal safety liabilities.\nGFMs reinforce and extend these ideas in several ways. Fine-mapping methods and multiple-instance models like MIFM can distinguish truly causal regulatory variants from correlated passengers (Wu et al. 2024; Rakowski and Lippert 2025). Combining these approaches with regulatory GFMs tightens the map from GWAS locus to variant to target gene. VEP scores from protein and regulatory GFMs can approximate effect sizes, estimating how severe a missense change is or how strongly a regulatory variant alters expression (Cheng et al. 2023; Benegas, Albors, et al. 2024; Z. Avsec, Latysheva, and Cheng 2025). This helps differentiate subtle modulators from catastrophic loss-of-function mutations. Finally, GFMs provide multi-task predictions across chromatin marks, transcription factor binding, expression, and splicing that make it easier to interpret how a risk locus affects biology (Ž. Avsec et al. 2021; Benegas, Ye, et al. 2024).\nIn practice, a target discovery workflow might proceed as follows. Starting from GWAS summary statistics or rare variant analyses, teams apply fine-mapping (such as MIFM) to identify candidate causal variants (Wu et al. 2024; Rakowski and Lippert 2025). They then score candidate variants with VEP GFMs for both protein and regulatory effects, map variants to genes using long-range regulatory models like Enformer, Nucleic Transformer, and HyenaDNA (Ž. Avsec et al. 2021; He et al. 2023; Nguyen et al. 2023), and aggregate signals into gene-level genetic support scores incorporating constraint and pleiotropy information. The result is a ranked list of candidate targets with structured evidence that can be compared across diseases and programs.\n\n\n25.3.3 Evolving from Hand-Curated to Model-Centric Target Triage\nHistorically, target triage relied heavily on manual curation. Experts would review GWAS hits, literature, and pathway diagrams, but limited quantitative information was available for most genes, especially in non-classical pathways. GFMs shift this toward a model-centric, continuously updated view.\nNew data from biobank sequencing or single-cell atlases can be fed through trained GFMs to update variant and gene evidence. The same underlying model suite can support many disease programs, enabling consistent cross-portfolio comparisons. Benchmark frameworks like TraitGym emphasize standardized evaluation of genotype-phenotype modeling, helping teams choose appropriate model stacks for a given trait (Benegas, Eraslan, and Song 2025).\nThe limiting factor becomes less about whether an annotation exists and more about whether teams can interpret the model’s representation and connect it to biological plausibility and druggability. This theme echoes discussions in Chapter 20 and Chapter 22 about the importance of interpretable predictions.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#network-aware-target-discovery-and-repurposing",
    "href": "p6-ch25-drugs.html#network-aware-target-discovery-and-repurposing",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.4 Network-Aware Target Discovery and Repurposing",
    "text": "25.4 Network-Aware Target Discovery and Repurposing\nEven with good variant-to-gene mapping, many genes live in dense networks of interactions. Genomic FMs that operate on networks, pathways, and cell-cell communication (see Chapter 16 and Chapter 17) further refine target hypotheses by propagating genetic signals across protein-protein interaction networks, gene regulatory networks, and metabolic pathways, identifying subnetworks or modules enriched for genetically perturbed genes, and highlighting bottleneck nodes whose modulation could normalize a broader dysregulated module.\nNetwork-based deep learning frameworks have successfully translated GWAS and multi-omics findings into candidate targets and repurposable drugs. For example, network approaches integrate non-coding GWAS loci, regulatory annotations, and protein-protein interactomes to identify disease genes and drug repurposing opportunities in complex diseases. From a foundation-model perspective, the key idea is to treat the network as another modality: nodes (genes, proteins, drugs) and edges (interactions, co-expression, similarity) can be embedded jointly with genomic and transcriptomic features.\nThis enables joint embeddings of genes and drugs in a shared space, proximity-based repurposing where drugs whose targets sit near genetically implicated genes or modules become candidates, and multi-disease comparison where genes or pathways with similar network-level genetic perturbation patterns across diseases can be identified. Deep learning frameworks that combine GWAS, multi-omics, and networks have already demonstrated repurposing potential, such as identifying existing drugs whose targets are enriched near disease-risk genes and observing reduced incidence among users of these drugs in real-world data.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A network diagram showing: (1) GWAS-implicated genes highlighted in color within a protein-protein interaction network, (2) propagation or diffusion of genetic signals across the network to identify enriched modules, (3) drug targets overlaid on the network with proximity connections to disease genes, (4) callout boxes showing specific repurposing candidates with supporting evidence. This could be a schematic rather than real data but should convey the concept of network-based signal propagation and drug-disease matching.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#functional-genomics-screens-and-perturbation-models",
    "href": "p6-ch25-drugs.html#functional-genomics-screens-and-perturbation-models",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.5 Functional Genomics Screens and Perturbation Models",
    "text": "25.5 Functional Genomics Screens and Perturbation Models\nWhile human genetics offers observational evidence, drug discovery also relies heavily on perturbation experiments: CRISPR knockout, knockdown, and activation screens; base-editing or saturation mutagenesis around key domains; MPRA and massively parallel promoter/enhancer assays; and perturb-seq and other high-throughput transcriptomic readouts. Genomic foundation models are well positioned to both design and interpret such screens.\n\n25.5.1 Designing Smarter Perturbation Libraries\nTraditional pooled screens often rely on simple design rules, such as one sgRNA per exon or tiling a region at fixed spacing. GFMs offer richer priors for library design. Variant effect scores from models like AlphaMissense or GPN-MSA can prioritize which amino acid positions are most likely to reveal functional differences when mutated (Cheng et al. 2023; Benegas, Albors, et al. 2024). Regulatory GFMs (Enformer, DeepSEA, Borzoi) can highlight which enhancer or promoter regions are predicted to have the largest expression effects in the cell type of interest (Ž. Avsec et al. 2021; Zhou and Troyanskaya 2015; Linder et al. 2025). Combinatorial designs can use model uncertainty to select perturbations that maximize expected information gain, focusing experimental budget on variants or regions where predictions are least confident.\nThis approach yields more informative libraries: instead of uniformly tiling a locus, teams can oversample positions that models flag as functionally important and undersample positions predicted to have negligible effects.\n\n\n25.5.2 Perturbation-Aware Genomic and Phenomic FMs\nPerturbation datasets (CRISPR screens, RNAi, overexpression libraries, small-molecule treatments) provide rich supervision for connecting genes, drugs, and phenotypes. When we train FMs on these data, we obtain representations that capture the direction and magnitude of gene knockdown/overexpression effects on transcriptomes (bulk or single-cell), the phenotypic consequences of target modulation in specific cell types or disease contexts, and the similarity between genetic and pharmacologic perturbations (such as when a compound’s expression signature resembles knocking down a particular gene).\nThese models enable perturbation matching tasks: given a disease state (for example, a transcriptomic signature from patient tissue), find perturbations (genes or drugs) that move the system toward a healthier state. This is conceptually similar to classical connectivity mapping, but powered by deep, multi-modal representations rather than literal signature overlap.\nHigh-content microscopy and other phenotypic assays generate images of cells under thousands of genetic and chemical perturbations. Phenomic foundation models trained on billions of image crops can learn a representation where perturbations with similar mechanisms of action cluster together, subtle morphological signatures of target engagement become detectable, and gene and drug perturbations share a representation space, enabling cross-modal retrieval (such as finding drugs that phenocopy a particular gene knockdown).\nFor a genomics-focused reader, the key link is: genomic FMs provide prior over biological context (which loci and genes matter); phenomic FMs provide readouts of functional consequences of targeting those genes with molecules. Bridging these two modalities (genotypes and cell images) remains a frontier area.\n\n\n25.5.3 Interpreting Screen Results and Closing the Loop\nAfter running a screen, GFMs help interpret which hits are most biologically meaningful. Embedding-based clustering can group perturbations with similar predicted functional profiles, even if their phenotypic readouts differ due to noise. Learned embeddings help propagate signal to weakly observed genes or variants, providing a form of regularization that improves detection of subtle effects.\nPerhaps the most powerful application is using screen outcomes as labeled examples to fine-tune sequence-to-function models in the relevant cell type or context. This lab-in-the-loop refinement turns generic GFMs into highly tuned models for the cell system of interest. For example, an MPRA that assays thousands of enhancer variants yields sequence-activity pairs that can dramatically improve expression-prediction GFMs in that locus or tissue. Conversely, model predictions can suggest follow-up experiments (additional variants, cell types, or perturbation strengths) that would be maximally informative given previous data. This iterative cycle between computation and experiment accelerates discovery while improving model accuracy in disease-relevant regions of sequence space.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A circular workflow diagram illustrating the lab-in-the-loop concept. Starting with a pre-trained GFM, arrows show: (1) model predicts variant effects to guide library design, (2) CRISPR/MPRA screen generates data, (3) screen results used to fine-tune the model, (4) refined model makes better predictions for next round. Include small data panels showing improved prediction accuracy (for example, correlation between predicted and observed effects) after each iteration.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#biomarker-discovery-patient-stratification-and-trial-design",
    "href": "p6-ch25-drugs.html#biomarker-discovery-patient-stratification-and-trial-design",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.6 Biomarker Discovery, Patient Stratification, and Trial Design",
    "text": "25.6 Biomarker Discovery, Patient Stratification, and Trial Design\nEven when a target is well validated, many programs fail in late-stage trials because the right patients, endpoints, or biomarkers were not selected. GFMs, combined with large cohorts, offer new tools for defining and validating biomarkers.\n\n25.6.1 From Polygenic Scores to GFM-Informed Biomarkers and Disease Embeddings\nClassical polygenic scores (PGS) summarize the additive effect of many common variants on disease risk. Deep learning methods such as Delphi extend this idea by learning non-linear genotype-phenotype mappings directly from genome-wide data (Georgantas, Kutalik, and Richiardi 2024).\nGFMs can enhance these approaches in several ways. Instead of using raw genotypes as input, models can use VEP-derived scores, variant embeddings, or gene-level features produced by GFMs. This captures non-additive effects, regulatory architecture, and variant-level biology in a more compact representation. Foundation models trained across diverse genomes (such as Nucleotide Transformer, GENA-LM, and HyenaDNA) provide features that may generalize more robustly across populations than trait-specific models (Dalla-Torre et al. 2023; Fishman et al. 2025; Nguyen et al. 2023). Fine-mapping-aware approaches like MIFM further reduce dependence on linkage disequilibrium patterns that vary across ancestries (Wu et al. 2024; Rakowski and Lippert 2025).\nBy integrating regulatory and expression predictions, risk models can also distinguish genetic influences on disease onset versus progression, enabling more targeted enrichment strategies for different trial designs. In trial design, such models can enrich for high-risk individuals in prevention trials, define genetic subtypes that may respond differently to the same mechanism, or construct composite biomarkers that mix genetics with conventional clinical features.\nBiobank-scale resources link genotypes to thousands of phenotypes, from ICD codes and lab values to imaging and wearables. By training FMs over these genotype-phenotype relationships, we can embed diseases in a space informed by shared genetic architecture, identify diseases that are neighbors of a target’s genetic profile, and quantify polygenic overlap that might predict cross-indication utility or safety risks.\nFor target selection, these disease embeddings help answer questions such as: Is this target genetically implicated in multiple autoimmune diseases, or is it specific to one? Does the pattern of genetic associations suggest central nervous system involvement (implicating blood-brain barrier challenges and CNS-specific safety)? Are there rare variant syndromes that provide natural experiments for long-term target modulation in humans?\n\n\n25.6.2 Multi-Omic and Single-Cell Biomarker Discovery\nBeyond DNA variation, drug development increasingly leverages multi-omic and single-cell readouts. Whole-genome or exome tumor sequencing can be combined with expression, methylation, and copy-number profiling. Single-cell multiome datasets (RNA plus ATAC) characterize cell-state landscapes in disease (Jurenaite et al. 2024; Yuan and Duren 2025). Microbiome sequencing provides insight into host-microbe interplay and response to therapy (Yan et al. 2025).\nGFMs and related architectures help here in several ways. Set-based and graph-based encoders, such as SetQuence/SetOmic, treat heterogeneous genomic features for each tumor as a set, using deep set transformers to extract predictive representations (Jurenaite et al. 2024). Gene regulatory network inference models such as LINGER leverage atlas-scale multiome data to infer regulatory networks that can serve as biomarkers of pathway activity (Yuan and Duren 2025).\nMulti-scale integration combines DNA and RNA GFMs with graph neural networks over gene and protein networks to build end-to-end predictors that map from genotype plus cell state to clinical endpoints (Gao et al. 2023; Benegas, Ye, et al. 2024). Embeddings from protein language models (such as ESM-2-based variant models) provide additional structure for coding variants (Brandes et al. 2023; Marquet et al. 2024).\nA typical biomarker discovery workflow uses GFMs to generate rich embeddings for patients from tumor genomes, germline variation, or multi-omic profiles. Teams then cluster or perform supervised learning to identify molecular subgroups with differential prognosis or treatment response, validating candidate biomarkers on held-out cohorts or external datasets before deploying them in a trial.\nThe key shift is that biomarkers are no longer limited to a handful of hand-picked variants or expression markers: they become functions over high-dimensional genomic and multi-omic embeddings, learned in a data-driven way yet grounded in biological priors from GFMs.\n\n\n25.6.3 Drug Repurposing and On-Target Safety\nGenomic FMs can generalize repurposing ideas by representing every approved drug via its targets, gene expression signatures, and phenotypic effects, representing diseases via their genetic architecture and omic signatures, and scoring drug-disease pairs based on representation similarity, constrained by mechanism and safety considerations. Crucially, these models are not a replacement for causal inference, but they can prioritize hypotheses that are later tested using Mendelian randomization, natural experiments, and clinical studies.\nThe same representations used for indication selection can flag potential safety issues. If a target is strongly associated with traits like cardiovascular events or QT prolongation across biobank phenotypes, intervention may carry inherent risks. For polypharmacy, embeddings of drugs and targets can highlight overlapping pathways or transporter systems that might amplify adverse effects. Here, the interaction with Chapter 19 and Chapter 21 is important: FM-derived scores can be confounded by indication patterns, healthcare access, and other biases. Genetic instruments and careful epidemiologic designs remain essential for causal claims.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A shared embedding space visualization (schematic UMAP or t-SNE style plot) where each point represents either a disease, a gene, or a drug. Show clusters corresponding to: (1) related diseases colored by therapeutic area, (2) genes colored by pathway membership, (3) drugs colored by mechanism of action. Draw connecting lines or proximity indicators between drugs and diseases with repurposing evidence, and highlight a few specific examples with callout boxes (for example, showing a drug whose targets are proximate to genes implicated in a disease different from its approved indication).",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#biotech-workflows-and-infrastructure-for-gfms",
    "href": "p6-ch25-drugs.html#biotech-workflows-and-infrastructure-for-gfms",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.7 Biotech Workflows and Infrastructure for GFMs",
    "text": "25.7 Biotech Workflows and Infrastructure for GFMs\nFor pharma and biotech organizations, the primary challenge is not whether they can train a big model but how to integrate GFMs into existing data platforms, governance, and decision-making processes.\n\n25.7.1 GFMs as Shared Infrastructure\nIn a mature organization, GFMs should be treated as shared infrastructure rather than ad hoc scripts developed by individual teams. A well-organized model catalog contains DNA language models (such as Nucleic Transformer, HyenaDNA, and GENA-LM), sequence-to-function models (such as Enformer and Genomic Interpreter), and variant effect predictors (AlphaMissense, GPN-MSA, AlphaGenome, CADD v1.7) (He et al. 2023; Nguyen et al. 2023; Fishman et al. 2025; Ž. Avsec et al. 2021; Li et al. 2023; Rentzsch et al. 2019; Schubach et al. 2024; Cheng et al. 2023; Benegas, Albors, et al. 2024; Z. Avsec, Latysheva, and Cheng 2025).\nFeature services provide centralized APIs that take variants, genomic intervals, or genes as input and return embeddings, predicted functional profiles, or risk features. Logging and versioning ensure that analyses can be reproduced even as models and data evolve.\nData governance maintains clear separation between models trained on public data versus sensitive internal cohorts. Guardrails define where internal data can be used for fine-tuning and how resulting models can be shared.\nEmbedding GFMs in this way allows multiple teams across target identification, biomarker discovery, and clinical genetics to reuse the same core representations rather than each building bespoke models.\n\n\n25.7.2 Build Versus Buy Versus Fine-Tune\nOrganizations face three strategic options when adopting GFMs. Using external GFMs as-is offers low up-front cost and benefits from community benchmarking (such as TraitGym for genotype-phenotype modeling), but may not capture organization-specific populations, assays, or traits (Benegas, Eraslan, and Song 2025).\nFine-tuning open-source GFMs on internal data retains powerful general representations while adapting to local data distributions. This approach requires careful privacy controls and computational investment, but often provides the best balance of generality and specificity.\nTraining bespoke internal GFMs offers maximum control and allows alignment of pretraining with available data and target use cases. However, this approach is expensive and requires complex MLOps, with risk of overfitting to narrow datasets if not complemented by broader pretraining.\nIn practice, many groups adopt a hybrid strategy. They start with public GFMs for early exploration and non-sensitive tasks, gradually fine-tune on internal biobank or trial data when added value is clear, and maintain lightweight model-serving infrastructure for latency-sensitive applications like clinical decision support alongside heavier offline systems for large-scale research workloads.\n\n\n\n\n\n\nNote\n\n\n\nVisual suggestion: A decision matrix table comparing the three strategies (Use External, Fine-Tune, Build Internal) across dimensions: initial cost, customization potential, data requirements, compute needs, time to deployment, generalization to new tasks, and risk of overfitting. Color-code cells to show relative advantages and disadvantages of each approach (for example, green for strengths, yellow for moderate, red for weaknesses).\n\n\n\n\n25.7.3 Intellectual Property, Collaboration, and Regulatory Considerations\nGFMs also raise new questions around intellectual property, data sharing, and regulatory expectations. Models trained on proprietary data can be valuable IP assets but are difficult to patent directly. Downstream discoveries (targets, biomarkers) derived from GFMs must be carefully documented for freedom-to-operate analyses.\nJoint training or evaluation across institutions may require federated learning or model-to-data paradigms, especially for patient-level data. For biomarkers used in pivotal trials, regulators will expect transparent documentation of model training, validation, and performance across subgroups. Chapter 21 and Chapter 22 highlight confounding and interpretability challenges that become even more acute when models inform trial inclusion or primary endpoints.\nOverall, leveraging GFMs in biotech is as much an organizational and regulatory engineering problem as a technical one.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#bridging-genomic-fms-to-molecular-design",
    "href": "p6-ch25-drugs.html#bridging-genomic-fms-to-molecular-design",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.8 Bridging Genomic FMs to Molecular Design",
    "text": "25.8 Bridging Genomic FMs to Molecular Design\nWhile this chapter focuses on target identification and indication selection, it is useful to briefly sketch how genomic FMs connect downstream to molecular design and optimization, which are covered in more detail in Chapter 26.\nModern chemistry and protein FMs treat SMILES strings, molecular graphs, protein sequences, and structures as languages amenable to transformer-style modeling. The bridge between genomic and molecular FMs typically involves using target context as a conditioning signal (using gene-level embeddings from genomic FMs, reflecting genetic evidence, tissue specificity, and network context, to condition molecule generation models), building multi-modal foundation models (jointly training models on sequences including DNA, RNA, and proteins, structures, small molecules, and gene expression or phenotypic readouts), and implementing closed-loop optimization (using genomic FMs to predict target relevance and liability, using chemistry and protein FMs to propose molecules, then updating both with experimental feedback in an active learning loop).\nFrom a translational perspective, the key point is that genomic FMs determine whether a target is worth pursuing at all, while downstream FMs help optimize how to hit it.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#evaluation-validation-and-pitfalls",
    "href": "p6-ch25-drugs.html#evaluation-validation-and-pitfalls",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.9 Evaluation, Validation, and Pitfalls",
    "text": "25.9 Evaluation, Validation, and Pitfalls\nAs with other applications in this book, evaluating genomic FMs in drug discovery requires carefully separating model performance from scientific and clinical validity.\nKey considerations include benchmark leakage, where benchmarks that draw targets and drugs from the same sources used to pre-train the models may overestimate performance (see Chapter 18, Chapter 19), and where many success stories in repurposing rely on retrospective data mining with limited prospective validation. Confounding and indication bias means models trained on observational clinical and genomic data inherit all of their confounders, and drug-disease associations learned by FMs may reflect treatment patterns rather than true protective or harmful effects (such as confounding by indication, survivorship bias) as discussed in Chapter 21. Over-interpretation of embeddings is a risk because distances in representation space are not guaranteed to correspond to clinically meaningful similarities, and mechanistic narratives constructed post hoc can be compelling but misleading (see Chapter 22). Finally, there is a lack of prospective evidence: ultimately, the value of FM-informed targets will be measured by prospectively validated hits and successful clinical programs. At present, published case studies are largely retrospective or early-stage; claims of revolutionizing drug discovery should be tempered accordingly.\nWe can already see the contours of more integrated systems with end-to-end training across modalities (models that jointly ingest DNA, RNA, proteins, small molecules, images, and clinical data, learning cross-modal correspondences at scale), task- and indication-specific adaptation (fine-tuning genomic FMs on disease-focused datasets to capture idiosyncratic biology while retaining broad priors, using parameter-efficient adaptation methods to customize models for specific company pipelines or therapeutic areas), and tighter coupling to experimental design (using FMs to propose the most informative perturbation experiments, not just to interpret existing data, with active-learning loops where experimental platforms and FMs co-evolve).\nRegulatory and ethical considerations become increasingly important. As FM-based recommendations influence target portfolios and clinical trial design, regulators will need frameworks for transparency, auditability, and validation. There is also a risk that data-rich indications and ancestries benefit disproportionately from FM-enabled discovery, exacerbating existing inequities, an issue tightly coupled to the themes of Chapter 23 and Chapter 27.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#forward-look-toward-lab-in-the-loop-gfms",
    "href": "p6-ch25-drugs.html#forward-look-toward-lab-in-the-loop-gfms",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.10 Forward Look: Toward Lab-in-the-Loop GFMs",
    "text": "25.10 Forward Look: Toward Lab-in-the-Loop GFMs\nA recurring theme across this book is moving from static models to closed loops that integrate foundational representation learning on large unlabeled datasets (genomes, multi-omics), task-specific supervision (disease status, expression, variant effects), and experimental feedback from perturbation assays, functional screens, and clinical trials.\nIn the drug discovery context, this suggests an evolution toward lab-in-the-loop GFMs. At the hypothesis generation stage, GFMs identify promising targets, variants, and regulatory regions. Graph and set-based models suggest network-level interventions (Jurenaite et al. 2024; Gao et al. 2023; Yuan and Duren 2025).\nFor experiment design, models propose perturbation libraries (CRISPR, MPRA) that maximize expected information gain. Safety and off-target predictions help filter risky designs before they reach the bench.\nDuring evidence integration and model refinement, screen results feed back into GFMs, improving their local accuracy in disease-relevant regions of sequence space. Clinical trial outcomes update biomarker models and risk predictors for future trials.\nFinally, portfolio-level decision support combines genetic and functional evidence from GFMs with classical pharmacology to prioritize or deprioritize programs. Uncertainty estimates and model critique (Chapter 22) help avoid over-confidence in purely model-driven recommendations.\nRealizing this vision will require better calibration and uncertainty quantification in GFMs, stronger causal reasoning to distinguish correlation from intervention-worthiness, and careful ethical and equity considerations, especially when models influence who gets access to trials or targeted therapies (Chapter 21).\nIf the genomics and AI communities succeed, future drug discovery pipelines may look markedly different: genetics and multi-omics will be used not just to rationalize targets in hindsight, but to systematically propose and prioritize interventions from the very beginning. Genomic foundation models are a key ingredient in moving from data-rich but insight-poor to genuinely mechanism-informed and patient-centric drug discovery.\nYet even in the near term, GFMs already offer tangible value in de-risking targets, enriching cohorts, and interpreting complex functional data. When combined with rigorous experimental design and domain expertise, they can act not as oracle decision-makers, but as force multipliers for human scientists and clinicians.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch25-drugs.html#summary",
    "href": "p6-ch25-drugs.html#summary",
    "title": "25  Drug Discovery & Biotech",
    "section": "25.11 Summary",
    "text": "25.11 Summary\nThis chapter has sketched how genomic foundation models extend beyond academic benchmarks into practical levers for drug discovery and biotech. GFMs turn variant and regulatory predictions into target discovery and validation pipelines, with workflows that aggregate variant-level scores into gene-level evidence and connect genetic signals to biological mechanisms. Network-aware approaches propagate these signals through protein and regulatory interaction networks to identify modules, bottlenecks, and repurposing opportunities. GFMs enable the design and interpretation of functional genomics screens that probe mechanism and vulnerability, closing the loop between computational prediction and experimental validation through lab-in-the-loop refinement. They support richer biomarkers and patient stratification schemes for trials, moving beyond individual variants to embeddings over high-dimensional genomic and multi-omic profiles, while disease embeddings inform indication selection and safety prediction. Finally, GFMs provide shared infrastructure for industrial data platforms and MLOps, raising questions about build-versus-buy strategies, data governance, and regulatory documentation.\nThe previous chapters on clinical risk prediction (Chapter 23) and pathogenic variant discovery (Chapter 24) use the conceptual toolkit laid out here in more specialized contexts. Together, these applications illustrate how the representational gains of genomic foundation models connect to the realities of translational research and patient care.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. “[TraitGym] Benchmarking DNA Sequence Models for Causal Regulatory Variant Prediction in Human Genetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nBenegas, Gonzalo, Chengzhong Ye, Carlos Albors, Jianan Canal Li, and Yun S. Song. 2024. “Genomic Language Models: Opportunities and Challenges.” arXiv. https://doi.org/10.48550/arXiv.2407.11435.\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.” Nature Genetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nFishman, Veniamin, Yuri Kuratov, Aleksei Shmelev, Maxim Petrov, Dmitry Penzar, Denis Shepelin, Nikolay Chekanov, Olga Kardymon, and Mikhail Burtsev. 2025. “GENA-LM: A Family of Open-Source Foundational DNA Language Models for Long Sequences.” Nucleic Acids Research 53 (2): gkae1310. https://doi.org/10.1093/nar/gkae1310.\n\n\nGao, Ziqi, Chenran Jiang, Jiawen Zhang, Xiaosen Jiang, Lanqing Li, Peilin Zhao, Huanming Yang, Yong Huang, and Jia Li. 2023. “[HIGH-PPI] Hierarchical Graph Learning for Protein–Protein Interaction.” Nature Communications 14 (1): 1093. https://doi.org/10.1038/s41467-023-36736-1.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nHe, Shujun, Baizhen Gao, Rushant Sabnis, and Qing Sun. 2023. “Nucleic Transformer: Classifying DNA Sequences with Self-Attention and Convolutions.” ACS Synthetic Biology 12 (11): 3205–14. https://doi.org/10.1021/acssynbio.3c00154.\n\n\nJurenaite, Neringa, Daniel León-Periñán, Veronika Donath, Sunna Torge, and René Jäkel. 2024. “SetQuence & SetOmic: Deep Set Transformers for Whole Genome and Exome Tumour Analysis.” BioSystems 235 (January): 105095. https://doi.org/10.1016/j.biosystems.2023.105095.\n\n\nLi, Zehui, Akashaditya Das, William A. V. Beardall, Yiren Zhao, and Guy-Bart Stan. 2023. “Genomic Interpreter: A Hierarchical Genomic Deep Neural Network with 1D Shifted Window Transformer.” arXiv. https://doi.org/10.48550/arXiv.2306.05143.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nMarquet, Céline, Julius Schlensok, Marina Abakarova, Burkhard Rost, and Elodie Laine. 2024. “[VespaG] Expert-Guided Protein Language Models Enable Accurate and Blazingly Fast Fitness Prediction.” Bioinformatics 40 (11): btae621. https://doi.org/10.1093/bioinformatics/btae621.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nTrop, Evan, Yair Schiff, Edgar Mariano Marroquin, Chia Hsiang Kao, Aaron Gokaslan, McKinley Polen, Mingyi Shao, et al. 2024. “The Genomics Long-Range Benchmark: Advancing DNA Language Models,” October. https://openreview.net/forum?id=8O9HLDrmtq.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping Improves Identification of Causal Variants.” Research Square, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nYan, Binghao, Yunbi Nam, Lingyao Li, Rebecca A. Deek, Hongzhe Li, and Siyuan Ma. 2025. “Recent Advances in Deep Learning and Language Models for Studying the Microbiome.” Frontiers in Genetics 15 (January). https://doi.org/10.3389/fgene.2024.1494474.\n\n\nYuan, Qiuyue, and Zhana Duren. 2025. “[LINGER] Inferring Gene Regulatory Networks from Single-Cell Multiome Data Using Atlas-Scale External Data.” Nature Biotechnology 43 (2): 247–57. https://doi.org/10.1038/s41587-024-02182-7.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Drug Discovery & Biotech</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html",
    "href": "p6-ch26-design.html",
    "title": "26  Sequence Design",
    "section": "",
    "text": "26.1 From prediction to design\nFoundation models have transformed our ability to predict the consequences of genetic and protein variation. In this chapter, we flip the direction of inference: instead of asking what a sequence does, we ask what sequence should we build to achieve a desired function.\nWe focus on three complementary views:\nMost chapters in this book assume a forward mapping: given a DNA, RNA, or protein sequence, a model predicts structure, activity, or phenotype. Design inverts this relationship. We specify a target (a structure, expression level, binding affinity, or multi-objective profile), then search over the astronomical space of sequences to find candidates predicted to satisfy that target. We experimentally test and iteratively refine both the sequences and the model.\nFormally, if \\(f_\\theta(x)\\) is a foundation model that predicts properties of a sequence \\(x\\), design problems can be posed as:\nThe central challenge is searching enormous combinatorial spaces (e.g., \\(20^{200}\\) for a 200-residue protein) while staying within the regime where model predictions are reliable.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#from-prediction-to-design",
    "href": "p6-ch26-design.html#from-prediction-to-design",
    "title": "26  Sequence Design",
    "section": "",
    "text": "Optimization: find \\(x^\\star = \\arg\\max_x f_\\theta(x)\\) for some scalar objective (e.g., predicted activity).\nConditional generation: sample \\(x \\sim p_\\theta(x \\mid y)\\) given a desired property or condition \\(y\\) (e.g., a structure, binding partner, or cell type).\nConstrained design: optimize subject to constraints \\(c(x) \\leq 0\\) (e.g., GC content, off-target scores, immunogenicity).\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Cartoon of a high-dimensional fitness landscape. Show a foundation model approximating the landscape and different design strategies (gradient ascent, MCMC, evolutionary search) climbing toward high-fitness regions.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#protein-design-with-foundation-models",
    "href": "p6-ch26-design.html#protein-design-with-foundation-models",
    "title": "26  Sequence Design",
    "section": "26.2 Protein design with foundation models",
    "text": "26.2 Protein design with foundation models\nProtein design pre-dates foundation models, but large-scale protein language models (PLMs) and structure-aware models have made it possible to generate and optimize sequences with minimal or no task-specific data.\n\n26.2.1 Sequence-only generative models\nProtein language models trained with masked-token or autoregressive objectives (e.g., ESM, ProGen, ProtGPT-like models) learn rich priors over amino acid sequences (Rao et al. 2019; Madani et al. 2023; Ferruz, Schmidt, and Höcker 2022). These priors can be used for design in multiple ways. Unconditional sampling generates novel, foldable proteins by sampling from the model. Latent-space optimization encodes sequences into embeddings, then optimizes in latent space for desired downstream scores. Conditional prompting or steering biases generation with prompts, control tokens, or guidance signals (e.g., family, subcellular localization).\nKey advantages include data efficiency (models can exploit vast unlabeled sequence corpora), diversity (generative sampling naturally explores multiple modes of sequence space), and transferability (the same PLM can support many downstream tasks including prediction, design, and annotation).\nLimitations remain. These models provide weak or indirect control over structure and function. They may regenerate or minimally modify training data, raising data leakage concerns. Additionally, the correspondence between “knobs” in latent space and functional properties remains poorly understood, limiting interpretability.\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Diagram of a protein language model used for design. Left: training on large sequence corpus. Right: using the trained model to sample new sequences, optionally conditioned on family or simple attributes.\n\n\n\n\n\n26.2.2 Structure-aware and diffusion-based design\nStructure-aware models like AlphaFold2 (Jumper et al. 2021) and related architectures provide accurate mappings from sequence to structure. Building on these, diffusion models and structure-conditioned generative models now enable direct design of sequences that fold into desired 3D structures (Watson et al. 2023; Dauparas et al. 2022).\nDesign strategies include backbone-conditioned sequence design, where a fixed backbone (natural or imagined) guides generation of sequences predicted to fold onto that backbone (e.g., ProteinMPNN). Hallucination of novel folds diffuses in the space of structures or sequence–structure pairs to generate entirely new topologies (e.g., RFdiffusion). Interface and binder design conditions generation on a target protein to create binding partners with specific affinity or epitope geometry.\nThese models often operate in a joint space of sequence and structure, coupling three components: (1) a model for structural consistency (e.g., diffusion in backbone coordinates), (2) a sequence-conditional model for structural plausibility and stability, and (3) a downstream oracle (binding, stability, catalytic activity) used during scoring or optimization.\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Multi-panel schematic of structure-aware design. Panel A: target backbone or target protein. Panel B: diffusion trajectory producing a new binder. Panel C: predicted structure overlay of designed vs. target complex.\n\n\n\n\n\n26.2.3 Functional conditioning and multi-objective design\nIn real applications, we rarely want “anything that folds”. We want proteins that are stable, expressible, and soluble; functional (enzymatic activity, binding, signaling); and safe and manufacturable (low aggregation, low immunogenicity, good developability).\nTo capture this, design pipelines combine foundation models with multi-objective optimization. A generative prior (PLM or diffusion model) proposes candidates. These candidates are then evaluated with oracles, which may be in silico (structure predictors, stability models, developability scores) or experimental (deep mutational scanning, binding assays, functional screens). Strategies like Bayesian optimization, evolutionary algorithms, or gradient-based editing iteratively improve proposals.\nMulti-objective design often produces a Pareto frontier of solutions trading off properties (e.g., activity vs. stability). Genomic foundation models contribute by providing cheap, differentiable oracles for properties linked to sequence (e.g., localization motifs, PTM sites) and encoding evolutionary constraints that discourage unrealistic sequences.\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: 2D scatter plot mock-up of designed proteins along two axes (e.g., predicted stability vs. binding score), highlighting a Pareto frontier. Overlay different design strategies as colored point sets.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#regulatory-and-noncoding-sequence-design",
    "href": "p6-ch26-design.html#regulatory-and-noncoding-sequence-design",
    "title": "26  Sequence Design",
    "section": "26.3 Regulatory and noncoding sequence design",
    "text": "26.3 Regulatory and noncoding sequence design\nMost genomic foundation models in this book learn mappings from noncoding DNA or RNA to regulatory activities: expression, chromatin state, splicing patterns, or transcription factor binding. These models can be inverted to design regulatory sequences with desired behaviors.\n\n26.3.1 Promoter and enhancer design\nModels trained on massive datasets (e.g., MPRA, ChIP–seq, ATAC–seq, CAGE) can predict regulatory activity from local sequence context (Boer et al. 2020). Design tasks include promoter optimization (maximize expression of a gene in a specific cell type or condition), cell-type-specific enhancers (high activity in a target cell/tissue and low activity elsewhere), and minimal regulatory elements (short synthetic enhancers with robust and tunable activity).\nTwo broad approaches exist for regulatory sequence design. Gradient-based sequence editing treats a sequence-to-function model as differentiable with respect to input embeddings. We compute gradients of the desired objective with respect to nucleotides, apply projected gradient steps or “soft token” optimization, then project back to discrete bases. This leverages the same models used for interpretation (saliency maps, in silico mutagenesis) but runs gradients “in reverse” for design.\nGenerative regulatory models take an alternative approach. These models train autoregressive or diffusion models directly on genomic regulatory regions, condition on metadata (cell type, histone marks, accessibility), and sample synthetic enhancers/promoters with targeted activity profiles before filtering using oracles.\n\n\n26.3.2 Splicing and RNA processing\nModels like SpliceAI and RNA-focused FMs (Chapter 12) can predict splicing outcomes from local sequence context. Design applications include therapeutic splice modulation (design antisense oligos or CRISPR base edits that restore normal splicing), alternative isoform tuning (adjust splicing of specific exons to modulate protein isoforms), and RNA processing elements (design polyadenylation signals, UTRs, and RNA stability motifs).\nDesign strategies mirror the promoter/enhancer setting: gradient-based editing, enumerative search guided by saliency maps, and generative sequence models trained on splicing-competent regions.\n\n\n26.3.3 RNA structure and functional RNA design\nRNA foundation models that jointly capture sequence and secondary/tertiary structure enable design of riboswitches and aptamers, guide RNAs with precise on-/off-target profiles, and synthetic RNAs for sensing and actuation (e.g., toehold switches). Here, the design objective blends structure, thermodynamics, and interaction propensity with genomic-context constraints (e.g., avoiding cryptic splice sites or immune-stimulatory motifs).\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Schematic of regulatory sequence design. Panel A: model predicts expression from promoter/enhancer sequence. Panel B: gradients or an optimization loop propose sequence edits. Panel C: synthetic sequences tested in an MPRA assay.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#designbuildtestlearn-loops",
    "href": "p6-ch26-design.html#designbuildtestlearn-loops",
    "title": "26  Sequence Design",
    "section": "26.4 Design–build–test–learn loops",
    "text": "26.4 Design–build–test–learn loops\nFoundation models realize their full potential in closed-loop DBTL workflows. In the design phase, we use generative or optimization algorithms to propose sequences. During build, we synthesize DNA/RNA or construct libraries (pooled or array-based). The test phase assays function using high-throughput methods (e.g., MPRA, DMS, functional genomics screens). Finally, we learn by updating model parameters or retraining with new data, focusing on regimes where model uncertainty was high.\n\n26.4.1 Active learning and adaptive experiments\nActive learning aims to select the most informative experiments given limited budget. Uncertainty sampling chooses sequences where the model is uncertain (e.g., high entropy over outputs). Bayesian optimization balances exploration (uncertainty) and exploitation (predicted high fitness). Diversity-aware selection enforces coverage over sequence and function space to avoid local optima.\nGenomic foundation models are especially well-suited for active learning. They provide calibrated uncertainty estimates (e.g., via ensembles, MC dropout, or explicit probabilistic outputs). They can be fine-tuned on task-specific data from each DBTL cycle, gradually shifting from a generic prior to a task-adapted model.\n\n\n26.4.2 High-throughput assays as feedback\nSeveral assay modalities naturally pair with foundation models. MPRA / STARR-seq provides parallel readouts of regulatory element activity for hundreds of thousands of sequences. Deep mutational scanning enables systematic exploration of mutational neighborhoods around proteins or regulatory elements. CRISPR screens introduce perturbations to regulatory regions or coding genes, with phenotypic readouts (e.g., proliferation, expression).\nThese assays generate dense local maps of function within specific sequence neighborhoods. Foundation models can interpolate across unmeasured variants, extrapolate to new regions by combining assay data with global priors, and suggest where to expand measurements next.\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Flowchart of a DBTL cycle specific to regulatory sequence design: model → library design → DNA synthesis → cellular assay → sequencing → model update. Use consistent design language with Chapter 20 (clinical) and Chapter 22 (drugs).",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#practical-considerations-and-pitfalls",
    "href": "p6-ch26-design.html#practical-considerations-and-pitfalls",
    "title": "26  Sequence Design",
    "section": "26.5 Practical considerations and pitfalls",
    "text": "26.5 Practical considerations and pitfalls\nDesign with genomic foundation models introduces a distinct set of practical challenges compared to prediction-only use.\n\n26.5.1 Constraints, safety, and manufacturability\nReal-world designs must satisfy numerous constraints beyond the primary objective. Sequence-level constraints include GC content, repeats, restriction sites, and synthesis compatibility, as well as coding vs. noncoding frame integrity and avoiding unwanted ORFs. Contextual constraints encompass the chromatin environment, genomic integration site, neighboring regulatory elements, and species- and tissue-specific sequence biases. Safety and biosecurity considerations require avoiding sequences with known pathogenic motifs or virulence determinants and controlling dual-use risks (see Chapter 27 for broader discussion).\nDesign algorithms must either hard-encode constraints (e.g., only sample from constrained spaces) or use penalty terms in objective functions, ideally with interpretable trade-offs.\n\n\n26.5.2 Model failure modes in the design regime\nMany pitfalls from Chapter 21 become amplified in design. Mode collapse toward training data occurs when generative models reproduce or minimally modify sequences seen during training, undermining novelty. Off-manifold proposals arise when aggressive optimization (e.g., many gradient steps) pushes sequences into regions where model predictions are unreliable. Reward hacking happens when optimization objectives only reflect surrogate scores (e.g., model-predicted activity), allowing the system to exploit quirks of the model rather than true biology.\nMitigation strategies include regularizing designs toward realistic priors (e.g., KL penalties against the PLM prior), enforcing novelty thresholds relative to training sequences, and using ensembles or multi-model agreement to guard against idiosyncratic failures.\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Small panel illustrating “reward hacking” in sequence design: sequences optimized to extreme model scores that are actually biologically implausible (e.g., bizarre motifs, impossible structures).",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#design-paradigms-and-algorithmic-toolkits",
    "href": "p6-ch26-design.html#design-paradigms-and-algorithmic-toolkits",
    "title": "26  Sequence Design",
    "section": "26.6 Design paradigms and algorithmic toolkits",
    "text": "26.6 Design paradigms and algorithmic toolkits\nAlthough implementation details vary, design workflows tend to fall into a few algorithmic patterns.\nGradient-based design uses differentiable models and surrogate continuous relaxations of discrete sequences. We apply gradient ascent with regularization and projection. This approach is efficient in high-dimensional spaces but can produce off-manifold, adversarial sequences.\nEvolutionary and genetic algorithms maintain populations of sequences, applying mutation, crossover, and selection based on model or assay scores. This approach provides a natural fit for multi-objective optimization and discrete constraints.\nBayesian optimization and bandits treat the sequence-to-fitness mapping as an unknown function, using a surrogate (e.g., Gaussian process, neural surrogate) to guide sampling. This strategy is particularly powerful when experimental budgets are small and assays are expensive.\nReinforcement learning (RL) formulates design as a sequential decision problem (e.g., build sequence token-by-token), using rewards based on foundation model predictions or assay outcomes. RL can leverage policy constraints to maintain similarity to natural sequences.\nDiffusion and flow-based generative models learn to map noise to sequences (or sequence–structure pairs), optionally conditioned on design targets. These models support sampling diverse sets of candidates with controllable properties.\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Table summarizing design algorithm families (gradient-based, evolutionary, Bayesian optimization, RL, diffusion) with columns for “pros”, “cons”, “typical use cases”, and “interaction with foundation models”.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#case-studies-and-applications",
    "href": "p6-ch26-design.html#case-studies-and-applications",
    "title": "26  Sequence Design",
    "section": "26.7 Case studies and applications",
    "text": "26.7 Case studies and applications\nBelow are representative application areas where genomic foundation model-enabled design is already making impact.\n\n26.7.1 Therapeutic protein and antibody design\nDe novo enzymes represent designed catalysts for specific chemical transformations, guided by structural and stability models. Antibodies and binders include synthetic binders targeting viral proteins, oncogenic receptors, or immune checkpoints, where FMs help optimize binding affinity and developability. Cytokines and signaling proteins comprise designed variants with tuned half-lives, receptor specificities, and signaling strength.\nFoundation models serve multiple roles in these applications. They provide priors over plausible sequences and interfaces. They act as oracles for properties such as stability, aggregation, and PTM patterns. They function as feature extractors for downstream models that predict pharmacokinetics or immunogenicity.\n\n\n26.7.2 Synthetic regulatory circuits and cell engineering\nSynthetic promoters and enhancers drive precise expression programs in CAR-T cells, stem cells, or engineered tissues. Logic-gated regulatory elements integrate multiple transcription factor inputs. Safety switches (kill switches, inducible expression) are embedded in therapeutic constructs.\nGenomic FMs are crucial for predicting how designed elements behave within real genomic and epigenomic contexts, not just in isolated plasmid systems.\n\n\n26.7.3 Genome-scale perturbation libraries\nEven when individual sequences are not used as products, design methods power saturation mutagenesis libraries for functional genomics, tiled CRISPR perturbation libraries targeting regulatory landscapes, and Perturb-seq designs that multiplex many regulatory variants across cell types.\nHere, the goal is to maximize information content of experiments rather than optimize a single construct, but the same models and algorithms apply.\n\n\n\n\n\n\n\nWarning\n\n\n\nFIGURE SUGGESTION: Multi-panel “applications” figure with small icons or schematic vignettes for (A) therapeutic proteins, (B) regulatory circuits, and (C) functional genomics libraries. Reuse iconography from previous chapters for coherence.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch26-design.html#outlook",
    "href": "p6-ch26-design.html#outlook",
    "title": "26  Sequence Design",
    "section": "26.8 Outlook",
    "text": "26.8 Outlook\nDesign sits at the intersection of modeling, optimization, and experimental biology. Genomic foundation models are rapidly shifting design from artisanal, hand-crafted processes to principled, data-driven workflows that can propose novel proteins and regulatory elements beyond natural evolution, exploit massive unlabeled sequence corpora as priors on what biology “allows”, and close loops between in silico hypotheses and in vitro/in vivo measurements.\nHowever, the same capabilities that enable beneficial applications also raise epistemic risks (overconfidence in models, especially out-of-distribution) and ethical and governance challenges (dual-use potential, unequal access, and misuse).\nThese themes connect directly to Chapter 23 and Chapter 25, and Chapter 27. Together, they suggest that the future of genomic design will depend not only on better models, but also on careful integration with experimental design, rigorous evaluation, and robust norms for safe and equitable use.\n\n\n\n\nBoer, Carl G. de, Eeshit Dhaval Vaishnav, Ronen Sadeh, Esteban Luis Abeyta, Nir Friedman, and Aviv Regev. 2020. “Deciphering Eukaryotic Gene-Regulatory Logic with 100 Million Random Promoters.” Nature Biotechnology 38 (1): 56–65. https://doi.org/10.1038/s41587-019-0315-8.\n\n\nDauparas, J., I. Anishchenko, N. Bennett, H. Bai, R. J. Ragotte, L. F. Milles, B. I. M. Wicky, et al. 2022. “Robust Deep Learning–Based Protein Sequence Design Using ProteinMPNN.” Science 378 (6615): 49–56. https://doi.org/10.1126/science.add2187.\n\n\nFerruz, Noelia, Steffen Schmidt, and Birte Höcker. 2022. “ProtGPT2 Is a Deep Unsupervised Language Model for Protein Design.” Nature Communications 13 (1): 4348. https://doi.org/10.1038/s41467-022-32007-7.\n\n\nJumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. “[AlphaFold2] Highly Accurate Protein Structure Prediction with AlphaFold.” Nature 596 (7873): 583–89. https://doi.org/10.1038/s41586-021-03819-2.\n\n\nMadani, Ali, Ben Krause, Eric R. Greene, Subu Subramanian, Benjamin P. Mohr, James M. Holton, Jose Luis Olmos, et al. 2023. “Large Language Models Generate Functional Protein Sequences Across Diverse Families.” Nature Biotechnology 41 (8): 1099–1106. https://doi.org/10.1038/s41587-022-01618-2.\n\n\nRao, Roshan, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Xi Chen, John Canny, Pieter Abbeel, and Yun S. Song. 2019. “Evaluating Protein Transfer Learning with TAPE.” arXiv. https://doi.org/10.48550/arXiv.1906.08230.\n\n\nWatson, Joseph L., David Juergens, Nathaniel R. Bennett, Brian L. Trippe, Jason Yim, Helen E. Eisenach, Woody Ahern, et al. 2023. “De Novo Design of Protein Structure and Function with RFdiffusion.” Nature 620 (7976): 1089–1100. https://doi.org/10.1038/s41586-023-06415-8.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sequence Design</span>"
    ]
  },
  {
    "objectID": "p6-ch27-future.html",
    "href": "p6-ch27-future.html",
    "title": "27  Future Work & Ethics",
    "section": "",
    "text": "27.1 Introduction\nGenomic foundation models (GFMs) sit at an unusual moment in their lifecycle. In only a few years, we have gone from task-specific convolutional networks and sequence models to large, pre-trained architectures that can score variants, predict regulatory effects, infer structure, and even design new sequences across many biological modalities. Yet most of the results in this book live in carefully curated benchmarks and controlled experimental settings. The gap between what is technically possible in silico and what is safely deployable in health systems, biotechnology, or public health remains wide.\nThis closing chapter looks forward. Rather than trying to predict a single future, we synthesize recurring themes from earlier chapters into a set of open technical problems, translational challenges, and ethical questions that will shape the trajectory of GFMs. The goal is less to forecast concrete milestones and more to equip you with a conceptual framework: what kinds of advances would really matter, what pitfalls to watch for, and what kinds of guardrails and institutions will be needed to realize benefits while minimizing harms.\nThroughout, we assume familiarity with the architectures (Part II), principles of pretraining and adaptation (Part III), multi-scale modeling (Part IV), and evaluation and interpretation (Part V). Here we step back and ask: if we take all of these ingredients seriously, what does a responsible future for genomic foundation models look like?",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Future Work & Ethics</span>"
    ]
  },
  {
    "objectID": "p6-ch27-future.html#technical-frontiers",
    "href": "p6-ch27-future.html#technical-frontiers",
    "title": "27  Future Work & Ethics",
    "section": "27.2 Technical Frontiers",
    "text": "27.2 Technical Frontiers\n\n27.2.1 Unified Multi-omic Foundation Models\nMost models in this book are still specialized. We have models pre-trained on genomic sequence, models for proteins, models for single-cell transcriptomes or chromatin accessibility, and models tuned for particular experimental assays. Even “multi-omic” systems often stitch together separate encoders rather than learning a single representation over the whole central dogma.\nA major frontier is unified multi-omic foundation models that can ingest and generate across DNA, RNA, proteins, chromatin state, and higher-level phenotypes. Such models could answer cross-modal questions directly. For instance, one might ask “What regulatory variants are most likely to disrupt this cell-type–specific enhancer?” or “How would editing this promoter alter downstream protein abundance in a given tissue?” In the ideal case, a single representation would capture a causal chain from nucleotide changes to molecular and cellular phenotypes, constrained by physical and evolutionary priors.\nEarly cross-modal models (including systems like Omni-DNA, G2PT, and related architectures discussed in Chapters Chapter 11, Chapter 12, and Chapter 17) hint at what is possible, but they remain limited in scope, scale, and biological coverage. Open questions include how to:\n\nLearn coherent representations when training data are sparse or missing for many modalities.\nBalance supervised and self-supervised objectives across modalities with very different noise characteristics and scales.\nMaintain interpretability of cross-modal reasoning, so that paths from variant to phenotype remain auditable rather than opaque.\n\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Multi-panel schematic showing unified multi-omic modeling: (1) diverse data types (DNA, chromatin, RNA, protein, phenotype) entering a shared backbone; (2) a joint embedding space; (3) cross-modal queries (e.g., variant → expression, expression → pathway). Label panels with example tasks.\n\n\n\n\n27.2.2 Long-Context and Whole-Genome Modeling\nEven the largest sequence models for DNA and RNA operate on chunks: kilobases, sometimes megabases. Yet the human genome spans ~3 billion base pairs, and many regulatory phenomena (chromatin domains, structural variants, long-range enhancer–promoter loops) unfold at scales far beyond current context windows.\nScaling GFMs to chromosome- or genome-length contexts raises fundamental questions about representation and computation. Architectures based on linear attention, state-space models, or sparse and hierarchical attention promise near-linear scaling in sequence length, but we still lack a principled understanding of what biological information requires truly global context versus local context plus learned summaries.\nOpen problems include:\n\nDesigning architectures that integrate 1D sequence with 3D genome conformation and nuclear organization.\nDeveloping curriculum strategies that grow context length without catastrophic forgetting of local patterns.\nCreating benchmarks that explicitly probe long-range reasoning (e.g., structural variants, multi-enhancer regulation, chromatin domain effects) rather than simple motif recognition.\n\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Cartoon of different context scales: (1) local motif-level modeling (tens of bp), (2) regulatory element modeling (hundreds–thousands of bp), (3) chromatin domain / chromosome-scale (megabases). Overlay example tasks and indicate approximate context lengths needed for each.\n\n\n\n\n27.2.3 Generative and Design-Oriented Models\nEarlier chapters emphasized predictive tasks: variant effect prediction, splicing, regulatory element activity, structure prediction. Increasingly, however, GFMs are being used as generators. They propose new regulatory sequences, protein variants, or RNA structures that satisfy user-defined constraints and then validate them experimentally (Chapter 26).\nGenerative GFMs raise opportunities and questions that differ from their predictive cousins:\n\nHow do we specify constraints and objectives (expression in a particular cell type, safety profiles, manufacturability) so that the model explores useful parts of sequence space rather than adversarial corners?\nHow do we design closed-loop “design–build–test–learn” cycles where experimental feedback is used to refine generative models without overfitting to a narrow set of assays?\nHow do we evaluate generative success beyond simple enrichment metrics, recognizing that even a small fraction of high-impact designs may justify application?\n\nSafety and robustness are particularly salient here. Generative models that can produce highly active regulatory elements or functional protein domains must be developed with guardrails: screening for off-target effects, restricting capability where appropriate, and integrating domain-specific safety checks into the design pipeline.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Pipeline diagram of a closed-loop design system: (1) generative GFM proposes sequences, (2) high-throughput assay tests a subset, (3) results feed back into fine-tuning or reward modeling, (4) iterative improvement. Highlight spots where safety filters or domain constraints can be applied.\n\n\n\n\n27.2.4 Causal and Mechanistic Integration\nMost GFMs today are powerful correlational machines. They exploit statistical regularities in training data to predict labels or masked tokens, but they do not explicitly encode causal structure. For genomic applications, this distinction matters: clinical decisions often require reasoning about interventions (“What if we knock out this gene?”) rather than passive prediction.\nThe next generation of GFMs will need to integrate causal and mechanistic information in several ways:\n\nLeveraging interventional datasets (CRISPR screens, perturb-seq, drug treatments) to disentangle cause and effect.\nIncorporating mechanistic priors such as gene regulatory networks, metabolic pathways, and structural constraints into model architectures or training objectives.\nSupporting counterfactual reasoning: simulating perturbations or edits and quantifying uncertainty in predicted outcomes.\n\nMechanistic interpretability, discussed in Chapter 22, takes on new urgency in this context. If GFMs are to inform experimental design or clinical decisions, it will not be enough to know that a model predicts a given effect; we will need to understand why, at least at the level of testable hypotheses about regulatory logic or pathway structure.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Conceptual diagram connecting (1) an interventional dataset (e.g., CRISPR perturbations), (2) a GFM that learns a latent representation, and (3) a causal graph or gene regulatory network derived from that representation. Use arrows to distinguish observational vs. interventional edges.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Future Work & Ethics</span>"
    ]
  },
  {
    "objectID": "p6-ch27-future.html#deployment-translation-considerations",
    "href": "p6-ch27-future.html#deployment-translation-considerations",
    "title": "27  Future Work & Ethics",
    "section": "27.3 Deployment & Translation Considerations",
    "text": "27.3 Deployment & Translation Considerations\n\n27.3.1 Prospective Validation and Regulatory Pathways\nAs emphasized in Chapters Chapter 18 and Chapter 19, strong retrospective performance on benchmarks is only a starting point. For clinical and public health use, GFMs must be evaluated prospectively in the settings where they will be deployed, on populations that resemble the intended users, and with endpoints that matter (clinical outcomes, time to diagnosis, cost-effectiveness).\nThis kind of validation is resource-intensive: it often requires multi-site collaborations, carefully designed trials or observational studies, and governance structures that can monitor performance over time. Regulatory frameworks such as those used by the FDA or European notified bodies treat many GFM-based tools as software as a medical device (SaMD), triggering requirements for documentation, quality management, and post-market surveillance.\nOpen questions include:\n\nHow to define clinically meaningful endpoints for GFM-enabled tools that may play only a small part in a larger diagnostic or therapeutic workflow.\nHow to handle “learning systems” whose parameters evolve over time as they ingest new data.\nHow to share evidence and best practices across institutions without compromising privacy or competitive advantage.\n\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Flowchart of the path from proof-of-concept GFM to deployed tool: (1) model development, (2) retrospective validation, (3) prospective studies, (4) regulatory review, (5) deployment and monitoring. Annotate each stage with example evidence and stakeholders.\n\n\n\n\n27.3.2 Infrastructure and Accessibility\nThe largest GFMs require massive compute for training and nontrivial resources for inference. Many clinical laboratories, public health agencies, and research groups cannot host such models locally, especially if they must process data within strict privacy or residency constraints.\nSeveral strategies have emerged and will likely intensify:\n\nModel compression and distillation to produce smaller, task-optimized models that retain most of the performance of their larger parents.\nQuantization and hardware-aware optimization to enable inference on accelerators or even CPUs in resource-constrained settings.\nHybrid deployment models where sensitive preprocessing happens locally, while more generic parts of the computation are offloaded to secure cloud services.\n\nThese technical choices intersect with equity: tools that require expensive infrastructure may exacerbate global disparities in access to genomic medicine, whereas lightweight or open models can help narrow the gap.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Table comparing deployment strategies (on-prem large model, distilled local model, cloud API, federated inference) with columns for pros, cons, typical use cases, and equity implications.\n\n\n\n\n27.3.3 Interoperability and Standards\nGFMs rarely operate in isolation. They ingest variant calls, clinical data, assay results, and metadata; they output scores, annotations, or design candidates that must feed into existing laboratory information systems, electronic health records, or downstream analysis pipelines.\nInteroperability challenges arise at multiple levels:\n\nData formats and nomenclature, such as variant representation (VCF, HGVS, SPDI) and consistent gene or transcript identifiers.\nMetadata standards, including provenance, consent status, and assay details.\nModel documentation, including standardized model cards, versioning, and changelogs that make it clear what a given model is suitable for and what its limitations are.\n\nCommunity standards efforts around genomic data models, ontologies, and clinical interoperability (e.g., FHIR, OMOP) provide a starting point, but they often need to be extended or adapted for GFM-specific considerations, such as documenting training data composition or known failure modes.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Schematic stack diagram: bottom layer = raw genomic data and variant formats; middle layer = standards/ontologies; top layer = GFM models and applications. Use arrows to show where mismatches or gaps in standards can cause failures.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Future Work & Ethics</span>"
    ]
  },
  {
    "objectID": "p6-ch27-future.html#ethical-dimensions",
    "href": "p6-ch27-future.html#ethical-dimensions",
    "title": "27  Future Work & Ethics",
    "section": "27.4 Ethical Dimensions",
    "text": "27.4 Ethical Dimensions\n\n27.4.1 Equity and Representation\nAn enduring concern throughout this book has been the mismatch between the diversity of global populations and the composition of training datasets. Many genomic and transcriptomic resources are heavily skewed toward individuals of European ancestry or toward well-funded health systems. GFMs trained on such data can encode and amplify these biases, leading to systematically worse performance for underrepresented groups.\nMitigating these disparities involves both upstream and downstream interventions:\n\nInvesting in diverse, community-engaged cohorts and biobanks that reflect global genetic and environmental diversity.\nDesigning pretraining and evaluation pipelines that explicitly track performance across ancestry groups, disease subtypes, and care settings.\nDeveloping recalibration and adaptation methods that can correct systematic biases without masking underlying data gaps.\n\nAt a deeper level, equity also concerns who benefits from GFM capabilities. If models trained on globally sourced data are deployed primarily in high-resource settings, the communities who contributed data may not see commensurate improvements in care. Addressing this imbalance requires governance structures, benefit-sharing mechanisms, and funding models that extend beyond technical fixes.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Bar chart or conceptual graphic showing performance disparities across ancestry groups or institutions, paired with a panel illustrating strategies to close these gaps (data diversification, recalibration, domain adaptation).\n\n\n\n\n27.4.2 Privacy, Consent, and Data Governance\nGenomic data are uniquely identifying and richly informative. Even when obvious identifiers are removed, linkage attacks can often re-identify individuals by connecting genomic data to public genealogy or demographic resources. Foundation model pretraining, which typically relies on massive centralized datasets, raises additional questions about how information is stored and reused.\nKey challenges include:\n\nConsent at scale: moving from narrow, study-specific consent to models that can justify long-term, multi-use pretraining on genomic and clinical data.\nDynamic and granular consent: mechanisms that allow participants to update preferences, opt out of certain uses, or specify conditions (e.g., no commercial use, restrictions on specific applications).\nNovel governance models such as data trusts, cooperative biobanks, or federated learning frameworks that keep raw data local while enabling collective model training.\n\nSynthetic data and privacy-preserving training techniques (differential privacy, secure aggregation, homomorphic encryption) offer promising tools but are not panaceas. They must be evaluated rigorously in the genomic context, where both privacy and utility stakes are unusually high.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Governance diagram contrasting centralized data lake + GFM training vs. federated or data-trust approaches. Include participants (researchers, data stewards, contributors) and flows of data, models, and consent.\n\n\n\n\n27.4.3 Dual Use and Biosecurity\nLike many powerful technologies, GFMs have dual-use potential. Tools that can design highly active regulatory elements, optimize viral proteins, or suggest edits with large phenotypic effects could, in principle, be misused to enhance pathogens, evade diagnostics, or undermine privacy.\nManaging dual-use risks will require a mix of technical, institutional, and cultural responses:\n\nAccess controls and graduated release, including staged sharing of models, filtered APIs, or restricted capabilities for the most sensitive applications.\nRed-teaming and risk assessment, where independent experts probe models for misuse potential and help prioritize mitigations.\nNorms for responsible publication and disclosure, including pre-publication risk review for work that significantly advances capabilities with unclear benefits.\n\nImportantly, many dual-use concerns are speculative and context-dependent. A balanced approach recognizes genuine risks without overstating them, and engages diverse stakeholders (biosecurity experts, ethicists, scientists, and affected communities) in setting acceptable boundaries.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Risk matrix with axes “benefit” and “misuse potential,” placing example applications (variant interpretation, diagnostic support, pathogen design) in different quadrants. Use this to illustrate when stronger safeguards may be justified.\n\n\n\n\n27.4.4 Transparency and Accountability\nWhen GFM outputs inform medical or public health decisions, transparency and accountability become central. Patients, clinicians, and regulators may reasonably ask:\n\nWhat data were used to train this model?\nHow often does it fail, and for whom?\nHow is responsibility shared when model recommendations contribute to errors?\n\nAnswers will likely involve layered transparency. At one layer, model cards, data statements, and benchmark reports provide technical documentation. At another, user-facing interfaces convey uncertainty, intended use, and limitations in accessible language. Interpretability tools from Chapter 22 can help connect internal model behavior to human-understandable patterns, though they are not sufficient on their own.\nAccountability mechanisms will range from institutional policies (e.g., requiring human oversight or second opinions for certain decisions) to legal frameworks that clarify liability when model-assisted care goes wrong. The challenge is to foster trust without creating unrealistic expectations of infallibility.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Two-level diagram: (1) technical transparency artifacts (model cards, evaluation reports, interpretability analyses) and (2) user-facing artifacts (clinician dashboards, patient explanations). Show how information flows between them.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Future Work & Ethics</span>"
    ]
  },
  {
    "objectID": "p6-ch27-future.html#the-shifting-research-landscape",
    "href": "p6-ch27-future.html#the-shifting-research-landscape",
    "title": "27  Future Work & Ethics",
    "section": "27.5 The Shifting Research Landscape",
    "text": "27.5 The Shifting Research Landscape\n\n27.5.1 Benchmark Culture and Incentives\nBenchmarks have been essential to progress in GFMs, providing common reference points and enabling rapid comparison of methods (Chapter 18). But an overemphasis on leaderboard performance can distort incentives, encouraging incremental gains on narrow tasks rather than broader advances in robustness, generalization, or clinical impact.\nFuture work must broaden both what we measure and how we reward success:\n\nDesigning benchmarks that better approximate real-world settings, including noisy labels, distribution shifts, and rare conditions.\nIncorporating robustness, fairness, and calibration into standard evaluation suites, not just accuracy or AUROC.\nValuing negative results and careful ablation studies that reveal limitations and failure modes, even when they do not produce a new state-of-the-art score.\n\nThere is also a social dimension: funding agencies, conferences, and journals shape what is rewarded. Explicit support for benchmark maintenance, community challenges that prioritize clinically meaningful endpoints, and recognition for infrastructure and dataset curation will all influence the trajectory of the field.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Illustration of two “leaderboards”: one traditional (single metric, sorted by AUROC) and one multi-dimensional (axes for performance, robustness, fairness, interpretability). Use this to motivate richer evaluation cultures.\n\n\n\n\n27.5.2 Open Science vs. Industrial Scale\nAs models grow larger and datasets more complex, the resources required to train state-of-the-art GFMs increasingly reside in a small number of well-funded institutions and companies. This concentrates power and raises questions about who sets research agendas, who controls access to high-performing models, and how the broader community can scrutinize and improve them.\nYet genomics has a strong tradition of open data and collaborative science. Future work will have to navigate this tension, exploring models such as:\n\nPublic–private partnerships that support large-scale training while committing to open or tiered access policies.\n“Public option” GFMs: high-quality, openly licensed models that provide a baseline of capability for research and public health.\nAPI-mediated access with transparency requirements, where even closed models must disclose evaluation results, limitations, and basic training data characteristics.\n\nOpen science does not always mean fully open weights. In some cases, privacy or dual-use concerns may justify restricted access. The challenge is to align openness with responsibility, so that the benefits of GFMs are widely shared while risks are managed proactively.\n\n\n\n\n\n\nWarning\n\n\n\nVisual suggestion: Landscape diagram situating different model access strategies along axes of openness (open weights → closed API) and governance (individual lab → consortia → public agency). Annotate with example pros/cons.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Future Work & Ethics</span>"
    ]
  },
  {
    "objectID": "p6-ch27-future.html#conclusion",
    "href": "p6-ch27-future.html#conclusion",
    "title": "27  Future Work & Ethics",
    "section": "27.6 Conclusion",
    "text": "27.6 Conclusion\nGenomic foundation models offer an extraordinary toolkit: the ability to learn from massive, heterogeneous biological datasets; to generalize across tasks and domains; and to generate new hypotheses and designs at scales no human could match. But they are not magic. Their behavior is constrained by the data they see, the objectives they optimize, the architectures we design, and the social and institutional contexts in which they operate.\nThis chapter has outlined several intertwined frontiers: technical challenges around multi-omic integration, long-context modeling, generative design, and causal reasoning; translational issues of validation, infrastructure, and interoperability; ethical questions of equity, privacy, dual use, and accountability; and a shifting research landscape shaped by benchmarks, openness, and industrial scale. None of these topics is unique to genomics, but the combination of high stakes, deep personal information, and rapidly advancing technology makes their intersection especially urgent.\nUltimately, the future of GFMs will be determined less by any single model or benchmark and more by the norms, institutions, and collaborations we build around them. Realizing the benefits of genomic foundation models (while avoiding predictable harms) will require sustained engagement across disciplines: genomic scientists, machine learning researchers, clinicians, ethicists, policy-makers, patient advocates, and communities worldwide. If this book has a single thesis, it is that technical sophistication must go hand-in-hand with responsibility. The open problems we face are as much social and ethical as they are algorithmic.",
    "crumbs": [
      "Part VI — Translation and Application",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Future Work & Ethics</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abramson, Josh, Jonas Adler, Jack Dunger, Richard Evans, Tim Green,\nAlexander Pritzel, Olaf Ronneberger, et al. 2024.\n“[AlphaFold3] Accurate Structure\nPrediction of Biomolecular Interactions with AlphaFold\n3.” Nature 630 (8016): 493–500. https://doi.org/10.1038/s41586-024-07487-w.\n\n\nAdzhubei, Ivan A., Steffen Schmidt, Leonid Peshkin, Vasily E. Ramensky,\nAnna Gerasimova, Peer Bork, Alexey S. Kondrashov, and Shamil R. Sunyaev.\n2010. “A Method and Server for Predicting Damaging Missense\nMutations.” Nature Methods 7 (4): 248–49. https://doi.org/10.1038/nmeth0410-248.\n\n\nAhdritz, Gustaf, Nazim Bouatta, Christina Floristean, Sachin Kadyan,\nQinghui Xia, William Gerecke, Timothy J. O’Donnell, et al. 2024.\n“OpenFold: Retraining AlphaFold2 Yields\nNew Insights into Its Learning Mechanisms and Capacity for\nGeneralization.” Nature Methods 21 (8): 1514–24. https://doi.org/10.1038/s41592-024-02272-z.\n\n\nAll of Us Research Program Investigators, All of Us; 2019. “The\n‘All of Us’ Research\nProgram.” New England Journal of Medicine\n381 (7): 668–76. https://doi.org/10.1056/NEJMsr1809937.\n\n\nAmberger, Joanna S., Carol A. Bocchini, François Schiettecatte, Alan F.\nScott, and Ada Hamosh. 2015. “OMIM.org:\nOnline Mendelian Inheritance in\nMan (OMIM®), an Online Catalog of Human Genes\nand Genetic Disorders.” Nucleic Acids Research 43 (D1):\nD789–98. https://doi.org/10.1093/nar/gku1205.\n\n\nAuton, Adam, Gonçalo R. Abecasis, David M. Altshuler, Richard M. Durbin,\nGonçalo R. Abecasis, David R. Bentley, Aravinda Chakravarti, et al.\n2015. “A Global Reference for Human Genetic Variation.”\nNature 526 (7571): 68–74. https://doi.org/10.1038/nature15393.\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A.\nGrabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet\nKohli, and David R. Kelley. 2021. “[Enformer]\nEffective Gene Expression Prediction from Sequence by\nIntegrating Long-Range Interactions.” Nature Methods 18\n(October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025.\n“AlphaGenome: AI for Better\nUnderstanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBaek, Minkyung, Frank DiMaio, Ivan Anishchenko, Justas Dauparas, Sergey\nOvchinnikov, Gyu Rie Lee, Jue Wang, et al. 2021. “Accurate\nPrediction of Protein Structures and Interactions Using a Three-Track\nNeural Network.” Science 373 (6557): 871–76. https://doi.org/10.1126/science.abj8754.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S.\nSong. 2024. “GPN-MSA: An Alignment-Based\nDNA Language Model for Genome-Wide Variant Effect\nPrediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBenegas, Gonzalo, Sanjit Singh Batra, and Yun S. Song. 2023.\n“[GPN] DNA Language Models Are Powerful\nPredictors of Genome-Wide Variant Effects.” Proceedings of\nthe National Academy of Sciences 120 (44): e2311219120. https://doi.org/10.1073/pnas.2311219120.\n\n\nBenegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025.\n“[TraitGym] Benchmarking\nDNA Sequence Models for\nCausal Regulatory Variant\nPrediction in Human\nGenetics.” bioRxiv. https://doi.org/10.1101/2025.02.11.637758.\n\n\nBenegas, Gonzalo, Chengzhong Ye, Carlos Albors, Jianan Canal Li, and Yun\nS. Song. 2024. “Genomic Language Models:\nOpportunities and Challenges.” arXiv.\nhttps://doi.org/10.48550/arXiv.2407.11435.\n\n\nBoer, Carl G. de, Eeshit Dhaval Vaishnav, Ronen Sadeh, Esteban Luis\nAbeyta, Nir Friedman, and Aviv Regev. 2020. “Deciphering\nEukaryotic Gene-Regulatory Logic with 100 Million Random\nPromoters.” Nature Biotechnology 38 (1): 56–65. https://doi.org/10.1038/s41587-019-0315-8.\n\n\nBommasani, Rishi, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran\nArora, Sydney von Arx, Michael S. Bernstein, et al. 2022. “On the\nOpportunities and Risks of\nFoundation Models.” arXiv. https://doi.org/10.48550/arXiv.2108.07258.\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and\nVasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant\nEffects with a Deep Protein Language Model.” Nature\nGenetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg\nBrockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025.\n“[Evo 2] Genome Modeling and Design\nAcross All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nBrowning, Brian L., Xiaowen Tian, Ying Zhou, and Sharon R. Browning.\n2021. “Fast Two-Stage Phasing of Large-Scale Sequence\nData.” American Journal of Human Genetics 108 (10):\n1880–90. https://doi.org/10.1016/j.ajhg.2021.08.005.\n\n\nBycroft, Clare, Colin Freeman, Desislava Petkova, Gavin Band, Lloyd T.\nElliott, Kevin Sharp, Allan Motyer, et al. 2018. “The\nUK Biobank Resource with Deep Phenotyping and\nGenomic Data.” Nature 562 (7726): 203–9. https://doi.org/10.1038/s41586-018-0579-z.\n\n\nCamillo, Lucas Paulo de Lima, Raghav Sehgal, Jenel Armstrong, Albert T.\nHiggins-Chen, Steve Horvath, and Bo Wang. 2024.\n“CpGPT: A Foundation Model\nfor DNA Methylation.” bioRxiv. https://doi.org/10.1101/2024.10.24.619766.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE]\nMulti-Omics Single-Cell Data Integration and Regulatory\nInference with Graph-Linked Embedding.” Nature\nBiotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nChafai, Narjice, Ichrak Hayah, Isidore Houaga, and Bouabid Badaoui.\n2023. “A Review of Machine Learning Models Applied to Genomic\nPrediction in Animal Breeding.” Frontiers in Genetics 14\n(September). https://doi.org/10.3389/fgene.2023.1150596.\n\n\nChandak, Payal, Kexin Huang, and Marinka Zitnik. 2023.\n“[PrimeKG] Building a Knowledge Graph to\nEnable Precision Medicine.” Scientific Data 10 (1): 67.\nhttps://doi.org/10.1038/s41597-023-01960-3.\n\n\nChen, Jiayang, Zhihang Hu, Siqi Sun, Qingxiong Tan, Yixuan Wang, Qinze\nYu, Licheng Zong, et al. 2022. “[RNA-FM]\nInterpretable RNA Foundation\nModel from Unannotated Data for\nHighly Accurate RNA\nStructure and Function\nPredictions.” arXiv. https://doi.org/10.48550/arXiv.2204.00300.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou.\n2022. “[DeepSEA Sei] A\nSequence-Based Global Map of Regulatory Activity for Deciphering Human\nGenetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nChen, Liyin. 2025. “Causal Genomics in the\nDeep Learning Era.” MDPI\nAG. https://doi.org/10.20944/preprints202503.2081.v1.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė,\nTaylor Applebaum, Alexander Pritzel, et al. 2023.\n“[AlphaMissense] Accurate Proteome-Wide\nMissense Variant Effect Prediction with\nAlphaMissense.” Science 381 (6664):\neadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nCheng, Wenduo, Zhenqiao Song, Yang Zhang, Shike Wang, Danqing Wang, Muyu\nYang, Lei Li, and Jian Ma. 2024. “DNALONGBENCH:\nA Benchmark Suite\nFor Long-Range DNA\nPrediction Tasks,” October. https://openreview.net/forum?id=opv67PpqLS.\n\n\nChoi, Shing Wan, Timothy Shin-Heng Mak, and Paul F. O’Reilly. 2020.\n“[PRS] Tutorial: A Guide to Performing\nPolygenic Risk Score Analyses.” Nature Protocols 15 (9):\n2759–72. https://doi.org/10.1038/s41596-020-0353-1.\n\n\nChung, Wen-Hung, Shuen-Iu Hung, Hong-Shang Hong, Mo-Song Hsih, Li-Cheng\nYang, Hsin-Chun Ho, Jer-Yuarn Wu, and Yuan-Tsong Chen. 2004. “A\nMarker for Stevens–Johnson Syndrome.”\nNature 428 (6982): 486–86. https://doi.org/10.1038/428486a.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus\nWahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024.\n“[DeepRVAT] Integration of Variant\nAnnotations Using Deep Set Networks Boosts Rare Variant Association\nTesting.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nConsens, Micaela E., Cameron Dufault, Michael Wainberg, Duncan Forster,\nMehran Karimzadeh, Hani Goodarzi, Fabian J. Theis, Alan Moses, and Bo\nWang. 2023. “To Transformers and Beyond:\nLarge Language Models for the\nGenome.” arXiv. https://doi.org/10.48550/arXiv.2311.07621.\n\n\nCorso, Gabriele, Hannes Stärk, Bowen Jing, Regina Barzilay, and Tommi\nJaakkola. 2022. “DiffDock: Diffusion\nSteps, Twists, and Turns for\nMolecular Docking.” arXiv.org.\nhttps://arxiv.org/abs/2210.01776v2.\n\n\nCui, Haotian, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan\nDuan, and Bo Wang. 2024. “scGPT:\nToward Building a Foundation Model for Single-Cell Multi-Omics Using\nGenerative AI.” Nature Methods 21 (8):\n1470–80. https://doi.org/10.1038/s41592-024-02201-0.\n\n\nDabernig-Heinz, Johanna, Mara Lohde, Martin Hölzer, Adriana Cabal, Rick\nConzemius, Christian Brandt, Matthias Kohl, et al. 2024. “A\nMulticenter Study on Accuracy and Reproducibility of Nanopore\nSequencing-Based Genotyping of Bacterial Pathogens.” Journal\nof Clinical Microbiology 62 (9): e00628–24. https://doi.org/10.1128/jcm.00628-24.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez\nCarranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago,\net al. 2023. “Nucleotide Transformer: Building and\nEvaluating Robust Foundation Models for Human Genomics.”\nNature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nDauparas, J., I. Anishchenko, N. Bennett, H. Bai, R. J. Ragotte, L. F.\nMilles, B. I. M. Wicky, et al. 2022. “Robust Deep Learning–Based\nProtein Sequence Design Using ProteinMPNN.”\nScience 378 (6615): 49–56. https://doi.org/10.1126/science.add2187.\n\n\nDavydov, Eugene V., David L. Goode, Marina Sirota, Gregory M. Cooper,\nArend Sidow, and Serafim Batzoglou. 2010. “Identifying a\nHigh Fraction of the Human\nGenome to Be Under Selective\nConstraint Using GERP++.”\nPLOS Computational Biology 6 (12): e1001025. https://doi.org/10.1371/journal.pcbi.1001025.\n\n\nDePristo, Mark A., Eric Banks, Ryan Poplin, Kiran V. Garimella, Jared R.\nMaguire, Christopher Hartl, Anthony A. Philippakis, et al. 2011.\n“A Framework for Variation Discovery and Genotyping Using\nNext-Generation DNA Sequencing Data.” Nature\nGenetics 43 (5): 491–98. https://doi.org/10.1038/ng.806.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.\n“BERT: Pre-Training of Deep\nBidirectional Transformers for\nLanguage Understanding.” arXiv. https://doi.org/10.48550/arXiv.1810.04805.\n\n\nDu, Jingcheng, Peilin Jia, Yulin Dai, Cui Tao, Zhongming Zhao, and Degui\nZhi. 2019. “Gene2vec: Distributed Representation of Genes Based on\nCo-Expression.” BMC Genomics 20 (1): 82. https://doi.org/10.1186/s12864-018-5370-x.\n\n\nEdgar, Ron, Michael Domrachev, and Alex E. Lash. 2002. “Gene\nExpression Omnibus: NCBI Gene\nExpression and Hybridization Array Data Repository.” Nucleic\nAcids Research 30 (1): 207–10. https://doi.org/10.1093/nar/30.1.207.\n\n\nElnaggar, Ahmed, Michael Heinzinger, Christian Dallago, Ghalia Rihawi,\nYu Wang, Llion Jones, Tom Gibbs, et al. 2021.\n“ProtTrans: Towards\nCracking the Language of Life’s\nCode Through\nSelf-Supervised Deep\nLearning and High Performance\nComputing.” arXiv. https://doi.org/10.48550/arXiv.2007.06225.\n\n\nFerruz, Noelia, Steffen Schmidt, and Birte Höcker. 2022.\n“ProtGPT2 Is a Deep Unsupervised Language Model for\nProtein Design.” Nature Communications 13 (1): 4348. https://doi.org/10.1038/s41467-022-32007-7.\n\n\nFinn, Robert D., Jody Clements, and Sean R. Eddy. 2011.\n“HMMER Web Server: Interactive Sequence Similarity\nSearching.” Nucleic Acids Research 39 (suppl_2): W29–37.\nhttps://doi.org/10.1093/nar/gkr367.\n\n\nFishman, Veniamin, Yuri Kuratov, Aleksei Shmelev, Maxim Petrov, Dmitry\nPenzar, Denis Shepelin, Nikolay Chekanov, Olga Kardymon, and Mikhail\nBurtsev. 2025. “GENA-LM: A Family of\nOpen-Source Foundational DNA Language Models for Long\nSequences.” Nucleic Acids Research 53 (2): gkae1310. https://doi.org/10.1093/nar/gkae1310.\n\n\nFrankish, Adam, Mark Diekhans, Anne-Maud Ferreira, Rory Johnson, Irwin\nJungreis, Jane Loveland, Jonathan M Mudge, et al. 2019.\n“GENCODE Reference Annotation for the Human and Mouse\nGenomes.” Nucleic Acids Research 47 (D1): D766–73. https://doi.org/10.1093/nar/gky955.\n\n\nFrazer, Jonathan, Pascal Notin, Mafalda Dias, Aidan Gomez, Joseph K.\nMin, Kelly Brock, Yarin Gal, and Debora S. Marks. 2021.\n“[EVE] Disease Variant Prediction with\nDeep Generative Models of Evolutionary Data.” Nature 599\n(7883): 91–95. https://doi.org/10.1038/s41586-021-04043-8.\n\n\nFudenberg, Geoff, David R. Kelley, and Katherine S. Pollard. 2020.\n“[Akita] Predicting 3D\nGenome Folding from DNA Sequence with\nAkita.” Nature Methods 17 (11): 1111–17. https://doi.org/10.1038/s41592-020-0958-x.\n\n\nGamazon, Eric R., Heather E. Wheeler, Kaanan P. Shah, Sahar V.\nMozaffari, Keston Aquino-Michaels, Robert J. Carroll, Anne E. Eyler, et\nal. 2015. “A Gene-Based Association Method for Mapping Traits\nUsing Reference Transcriptome Data.” Nature Genetics 47\n(9): 1091–98. https://doi.org/10.1038/ng.3367.\n\n\nGao, Ziqi, Chenran Jiang, Jiawen Zhang, Xiaosen Jiang, Lanqing Li,\nPeilin Zhao, Huanming Yang, Yong Huang, and Jia Li. 2023.\n“[HIGH-PPI] Hierarchical\nGraph Learning for Protein–Protein Interaction.” Nature\nCommunications 14 (1): 1093. https://doi.org/10.1038/s41467-023-36736-1.\n\n\nGarrison, Erik, Jouni Sirén, Adam M. Novak, Glenn Hickey, Jordan M.\nEizenga, Eric T. Dawson, William Jones, et al. 2018. “Variation\nGraph Toolkit Improves Read Mapping by Representing Genetic Variation in\nthe Reference.” Nature Biotechnology 36 (9): 875–79. https://doi.org/10.1038/nbt.4227.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024.\n“Delphi: A Deep-Learning\nMethod for Polygenic Risk\nPrediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nGoodwin, Sara, John D. McPherson, and W. Richard McCombie. 2016.\n“Coming of Age: Ten Years of Next-Generation Sequencing\nTechnologies.” Nature Reviews Genetics 17 (6): 333–51.\nhttps://doi.org/10.1038/nrg.2016.49.\n\n\nGrešová, Katarína, Vlastimil Martinek, David Čechák, Petr Šimeček, and\nPanagiotis Alexiou. 2023. “Genomic Benchmarks: A Collection of\nDatasets for Genomic Sequence Classification.” BMC Genomic\nData 24 (1): 25. https://doi.org/10.1186/s12863-023-01123-8.\n\n\nGuo, Fei, Renchu Guan, Yaohang Li, Qi Liu, Xiaowo Wang, Can Yang, and\nJianxin Wang. 2025. “Foundation Models in Bioinformatics.”\nNational Science Review 12 (4): nwaf028. https://doi.org/10.1093/nsr/nwaf028.\n\n\nGusev, Alexander, Arthur Ko, Huwenbo Shi, Gaurav Bhatia, Wonil Chung,\nBrenda W. J. H. Penninx, Rick Jansen, et al. 2016. “Integrative\nApproaches for Large-Scale Transcriptome-Wide Association\nStudies.” Nature Genetics 48 (3): 245–52. https://doi.org/10.1038/ng.3506.\n\n\nHamilton, William L., Rex Ying, and Jure Leskovec. 2017.\n“[GraphSAGE] Inductive\nRepresentation Learning on Large\nGraphs.” arXiv.org. https://arxiv.org/abs/1706.02216v4.\n\n\nHe, Shujun, Baizhen Gao, Rushant Sabnis, and Qing Sun. 2023.\n“Nucleic Transformer: Classifying\nDNA Sequences with\nSelf-Attention and\nConvolutions.” ACS Synthetic Biology 12\n(11): 3205–14. https://doi.org/10.1021/acssynbio.3c00154.\n\n\nHoffmann, Markus, Julian M Poschenrieder, Massimiliano Incudini, Sylvie\nBaier, Amelie Fritz, Andreas Maier, Michael Hartung, et al. 2024.\n“[NeEDL] Network Medicine-Based\nEpistasis Detection in Complex Diseases: Ready for Quantum\nComputing.” Nucleic Acids Research 52 (17): 10144–60. https://doi.org/10.1093/nar/gkae697.\n\n\nHudaiberdiev, Sanjarbek, D. Leland Taylor, Wei Song, Narisu Narisu,\nRedwan M. Bhuiyan, Henry J. Taylor, Xuming Tang, et al. 2023.\n“[TREDNet] Modeling Islet Enhancers\nUsing Deep Learning Identifies Candidate Causal Variants at Loci\nAssociated with T2D and Glycemic Traits.”\nProceedings of the National Academy of Sciences 120 (35):\ne2206612120. https://doi.org/10.1073/pnas.2206612120.\n\n\nIoannidis, Nilah M., Joseph H. Rothstein, Vikas Pejaver, Sumit Middha,\nShannon K. McDonnell, Saurabh Baheti, Anthony Musolf, et al. 2016.\n“REVEL: An Ensemble\nMethod for Predicting the\nPathogenicity of Rare Missense\nVariants.” The American Journal of Human\nGenetics 99 (4): 877–85. https://doi.org/10.1016/j.ajhg.2016.08.016.\n\n\nIshigaki, Kazuyoshi, Saori Sakaue, Chikashi Terao, Yang Luo, Kyuto\nSonehara, Kensuke Yamaguchi, Tiffany Amariuta, et al. 2022.\n“Multi-Ancestry Genome-Wide Association Analyses Identify Novel\nGenetic Mechanisms in Rheumatoid Arthritis.” Nature\nGenetics 54 (11): 1640–51. https://doi.org/10.1038/s41588-022-01213-w.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F.\nMcRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A.\nKosmicki, et al. 2019. “[SpliceAI]\nPredicting Splicing from Primary\nSequence with Deep\nLearning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJagota, Milind, Chengzhong Ye, Carlos Albors, Ruchir Rastogi, Antoine\nKoehl, Nilah Ioannidis, and Yun S. Song. 2023. “Cross-Protein\nTransfer Learning Substantially Improves Disease Variant\nPrediction.” Genome Biology 24 (1): 182. https://doi.org/10.1186/s13059-023-03024-6.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021.\n“DNABERT: Pre-Trained Bidirectional\nEncoder Representations from\nTransformers Model for DNA-Language in\nGenome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nJiang, Tao, Yongzhuang Liu, Yue Jiang, Junyi Li, Yan Gao, Zhe Cui,\nYadong Liu, Bo Liu, and Yadong Wang. 2020. “Long-Read-Based Human\nGenomic Structural Variation Detection with cuteSV.” Genome Biology 21 (1):\n189. https://doi.org/10.1186/s13059-020-02107-y.\n\n\nJumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael\nFigurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021.\n“[AlphaFold2] Highly Accurate Protein\nStructure Prediction with AlphaFold.”\nNature 596 (7873): 583–89. https://doi.org/10.1038/s41586-021-03819-2.\n\n\nJurenaite, Neringa, Daniel León-Periñán, Veronika Donath, Sunna Torge,\nand René Jäkel. 2024. “SetQuence &\nSetOmic: Deep Set Transformers for Whole\nGenome and Exome Tumour Analysis.” BioSystems 235\n(January): 105095. https://doi.org/10.1016/j.biosystems.2023.105095.\n\n\nKagda, Meenakshi S., Bonita Lam, Casey Litton, Corinn Small, Cricket A.\nSloan, Emma Spragins, Forrest Tanaka, et al. 2025. “Data\nNavigation on the ENCODE Portal.” Nature\nCommunications 16 (1): 9592. https://doi.org/10.1038/s41467-025-64343-9.\n\n\nKarczewski, Konrad J., Laurent C. Francioli, Grace Tiao, Beryl B.\nCummings, Jessica Alföldi, Qingbo Wang, Ryan L. Collins, et al. 2020.\n“The Mutational Constraint Spectrum Quantified from Variation in\n141,456 Humans.” Nature 581 (7809): 434–43. https://doi.org/10.1038/s41586-020-2308-7.\n\n\nKelley, David R. 2020. “[Basenji2]\nCross-Species Regulatory Sequence Activity\nPrediction.” PLOS Computational Biology 16 (7):\ne1008050. https://doi.org/10.1371/journal.pcbi.1008050.\n\n\nKelley, David R., Yakir A. Reshef, Maxwell Bileschi, David Belanger,\nCory Y. McLean, and Jasper Snoek. 2018. “[Basenji2]\nSequential Regulatory Activity Prediction Across\nChromosomes with Convolutional Neural Networks.” Genome\nResearch 28 (5): 739–50. https://doi.org/10.1101/gr.227819.117.\n\n\nKipf, Thomas N., and Max Welling. 2017.\n“Semi-Supervised Classification with\nGraph Convolutional\nNetworks.” arXiv. https://doi.org/10.48550/arXiv.1609.02907.\n\n\nKircher, Martin, Daniela M. Witten, Preti Jain, Brian J. O’Roak, Gregory\nM. Cooper, and Jay Shendure. 2014. “A General Framework for\nEstimating the Relative Pathogenicity of Human Genetic Variants.”\nNature Genetics 46 (3): 310–15. https://doi.org/10.1038/ng.2892.\n\n\nKrusche, Peter, Len Trigg, Paul C. Boutros, Christopher E. Mason,\nFrancisco M. De La Vega, Benjamin L. Moore, Mar Gonzalez-Porta, et al.\n2019. “Best Practices for Benchmarking\nGermline Small Variant\nCalls in Human Genomes.”\nNature Biotechnology 37 (5): 555–60. https://doi.org/10.1038/s41587-019-0054-x.\n\n\nKundaje, Anshul, Wouter Meuleman, Jason Ernst, Misha Bilenky, Angela\nYen, Alireza Heravi-Moussavi, Pouya Kheradpour, et al. 2015.\n“Integrative Analysis of 111 Reference Human Epigenomes.”\nNature 518 (7539): 317–30. https://doi.org/10.1038/nature14248.\n\n\nKurki, Mitja I., Juha Karjalainen, Priit Palta, Timo P. Sipilä, Kati\nKristiansson, Kati M. Donner, Mary P. Reeve, et al. 2023.\n“FinnGen Provides Genetic Insights from a\nWell-Phenotyped Isolated Population.” Nature 613 (7944):\n508–18. https://doi.org/10.1038/s41586-022-05473-8.\n\n\nLambert, Samuel A., Laurent Gil, Simon Jupp, Scott C. Ritchie, Yu Xu,\nAnnalisa Buniello, Aoife McMahon, et al. 2021. “The\nPolygenic Score Catalog as an\nOpen Database for Reproducibility and Systematic Evaluation.”\nNature Genetics 53 (4): 420–25. https://doi.org/10.1038/s41588-021-00783-5.\n\n\nLandrum, Melissa J, Jennifer M Lee, Mark Benson, Garth R Brown, Chen\nChao, Shanmuga Chitipiralla, Baoshan Gu, et al. 2018.\n“ClinVar: Improving Access to Variant Interpretations\nand Supporting Evidence.” Nucleic Acids Research 46\n(D1): D1062–67. https://doi.org/10.1093/nar/gkx1153.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam,\nAmit R. Majithia, and Trey Ideker. 2025. “[G2PT]\nA Genotype-Phenotype Transformer to Assess and Explain\nPolygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai,\net al. 2024. “CGMega: Explainable Graph Neural\nNetwork Framework with Attention Mechanisms for Cancer Gene Module\nDissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Heng. 2013. “Aligning Sequence Reads, Clone Sequences and\nAssembly Contigs with BWA-MEM.” arXiv.\nhttps://doi.org/10.48550/arXiv.1303.3997.\n\n\n———. 2014. “Towards Better Understanding\nof Artifacts in Variant Calling\nfrom High-Coverage\nSamples.” Bioinformatics 30 (20): 2843–51.\nhttps://doi.org/10.1093/bioinformatics/btu356.\n\n\n———. 2018. “Minimap2: Pairwise Alignment for Nucleotide\nSequences.” Bioinformatics 34 (18): 3094–3100. https://doi.org/10.1093/bioinformatics/bty191.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and\nYunping Zhu. 2022. “MoGCN: A\nMulti-Omics Integration\nMethod Based on Graph\nConvolutional Network for Cancer\nSubtype Analysis.” Frontiers in\nGenetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nLi, Zehui, Akashaditya Das, William A. V. Beardall, Yiren Zhao, and\nGuy-Bart Stan. 2023. “Genomic Interpreter:\nA Hierarchical Genomic\nDeep Neural Network with\n1D Shifted Window\nTransformer.” arXiv. https://doi.org/10.48550/arXiv.2306.05143.\n\n\nLi, Zehui, Vallijah Subasri, Yifei Shen, Dongsheng Li, Yiren Zhao,\nGuy-Bart Stan, and Caihua Shan. 2025. “Omni-DNA:\nA Unified Genomic\nFoundation Model for\nCross-Modal and\nMulti-Task Learning.”\narXiv. https://doi.org/10.48550/arXiv.2502.03499.\n\n\nLiao, Wen-Wei, Mobin Asri, Jana Ebler, Daniel Doerr, Marina Haukness,\nGlenn Hickey, Shuangjia Lu, et al. 2023. “A Draft Human Pangenome\nReference.” Nature 617 (7960): 312–24. https://doi.org/10.1038/s41586-023-05896-x.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting\nLu, Allan dos Santos Costa, et al. 2022. “[ESM-2]\nLanguage Models of Protein Sequences at the Scale of\nEvolution Enable Accurate Structure Prediction.” bioRxiv. https://doi.org/10.1101/2022.07.20.500902.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and\nDavid R. Kelley. 2025. “[Borzoi]\nPredicting RNA-Seq Coverage from\nDNA Sequence as a Unifying Model of Gene\nRegulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nLiu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang,\nYucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025.\n“Life-Code: Central Dogma\nModeling with Multi-Omics\nSequence Unification.” arXiv. https://doi.org/10.48550/arXiv.2502.07299.\n\n\nLoh, Po-Ru, Petr Danecek, Pier Francesco Palamara, Christian\nFuchsberger, Yakir A Reshef, Hilary K Finucane, Sebastian Schoenherr, et\nal. 2016. “Reference-Based Phasing Using the\nHaplotype Reference Consortium\nPanel.” Nature Genetics 48 (11): 1443–48. https://doi.org/10.1038/ng.3679.\n\n\nMadani, Ali, Ben Krause, Eric R. Greene, Subu Subramanian, Benjamin P.\nMohr, James M. Holton, Jose Luis Olmos, et al. 2023. “Large\nLanguage Models Generate Functional Protein Sequences Across Diverse\nFamilies.” Nature Biotechnology 41 (8): 1099–1106. https://doi.org/10.1038/s41587-022-01618-2.\n\n\nMallal, Simon, Elizabeth Phillips, Giampiero Carosi, Jean-Michel Molina,\nCassy Workman, Janez Tomažič, Eva Jägel-Guedes, et al. 2008.\n“HLA-B*5701 Screening for\nHypersensitivity to Abacavir.” New\nEngland Journal of Medicine 358 (6): 568–79. https://doi.org/10.1056/NEJMoa0706135.\n\n\nManolio, Teri A., Francis S. Collins, Nancy J. Cox, David B. Goldstein,\nLucia A. Hindorff, David J. Hunter, Mark I. McCarthy, et al. 2009.\n“Finding the Missing Heritability of Complex Diseases.”\nNature 461 (7265): 747–53. https://doi.org/10.1038/nature08494.\n\n\nManzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025.\n“Comparative Analysis of Deep\nLearning Models for Predicting\nCausative Regulatory\nVariants.” bioRxiv: The Preprint Server for\nBiology, June, 2025.05.19.654920. https://doi.org/10.1101/2025.05.19.654920.\n\n\nMarees, Andries T., Hilde de Kluiver, Sven Stringer, Florence Vorspan,\nEmmanuel Curis, Cynthia Marie-Claire, and Eske M. Derks. 2018.\n“[GWAS] A Tutorial on Conducting\nGenome-Wide Association Studies: Quality Control and\nStatistical Analysis.” International Journal of Methods in\nPsychiatric Research 27 (2): e1608. https://doi.org/10.1002/mpr.1608.\n\n\nMarquet, Céline, Julius Schlensok, Marina Abakarova, Burkhard Rost, and\nElodie Laine. 2024. “[VespaG]\nExpert-Guided Protein Language Models Enable Accurate and\nBlazingly Fast Fitness Prediction.” Bioinformatics 40\n(11): btae621. https://doi.org/10.1093/bioinformatics/btae621.\n\n\nMaurano, Matthew T., Richard Humbert, Eric Rynes, Robert E. Thurman,\nEric Haugen, Hao Wang, Alex P. Reynolds, et al. 2012. “Systematic\nLocalization of Common\nDisease-Associated Variation in\nRegulatory DNA.” Science 337\n(6099): 1190–95. https://doi.org/10.1126/science.1222794.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill\nVishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel,\nRonnie Rajan, and Shadab Khan. 2025. “BioToken and\nBioFM – Biologically-Informed\nTokenization Enables Accurate and\nEfficient Genomic Foundation\nModels.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nMeier, Joshua, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu, and\nAlexander Rives. 2021. “[ESM-1v]\nLanguage Models Enable Zero-Shot Prediction of the Effects\nof Mutations on Protein Function.” bioRxiv. https://doi.org/10.1101/2021.07.09.450648.\n\n\nMirdita, Milot, Konstantin Schütze, Yoshitaka Moriwaki, Lim Heo, Sergey\nOvchinnikov, and Martin Steinegger. 2022. “ColabFold:\nMaking Protein Folding Accessible to All.” Nature\nMethods 19 (6): 679–82. https://doi.org/10.1038/s41592-022-01488-1.\n\n\nMorales, Joannella, Shashikant Pujar, Jane E. Loveland, Alex Astashyn,\nRuth Bennett, Andrew Berry, Eric Cox, et al. 2022. “A Joint\nNCBI and EMBL-EBI Transcript Set\nfor Clinical Genomics and Research.” Nature 604 (7905):\n310–15. https://doi.org/10.1038/s41586-022-04558-8.\n\n\nMountjoy, Edward, Ellen M. Schmidt, Miguel Carmona, Jeremy\nSchwartzentruber, Gareth Peat, Alfredo Miranda, Luca Fumis, et al. 2021.\n“An Open Approach to Systematically Prioritize Causal Variants and\nGenes at All Published Human GWAS Trait-Associated\nLoci.” Nature Genetics 53 (11): 1527–33. https://doi.org/10.1038/s41588-021-00945-5.\n\n\nMukherjee, Sumit, Zachary R. McCaw, Jingwen Pei, Anna Merkoulovitch, Tom\nSoare, Raghav Tandon, David Amar, et al. 2024.\n“EmbedGEM: A Framework to Evaluate the Utility of\nEmbeddings for Genetic Discovery.” Bioinformatics\nAdvances 4 (1). https://doi.org/10.1093/bioadv/vbae135.\n\n\nNaghipourfar, Mohsen, Siyu Chen, Mathew K. Howard, Christian B.\nMacdonald, Ali Saberi, Timo Hagen, Mohammad R. K. Mofrad, Willow\nCoyote-Maestas, and Hani Goodarzi. 2024. “[cdsFM - EnCodon/DeCodon]\nA Suite of Foundation\nModels Captures the Contextual\nInterplay Between Codons.”\nbioRxiv. https://doi.org/10.1101/2024.10.10.617568.\n\n\nNg, Pauline C., and Steven Henikoff. 2003. “SIFT:\nPredicting Amino Acid Changes That Affect Protein\nFunction.” Nucleic Acids Research 31 (13): 3812–14. https://doi.org/10.1093/nar/gkg509.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum\nBirch-Sykes, Michael Wornow, Aman Patel, et al. 2023.\n“HyenaDNA: Long-Range\nGenomic Sequence Modeling at\nSingle Nucleotide\nResolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nNielsen, Rasmus, Joshua S. Paul, Anders Albrechtsen, and Yun S. Song.\n2011. “Genotype and SNP Calling from Next-Generation\nSequencing Data.” Nature Reviews. Genetics 12 (6):\n443–51. https://doi.org/10.1038/nrg2986.\n\n\nNotin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk,\nSteffanie Paul, Han Spinner, Nathan Rollins, et al. 2023.\n“ProteinGym: Large-Scale\nBenchmarks for Protein Fitness\nPrediction and Design.” Advances in\nNeural Information Processing Systems 36 (December): 64331–79. https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html.\n\n\nNurk, Sergey, Sergey Koren, Arang Rhie, Mikko Rautiainen, Andrey V.\nBzikadze, Alla Mikheenko, Mitchell R. Vollger, et al. 2022. “The\nComplete Sequence of a Human Genome.” Science 376\n(6588): 44–53. https://doi.org/10.1126/science.abj6987.\n\n\nO’Connell, Jared, Deepti Gurdasani, Olivier Delaneau, Nicola Pirastu,\nSheila Ulivi, Massimiliano Cocca, Michela Traglia, et al. 2014. “A\nGeneral Approach for Haplotype\nPhasing Across the Full Spectrum\nof Relatedness.” PLOS Genetics 10 (4):\ne1004234. https://doi.org/10.1371/journal.pgen.1004234.\n\n\nO’Leary, Nuala A., Mathew W. Wright, J. Rodney Brister, Stacy Ciufo,\nDiana Haddad, Rich McVeigh, Bhanu Rajput, et al. 2016. “Reference\nSequence (RefSeq) Database at NCBI: Current\nStatus, Taxonomic Expansion, and Functional Annotation.”\nNucleic Acids Research 44 (D1): D733–45. https://doi.org/10.1093/nar/gkv1189.\n\n\nOrenbuch, Rose, Courtney A. Shearer, Aaron W. Kollasch, Aviv D. Spinner,\nThomas Hopf, Lood van Niekerk, Dinko Franceschi, Mafalda Dias, Jonathan\nFrazer, and Debora S. Marks. 2025. “[popEVE] Proteome-Wide Model for Human\nDisease Genetics.” Nature Genetics, November, 1–10. https://doi.org/10.1038/s41588-025-02400-1.\n\n\n“PacificBiosciences/Pbsv.” 2025. PacBio. https://github.com/PacificBiosciences/pbsv.\n\n\nPasaniuc, Bogdan, and Alkes L. Price. 2016. “Dissecting the\nGenetics of Complex Traits Using Summary Association Statistics.”\nNature Reviews Genetics 18 (2): 117–27. https://doi.org/10.1038/nrg.2016.142.\n\n\nPatterson, Nick, Alkes L. Price, and David Reich. 2006.\n“Population Structure and\nEigenanalysis.” PLOS Genetics 2 (12): e190.\nhttps://doi.org/10.1371/journal.pgen.0020190.\n\n\nPe’er, Itsik, Roman Yelensky, David Altshuler, and Mark J. Daly. 2008.\n“Estimation of the Multiple Testing Burden for Genomewide\nAssociation Studies of Nearly All Common Variants.” Genetic\nEpidemiology 32 (4): 381–85. https://doi.org/10.1002/gepi.20303.\n\n\nPearce, James D., Sara E. Simmonds, Gita Mahmoudabadi, Lakshmi Krishnan,\nGiovanni Palla, Ana-Maria Istrate, Alexander Tarashansky, et al. 2025.\n“[TranscriptFormer]\nCross-Species Generative\nCell Atlas Across 1.5\nBillion Years of Evolution:\nThe TranscriptFormer Single-Cell\nModel.” bioRxiv. https://doi.org/10.1101/2025.04.25.650731.\n\n\nPejaver, Vikas, Alicia B. Byrne, Bing-Jian Feng, Kymberleigh A. Pagel,\nSean D. Mooney, Rachel Karchin, Anne O’Donnell-Luria, et al. 2022.\n“Calibration of Computational Tools for Missense Variant\nPathogenicity Classification and ClinGen Recommendations\nfor PP3/BP4 Criteria.” American\nJournal of Human Genetics 109 (12): 2163–77. https://doi.org/10.1016/j.ajhg.2022.10.013.\n\n\nPoplin, Ryan, Pi-Chuan Chang, David Alexander, Scott Schwartz, Thomas\nColthurst, Alexander Ku, Dan Newburger, et al. 2018.\n“[DeepVariant] A Universal\nSNP and Small-Indel Variant Caller Using Deep Neural\nNetworks.” Nature Biotechnology 36 (10): 983–87. https://doi.org/10.1038/nbt.4235.\n\n\nPrice, Alkes L., Nick J. Patterson, Robert M. Plenge, Michael E.\nWeinblatt, Nancy A. Shadick, and David Reich. 2006. “Principal\nComponents Analysis Corrects for Stratification in Genome-Wide\nAssociation Studies.” Nature Genetics 38 (8): 904–9. https://doi.org/10.1038/ng1847.\n\n\nRaffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,\nMichael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2019.\n“Exploring the Limits of Transfer\nLearning with a Unified\nText-to-Text Transformer.”\narXiv. https://doi.org/10.48550/arXiv.1910.10683.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025.\n“[MIFM] Multiple Instance Fine-Mapping:\nPredicting Causal Regulatory Variants with a Deep Sequence\nModel.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRao, Roshan, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Xi Chen, John\nCanny, Pieter Abbeel, and Yun S. Song. 2019. “Evaluating\nProtein Transfer Learning with\nTAPE.” arXiv. https://doi.org/10.48550/arXiv.1906.08230.\n\n\n“RealTimeGenomics/Rtg-Core.” 2025. Real Time\nGenomics. https://github.com/RealTimeGenomics/rtg-core.\n\n\nRegev, Aviv, Sarah A Teichmann, Eric S Lander, Ido Amit, Christophe\nBenoist, Ewan Birney, Bernd Bodenmiller, et al. 2017. “The\nHuman Cell Atlas.” Edited\nby Thomas R Gingeras. eLife 6 (December): e27041. https://doi.org/10.7554/eLife.27041.\n\n\nRehm, Heidi L., Jonathan S. Berg, Lisa D. Brooks, Carlos D. Bustamante,\nJames P. Evans, Melissa J. Landrum, David H. Ledbetter, et al. 2015.\n“ClinGen — The Clinical\nGenome Resource.” New England\nJournal of Medicine 372 (23): 2235–42. https://doi.org/10.1056/NEJMsr1406261.\n\n\nRemmert, Michael, Andreas Biegert, Andreas Hauser, and Johannes Söding.\n2012. “HHblits: Lightning-Fast Iterative Protein\nSequence Searching by HMM-HMM\nAlignment.” Nature Methods 9 (2): 173–75. https://doi.org/10.1038/nmeth.1818.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and\nMartin Kircher. 2019. “CADD: Predicting the\nDeleteriousness of Variants Throughout the Human Genome.”\nNucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nRiesselman, Adam J., John B. Ingraham, and Debora S. Marks. 2018.\n“Deep Generative Models of Genetic Variation Capture the Effects\nof Mutations.” Nature Methods 15 (10): 816–22. https://doi.org/10.1038/s41592-018-0138-4.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin,\nJason Liu, Demi Guo, et al. 2021. “[ESM-1b]\nBiological Structure and Function Emerge from Scaling\nUnsupervised Learning to 250 Million Protein Sequences.”\nProceedings of the National Academy of Sciences of the United States\nof America 118 (15): e2016239118. https://doi.org/10.1073/pnas.2016239118.\n\n\nRobinson, James, Dominic J Barker, Xenia Georgiou, Michael A Cooper,\nPaul Flicek, and Steven G E Marsh. 2020.\n“IPD-IMGT/HLA\nDatabase.” Nucleic Acids Research 48 (D1):\nD948–55. https://doi.org/10.1093/nar/gkz950.\n\n\nSakaue, Saori, Saisriram Gurajala, Michelle Curtis, Yang Luo, Wanson\nChoi, Kazuyoshi Ishigaki, Joyce B. Kang, et al. 2023. “Tutorial: A\nStatistical Genetics Guide to Identifying HLA Alleles\nDriving Complex Disease.” Nature Protocols 18 (9):\n2625–41. https://doi.org/10.1038/s41596-023-00853-4.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch.\n2024. “[GROVER] DNA Language Model\nGROVER Learns Sequence Context in the Human Genome.”\nNature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nSchiff, Yair, Chia-Hsiang Kao, Aaron Gokaslan, Tri Dao, Albert Gu, and\nVolodymyr Kuleshov. 2024. “Caduceus:\nBi-Directional Equivariant\nLong-Range DNA\nSequence Modeling.” arXiv. https://doi.org/10.48550/arXiv.2403.03234.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and\nMartin Kircher. 2024. “CADD V1.7: Using Protein\nLanguage Models, Regulatory CNNs and Other Nucleotide-Level\nScores to Improve Genome-Wide Variant Predictions.” Nucleic\nAcids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nShafin, Kishwar, Trevor Pesout, Pi-Chuan Chang, Maria Nattestad, Alexey\nKolesnikov, Sidharth Goel, Gunjan Baid, et al. 2021.\n“Haplotype-Aware Variant Calling with\nPEPPER-Margin-DeepVariant Enables\nHigh Accuracy in Nanopore Long-Reads.” Nature Methods 18\n(11): 1322–32. https://doi.org/10.1038/s41592-021-01299-w.\n\n\nSherry, S. T., M.-H. Ward, M. Kholodov, J. Baker, L. Phan, E. M.\nSmigielski, and K. Sirotkin. 2001. “dbSNP: The NCBI Database of Genetic\nVariation.” Nucleic Acids Research 29 (1): 308–11. https://doi.org/10.1093/nar/29.1.308.\n\n\nSiepel, Adam, Gill Bejerano, Jakob S. Pedersen, Angie S. Hinrichs,\nMinmei Hou, Kate Rosenbloom, Hiram Clawson, et al. 2005.\n“[PhastCons] Evolutionarily Conserved\nElements in Vertebrate, Insect, Worm, and Yeast Genomes.”\nGenome Research 15 (8): 1034–50. https://doi.org/10.1101/gr.3715005.\n\n\nSirugo, Giorgio, Scott M. Williams, and Sarah A. Tishkoff. 2019.\n“The Missing Diversity in\nHuman Genetic Studies.”\nCell 177 (1): 26–31. https://doi.org/10.1016/j.cell.2019.02.048.\n\n\nSmolka, Moritz, Luis F. Paulin, Christopher M. Grochowski, Dominic W.\nHorner, Medhat Mahmoud, Sairam Behera, Ester Kalef-Ezra, et al. 2024.\n“Detection of Mosaic and Population-Level Structural Variants with\nSniffles2.” Nature Biotechnology 42 (10):\n1571–80. https://doi.org/10.1038/s41587-023-02024-y.\n\n\nSollis, Elliot, Abayomi Mosaku, Ala Abid, Annalisa Buniello, Maria\nCerezo, Laurent Gil, Tudor Groza, et al. 2023. “The\nNHGRI-EBI GWAS\nCatalog: Knowledgebase and Deposition Resource.”\nNucleic Acids Research 51 (D1): D977–85. https://doi.org/10.1093/nar/gkac1010.\n\n\nSong, Li, Gali Bai, X. Shirley Liu, Bo Li, and Heng Li. 2022.\n“T1K: Efficient and Accurate KIR and\nHLA Genotyping with Next-Generation Sequencing\nData.” bioRxiv. https://doi.org/10.1101/2022.10.26.513955.\n\n\nSteinegger, Martin, and Johannes Söding. 2017.\n“MMseqs2 Enables Sensitive Protein Sequence Searching\nfor the Analysis of Massive Data Sets.” Nature\nBiotechnology 35 (11): 1026–28. https://doi.org/10.1038/nbt.3988.\n\n\nSullivan, Patrick F., Jennifer R. S. Meadows, Steven Gazal, BaDoi N.\nPhan, Xue Li, Diane P. Genereux, Michael X. Dong, et al. 2023.\n“Leveraging Base-Pair Mammalian Constraint to Understand Genetic\nVariation and Human Disease.” Science 380 (6643):\neabn2937. https://doi.org/10.1126/science.abn2937.\n\n\nSuzek, Baris E., Hongzhan Huang, Peter McGarvey, Raja Mazumder, and\nCathy H. Wu. 2007. “UniRef: Comprehensive and\nNon-Redundant UniProt Reference Clusters.”\nBioinformatics 23 (10): 1282–88. https://doi.org/10.1093/bioinformatics/btm098.\n\n\n“The Genome Aggregation\nDatabase (gnomAD).” n.d.\nAccessed July 3, 2025. https://www.nature.com/immersive/d42859-020-00002-x/index.html.\n\n\nThe GTEx Consortium. 2020. “The GTEx\nConsortium Atlas of Genetic Regulatory Effects Across Human\nTissues.” Science 369 (6509): 1318–30. https://doi.org/10.1126/science.aaz1776.\n\n\nThe Tabula Sapiens Consortium. 2022. “The Tabula\nSapiens: A Multiple-Organ, Single-Cell\nTranscriptomic Atlas of Humans.” Science 376 (6594):\neabl4896. https://doi.org/10.1126/science.abl4896.\n\n\nTheodoris, Christina V., Ling Xiao, Anant Chopra, Mark D. Chaffin, Zeina\nR. Al Sayed, Matthew C. Hill, Helene Mantineo, et al. 2023.\n“[Geneformer] Transfer Learning Enables\nPredictions in Network Biology.” Nature 618 (7965):\n616–24. https://doi.org/10.1038/s41586-023-06139-9.\n\n\nTrop, Evan, Yair Schiff, Edgar Mariano Marroquin, Chia Hsiang Kao, Aaron\nGokaslan, McKinley Polen, Mingyi Shao, et al. 2024. “The\nGenomics Long-Range\nBenchmark: Advancing DNA\nLanguage Models,” October. https://openreview.net/forum?id=8O9HLDrmtq.\n\n\nVan der Auwera, Geraldine A., Mauricio O. Carneiro, Christopher Hartl,\nRyan Poplin, Guillermo del Angel, Ami Levy-Moonshine, Tadeusz Jordan, et\nal. 2018. “From FastQ Data to\nHigh-Confidence Variant\nCalls: The Genome\nAnalysis Toolkit Best\nPractices Pipeline.” Current\nProtocols in Bioinformatics 43 (1): 11.10.1–33. https://doi.org/10.1002/0471250953.bi1110s43.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.\n“Attention Is All You\nNeed.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVeličković, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero,\nPietro Liò, and Yoshua Bengio. 2018. “Graph Attention\nNetworks.” arXiv. https://doi.org/10.48550/arXiv.1710.10903.\n\n\nVerma, Anurag, Jennifer E. Huffman, Alex Rodriguez, Mitchell Conery,\nMolei Liu, Yuk-Lam Ho, Youngdae Kim, et al. 2024. “Diversity and\nScale: Genetic Architecture of 2068 Traits in the\nVA Million Veteran\nProgram.” Science 385 (6706): eadj1182. https://doi.org/10.1126/science.adj1182.\n\n\nVilhjálmsson, Bjarni J., Jian Yang, Hilary K. Finucane, Alexander Gusev,\nSara Lindström, Stephan Ripke, Giulio Genovese, et al. 2015.\n“Modeling Linkage Disequilibrium\nIncreases Accuracy of Polygenic\nRisk Scores.” American Journal of\nHuman Genetics 97 (4): 576–92. https://doi.org/10.1016/j.ajhg.2015.09.001.\n\n\nVõsa, Urmo, Annique Claringbould, Harm-Jan Westra, Marc Jan Bonder,\nPatrick Deelen, Biao Zeng, Holger Kirsten, et al. 2021.\n“Large-Scale Cis- and Trans-eQTL\nAnalyses Identify Thousands of Genetic Loci and Polygenic Scores That\nRegulate Blood Gene Expression.” Nature Genetics 53 (9):\n1300–1310. https://doi.org/10.1038/s41588-021-00913-z.\n\n\nWatson, Joseph L., David Juergens, Nathaniel R. Bennett, Brian L.\nTrippe, Jason Yim, Helen E. Eisenach, Woody Ahern, et al. 2023.\n“De Novo Design of Protein Structure and Function with\nRFdiffusion.” Nature 620 (7976): 1089–1100.\nhttps://doi.org/10.1038/s41586-023-06415-8.\n\n\nWenger, Aaron M., Paul Peluso, William J. Rowell, Pi-Chuan Chang,\nRichard J. Hall, Gregory T. Concepcion, Jana Ebler, et al. 2019.\n“Accurate Circular Consensus Long-Read Sequencing Improves Variant\nDetection and Assembly of a Human Genome.” Nature\nBiotechnology 37 (10): 1155–62. https://doi.org/10.1038/s41587-019-0217-9.\n\n\nWhirl-Carrillo, M, E M McDonagh, J M Hebert, L Gong, K Sangkuhl, C F\nThorn, R B Altman, and T E Klein. 2012. “Pharmacogenomics\nKnowledge for Personalized\nMedicine.” Clinical Pharmacology &\nTherapeutics 92 (4): 414–17. https://doi.org/10.1038/clpt.2012.96.\n\n\nWohlwend, Jeremy, Gabriele Corso, Saro Passaro, Noah Getz, Mateo Reveiz,\nKen Leidal, Wojtek Swiderski, et al. 2025. “Boltz-1\nDemocratizing Biomolecular\nInteraction Modeling.” bioRxiv. https://doi.org/10.1101/2024.11.19.624167.\n\n\nWu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray,\nPeter M. Visscher, and Jian Zeng. 2024. “Genome-Wide Fine-Mapping\nImproves Identification of Causal Variants.” Research\nSquare, August, rs.3.rs–4759390. https://doi.org/10.21203/rs.3.rs-4759390/v1.\n\n\nYan, Binghao, Yunbi Nam, Lingyao Li, Rebecca A. Deek, Hongzhe Li, and\nSiyuan Ma. 2025. “Recent Advances in Deep Learning and Language\nModels for Studying the Microbiome.” Frontiers in\nGenetics 15 (January). https://doi.org/10.3389/fgene.2024.1494474.\n\n\nYang, Jian, Beben Benyamin, Brian P. McEvoy, Scott Gordon, Anjali K.\nHenders, Dale R. Nyholt, Pamela A. Madden, et al. 2010. “Common\nSNPs Explain a Large Proportion of the Heritability for\nHuman Height.” Nature Genetics 42 (7): 565–69. https://doi.org/10.1038/ng.608.\n\n\nYang, Zhilin, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan\nSalakhutdinov, and Quoc V. Le. 2020. “XLNet:\nGeneralized Autoregressive\nPretraining for Language\nUnderstanding.” arXiv. https://doi.org/10.48550/arXiv.1906.08237.\n\n\nYeo, Gene, and Christopher B. Burge. 2004. “Maximum\nEntropy Modeling of Short\nSequence Motifs with Applications\nto RNA Splicing Signals.”\nJournal of Computational Biology 11 (2-3): 377–94. https://doi.org/10.1089/1066527041410418.\n\n\nYuan, Qiuyue, and Zhana Duren. 2025. “[LINGER]\nInferring Gene Regulatory Networks from Single-Cell\nMultiome Data Using Atlas-Scale External Data.” Nature\nBiotechnology 43 (2): 247–57. https://doi.org/10.1038/s41587-024-02182-7.\n\n\nYun, Taedong, Helen Li, Pi-Chuan Chang, Michael F Lin, Andrew Carroll,\nand Cory Y McLean. 2021. “Accurate, Scalable Cohort Variant Calls\nUsing DeepVariant and GLnexus.”\nBioinformatics 36 (24): 5582–89. https://doi.org/10.1093/bioinformatics/btaa1081.\n\n\nZheng, Rongbin, Changxin Wan, Shenglin Mei, Qian Qin, Qiu Wu, Hanfei\nSun, Chen-Hao Chen, et al. 2019. “Cistrome Data\nBrowser: Expanded Datasets and New Tools for Gene\nRegulatory Analysis.” Nucleic Acids Research 47 (D1):\nD729–35. https://doi.org/10.1093/nar/gky1094.\n\n\nZheng, Zhenxian, Shumin Li, Junhao Su, Amy Wing-Sze Leung, Tak-Wah Lam,\nand Ruibang Luo. 2022. “Symphonizing Pileup and Full-Alignment for\nDeep Learning-Based Long-Read Variant Calling.” Nature\nComputational Science 2 (12): 797–803. https://doi.org/10.1038/s43588-022-00387-x.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K.\nWong, and Olga G. Troyanskaya. 2018. “[Expecto]\nDeep Learning Sequence-Based Ab Initio Prediction of\nVariant Effects on Expression and Disease Risk.” Nature\nGenetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA]\nPredicting Effects of Noncoding Variants with Deep\nLearning–Based Sequence Model.” Nature Methods 12 (10):\n931–34. https://doi.org/10.1038/nmeth.3547.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and\nHan Liu. 2024. “DNABERT-2: Efficient\nFoundation Model and Benchmark\nFor Multi-Species\nGenome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.\n\n\nZook, Justin M., Jennifer McDaniel, Nathan D. Olson, Justin Wagner,\nHemang Parikh, Haynes Heaton, Sean A. Irvine, et al. 2019. “An\nOpen Resource for Accurately Benchmarking Small Variant and Reference\nCalls.” Nature Biotechnology 37 (5): 561–66. https://doi.org/10.1038/s41587-019-0074-6.\n\n\nZvyagin, Maxim, Alexander Brace, Kyle Hippe, Yuntian Deng, Bin Zhang,\nCindy Orozco Bohorquez, Austin Clyde, et al. 2022.\n“GenSLMs: Genome-Scale Language Models\nReveal SARS-CoV-2 Evolutionary\nDynamics.” bioRxiv. https://doi.org/10.1101/2022.10.10.511571.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "app-a-dl.html",
    "href": "app-a-dl.html",
    "title": "Appendix A — Deep Learning Primer",
    "section": "",
    "text": "A.1 From Linear Models to Deep Networks\nThis appendix gives a compact introduction to deep learning for readers who are comfortable with genomics but less familiar with modern neural networks. The goal is not to replace a full machine learning textbook, but to provide enough background to make the models in Chapters 5–19 feel intuitive rather than magical.\nWe focus on:\nWhere possible, we connect directly to the genomic case studies in the main text (DeepSEA, ExPecto, SpliceAI, Enformer, genomic language models, and GFMs).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#from-linear-models-to-deep-networks",
    "href": "app-a-dl.html#from-linear-models-to-deep-networks",
    "title": "Appendix A — Deep Learning Primer",
    "section": "",
    "text": "A.1.1 Models as Functions\nAt its core, a predictive model is just a function:\n\\[\nf_\\theta: x \\mapsto \\hat{y}\n\\tag{A.1}\\]\nwhere:\n\n\\(x\\) is an input (e.g., a one-hot encoded DNA sequence, variant-level features, or a patient feature vector).\n\n\\(\\hat{y}\\) is a prediction (e.g., probability of a histone mark, gene expression level, disease risk).\n\n\\(\\theta\\) are the parameters (weights) of the model.\n\nIn classical genomics workflows, \\(f_\\theta\\) might be:\n\nLogistic regression (for case–control status)\n\nLinear regression (for quantitative traits)\n\nRandom forests or gradient boosting (for variant pathogenicity scores)\n\nDeep learning keeps the same basic structure but allows \\(f_\\theta\\) to be a much more flexible, high-capacity function built by composing many simple operations.\n\n\nA.1.2 Linear Models vs Neural Networks\nA simple linear model for classification looks like:\n\\[\n\\hat{y} = \\sigma(w^\\top x + b),\n\\]\nwhere \\(w\\) and \\(b\\) are parameters and \\(\\sigma(\\cdot)\\) is a squashing nonlinearity (e.g., the logistic function). The model draws a single separating hyperplane in feature space.\nA neural network generalizes this by stacking multiple linear transformations with nonlinear activation functions:\n\\[\n\\begin{aligned}\nh_1 &= \\phi(W_1 x + b_1) \\\\\nh_2 &= \\phi(W_2 h_1 + b_2) \\\\\n&\\vdots \\\\\n\\hat{y} &= g(W_L h_{L-1} + b_L)\n\\end{aligned}\n\\]\nwhere:\n\nEach \\(W_\\ell, b_\\ell\\) is a layer’s weight matrix and bias.\n\n\\(\\phi(\\cdot)\\) is a nonlinear activation (e.g., ReLU).\n\n\\(g(\\cdot)\\) is a final activation (e.g., sigmoid for probabilities, identity for regression).\n\nThe key idea:\n\nBy composing many simple nonlinear transformations, deep networks can approximate very complex functions.\n\nIn Chapters 5–7, DeepSEA, ExPecto, and SpliceAI implement exactly this pattern, but with convolutional layers (Section 4) tailored to 1D DNA sequence instead of dense matrix multiplications (Zhou and Troyanskaya 2015; Zhou et al. 2018; Jaganathan et al. 2019).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#training-deep-models",
    "href": "app-a-dl.html#training-deep-models",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.2 Training Deep Models",
    "text": "A.2 Training Deep Models\n\nA.2.1 Data, Labels, and Loss Functions\nTo train a model, we need:\n\nA dataset of examples \\(\\{(x_i, y_i)\\}_{i=1}^N\\)\n\nA model \\(f_\\theta\\)\n\nA loss function \\(L(\\hat{y}, y)\\) that measures how wrong a prediction is\n\nCommon loss functions:\n\nBinary cross-entropy (for yes/no labels, e.g., “is this ChIP–seq peak present?”):\n\\[\nL(\\hat{p}, y) = -\\big(y \\log \\hat{p} + (1-y)\\log(1-\\hat{p})\\big)\n\\]\nMulticlass cross-entropy (for one-of-K labels)\n\nMean squared error (MSE) (for continuous outputs, e.g., gene expression)\n\nThe training objective is to find \\(\\theta\\) that minimizes the average loss:\n\\[\n\\mathcal{L}(\\theta) = \\frac{1}{N}\\sum_{i=1}^N L\\big(f_\\theta(x_i), y_i\\big).\n\\]\n\n\nA.2.2 2.2 Gradient-Based Optimization\nDeep networks may have millions to billions of parameters. We can’t search over all possibilities, but we can follow the gradient of the loss with respect to \\(\\theta\\):\n\nGradient descent updates: \\[\n\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta \\mathcal{L}(\\theta),\n\\] where \\(\\eta\\) is the learning rate.\n\nIn practice, we use:\n\nMini-batch stochastic gradient descent (SGD): Compute gradients on small batches of examples (e.g., 128 sequences at a time) for efficiency and better generalization.\nAdaptive optimizers like Adam, which adjust learning rates per parameter.\n\nYou never compute gradients by hand; modern frameworks (PyTorch, JAX, TensorFlow) use automatic differentiation to efficiently compute \\(\\nabla_\\theta \\mathcal{L}\\) even for very complex architectures.\n\n\nA.2.3 Backpropagation in One Sentence\nBackpropagation is just the chain rule of calculus applied efficiently through the layers of a network. It propagates “blame” from the output back to each weight, telling us how changing that weight would change the loss.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#generalization-overfitting-and-evaluation",
    "href": "app-a-dl.html#generalization-overfitting-and-evaluation",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.3 Generalization, Overfitting, and Evaluation",
    "text": "A.3 Generalization, Overfitting, and Evaluation\n\nA.3.1 Train / Validation / Test Splits\nDeep networks can memorize training data if we’re not careful. To evaluate generalization, we typically split data into:\n\nTraining set – used to fit parameters\n\nValidation set – used to tune hyperparameters (learning rate, depth, etc.) and perform early stopping\n\nTest set – held out until the end to estimate performance on new data\n\nIn genomics, how we split matters as much as how much data we have:\n\nSplitting by locus or chromosome (to test cross-locus generalization)\n\nSplitting by individual or cohort (to avoid leakage between related samples)\n\nSplitting by species or ancestry when evaluating transfer\n\nThese issues are developed in more depth in the evaluation and confounding chapters (Chapter 19 and Chapter 21).\n\n\nA.3.2 Overfitting and Regularization\nSigns of overfitting:\n\nTraining loss keeps decreasing, but validation loss starts increasing.\n\nMetrics like AUROC or AUPRC plateau or drop on validation data even as they improve on training data.\n\nCommon regularization techniques:\n\nWeight decay / L2 regularization – penalize large weights.\n\nDropout – randomly zero out activations during training.\n\nEarly stopping – stop training when validation performance stops improving.\n\nData augmentation – generate more training examples by transforming inputs, e.g.:\n\nReverse-complement augmentation for DNA sequences (treat sequence and its reverse complement as equivalent).\n\nWindow jittering: randomly shifting the sequence window around a target site.\n\n\n\n\nA.3.3 Basic Metrics\nYou’ll encounter metrics such as:\n\nAUROC (Area Under the ROC Curve) – how well the model ranks positives above negatives.\n\nAUPRC (Area Under the Precision–Recall Curve) – more informative when positives are rare.\n\nCalibration metrics (e.g., Brier score) and reliability diagrams – especially for clinical risk prediction (Chapter 23).\n\nThe model and application chapters provide details about which metrics are appropriate for which tasks. See Chapter 19 for more on evaluation metrics.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#convolutional-networks-for-genomic-sequences",
    "href": "app-a-dl.html#convolutional-networks-for-genomic-sequences",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.4 Convolutional Networks for Genomic Sequences",
    "text": "A.4 Convolutional Networks for Genomic Sequences\nConvolutional neural networks (CNNs) are the workhorse architecture in early genomic deep learning models like DeepSEA, ExPecto, and SpliceAI (Zhou and Troyanskaya 2015; Zhou et al. 2018; Jaganathan et al. 2019).\n\nA.4.1 1D Convolutions as Motif Detectors\nFor a 1D DNA sequence encoded as a matrix \\(X \\in \\mathbb{R}^{L \\times 4}\\) (length \\(L\\), 4 nucleotides), a convolutional layer applies a set of filters (kernels) of width \\(k\\):\n\nEach filter is a small matrix \\(K \\in \\mathbb{R}^{k \\times 4}\\).\n\nAt each position, the filter computes a dot product between \\(K\\) and the corresponding \\(k\\)-length chunk of \\(X\\).\n\nSliding the filter along the sequence creates an activation map that is high wherever the motif encoded by \\(K\\) is present.\n\nIntuitively:\n\nA 1D convolutional filter learns to recognize sequence motifs (e.g., transcription factor binding sites) directly from data.\n\n\n\nA.4.2 Stacking Layers and Receptive Fields\nDeeper convolutional layers allow the model to “see” longer-range patterns:\n\nFirst layer: short motifs (e.g., 8–15 bp).\n\nHigher layers: combinations of motifs, motif spacing, and local regulatory grammar.\n\nPooling layers (e.g., max pooling) reduce spatial resolution while aggregating features, increasing the receptive field.\n\nIn DeepSEA, stacked convolutions and pooling allow the model to use hundreds of base pairs of context around a locus to predict chromatin state (Zhou and Troyanskaya 2015). ExPecto extends this idea by mapping sequence to tissue-specific expression predictions (Zhou et al. 2018). SpliceAI uses very deep dilated convolutions to reach ~10 kb of context for splicing (Jaganathan et al. 2019).\n\n\nA.4.3 Multi-Task Learning\nEarly sequence-to-function CNNs are almost always multi-task:\n\nA single input sequence is used to predict many outputs simultaneously (e.g., hundreds of TF ChIP–seq peaks, histone marks, DNase hypersensitivity tracks).\n\nShared convolutional layers learn common features, while the final layer has many output units (one per task).\n\nBenefits:\n\nEfficient use of data and compute\n\nBetter regularization: related tasks constrain each other\n\nNatural interface for variant effect prediction: you can see how a mutation affects many functional readouts at once",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#beyond-cnns-recurrent-networks-briefly",
    "href": "app-a-dl.html#beyond-cnns-recurrent-networks-briefly",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.5 Beyond CNNs: Recurrent Networks (Briefly)",
    "text": "A.5 Beyond CNNs: Recurrent Networks (Briefly)\nBefore Transformers dominated sequence modeling, recurrent neural networks (RNNs)—especially LSTMs and GRUs—were the default architecture for language and time series.\nConceptually:\n\nAn RNN processes a sequence one position at a time.\n\nIt maintains a hidden state that is updated as it moves along the sequence.\n\nIn principle, it can capture arbitrarily long-range dependencies.\n\nIn practice, for genomic sequences:\n\nVery long-range dependencies (tens to hundreds of kilobases) are difficult to learn with standard RNNs.\n\nTraining can be slow and unstable on very long sequences.\n\nCNNs and attention-based models have largely displaced RNNs in genomic applications.\n\nYou may still see RNNs in some multi-modal or temporal settings (e.g., modeling longitudinal clinical data), but they are not central to this book’s architectures.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#transformers-and-self-attention",
    "href": "app-a-dl.html#transformers-and-self-attention",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.6 Transformers and Self-Attention",
    "text": "A.6 Transformers and Self-Attention\nTransformers, introduced in natural language processing, have become the dominant architecture for sequence modeling. In this book, they underpin protein language models, DNA language models (DNABERT and successors), and long-range models like Enformer (Ji et al. 2021; Avsec et al. 2021).\n\nA.6.1 The Idea of Self-Attention\nIn a self-attention layer, each position in a sequence can directly “look at” and combine information from every other position.\nFor an input sequence represented as vectors \\(\\{x_1, \\dots, x_L\\}\\):\n\nEach position is mapped to query (\\(q_i\\)), key (\\(k_i\\)), and value (\\(v_i\\)) vectors via learned linear projections.\n\nThe attention weight from position \\(i\\) to position \\(j\\) is:\n\\[\n\\alpha_{ij} \\propto \\exp\\left(\\frac{q_i^\\top k_j}{\\sqrt{d}}\\right),\n\\]\nfollowed by normalization so that \\(\\sum_j \\alpha_{ij} = 1\\).\nThe new representation of position \\(i\\) is a weighted sum of all value vectors:\n\\[\nz_i = \\sum_{j=1}^L \\alpha_{ij} v_j.\n\\]\n\nKey properties:\n\nContent-based: Interactions are determined by similarity of representations, not just distance.\n\nGlobal context: Each position can, in principle, attend to any other position.\n\nPermutation-aware via positional encodings: Additional information (sinusoidal or learned) encodes position so the model knows order.\n\n\n\nA.6.2 Multi-Head Attention and Transformer Blocks\nReal Transformer layers use multi-head attention:\n\nThe model runs self-attention in parallel with multiple sets of \\((Q,K,V)\\) projections (heads).\n\nDifferent heads can specialize in different patterns (e.g., local motif combinations, long-range enhancer–promoter contacts).\n\nA typical Transformer block has:\n\nMulti-head self-attention\n\nAdd & layer normalization\n\nPosition-wise feed-forward network\n\nAnother add & layer normalization\n\nStacking many blocks yields a deep Transformer.\n\n\nA.6.3 Computational Cost and Long-Range Genomics\nNaive self-attention has \\(O(L^2)\\) cost in sequence length \\(L\\). For genomic sequences, where we might want 100 kb–1 Mb contexts, this is expensive.\nLong-range genomic models like Enformer and HyenaDNA address this with:\n\nHybrid designs (CNNs + attention) to reduce sequence length before applying global attention (Avsec et al. 2021).\n\nStructured state space models (SSMs) and related architectures that scale more gracefully with length (Nguyen et al. 2023).\n\nThese details are treated in depth in the long-range modeling chapters; here it suffices to know that Transformers give flexible global context at the cost of higher computational complexity.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#self-supervised-learning-and-pretraining",
    "href": "app-a-dl.html#self-supervised-learning-and-pretraining",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.7 Self-Supervised Learning and Pretraining",
    "text": "A.7 Self-Supervised Learning and Pretraining\nA central theme of this book is pretraining: training a large model once on a broad, unlabeled or weakly-labeled task, then re-using it for many downstream problems.\n\nA.7.1 Supervised vs Self-Supervised\n\nSupervised learning: Each input \\(x\\) comes with a label \\(y\\). Examples:\n\nPredicting chromatin marks from sequence (DeepSEA).\n\nPredicting splice junctions (SpliceAI).\n\nPredicting disease risk from features (Chapter 23).\n\nSelf-supervised learning: The model learns from raw input data without explicit labels, using some pretext task constructed from the data itself. Examples:\n\nMasked token prediction (BERT-style): hide some nucleotides and train the model to predict them from surrounding context.\n\nNext-token prediction (GPT-style): predict the next base given previous ones.\n\nDenoising or reconstruction tasks.\n\n\nIn genomics, self-supervised models treat DNA sequences as a language and learn from the vast amount of genomic sequence without needing curated labels.\n\n\nA.7.2 Masked Language Modeling on DNA\nDNABERT applied BERT-style masked language modeling to DNA sequences tokenized as overlapping k-mers (Ji et al. 2021). The model:\n\nReads sequences as k-mer tokens.\n\nRandomly masks a subset of tokens.\n\nLearns to predict the masked tokens given surrounding context.\n\nBenefits:\n\nUses essentially unlimited unlabeled genomic data.\n\nLearns rich representations that can be fine-tuned for tasks like promoter prediction, splice site detection, and variant effect prediction.\n\nChapter 11 generalizes this story to broader DNA foundation models, including alternative tokenization schemes and architectures.\n\n\nA.7.3 Pretraining, Fine-Tuning, and Probing\nAfter pretraining, we can use a model in several ways:\n\nFine-tuning: Initialize with pretrained weights, then continue training on a specific downstream task with task-specific labels.\n\nLinear probing: Freeze the pretrained model, extract embeddings, and train a simple linear classifier on top.\n\nPrompting / adapters: Add small task-specific modules (adapters) while keeping most of the model fixed.\n\nThese patterns reappear across protein LMs, DNA LMs, variant effect models, and GFMs in Chapters 9–16.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#foundations-for-evaluation-and-reliability",
    "href": "app-a-dl.html#foundations-for-evaluation-and-reliability",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.8 Foundations for Evaluation and Reliability",
    "text": "A.8 Foundations for Evaluation and Reliability\nWhile the main book has dedicated chapters for evaluation (Chapter 19), confounding (Chapter 21), and clinical metrics (Chapter 23), it’s useful to have a few basic concepts in mind.\n\nA.8.1 Distribution Shift\nA model is trained under some data distribution (e.g., certain assays, cohorts, ancestries) and then deployed under another (e.g., a different hospital system or population). When these differ, we have distribution shift, which can degrade performance.\nTypical genomic shifts include:\n\nNew sequencing technologies or lab protocols\n\nNew ancestries or populations\n\nNew tissues, diseases, or phenotypes\n\n\n\nA.8.2 Data Leakage\nData leakage occurs when information from the test set “leaks” into training (e.g., through overlapping loci or related individuals), leading to overly optimistic estimates of performance. Chapter 19 and Chapter 21 discuss strategies for leak-resistant splits in detail.\n\n\nA.8.3 Calibration and Uncertainty\nFor many applications, especially in the clinic, we care not just about whether the model is correct, but whether its probabilities are well calibrated and whether we know when the model is uncertain. Calibration and uncertainty quantification are covered in Chapter 23; here, the main takeaway is that perfect AUROC does not imply perfect clinical utility.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#a-minimal-recipe-for-a-genomic-deep-learning-project",
    "href": "app-a-dl.html#a-minimal-recipe-for-a-genomic-deep-learning-project",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.9 A Minimal Recipe for a Genomic Deep Learning Project",
    "text": "A.9 A Minimal Recipe for a Genomic Deep Learning Project\nTo make the abstractions more concrete, here is a lightweight “recipe” that roughly mirrors what the case-study chapters do.\n\nDefine the prediction problem\n\nInput: e.g., 1 kb sequence around a variant, or patient-level features.\n\nOutput: e.g., presence of a chromatin mark, change in expression, disease risk.\n\nChoose an input representation\n\nOne-hot encoding or tokenization scheme for sequences (see Chapter 5).\n\nEncodings for variants, genes, or patients (e.g., aggregate from per-variant features).\n\nPick a model family\n\nCNN for local sequence-to-function (Chapters 5–7).\n\nTransformer or SSM for long-range or language model-style tasks (Chapters 8–11).\n\nPretrained GFM + small task-specific head (Chapters 12–16).\n\nSpecify the loss and metrics\n\nCross-entropy for binary classification, MSE for regression, etc.\n\nMetrics like AUROC, AUPRC, correlation, calibration.\n\nSet up data splits and evaluation\n\nDecide whether to split by locus, individual, cohort, or species.\n\nHold out a test set and use validation data to tune hyperparameters.\n\nTrain with regularization and monitoring\n\nUse an optimizer (SGD or Adam-like) with a learning rate schedule.\n\nApply regularization (dropout, weight decay, augmentation).\n\nMonitor training and validation curves for overfitting.\n\nInspect and stress-test\n\nCheck performance across subgroups (e.g., ancestries, assays, cohorts).\n\nUse interpretability tools (Chapter 22) to see what patterns the model is using.\n\nRun robustness checks and ablations.\n\nIterate\n\nAdjust architecture, add more data, refine labels, or incorporate pretrained backbones.\n\nMove from model-centric tuning to system-level considerations (data quality, deployment environment, feedback loops).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-a-dl.html#how-this-primer-connects-to-the-rest-of-the-book",
    "href": "app-a-dl.html#how-this-primer-connects-to-the-rest-of-the-book",
    "title": "Appendix A — Deep Learning Primer",
    "section": "A.10 How This Primer Connects to the Rest of the Book",
    "text": "A.10 How This Primer Connects to the Rest of the Book\nThis appendix gives you the minimum vocabulary to navigate the rest of the text:\n\nChapters 5–7 show how CNNs on one-hot sequence learn regulatory code, expression, and splicing.\n\nChapters 8–11 extend these ideas to richer sequence representations, Transformers, and long-range sequence models.\n\nChapters 12–16 frame these models as genomic foundation models, introduce evaluation, interpretability, and multi-omics.\n\nChapters 17–19 show how these ingredients are assembled into clinical, discovery, and biotech applications.\n\nYou don’t need to internalize every detail here. The goal is simply that when you see terms like “convolution,” “attention,” “pretraining,” or “fine-tuning” in the main chapters, they feel like familiar tools rather than mysterious jargon.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Deep Learning Primer</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html",
    "href": "app-b-deployment.html",
    "title": "Appendix B — Model Deployment",
    "section": "",
    "text": "B.1 From Linear Models to Deep Networks\nThis appendix gives a compact introduction to deep learning for readers who are comfortable with genomics but less familiar with modern neural networks. The goal is not to replace a full machine learning textbook, but to provide enough background to make the models in Chapters 5–19 feel intuitive rather than magical.\nWe focus on:\nWhere possible, we connect directly to the genomic case studies in the main text (DeepSEA, ExPecto, SpliceAI, Enformer, genomic language models, and GFMs).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#from-linear-models-to-deep-networks",
    "href": "app-b-deployment.html#from-linear-models-to-deep-networks",
    "title": "Appendix B — Model Deployment",
    "section": "",
    "text": "B.1.1 Models as Functions\nAt its core, a predictive model is just a function:\n\\[\nf_\\theta: x \\mapsto \\hat{y}\n\\tag{B.1}\\]\nwhere:\n\n\\(x\\) is an input (e.g., a one-hot encoded DNA sequence, variant-level features, or a patient feature vector).\n\n\\(\\hat{y}\\) is a prediction (e.g., probability of a histone mark, gene expression level, disease risk).\n\n\\(\\theta\\) are the parameters (weights) of the model.\n\nIn classical genomics workflows, \\(f_\\theta\\) might be:\n\nLogistic regression (for case–control status)\n\nLinear regression (for quantitative traits)\n\nRandom forests or gradient boosting (for variant pathogenicity scores)\n\nDeep learning keeps the same basic structure but allows \\(f_\\theta\\) to be a much more flexible, high-capacity function built by composing many simple operations.\n\n\nB.1.2 Linear Models vs Neural Networks\nA simple linear model for classification looks like:\n\\[\n\\hat{y} = \\sigma(w^\\top x + b),\n\\]\nwhere \\(w\\) and \\(b\\) are parameters and \\(\\sigma(\\cdot)\\) is a squashing nonlinearity (e.g., the logistic function). The model draws a single separating hyperplane in feature space.\nA neural network generalizes this by stacking multiple linear transformations with nonlinear activation functions:\n\\[\n\\begin{aligned}\nh_1 &= \\phi(W_1 x + b_1) \\\\\nh_2 &= \\phi(W_2 h_1 + b_2) \\\\\n&\\vdots \\\\\n\\hat{y} &= g(W_L h_{L-1} + b_L)\n\\end{aligned}\n\\]\nwhere:\n\nEach \\(W_\\ell, b_\\ell\\) is a layer’s weight matrix and bias.\n\n\\(\\phi(\\cdot)\\) is a nonlinear activation (e.g., ReLU).\n\n\\(g(\\cdot)\\) is a final activation (e.g., sigmoid for probabilities, identity for regression).\n\nThe key idea:\n\nBy composing many simple nonlinear transformations, deep networks can approximate very complex functions.\n\nIn Chapters 5–7, DeepSEA, ExPecto, and SpliceAI implement exactly this pattern, but with convolutional layers (Section 4) tailored to 1D DNA sequence instead of dense matrix multiplications (Zhou and Troyanskaya 2015; Zhou et al. 2018; Jaganathan et al. 2019).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#training-deep-models",
    "href": "app-b-deployment.html#training-deep-models",
    "title": "Appendix B — Model Deployment",
    "section": "B.2 Training Deep Models",
    "text": "B.2 Training Deep Models\n\nB.2.1 Data, Labels, and Loss Functions\nTo train a model, we need:\n\nA dataset of examples \\(\\{(x_i, y_i)\\}_{i=1}^N\\)\n\nA model \\(f_\\theta\\)\n\nA loss function \\(L(\\hat{y}, y)\\) that measures how wrong a prediction is\n\nCommon loss functions:\n\nBinary cross-entropy (for yes/no labels, e.g., “is this ChIP–seq peak present?”):\n\\[\nL(\\hat{p}, y) = -\\big(y \\log \\hat{p} + (1-y)\\log(1-\\hat{p})\\big)\n\\]\nMulticlass cross-entropy (for one-of-K labels)\n\nMean squared error (MSE) (for continuous outputs, e.g., gene expression)\n\nThe training objective is to find \\(\\theta\\) that minimizes the average loss:\n\\[\n\\mathcal{L}(\\theta) = \\frac{1}{N}\\sum_{i=1}^N L\\big(f_\\theta(x_i), y_i\\big).\n\\]\n\n\nB.2.2 2.2 Gradient-Based Optimization\nDeep networks may have millions to billions of parameters. We can’t search over all possibilities, but we can follow the gradient of the loss with respect to \\(\\theta\\):\n\nGradient descent updates: \\[\n\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta \\mathcal{L}(\\theta),\n\\] where \\(\\eta\\) is the learning rate.\n\nIn practice, we use:\n\nMini-batch stochastic gradient descent (SGD): Compute gradients on small batches of examples (e.g., 128 sequences at a time) for efficiency and better generalization.\nAdaptive optimizers like Adam, which adjust learning rates per parameter.\n\nYou never compute gradients by hand; modern frameworks (PyTorch, JAX, TensorFlow) use automatic differentiation to efficiently compute \\(\\nabla_\\theta \\mathcal{L}\\) even for very complex architectures.\n\n\nB.2.3 Backpropagation in One Sentence\nBackpropagation is just the chain rule of calculus applied efficiently through the layers of a network. It propagates “blame” from the output back to each weight, telling us how changing that weight would change the loss.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#generalization-overfitting-and-evaluation",
    "href": "app-b-deployment.html#generalization-overfitting-and-evaluation",
    "title": "Appendix B — Model Deployment",
    "section": "B.3 Generalization, Overfitting, and Evaluation",
    "text": "B.3 Generalization, Overfitting, and Evaluation\n\nB.3.1 Train / Validation / Test Splits\nDeep networks can memorize training data if we’re not careful. To evaluate generalization, we typically split data into:\n\nTraining set – used to fit parameters\n\nValidation set – used to tune hyperparameters (learning rate, depth, etc.) and perform early stopping\n\nTest set – held out until the end to estimate performance on new data\n\nIn genomics, how we split matters as much as how much data we have:\n\nSplitting by locus or chromosome (to test cross-locus generalization)\n\nSplitting by individual or cohort (to avoid leakage between related samples)\n\nSplitting by species or ancestry when evaluating transfer\n\nThese issues are developed in more depth in the evaluation and confounding chapters (Chapter 19 and Chapter 21).\n\n\nB.3.2 Overfitting and Regularization\nSigns of overfitting:\n\nTraining loss keeps decreasing, but validation loss starts increasing.\n\nMetrics like AUROC or AUPRC plateau or drop on validation data even as they improve on training data.\n\nCommon regularization techniques:\n\nWeight decay / L2 regularization – penalize large weights.\n\nDropout – randomly zero out activations during training.\n\nEarly stopping – stop training when validation performance stops improving.\n\nData augmentation – generate more training examples by transforming inputs, e.g.:\n\nReverse-complement augmentation for DNA sequences (treat sequence and its reverse complement as equivalent).\n\nWindow jittering: randomly shifting the sequence window around a target site.\n\n\n\n\nB.3.3 Basic Metrics\nYou’ll encounter metrics such as:\n\nAUROC (Area Under the ROC Curve) – how well the model ranks positives above negatives.\n\nAUPRC (Area Under the Precision–Recall Curve) – more informative when positives are rare.\n\nCalibration metrics (e.g., Brier score) and reliability diagrams – especially for clinical risk prediction (Chapter 23).\n\nThe model and application chapters provide details about which metrics are appropriate for which tasks. See Chapter 19 for more on evaluation metrics.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#convolutional-networks-for-genomic-sequences",
    "href": "app-b-deployment.html#convolutional-networks-for-genomic-sequences",
    "title": "Appendix B — Model Deployment",
    "section": "B.4 Convolutional Networks for Genomic Sequences",
    "text": "B.4 Convolutional Networks for Genomic Sequences\nConvolutional neural networks (CNNs) are the workhorse architecture in early genomic deep learning models like DeepSEA, ExPecto, and SpliceAI (Zhou and Troyanskaya 2015; Zhou et al. 2018; Jaganathan et al. 2019).\n\nB.4.1 1D Convolutions as Motif Detectors\nFor a 1D DNA sequence encoded as a matrix \\(X \\in \\mathbb{R}^{L \\times 4}\\) (length \\(L\\), 4 nucleotides), a convolutional layer applies a set of filters (kernels) of width \\(k\\):\n\nEach filter is a small matrix \\(K \\in \\mathbb{R}^{k \\times 4}\\).\n\nAt each position, the filter computes a dot product between \\(K\\) and the corresponding \\(k\\)-length chunk of \\(X\\).\n\nSliding the filter along the sequence creates an activation map that is high wherever the motif encoded by \\(K\\) is present.\n\nIntuitively:\n\nA 1D convolutional filter learns to recognize sequence motifs (e.g., transcription factor binding sites) directly from data.\n\n\n\nB.4.2 Stacking Layers and Receptive Fields\nDeeper convolutional layers allow the model to “see” longer-range patterns:\n\nFirst layer: short motifs (e.g., 8–15 bp).\n\nHigher layers: combinations of motifs, motif spacing, and local regulatory grammar.\n\nPooling layers (e.g., max pooling) reduce spatial resolution while aggregating features, increasing the receptive field.\n\nIn DeepSEA, stacked convolutions and pooling allow the model to use hundreds of base pairs of context around a locus to predict chromatin state (Zhou and Troyanskaya 2015). ExPecto extends this idea by mapping sequence to tissue-specific expression predictions (Zhou et al. 2018). SpliceAI uses very deep dilated convolutions to reach ~10 kb of context for splicing (Jaganathan et al. 2019).\n\n\nB.4.3 Multi-Task Learning\nEarly sequence-to-function CNNs are almost always multi-task:\n\nA single input sequence is used to predict many outputs simultaneously (e.g., hundreds of TF ChIP–seq peaks, histone marks, DNase hypersensitivity tracks).\n\nShared convolutional layers learn common features, while the final layer has many output units (one per task).\n\nBenefits:\n\nEfficient use of data and compute\n\nBetter regularization: related tasks constrain each other\n\nNatural interface for variant effect prediction: you can see how a mutation affects many functional readouts at once",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#beyond-cnns-recurrent-networks-briefly",
    "href": "app-b-deployment.html#beyond-cnns-recurrent-networks-briefly",
    "title": "Appendix B — Model Deployment",
    "section": "B.5 Beyond CNNs: Recurrent Networks (Briefly)",
    "text": "B.5 Beyond CNNs: Recurrent Networks (Briefly)\nBefore Transformers dominated sequence modeling, recurrent neural networks (RNNs)—especially LSTMs and GRUs—were the default architecture for language and time series.\nConceptually:\n\nAn RNN processes a sequence one position at a time.\n\nIt maintains a hidden state that is updated as it moves along the sequence.\n\nIn principle, it can capture arbitrarily long-range dependencies.\n\nIn practice, for genomic sequences:\n\nVery long-range dependencies (tens to hundreds of kilobases) are difficult to learn with standard RNNs.\n\nTraining can be slow and unstable on very long sequences.\n\nCNNs and attention-based models have largely displaced RNNs in genomic applications.\n\nYou may still see RNNs in some multi-modal or temporal settings (e.g., modeling longitudinal clinical data), but they are not central to this book’s architectures.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#transformers-and-self-attention",
    "href": "app-b-deployment.html#transformers-and-self-attention",
    "title": "Appendix B — Model Deployment",
    "section": "B.6 Transformers and Self-Attention",
    "text": "B.6 Transformers and Self-Attention\nTransformers, introduced in natural language processing, have become the dominant architecture for sequence modeling. In this book, they underpin protein language models, DNA language models (DNABERT and successors), and long-range models like Enformer (Ji et al. 2021; Avsec et al. 2021).\n\nB.6.1 The Idea of Self-Attention\nIn a self-attention layer, each position in a sequence can directly “look at” and combine information from every other position.\nFor an input sequence represented as vectors \\(\\{x_1, \\dots, x_L\\}\\):\n\nEach position is mapped to query (\\(q_i\\)), key (\\(k_i\\)), and value (\\(v_i\\)) vectors via learned linear projections.\n\nThe attention weight from position \\(i\\) to position \\(j\\) is:\n\\[\n\\alpha_{ij} \\propto \\exp\\left(\\frac{q_i^\\top k_j}{\\sqrt{d}}\\right),\n\\]\nfollowed by normalization so that \\(\\sum_j \\alpha_{ij} = 1\\).\nThe new representation of position \\(i\\) is a weighted sum of all value vectors:\n\\[\nz_i = \\sum_{j=1}^L \\alpha_{ij} v_j.\n\\]\n\nKey properties:\n\nContent-based: Interactions are determined by similarity of representations, not just distance.\n\nGlobal context: Each position can, in principle, attend to any other position.\n\nPermutation-aware via positional encodings: Additional information (sinusoidal or learned) encodes position so the model knows order.\n\n\n\nB.6.2 Multi-Head Attention and Transformer Blocks\nReal Transformer layers use multi-head attention:\n\nThe model runs self-attention in parallel with multiple sets of \\((Q,K,V)\\) projections (heads).\n\nDifferent heads can specialize in different patterns (e.g., local motif combinations, long-range enhancer–promoter contacts).\n\nA typical Transformer block has:\n\nMulti-head self-attention\n\nAdd & layer normalization\n\nPosition-wise feed-forward network\n\nAnother add & layer normalization\n\nStacking many blocks yields a deep Transformer.\n\n\nB.6.3 Computational Cost and Long-Range Genomics\nNaive self-attention has \\(O(L^2)\\) cost in sequence length \\(L\\). For genomic sequences, where we might want 100 kb–1 Mb contexts, this is expensive.\nLong-range genomic models like Enformer and HyenaDNA address this with:\n\nHybrid designs (CNNs + attention) to reduce sequence length before applying global attention (Avsec et al. 2021).\n\nStructured state space models (SSMs) and related architectures that scale more gracefully with length (Nguyen et al. 2023).\n\nThese details are treated in depth in the long-range modeling chapters; here it suffices to know that Transformers give flexible global context at the cost of higher computational complexity.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#self-supervised-learning-and-pretraining",
    "href": "app-b-deployment.html#self-supervised-learning-and-pretraining",
    "title": "Appendix B — Model Deployment",
    "section": "B.7 Self-Supervised Learning and Pretraining",
    "text": "B.7 Self-Supervised Learning and Pretraining\nA central theme of this book is pretraining: training a large model once on a broad, unlabeled or weakly-labeled task, then re-using it for many downstream problems.\n\nB.7.1 Supervised vs Self-Supervised\n\nSupervised learning: Each input \\(x\\) comes with a label \\(y\\). Examples:\n\nPredicting chromatin marks from sequence (DeepSEA).\n\nPredicting splice junctions (SpliceAI).\n\nPredicting disease risk from features (Chapter 23).\n\nSelf-supervised learning: The model learns from raw input data without explicit labels, using some pretext task constructed from the data itself. Examples:\n\nMasked token prediction (BERT-style): hide some nucleotides and train the model to predict them from surrounding context.\n\nNext-token prediction (GPT-style): predict the next base given previous ones.\n\nDenoising or reconstruction tasks.\n\n\nIn genomics, self-supervised models treat DNA sequences as a language and learn from the vast amount of genomic sequence without needing curated labels.\n\n\nB.7.2 Masked Language Modeling on DNA\nDNABERT applied BERT-style masked language modeling to DNA sequences tokenized as overlapping k-mers (Ji et al. 2021). The model:\n\nReads sequences as k-mer tokens.\n\nRandomly masks a subset of tokens.\n\nLearns to predict the masked tokens given surrounding context.\n\nBenefits:\n\nUses essentially unlimited unlabeled genomic data.\n\nLearns rich representations that can be fine-tuned for tasks like promoter prediction, splice site detection, and variant effect prediction.\n\nChapter 11 generalizes this story to broader DNA foundation models, including alternative tokenization schemes and architectures.\n\n\nB.7.3 Pretraining, Fine-Tuning, and Probing\nAfter pretraining, we can use a model in several ways:\n\nFine-tuning: Initialize with pretrained weights, then continue training on a specific downstream task with task-specific labels.\n\nLinear probing: Freeze the pretrained model, extract embeddings, and train a simple linear classifier on top.\n\nPrompting / adapters: Add small task-specific modules (adapters) while keeping most of the model fixed.\n\nThese patterns reappear across protein LMs, DNA LMs, variant effect models, and GFMs in Chapters 9–16.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#foundations-for-evaluation-and-reliability",
    "href": "app-b-deployment.html#foundations-for-evaluation-and-reliability",
    "title": "Appendix B — Model Deployment",
    "section": "B.8 Foundations for Evaluation and Reliability",
    "text": "B.8 Foundations for Evaluation and Reliability\nWhile the main book has dedicated chapters for evaluation (Chapter 19), confounding (Chapter 21), and clinical metrics (Chapter 23), it’s useful to have a few basic concepts in mind.\n\nB.8.1 Distribution Shift\nA model is trained under some data distribution (e.g., certain assays, cohorts, ancestries) and then deployed under another (e.g., a different hospital system or population). When these differ, we have distribution shift, which can degrade performance.\nTypical genomic shifts include:\n\nNew sequencing technologies or lab protocols\n\nNew ancestries or populations\n\nNew tissues, diseases, or phenotypes\n\n\n\nB.8.2 Data Leakage\nData leakage occurs when information from the test set “leaks” into training (e.g., through overlapping loci or related individuals), leading to overly optimistic estimates of performance. Chapter 19 and Chapter 21 discuss strategies for leak-resistant splits in detail.\n\n\nB.8.3 Calibration and Uncertainty\nFor many applications, especially in the clinic, we care not just about whether the model is correct, but whether its probabilities are well calibrated and whether we know when the model is uncertain. Calibration and uncertainty quantification are covered in Chapter 23; here, the main takeaway is that perfect AUROC does not imply perfect clinical utility.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#a-minimal-recipe-for-a-genomic-deep-learning-project",
    "href": "app-b-deployment.html#a-minimal-recipe-for-a-genomic-deep-learning-project",
    "title": "Appendix B — Model Deployment",
    "section": "B.9 A Minimal Recipe for a Genomic Deep Learning Project",
    "text": "B.9 A Minimal Recipe for a Genomic Deep Learning Project\nTo make the abstractions more concrete, here is a lightweight “recipe” that roughly mirrors what the case-study chapters do.\n\nDefine the prediction problem\n\nInput: e.g., 1 kb sequence around a variant, or patient-level features.\n\nOutput: e.g., presence of a chromatin mark, change in expression, disease risk.\n\nChoose an input representation\n\nOne-hot encoding or tokenization scheme for sequences (see Chapter 5).\n\nEncodings for variants, genes, or patients (e.g., aggregate from per-variant features).\n\nPick a model family\n\nCNN for local sequence-to-function (Chapters 5–7).\n\nTransformer or SSM for long-range or language model-style tasks (Chapters 8–11).\n\nPretrained GFM + small task-specific head (Chapters 12–16).\n\nSpecify the loss and metrics\n\nCross-entropy for binary classification, MSE for regression, etc.\n\nMetrics like AUROC, AUPRC, correlation, calibration.\n\nSet up data splits and evaluation\n\nDecide whether to split by locus, individual, cohort, or species.\n\nHold out a test set and use validation data to tune hyperparameters.\n\nTrain with regularization and monitoring\n\nUse an optimizer (SGD or Adam-like) with a learning rate schedule.\n\nApply regularization (dropout, weight decay, augmentation).\n\nMonitor training and validation curves for overfitting.\n\nInspect and stress-test\n\nCheck performance across subgroups (e.g., ancestries, assays, cohorts).\n\nUse interpretability tools (Chapter 22) to see what patterns the model is using.\n\nRun robustness checks and ablations.\n\nIterate\n\nAdjust architecture, add more data, refine labels, or incorporate pretrained backbones.\n\nMove from model-centric tuning to system-level considerations (data quality, deployment environment, feedback loops).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-b-deployment.html#how-this-primer-connects-to-the-rest-of-the-book",
    "href": "app-b-deployment.html#how-this-primer-connects-to-the-rest-of-the-book",
    "title": "Appendix B — Model Deployment",
    "section": "B.10 How This Primer Connects to the Rest of the Book",
    "text": "B.10 How This Primer Connects to the Rest of the Book\nThis appendix gives you the minimum vocabulary to navigate the rest of the text:\n\nChapters 5–7 show how CNNs on one-hot sequence learn regulatory code, expression, and splicing.\n\nChapters 8–11 extend these ideas to richer sequence representations, Transformers, and long-range sequence models.\n\nChapters 12–16 frame these models as genomic foundation models, introduce evaluation, interpretability, and multi-omics.\n\nChapters 17–19 show how these ingredients are assembled into clinical, discovery, and biotech applications.\n\nYou don’t need to internalize every detail here. The goal is simply that when you see terms like “convolution,” “attention,” “pretraining,” or “fine-tuning” in the main chapters, they feel like familiar tools rather than mysterious jargon.\n\n\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "app-c-model-list.html",
    "href": "app-c-model-list.html",
    "title": "Appendix C — Referenced Models",
    "section": "",
    "text": "C.1 Category Definitions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Referenced Models</span>"
    ]
  },
  {
    "objectID": "app-c-model-list.html#category-definitions",
    "href": "app-c-model-list.html#category-definitions",
    "title": "Appendix C — Referenced Models",
    "section": "",
    "text": "DNA LM: DNA language models using self-supervised pretraining on genomic sequences\nPLM: Protein language models trained on protein sequences\nSeq→Func: Supervised sequence-to-function models predicting chromatin/expression from DNA\nSplice: Specialized splice site prediction models\nVEP: Variant effect predictors (various paradigms)\nGFM: Genomic foundation model (broad, reusable representations)\nPGS: Polygenic score or risk prediction models\nGNN: Graph neural network for gene/pathway analysis\n\n\n\n\n\nAbramson, Josh, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, et al. 2024. “[AlphaFold3] Accurate Structure Prediction of Biomolecular Interactions with AlphaFold 3.” Nature 630 (8016): 493–500. https://doi.org/10.1038/s41586-024-07487-w.\n\n\nAdzhubei, Ivan A., Steffen Schmidt, Leonid Peshkin, Vasily E. Ramensky, Anna Gerasimova, Peer Bork, Alexey S. Kondrashov, and Shamil R. Sunyaev. 2010. “A Method and Server for Predicting Damaging Missense Mutations.” Nature Methods 7 (4): 248–49. https://doi.org/10.1038/nmeth0410-248.\n\n\nAvsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. “[Enformer] Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.” Nature Methods 18 (October): 1196–1203. https://doi.org/10.1038/s41592-021-01252-x.\n\n\nAvsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. “AlphaGenome: AI for Better Understanding the Genome.” Google DeepMind. https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/.\n\n\nBenegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. “GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.” bioRxiv, April, 2023.10.10.561776. https://doi.org/10.1101/2023.10.10.561776.\n\n\nBrandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. “Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.” Nature Genetics 55 (9): 1512–22. https://doi.org/10.1038/s41588-023-01465-0.\n\n\nBrixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. “[Evo 2] Genome Modeling and Design Across All Domains of Life with Evo 2.” bioRxiv. https://doi.org/10.1101/2025.02.18.638918.\n\n\nCao, Zhi-Jie, and Ge Gao. 2022. “[GLUE] Multi-Omics Single-Cell Data Integration and Regulatory Inference with Graph-Linked Embedding.” Nature Biotechnology 40 (10): 1458–66. https://doi.org/10.1038/s41587-022-01284-4.\n\n\nChen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. “[DeepSEA Sei] A Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.” Nature Genetics 54 (7): 940–49. https://doi.org/10.1038/s41588-022-01102-2.\n\n\nCheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. “[AlphaMissense] Accurate Proteome-Wide Missense Variant Effect Prediction with AlphaMissense.” Science 381 (6664): eadg7492. https://doi.org/10.1126/science.adg7492.\n\n\nClarke, Brian, Eva Holtkamp, Hakime Öztürk, Marcel Mück, Magnus Wahlberg, Kayla Meyer, Felix Munzlinger, et al. 2024. “[DeepRVAT] Integration of Variant Annotations Using Deep Set Networks Boosts Rare Variant Association Testing.” Nature Genetics 56 (10): 2271–80. https://doi.org/10.1038/s41588-024-01919-z.\n\n\nDalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. “Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.” Nature Methods 22 (2): 287–97. https://doi.org/10.1038/s41592-024-02523-z.\n\n\nDavydov, Eugene V., David L. Goode, Marina Sirota, Gregory M. Cooper, Arend Sidow, and Serafim Batzoglou. 2010. “Identifying a High Fraction of the Human Genome to Be Under Selective Constraint Using GERP++.” PLOS Computational Biology 6 (12): e1001025. https://doi.org/10.1371/journal.pcbi.1001025.\n\n\nGeorgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. “Delphi: A Deep-Learning Method for Polygenic Risk Prediction.” medRxiv. https://doi.org/10.1101/2024.04.19.24306079.\n\n\nJaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. “[SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.” Cell 176 (3): 535–548.e24. https://doi.org/10.1016/j.cell.2018.12.015.\n\n\nJi, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. “DNABERT: Pre-Trained Bidirectional Encoder Representations from Transformers Model for DNA-Language in Genome.” Bioinformatics 37 (15): 2112–20. https://doi.org/10.1093/bioinformatics/btab083.\n\n\nJumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. “[AlphaFold2] Highly Accurate Protein Structure Prediction with AlphaFold.” Nature 596 (7873): 583–89. https://doi.org/10.1038/s41586-021-03819-2.\n\n\nKelley, David R. 2020. “[Basenji2] Cross-Species Regulatory Sequence Activity Prediction.” PLOS Computational Biology 16 (7): e1008050. https://doi.org/10.1371/journal.pcbi.1008050.\n\n\nKelley, David R., Yakir A. Reshef, Maxwell Bileschi, David Belanger, Cory Y. McLean, and Jasper Snoek. 2018. “[Basenji2] Sequential Regulatory Activity Prediction Across Chromosomes with Convolutional Neural Networks.” Genome Research 28 (5): 739–50. https://doi.org/10.1101/gr.227819.117.\n\n\nLee, Ingoo, Zachary S. Wallace, Yuqi Wang, Sungjoon Park, Hojung Nam, Amit R. Majithia, and Trey Ideker. 2025. “[G2PT] A Genotype-Phenotype Transformer to Assess and Explain Polygenic Risk.” bioRxiv. https://doi.org/10.1101/2024.10.23.619940.\n\n\nLi, Hao, Zebei Han, Yu Sun, Fu Wang, Pengzhen Hu, Yuang Gao, Xuemei Bai, et al. 2024. “CGMega: Explainable Graph Neural Network Framework with Attention Mechanisms for Cancer Gene Module Dissection.” Nature Communications 15 (1): 5997. https://doi.org/10.1038/s41467-024-50426-6.\n\n\nLi, Xiao, Jie Ma, Ling Leng, Mingfei Han, Mansheng Li, Fuchu He, and Yunping Zhu. 2022. “MoGCN: A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Analysis.” Frontiers in Genetics 13 (February). https://doi.org/10.3389/fgene.2022.806842.\n\n\nLin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, et al. 2022. “[ESM-2] Language Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction.” bioRxiv. https://doi.org/10.1101/2022.07.20.500902.\n\n\nLinder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. “[Borzoi] Predicting RNA-Seq Coverage from DNA Sequence as a Unifying Model of Gene Regulation.” Nature Genetics 57 (4): 949–61. https://doi.org/10.1038/s41588-024-02053-6.\n\n\nMedvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. “BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models.” bioRxiv. https://doi.org/10.1101/2025.03.27.645711.\n\n\nNg, Pauline C., and Steven Henikoff. 2003. “SIFT: Predicting Amino Acid Changes That Affect Protein Function.” Nucleic Acids Research 31 (13): 3812–14. https://doi.org/10.1093/nar/gkg509.\n\n\nNguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. “HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.” arXiv. https://doi.org/10.48550/arXiv.2306.15794.\n\n\nRakowski, Alexander, and Christoph Lippert. 2025. “[MIFM] Multiple Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.” medRxiv. https://doi.org/10.1101/2025.06.13.25329551.\n\n\nRentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. “CADD: Predicting the Deleteriousness of Variants Throughout the Human Genome.” Nucleic Acids Research 47 (D1): D886–94. https://doi.org/10.1093/nar/gky1016.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. “[ESM-1b] Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.” Proceedings of the National Academy of Sciences of the United States of America 118 (15): e2016239118. https://doi.org/10.1073/pnas.2016239118.\n\n\nSanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. “[GROVER] DNA Language Model GROVER Learns Sequence Context in the Human Genome.” Nature Machine Intelligence 6 (8): 911–23. https://doi.org/10.1038/s42256-024-00872-0.\n\n\nSchiff, Yair, Chia-Hsiang Kao, Aaron Gokaslan, Tri Dao, Albert Gu, and Volodymyr Kuleshov. 2024. “Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling.” arXiv. https://doi.org/10.48550/arXiv.2403.03234.\n\n\nSchubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. “CADD V1.7: Using Protein Language Models, Regulatory CNNs and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.” Nucleic Acids Research 52 (D1): D1143–54. https://doi.org/10.1093/nar/gkad989.\n\n\nSiepel, Adam, Gill Bejerano, Jakob S. Pedersen, Angie S. Hinrichs, Minmei Hou, Kate Rosenbloom, Hiram Clawson, et al. 2005. “[PhastCons] Evolutionarily Conserved Elements in Vertebrate, Insect, Worm, and Yeast Genomes.” Genome Research 15 (8): 1034–50. https://doi.org/10.1101/gr.3715005.\n\n\nYeo, Gene, and Christopher B. Burge. 2004. “Maximum Entropy Modeling of Short Sequence Motifs with Applications to RNA Splicing Signals.” Journal of Computational Biology 11 (2-3): 377–94. https://doi.org/10.1089/1066527041410418.\n\n\nZhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. “[Expecto] Deep Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.” Nature Genetics 50 (8): 1171–79. https://doi.org/10.1038/s41588-018-0160-6.\n\n\nZhou, Jian, and Olga G. Troyanskaya. 2015. “[DeepSEA] Predicting Effects of Noncoding Variants with Deep Learning–Based Sequence Model.” Nature Methods 12 (10): 931–34. https://doi.org/10.1038/nmeth.3547.\n\n\nZhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. “DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.” arXiv. https://doi.org/10.48550/arXiv.2306.15006.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Referenced Models</span>"
    ]
  },
  {
    "objectID": "app-d-resources.html",
    "href": "app-d-resources.html",
    "title": "Appendix D — Additional Resources",
    "section": "",
    "text": "D.1 Genomics & Human Genetics",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Additional Resources</span>"
    ]
  },
  {
    "objectID": "app-d-resources.html#genomics-human-genetics",
    "href": "app-d-resources.html#genomics-human-genetics",
    "title": "Appendix D — Additional Resources",
    "section": "",
    "text": "Thompson & Thompson Genetics and Genomics in Medicine (9th ed.)\nRonald Cohn, Stephen Scherer, Ada Hamosh. Clinical-focused overview of human genetics and genomics for medicine, great for grounding in clinical genomics.\nHuman Molecular Genetics (5th ed.)\nTom Strachan, Andrew Read. Higher-level molecular genetics/genomics text with strong coverage of mechanisms, technologies, and disease applications.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Additional Resources</span>"
    ]
  },
  {
    "objectID": "app-d-resources.html#immunology",
    "href": "app-d-resources.html#immunology",
    "title": "Appendix D — Additional Resources",
    "section": "D.2 Immunology",
    "text": "D.2 Immunology\n\nJaneway’s Immunobiology (10th ed.)\nKenneth M. Murphy, Casey Weaver, Leslie J. Berg. Standard comprehensive immunology textbook, excellent for understanding immune system biology relevant to genomics and disease.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Additional Resources</span>"
    ]
  },
  {
    "objectID": "app-d-resources.html#machine-learning-deep-learning",
    "href": "app-d-resources.html#machine-learning-deep-learning",
    "title": "Appendix D — Additional Resources",
    "section": "D.3 Machine Learning & Deep Learning",
    "text": "D.3 Machine Learning & Deep Learning\n\nDeep Learning\nIan Goodfellow, Yoshua Bengio, Aaron Courville. Comprehensive deep learning textbook; free online: https://www.deeplearningbook.org/\nDive into Deep Learning (D2L)\nAston Zhang et al. Interactive deep learning book with Jupyter notebooks and multi-framework code; free online: https://d2l.ai/\nAn Introduction to Statistical Learning (ISLR, 2nd ed.)\nGareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. Gentle introduction to statistical learning methods used in ML, available free online: https://www.statlearning.com/\nThe Elements of Statistical Learning (ESL)\nTrevor Hastie, Robert Tibshirani, Jerome Friedman. More advanced, theory-heavy companion to ISLR; free PDF: https://hastie.su.domains/ElemStatLearn/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Additional Resources</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html",
    "href": "app-e-glossary.html",
    "title": "Appendix E — Glossary",
    "section": "",
    "text": "E.1 CH 01",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-01",
    "href": "app-e-glossary.html#ch-01",
    "title": "Appendix E — Glossary",
    "section": "",
    "text": "E.1.1 Sequencing Technologies & Data\n\nNext-generation sequencing (NGS)\nHigh-throughput DNA sequencing technologies that allow rapid…stretches of DNA, producing millions of short reads in parallel….\n\n\nIllumina sequencing\nA widely used NGS technology that utilizes reversible dye-terminators to sequence DNA by synthesis\n\n\nShort reads / Paired-end reads\nDNA sequences generated by NGS technologies, typically rangi… a DNA fragment, providing additional information for alignment.\n\n\nLong-read sequencing (PacBio HiFi, Oxford Nanopore)\nDNA sequencing technologies that produce longer reads, typic…ases, allowing for better resolution of complex genomic regions.\n\n\nCircular consensus sequencing\nA sequencing method used by PacBio to generate highly accura… long reads by repeatedly sequencing the same DNA molecule.\n\n\nBase calling\nThe process of determining the nucleotide sequence from raw sequencing data.\n\n\nFASTQ\nA file format that stores both nucleotide sequences and their corresponding quality scores.\n\n\nRead depth / Coverage (e.g., 30×, 100×)\nThe number of times a particular nucleotide is sequenced, indicating the reliability of the sequencing data.\n\n\n\nE.1.2 Targeting Strategies\n\nTargeted gene panel\nA sequencing approach that focuses on a specific set of gene…or cost-effective analysis of known disease-associated variants.\n\n\nWhole-exome sequencing (WES)\nA sequencing approach that targets all protein-coding region…the genome, providing a comprehensive view of coding variants.\n\n\nWhole-genome sequencing (WGS)\nA sequencing approach that captures the entire genome, inclu…ng regions, providing the most comprehensive view of genetic var\n\n\nCapture efficiency\nThe effectiveness of a targeted sequencing approach in enric…interest, impacting the overall quality and coverage of the data.\n\n\n\nE.1.3 Alignment & Processing\n\nRead alignment / Mapping\nThe process of aligning sequencing reads to a reference genome to determine their genomic origin.\n\n\nSeed-and-extend alignment\nAn algorithmic approach for read alignment that first identi…ences (seeds) and then extends the alignment around these seeds.\n\n\nPCR duplicates\nIdentical sequencing reads that originate from the same DNA …esulting from PCR amplification, which can bias variant calling.\n\n\nBase quality score recalibration (BQSR)\nA process that adjusts the quality scores of sequencing read…or systematic errors made by the sequencer.\n\n\nMapping quality\nA measure of the confidence that a read is correctly aligned to the reference genome.\n\n\nReference bias\nThe tendency for sequencing and alignment processes to preferentially detect alleles present in the reference genome.\n\n\n\nE.1.4 Variant Calling\n\nVariant calling\nThe process of identifying variants from sequencing data by comparing it to a reference genome.\n\n\nGenotype likelihood\nThe probability of observing the sequencing data given a particular genotype.\n\n\nPair-HMM (pair hidden Markov model)\nA statistical model used in variant calling to calculate the likelihood of different alignments between reads and the reference genome.\n\n\nJoint genotyping / Cohort calling\nThe process of simultaneously calling variants across multiple samples to improve accuracy and consistency.\n\n\ngVCF (genomic VCF)\nA variant call format that includes information about both va…sites, allowing for joint genotyping.\n\n\nVCF (variant call format)\nA standardized file format for storing variant information, including SNPs, indels, and structural variants.\n\n\nVQSR (Variant Quality Score Recalibration)\nA method for improving the accuracy of variant calls by mode…lationship between variant quality scores and various annotatio\n\n\nPileup\nA summary of the base calls at each position in a set of align…ing reads, used for variant calling and visualization.\n\n\n\nE.1.5 Phasing\n\nHaplotype phasing\nThe process of determining which variants are inherited together on the same chromosome.\n\n\nRead-backed phasing\nA method of phasing that uses sequencing reads that span multiple variants to determine their phase.\n\n\nStatistical phasing\nA method of phasing that uses population-level genotype data and statistical models to infer haplotypes.\n\n\nCompound heterozygosity\nThe presence of two different variants at a particular gene locus, one on each chromosome of a pair.\n\n\nCis vs. trans configuration\nDescribes the relative arrangement of two variants on the same chromosome (cis) or on different chromosomes (trans).\n\n\n\nE.1.6 Variant Types\n\nSNV (single nucleotide variant)\nA variation in a single nucleotide that occurs at a specific position in the genome.\n\n\nIndel\nAn insertion or deletion of bases in the genome of an organism.\n\n\nStructural variant\nA large-scale alteration in the genome, such as a deletion, duplication, inversion, or translocation.\n\n\nMulti-nucleotide variant (MNV)\nA variation that affects multiple consecutive nucleotides in the genome.\n\n\nMosaic variant\nA genetic variant that is present in some but not all cells of an organism, often arising during development.\n\n\nSomatic variant\nA genetic variant that occurs in non-germline cells and is not inherited, often associated with cancer.\n\n\nGermline variant\nA genetic variant that is present in the egg or sperm and can be passed on to offspring.\n\n\nDe novo variant\nA genetic variant that arises spontaneously in an individual and is not inherited from either parent.\n\n\n\nE.1.7 Difficult Regions\n\nSegmental duplication\nLarge, highly similar sequences in the genome that can complicate read alignment and variant calling.\n\n\nParalog / Paralogous gene\nA gene that is related to another gene in the same organism due to a duplication event.\n\n\nHomopolymer\nA sequence of identical nucleotides in a row, which can be prone to sequencing errors.\n\n\nLow-complexity region\nA region of the genome with a simple sequence composition, which can be challenging for alignment and variant calling.\n\n\nHLA region / MHC\nThe human leukocyte antigen (HLA) region, also known as the major histocompatibility complex (MHC), is a highly polymorphic region involved in immune response.\n\n\n\nE.1.8 Benchmarking\n\nPrecision (positive predictive value)\nThe proportion of true positive variant calls among all positive calls.\n\n\nRecall (sensitivity)\nThe proportion of true positive variant calls detected among all actual variants.\n\n\nF1 score\nThe harmonic mean of precision and recall, providing a single metric for evaluating variant calling performance.\n\n\nTrue positive (TP) / False positive (FP) / False negative (FN)\nMetrics used to evaluate the accuracy of variant calls, where TP represents correctly identified variants, FP represents incorrectly identified variants, and FN represents missed variants.\n\n\nHigh-confidence region\nA region of the genome where variant calls are considered to b… reliable, often used for benchmarking and validation.\n\n\n\nE.1.9 Key Resources/Tools (may warrant brief glossary entries)\n\nGIAB (Genome in a Bottle)\nA consortium that develops reference materials and data for benchmarking genome sequencing and variant calling.\n\n\nDeepVariant\nA deep learning-based variant caller developed by Google that identifies genetic variants from sequencing data.\n\n\nGLnexus\nA tool for joint variant calling across multiple samples, designed to work with DeepVariant outputs.\n\n\nHaplotypeCaller\nA variant caller from the Genome Analysis Toolkit (GATK) that uses local de-novo assembly of haplotypes to call variants.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-02",
    "href": "app-e-glossary.html#ch-02",
    "title": "Appendix E — Glossary",
    "section": "E.2 CH 02",
    "text": "E.2 CH 02\n\nE.2.1 Reference & Coordinate Systems\n\nReference genome/assembly\nA digital nucleic acid sequence database, assembled as a repre…example of a species’ set of genes. Multiple versions exist.\n\n\nGRCh37\nThe 37th version of the Genome Reference Consortium human genome assembly.\n\n\nGRCh38\nThe 38th version of the Genome Reference Consortium human genome assembly.\n\n\nT2T-CHM13\nThe Telomere-to-Telomere (T2T) CHM13 human genome assembly, r…ting a complete, gapless sequence of a human genome.\n\n\nPangenome reference\nA reference that represents the genetic diversity of a species, rather than a single individual.\n\n\nGene model\nA representation of the structure of a gene, including its exons, introns, and regulatory elements.\n\n\nCanonical transcript\nThe most biologically relevant transcript of a gene, often used as the reference for annotation.\n\n\nAlternative transcript/isoform\nDifferent versions of a transcript produced from the same gene due to alternative splicing or other mechanisms.\n\n\nMANE Select\nMatched Annotation from NCBI and EMBL-EBI (MANE) Select is a …cripts that are consistently annotated across databases.\n\n\n\nE.2.2 Variant Types & Properties\n\nAllele frequency\nThe proportion of a specific allele among all alleles of a gene in a population.\n\n\nMAF (minor allele frequency)\nThe frequency at which the less common allele occurs in a given population.\n\n\nrsID\nA unique identifier assigned to a single nucleotide polymorphism (SNP) in the dbSNP database.\n\n\nLoss-of-function (LoF) variant\nA genetic variant that results in reduced or abolished protein function.\n\n\nUltra-rare variant\nA genetic variant that is extremely uncommon in the population, often with a frequency of less than 0.01%.\n\n\n\nE.2.3 Population Genetics Metrics\n\nLinkage disequilibrium\nA non-random association of alleles at different loci in a given population.\n\n\npLI (probability of being loss-of-function intolerant)\nA metric that estimates the likelihood that a gene is intolerant to loss-of-function variants.\n\n\nLOEUF (loss-of-function observed/expected upper bound fraction)\nA metric that quantifies the observed versus expected number of loss-of-function variants in a gene.\n\n\nConstraint metrics\nMetrics that assess the tolerance of a gene to functional genetic variation.\n\n\nImputation\nThe process of inferring unobserved genotypes in a study sample based on observed genotypes and a reference panel.\n\n\n\nE.2.4 Functional Genomics\n\nChIP-seq\nChromatin Immunoprecipitation followed by sequencing, a method used to analyze protein-DNA interactions.\n\n\nDNase-seq\nA method to identify regions of open chromatin by sequencing DNA fragments generated by DNase I digestion.\n\n\nATAC-seq\nAssay for Transposase-Accessible Chromatin using sequencing, a technique to study chromatin accessibility.\n\n\nHi-C\nA method to study the three-dimensional architecture of genomes by capturing chromatin interactions.\n\n\nChromatin accessibility\nThe degree to which DNA is exposed and available for binding by proteins, often assessed by DNase-seq or ATAC-seq.\n\n\nHistone modification\nChemical modifications to histone proteins that can influence chromatin structure and gene expression.\n\n\nPeak calling\nThe process of identifying regions of the genome with signific…ment of sequencing reads, often used in ChIP-seq and ATAC-seq analyses.\n\n\nSignal track\nA graphical representation of sequencing data across the genom… intensity of signals such as read coverage or enrichment.\n\n\n\nE.2.5 Expression Genetics\n\neQTL (expression quantitative trait locus)\nA genomic locus that explains variation in gene expression levels.\n\n\nSplicing QTL\nA genomic locus that affects the splicing of pre-mRNA.\n\n\nMolecular QTL\nA quantitative trait locus that influences molecular traits such as gene expression, protein levels, or metabolite concentrations.\n\n\nCis-regulatory\nReferring to regulatory elements, such as promoters or enhanc…ated on the same molecule of DNA as the gene they regulate.\n\n\nColocalization\nThe occurrence of two or more genetic signals at the same genomic location, suggesting a shared causal variant.\n\n\nDropout (single-cell context)\nThe failure to detect a transcript in a single-cell RNA-seq ex…often due to low mRNA capture efficiency.\n\n\n\nE.2.6 Clinical Interpretation\n\nACMG/AMP criteria\nA set of guidelines developed by the American College of Medic…ogy (AMP) for the interpretation of sequence variants. These c…vide a framework for classifying variants into categories such path\n\n\nPathogenicity\nThe ability of a genetic variant to cause disease.\n\n\nHaploinsufficiency\nA condition in which a single functional copy of a gene is in…maintain normal function, leading to a disease phenotype.\n\n\nTriplosensitivity\nA condition in which an extra copy of a gene leads to a disease phenotype.\n\n\nGene-disease validity\nThe strength of evidence supporting a relationship between a gene and a disease.\n\n\nPharmacogenomics\nThe study of how genetic variation affects an individual’s response to drugs.\n\n\nDiplotype\nThe combination of alleles at multiple loci on a single chromosome that are inherited together.\n\n\n\nE.2.7 Study Designs & Statistics\n\nGWAS summary statistics\nAggregated data from genome-wide association studies, typicall…ormation on the association between genetic variants and traits across the genome.\n\n\nFine-mapping\nThe process of identifying the specific causal variants within…omic region associated with a trait.\n\n\nEffect size\nA measure of the strength of the relationship between a genetic variant and a trait.\n\n\nAscertainment bias\nA systematic distortion in the estimation of genetic effects d…non-random sampling of individuals or variants.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-03",
    "href": "app-e-glossary.html#ch-03",
    "title": "Appendix E — Glossary",
    "section": "E.3 CH 03",
    "text": "E.3 CH 03",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-04",
    "href": "app-e-glossary.html#ch-04",
    "title": "Appendix E — Glossary",
    "section": "E.4 CH 04",
    "text": "E.4 CH 04",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-05",
    "href": "app-e-glossary.html#ch-05",
    "title": "Appendix E — Glossary",
    "section": "E.5 CH 05",
    "text": "E.5 CH 05",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-06",
    "href": "app-e-glossary.html#ch-06",
    "title": "Appendix E — Glossary",
    "section": "E.6 CH 06",
    "text": "E.6 CH 06",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-07",
    "href": "app-e-glossary.html#ch-07",
    "title": "Appendix E — Glossary",
    "section": "E.7 CH 07",
    "text": "E.7 CH 07",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-08",
    "href": "app-e-glossary.html#ch-08",
    "title": "Appendix E — Glossary",
    "section": "E.8 CH 08",
    "text": "E.8 CH 08",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-09",
    "href": "app-e-glossary.html#ch-09",
    "title": "Appendix E — Glossary",
    "section": "E.9 CH 09",
    "text": "E.9 CH 09",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-10",
    "href": "app-e-glossary.html#ch-10",
    "title": "Appendix E — Glossary",
    "section": "E.10 CH 10",
    "text": "E.10 CH 10",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-11",
    "href": "app-e-glossary.html#ch-11",
    "title": "Appendix E — Glossary",
    "section": "E.11 CH 11",
    "text": "E.11 CH 11",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-12",
    "href": "app-e-glossary.html#ch-12",
    "title": "Appendix E — Glossary",
    "section": "E.12 CH 12",
    "text": "E.12 CH 12",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-13",
    "href": "app-e-glossary.html#ch-13",
    "title": "Appendix E — Glossary",
    "section": "E.13 CH 13",
    "text": "E.13 CH 13",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-14",
    "href": "app-e-glossary.html#ch-14",
    "title": "Appendix E — Glossary",
    "section": "E.14 CH 14",
    "text": "E.14 CH 14",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-15",
    "href": "app-e-glossary.html#ch-15",
    "title": "Appendix E — Glossary",
    "section": "E.15 CH 15",
    "text": "E.15 CH 15",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-16",
    "href": "app-e-glossary.html#ch-16",
    "title": "Appendix E — Glossary",
    "section": "E.16 CH 16",
    "text": "E.16 CH 16",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-17",
    "href": "app-e-glossary.html#ch-17",
    "title": "Appendix E — Glossary",
    "section": "E.17 CH 17",
    "text": "E.17 CH 17",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-18",
    "href": "app-e-glossary.html#ch-18",
    "title": "Appendix E — Glossary",
    "section": "E.18 CH 18",
    "text": "E.18 CH 18",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-19",
    "href": "app-e-glossary.html#ch-19",
    "title": "Appendix E — Glossary",
    "section": "E.19 CH 19",
    "text": "E.19 CH 19",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#ch-20",
    "href": "app-e-glossary.html#ch-20",
    "title": "Appendix E — Glossary",
    "section": "E.20 CH 20",
    "text": "E.20 CH 20",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#apx-a",
    "href": "app-e-glossary.html#apx-a",
    "title": "Appendix E — Glossary",
    "section": "E.21 APX A",
    "text": "E.21 APX A",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "app-e-glossary.html#apx-b",
    "href": "app-e-glossary.html#apx-b",
    "title": "Appendix E — Glossary",
    "section": "E.22 APX B",
    "text": "E.22 APX B",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Glossary</span>"
    ]
  }
]