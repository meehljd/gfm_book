<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>16&nbsp; Graphs, Networks, and Biology – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./p4-ch17-systems.html" rel="next">
<link href="./p4-ch15-sc-epi.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-d1e9b63c6b6094879b9f94a7628e3370.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p4-ch15-sc-epi.html">p4–multi-modal_multi-scale.qmd</a></li><li class="breadcrumb-item"><a href="./p4-ch16-networks.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Graphs, Networks, and Biology</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sequencing: From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Genomic Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch03-pgs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS &amp; Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch04-cadd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deleteriousness Scores</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p2--principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Core Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch05-tokens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch06-transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Transformer Architecture for Genomics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch07-foundation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Genomic Foundation Models: Concepts &amp; Taxonomy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch08-pretrain.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Objectives &amp; Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning &amp; Deployment</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p3--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Deep Learning Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch10-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">CNN Sequence-to-Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch11-dna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">DNA and Genomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch12-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RNA &amp; Transcript-Level Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch13-plm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch14-hybrid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">p4–multi-modal_multi-scale.qmd</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch15-sc-epi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Single-Cell &amp; Epigenomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch16-networks.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Graphs, Networks, and Biology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch17-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Multi-Omics &amp; Systems Biology</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p5--eval-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Evaluation and Reliability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch18-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Benchmarks for Genomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch19-eval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Evaluation of Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch20-vep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch21-confound.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch22-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p6--translation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI — Translation and Application</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch23-clinical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch24-variants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Pathogenic Variant Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch25-drugs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Drug Discovery &amp; Biotech</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch26-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Sequence Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch27-future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Future Work &amp; Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-b-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Model Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-c-model-list.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Referenced Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-d-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Additional Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-e-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#graph-neural-network-fundamentals" id="toc-graph-neural-network-fundamentals" class="nav-link active" data-scroll-target="#graph-neural-network-fundamentals"><span class="header-section-number">16.1</span> Graph Neural Network Fundamentals</a>
  <ul class="collapse">
  <li><a href="#graphs-as-data-structures" id="toc-graphs-as-data-structures" class="nav-link" data-scroll-target="#graphs-as-data-structures"><span class="header-section-number">16.1.1</span> Graphs as Data Structures</a></li>
  <li><a href="#message-passing-and-neighborhood-aggregation" id="toc-message-passing-and-neighborhood-aggregation" class="nav-link" data-scroll-target="#message-passing-and-neighborhood-aggregation"><span class="header-section-number">16.1.2</span> Message Passing and Neighborhood Aggregation</a></li>
  <li><a href="#canonical-gnn-architectures" id="toc-canonical-gnn-architectures" class="nav-link" data-scroll-target="#canonical-gnn-architectures"><span class="header-section-number">16.1.3</span> Canonical GNN Architectures</a></li>
  </ul></li>
  <li><a href="#biological-graph-types" id="toc-biological-graph-types" class="nav-link" data-scroll-target="#biological-graph-types"><span class="header-section-number">16.2</span> Biological Graph Types</a>
  <ul class="collapse">
  <li><a href="#protein-protein-interaction-networks" id="toc-protein-protein-interaction-networks" class="nav-link" data-scroll-target="#protein-protein-interaction-networks"><span class="header-section-number">16.2.1</span> Protein-Protein Interaction Networks</a></li>
  <li><a href="#gene-regulatory-networks" id="toc-gene-regulatory-networks" class="nav-link" data-scroll-target="#gene-regulatory-networks"><span class="header-section-number">16.2.2</span> Gene Regulatory Networks</a></li>
  <li><a href="#pathway-and-metabolic-networks" id="toc-pathway-and-metabolic-networks" class="nav-link" data-scroll-target="#pathway-and-metabolic-networks"><span class="header-section-number">16.2.3</span> Pathway and Metabolic Networks</a></li>
  <li><a href="#spatial-and-cell-cell-interaction-graphs" id="toc-spatial-and-cell-cell-interaction-graphs" class="nav-link" data-scroll-target="#spatial-and-cell-cell-interaction-graphs"><span class="header-section-number">16.2.4</span> Spatial and Cell-Cell Interaction Graphs</a></li>
  <li><a href="#molecular-association-graphs" id="toc-molecular-association-graphs" class="nav-link" data-scroll-target="#molecular-association-graphs"><span class="header-section-number">16.2.5</span> Molecular Association Graphs</a></li>
  <li><a href="#variant-gene-phenotype-graphs" id="toc-variant-gene-phenotype-graphs" class="nav-link" data-scroll-target="#variant-gene-phenotype-graphs"><span class="header-section-number">16.2.6</span> Variant-Gene-Phenotype Graphs</a></li>
  </ul></li>
  <li><a href="#key-applications" id="toc-key-applications" class="nav-link" data-scroll-target="#key-applications"><span class="header-section-number">16.3</span> Key Applications</a>
  <ul class="collapse">
  <li><a href="#disease-gene-prioritization" id="toc-disease-gene-prioritization" class="nav-link" data-scroll-target="#disease-gene-prioritization"><span class="header-section-number">16.3.1</span> Disease Gene Prioritization</a></li>
  <li><a href="#pathway-and-module-discovery" id="toc-pathway-and-module-discovery" class="nav-link" data-scroll-target="#pathway-and-module-discovery"><span class="header-section-number">16.3.2</span> Pathway and Module Discovery</a></li>
  <li><a href="#integration-with-sequence-foundation-models" id="toc-integration-with-sequence-foundation-models" class="nav-link" data-scroll-target="#integration-with-sequence-foundation-models"><span class="header-section-number">16.3.3</span> Integration with Sequence Foundation Models</a></li>
  </ul></li>
  <li><a href="#architecture-patterns-for-biological-gnns" id="toc-architecture-patterns-for-biological-gnns" class="nav-link" data-scroll-target="#architecture-patterns-for-biological-gnns"><span class="header-section-number">16.4</span> Architecture Patterns for Biological GNNs</a>
  <ul class="collapse">
  <li><a href="#heterogeneous-and-multi-relational-graphs" id="toc-heterogeneous-and-multi-relational-graphs" class="nav-link" data-scroll-target="#heterogeneous-and-multi-relational-graphs"><span class="header-section-number">16.4.1</span> Heterogeneous and Multi-Relational Graphs</a></li>
  <li><a href="#hierarchical-pooling-and-coarsening" id="toc-hierarchical-pooling-and-coarsening" class="nav-link" data-scroll-target="#hierarchical-pooling-and-coarsening"><span class="header-section-number">16.4.2</span> Hierarchical Pooling and Coarsening</a></li>
  <li><a href="#dynamic-and-temporal-graphs" id="toc-dynamic-and-temporal-graphs" class="nav-link" data-scroll-target="#dynamic-and-temporal-graphs"><span class="header-section-number">16.4.3</span> Dynamic and Temporal Graphs</a></li>
  </ul></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations"><span class="header-section-number">16.5</span> Practical Considerations</a>
  <ul class="collapse">
  <li><a href="#graph-construction-and-quality" id="toc-graph-construction-and-quality" class="nav-link" data-scroll-target="#graph-construction-and-quality"><span class="header-section-number">16.5.1</span> Graph Construction and Quality</a></li>
  <li><a href="#scalability-and-efficiency" id="toc-scalability-and-efficiency" class="nav-link" data-scroll-target="#scalability-and-efficiency"><span class="header-section-number">16.5.2</span> Scalability and Efficiency</a></li>
  <li><a href="#robustness-to-noise-and-incompleteness" id="toc-robustness-to-noise-and-incompleteness" class="nav-link" data-scroll-target="#robustness-to-noise-and-incompleteness"><span class="header-section-number">16.5.3</span> Robustness to Noise and Incompleteness</a></li>
  <li><a href="#interpretability-and-biological-insight" id="toc-interpretability-and-biological-insight" class="nav-link" data-scroll-target="#interpretability-and-biological-insight"><span class="header-section-number">16.5.4</span> Interpretability and Biological Insight</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">16.6</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p4-ch15-sc-epi.html">p4–multi-modal_multi-scale.qmd</a></li><li class="breadcrumb-item"><a href="./p4-ch16-networks.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Graphs, Networks, and Biology</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-networks" class="quarto-section-identifier"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Graphs, Networks, and Biology</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The foundation models explored in earlier chapters treat genomic data as sequences: DNA bases arranged in chromosomal order, amino acids forming protein chains, or RNA transcripts as linear strings of nucleotides. This sequential view has proven remarkably powerful for tasks ranging from variant effect prediction to protein structure modeling. Yet biology is fundamentally relational. Genes regulate one another through transcription factor networks, proteins assemble into functional complexes, metabolites flow through biochemical pathways, and cells coordinate across tissues through spatial signaling. These relationships are not well captured by sequences alone.</p>
<p>Graphs provide a natural mathematical framework for representing such relational structure. In a graph, biological entities become <strong>nodes</strong> and their interactions become <strong>edges</strong>. A protein-protein interaction network represents proteins as nodes with edges denoting physical binding or functional association. A gene regulatory network encodes transcription factors and their targets with directed edges indicating regulatory control. Spatial transcriptomics data can be modeled as a graph where cells are nodes and edges capture physical proximity or inferred cell-cell communication. This graph perspective allows us to ask questions that sequence models cannot easily address: How does a perturbation in one gene propagate through regulatory cascades? Which protein complexes are enriched in disease-associated genes? How do spatial neighborhoods of cells influence tissue-level phenotypes?</p>
<p>Graph neural networks (GNNs) extend deep learning to operate directly on graph-structured data. Rather than sliding convolutional filters across a regular grid or attending over a fixed-length sequence, GNNs perform <strong>message passing</strong> along edges: each node iteratively aggregates information from its neighbors to refine its representation. This allows models to incorporate both node-level features (such as gene expression or sequence embeddings) and edge-level structure (such as known interactions or spatial relationships) in a unified framework. GNNs have achieved state-of-the-art results across diverse domains including molecular property prediction, recommendation systems, and social network analysis, and are increasingly central to genomic and multi-omic applications.</p>
<p>This chapter introduces graphs and graph neural networks as tools for genomic foundation modeling. We begin by reviewing core GNN concepts and architectures, then survey major classes of biological graphs, from protein interaction networks to spatial cell graphs to variant-gene-phenotype hierarchies. We discuss how GNNs can be integrated with sequence-based foundation models, highlight key applications in disease gene prioritization and pathway analysis, and examine practical challenges in graph construction, scalability, and interpretability. This chapter establishes foundational concepts that will be extended in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>, where we consider multi-omics integration and systems-level modeling, and connects to evaluation themes in <a href="p5-ch18-benchmarks.html" class="quarto-xref"><span>Chapter 18</span></a> and <a href="p5-ch19-eval.html" class="quarto-xref"><span>Chapter 19</span></a> regarding robustness and generalization on graph-structured tasks.</p>
<section id="graph-neural-network-fundamentals" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="graph-neural-network-fundamentals"><span class="header-section-number">16.1</span> Graph Neural Network Fundamentals</h2>
<section id="graphs-as-data-structures" class="level3" data-number="16.1.1">
<h3 data-number="16.1.1" class="anchored" data-anchor-id="graphs-as-data-structures"><span class="header-section-number">16.1.1</span> Graphs as Data Structures</h3>
<p>A graph <span class="math inline">\(G = (V, E)\)</span> consists of a set of <strong>nodes</strong> (or vertices) <span class="math inline">\(V\)</span> and a set of <strong>edges</strong> <span class="math inline">\(E\)</span> connecting pairs of nodes. In biological contexts, nodes typically represent molecular or cellular entities such as genes, proteins, metabolites, regulatory elements, cells, or even higher-level abstractions like pathways or phenotypes. Edges encode relationships between these entities: physical binding between proteins, regulatory influence from a transcription factor to a target gene, metabolic reactions linking substrates to products, spatial proximity between cells, or co-expression patterns across conditions.</p>
<p>Edges may be <strong>undirected</strong> when the relationship is symmetric (such as physical protein-protein interactions or mutual co-expression) or <strong>directed</strong> when the relationship is asymmetric (such as transcriptional regulation where a factor activates or represses a target). Edges can also carry <strong>weights</strong> representing interaction strength, confidence scores, or distances. In many biological applications, graphs are <strong>heterogeneous</strong>, meaning they contain multiple node types (genes, proteins, cells) and multiple edge types (physical interaction, regulation, co-localization), each potentially requiring different treatment by the model.</p>
<p>Both nodes and edges can be associated with <strong>features</strong>. Node features might include gene expression levels, protein sequence embeddings from foundation models (<a href="p3-ch13-plm.html" class="quarto-xref"><span>Chapter 13</span></a>), chromatin accessibility scores, or cell type annotations. Edge features could encode binding affinities, tissue specificity, or experimental evidence codes. These features provide the raw material that GNNs will integrate with graph structure to produce task-relevant representations.</p>
<p>Traditional graph algorithms operate directly on this structure to compute properties such as shortest paths, centrality measures, or network communities. While these classical methods remain valuable for exploratory analysis, they typically require hand-crafted features and do not learn from data in an end-to-end fashion. Graph neural networks instead learn task-specific transformations of graph structure and features, enabling more flexible and powerful modeling.</p>
</section>
<section id="message-passing-and-neighborhood-aggregation" class="level3" data-number="16.1.2">
<h3 data-number="16.1.2" class="anchored" data-anchor-id="message-passing-and-neighborhood-aggregation"><span class="header-section-number">16.1.2</span> Message Passing and Neighborhood Aggregation</h3>
<p>The core operation in modern GNNs is <strong>message passing</strong>, a local information exchange mechanism where each node updates its representation by aggregating information from its neighbors. At layer <span class="math inline">\(\ell\)</span>, each node <span class="math inline">\(i\)</span> maintains a hidden state <span class="math inline">\(\mathbf{h}_i^{(\ell)}\)</span>. A generic message passing layer proceeds in two conceptual steps.</p>
<p>First, for each edge <span class="math inline">\((i, j)\)</span> connecting node <span class="math inline">\(i\)</span> to its neighbor <span class="math inline">\(j\)</span>, the model computes a <strong>message</strong> from <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span>: <span class="math display">\[
\mathbf{m}_{ij}^{(\ell)} = \phi_m\left(\mathbf{h}_i^{(\ell)}, \mathbf{h}_j^{(\ell)}, \mathbf{e}_{ij}\right),
\]</span> where <span class="math inline">\(\phi_m\)</span> is a learned function (typically a small neural network) and <span class="math inline">\(\mathbf{e}_{ij}\)</span> represents edge features. This message captures how neighbor <span class="math inline">\(j\)</span> should influence node <span class="math inline">\(i\)</span> given their current states and their relationship.</p>
<p>Second, node <span class="math inline">\(i\)</span> <strong>aggregates</strong> messages from all its neighbors and updates its own state: <span class="math display">\[
\mathbf{h}_i^{(\ell+1)} = \phi_h\left(\mathbf{h}_i^{(\ell)}, \square_{j \in \mathcal{N}(i)} \mathbf{m}_{ij}^{(\ell)}\right),
\]</span> where <span class="math inline">\(\mathcal{N}(i)\)</span> denotes the neighbors of node <span class="math inline">\(i\)</span>, <span class="math inline">\(\square\)</span> is a permutation-invariant aggregation operation (such as summation, mean, max, or attention-weighted sum), and <span class="math inline">\(\phi_h\)</span> is an update function that combines the aggregated messages with the node’s previous state.</p>
<p>By stacking multiple message passing layers, information can propagate across multiple hops in the graph. A node’s representation at layer <span class="math inline">\(\ell\)</span> incorporates information from all nodes within <span class="math inline">\(\ell\)</span> hops. For biological networks, this means that a gene’s learned representation can reflect not only its own features but also signals from its immediate interaction partners, their partners, and so on. This multi-hop aggregation allows the model to capture pathways, cascades, and communities that influence downstream tasks.</p>
<p>The aggregation function <span class="math inline">\(\square\)</span> must be permutation-invariant because the set of neighbors has no inherent ordering. Simple choices like summation or averaging work well in many settings, while more sophisticated options like attention mechanisms allow the model to weight neighbors differentially based on their relevance. The expressiveness of a GNN is closely tied to the expressiveness of these aggregation and update functions, with connections to the Weisfeiler-Lehman graph isomorphism test suggesting inherent limitations for certain graph structures.</p>
</section>
<section id="canonical-gnn-architectures" class="level3" data-number="16.1.3">
<h3 data-number="16.1.3" class="anchored" data-anchor-id="canonical-gnn-architectures"><span class="header-section-number">16.1.3</span> Canonical GNN Architectures</h3>
<p>Several standard GNN architectures have emerged as workhorses for biological applications, each with distinct design choices for message passing and aggregation.</p>
<p><strong>Graph Convolutional Networks (GCN)</strong> <span class="citation" data-cites="kipf_gcn_2017">(<a href="references.html#ref-kipf_gcn_2017" role="doc-biblioref">Kipf and Welling 2017</a>)</span> perform a simple neighborhood averaging operation, where each node’s new representation is a normalized weighted sum of its neighbors’ representations followed by a linear transformation and nonlinearity. GCNs are conceptually straightforward and computationally efficient, making them popular for initial explorations. However, they can suffer from over-smoothing when many layers are stacked, as repeated averaging causes node representations to become increasingly similar regardless of their position in the graph.</p>
<p><strong>GraphSAGE</strong> <span class="citation" data-cites="hamilton_graphsage_2017">(<a href="references.html#ref-hamilton_graphsage_2017" role="doc-biblioref">Hamilton, Ying, and Leskovec 2017</a>)</span> addresses scalability by learning aggregation functions that operate on sampled neighborhoods rather than the full set of neighbors. This enables mini-batch training on large graphs where full-batch methods would be infeasible. GraphSAGE supports multiple aggregation strategies including mean pooling, max pooling, and LSTM-based aggregation, and can generalize to unseen nodes by applying learned aggregators to new neighborhoods. This inductive capability is particularly valuable for biological networks that grow over time as new genes or proteins are characterized.</p>
<p><strong>Graph Attention Networks (GAT)</strong> <span class="citation" data-cites="velickovic_gat_2018">(<a href="references.html#ref-velickovic_gat_2018" role="doc-biblioref">Veličković et al. 2018</a>)</span> introduce attention mechanisms to weight neighbors differently based on their relevance to the target node. Rather than treating all neighbors equally, GAT computes attention coefficients for each edge using a learned compatibility function, allowing the model to focus on the most informative interactions. In biological contexts, attention weights are often interpreted as highlighting key regulatory relationships, critical protein partners, or important cell-cell communications, providing a degree of interpretability beyond black-box aggregation.</p>
<p><strong>Graph Transformers</strong> extend the transformer architecture to graphs by replacing local message passing with global or structured attention over nodes. Some variants use full attention over all nodes with structural encodings (such as shortest path distances or Laplacian eigenvectors) injected as positional information. Others restrict attention to k-hop neighborhoods or learned sparse patterns. Graph transformers blur the boundary between sequence models and GNNs, and are increasingly applied to large heterogeneous biological graphs where capturing long-range dependencies is important.</p>
<p>Beyond these canonical architectures, many specialized variants exist for specific graph properties. Heterogeneous GNNs handle multiple node and edge types with type-specific parameters. Temporal GNNs model dynamic graphs where edges appear or disappear over time, relevant for modeling development or disease progression. Hierarchical GNNs incorporate multi-scale structure through pooling operations that coarsen graphs into super-nodes representing modules or communities. The choice of architecture depends on the structure of the biological graph, the nature of the task, and computational constraints.</p>
</section>
</section>
<section id="biological-graph-types" class="level2" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="biological-graph-types"><span class="header-section-number">16.2</span> Biological Graph Types</h2>
<p>Biological systems can be represented as graphs at multiple scales and with diverse semantics. This section surveys major classes of biological graphs encountered in genomic foundation modeling, highlighting their structure, typical applications, and connections to other chapters.</p>
<section id="protein-protein-interaction-networks" class="level3" data-number="16.2.1">
<h3 data-number="16.2.1" class="anchored" data-anchor-id="protein-protein-interaction-networks"><span class="header-section-number">16.2.1</span> Protein-Protein Interaction Networks</h3>
<p>Protein-protein interaction (PPI) networks represent one of the most extensively studied biological graph types. Nodes correspond to proteins, and edges denote physical binding or stable complex formation. Interactions are typically derived from curated databases such as BioGRID, STRING, or IntAct, which aggregate evidence from yeast two-hybrid screens, affinity purification mass spectrometry, co-crystallization studies, and computational predictions. Edges may be weighted by confidence scores reflecting the strength and reliability of experimental evidence.</p>
<p>PPI networks provide a natural substrate for disease gene prioritization. The premise is that genes causing similar diseases or participating in related biological processes tend to cluster in network neighborhoods. Graph neural networks trained on PPI networks can learn to propagate disease labels or expression signatures across the interactome, identifying candidate disease genes whose neighbors exhibit characteristic patterns even if the genes themselves lack direct annotations. This approach has been applied to prioritize cancer drivers, Mendelian disease genes, and drug targets.</p>
<p>PPI networks also support function prediction tasks. By training GNNs to predict Gene Ontology terms, KEGG pathways, or subcellular localizations from network context, models can transfer functional knowledge from well-studied proteins to poorly characterized ones. This is particularly valuable for non-model organisms or tissue-specific contexts where experimental annotations are sparse. The learned embeddings often reveal modular structure corresponding to protein complexes, signaling cascades, or metabolic pathways, providing interpretable intermediate representations.</p>
<p>A common pattern is to initialize node features using protein sequence foundation models such as ESM (<a href="p3-ch13-plm.html" class="quarto-xref"><span>Chapter 13</span></a>), then refine these embeddings with GNN layers that incorporate interaction context. This two-stage approach leverages the strong inductive bias of sequence models while allowing network structure to adjust representations for relational tasks. The resulting embeddings can be used for downstream applications ranging from variant effect prediction to drug-target interaction screening.</p>
</section>
<section id="gene-regulatory-networks" class="level3" data-number="16.2.2">
<h3 data-number="16.2.2" class="anchored" data-anchor-id="gene-regulatory-networks"><span class="header-section-number">16.2.2</span> Gene Regulatory Networks</h3>
<p>Gene regulatory networks (GRNs) encode the control logic of gene expression. Nodes represent genes or regulatory elements, and directed edges indicate regulatory relationships such as transcription factor binding to target promoters, enhancer-promoter loops, or microRNA-mediated silencing. Unlike PPI networks, GRNs are inherently directed and often context-specific, varying across cell types, developmental stages, and environmental conditions.</p>
<p>Constructing GRNs typically involves integrating multiple data sources. Chromatin immunoprecipitation followed by sequencing (ChIP-seq) identifies direct transcription factor binding sites. Chromatin accessibility assays (ATAC-seq, DNase-seq) reveal open regulatory regions likely to be active. Chromosome conformation capture techniques (Hi-C, promoter capture Hi-C) map physical contacts between enhancers and promoters. Single-cell RNA-seq provides expression correlations that can suggest regulatory relationships. Computational tools combine these signals with sequence motifs and conservation to infer GRN edges, though the resulting networks remain incomplete and noisy.</p>
<p>Graph neural networks applied to GRNs can learn to predict context-specific gene expression from regulatory architecture and chromatin state. For example, a GNN might take as input a graph where nodes represent genes with features from chromatin accessibility models (<a href="p4-ch15-sc-epi.html" class="quarto-xref"><span>Chapter 15</span></a>) and edges represent inferred regulatory connections, then predict cell-type-specific expression levels. By training across many cell types, the model can learn which regulatory motifs and network motifs are associated with active or repressed states.</p>
<p>GRNs are also valuable for modeling perturbation effects. Given a CRISPR knockout or transcription factor overexpression, one can simulate how signals propagate through the regulatory network to predict changes in downstream targets. This connects to the perturbation prediction models discussed in <a href="p4-ch15-sc-epi.html" class="quarto-xref"><span>Chapter 15</span></a> and provides a systems-level complement to sequence-based variant effect prediction (<a href="p5-ch20-vep.html" class="quarto-xref"><span>Chapter 20</span></a>).</p>
</section>
<section id="pathway-and-metabolic-networks" class="level3" data-number="16.2.3">
<h3 data-number="16.2.3" class="anchored" data-anchor-id="pathway-and-metabolic-networks"><span class="header-section-number">16.2.3</span> Pathway and Metabolic Networks</h3>
<p>Biochemical pathways represent chains of enzymatic reactions, where metabolites are converted from substrates to products through catalysis by proteins. Pathway databases such as KEGG, Reactome, and BioCyc organize this knowledge into hierarchical graphs where nodes can represent genes, proteins, metabolites, or reactions, and edges denote substrate-product relationships, catalytic roles, or regulatory influences.</p>
<p>Graph neural networks on pathway networks enable several applications. One is pathway activity inference: given gene expression or proteomic measurements, a GNN can propagate signals through the pathway graph to estimate activity levels of metabolic or signaling pathways. This provides more robust and interpretable summaries than gene set enrichment approaches that treat pathways as flat lists of members. Another application is drug mechanism prediction, where GNNs trained on compound-target-pathway graphs can predict off-target effects or suggest repurposing opportunities by identifying drugs that modulate similar network neighborhoods.</p>
<p>Pathway graphs also support mechanistic interpretation of genome-wide association studies (GWAS). Rather than treating associated variants independently, one can map variants to genes, genes to pathways, and train GNNs to identify which pathway modules are enriched for risk variants. This network-based view can reveal convergent effects of multiple low-frequency variants that would be missed by single-variant tests.</p>
<p>Hierarchical pathway graphs, such as the Reactome hierarchy, provide multi-scale structure where higher-level nodes represent broad processes (such as metabolism or immune response) and lower-level nodes represent specific reactions. GNNs with hierarchical pooling (<a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>) can learn representations at multiple levels of granularity, aligning with biological intuition that complex traits involve perturbations at multiple scales.</p>
</section>
<section id="spatial-and-cell-cell-interaction-graphs" class="level3" data-number="16.2.4">
<h3 data-number="16.2.4" class="anchored" data-anchor-id="spatial-and-cell-cell-interaction-graphs"><span class="header-section-number">16.2.4</span> Spatial and Cell-Cell Interaction Graphs</h3>
<p>Spatial transcriptomics and multiplexed imaging assays measure gene expression or protein abundance while preserving spatial coordinates in tissue sections. These data naturally give rise to spatial graphs where nodes represent cells or spatial spots and edges encode physical proximity, shared boundaries, or inferred cell-cell communication.</p>
<p>Constructing spatial graphs typically involves first segmenting cells or tiles from imaging data, then connecting nodes based on distance thresholds, Delaunay triangulation, or k-nearest neighbors in spatial coordinates. Node features can include gene expression profiles, morphological descriptors from imaging, or embeddings from single-cell foundation models (<a href="p4-ch15-sc-epi.html" class="quarto-xref"><span>Chapter 15</span></a>). Edge features might encode distances, shared membrane area, or predicted ligand-receptor interactions inferred from expression of known communication pairs.</p>
<p>Graph neural networks on spatial graphs have been applied to diverse tasks. One is tissue region classification, where the goal is to label regions as tumor, stroma, immune-infiltrated, or necrotic based on the spatial organization of cells. Another is cell state prediction, where spatial context (such as proximity to blood vessels or immune cells) influences cell behavior in ways not captured by expression alone. Spatial GNNs have also been used to identify tissue niches, such as tertiary lymphoid structures in tumors or stem cell niches in developmental systems, by learning embeddings that cluster spatially coherent functional regions.</p>
<p>A key advantage of spatial graphs over purely expression-based models is the ability to capture emergent tissue-level properties. For example, a tumor’s response to immunotherapy may depend not just on the abundance of immune cells but on their spatial distribution and proximity to tumor cells. GNNs can integrate expression and spatial signals to predict such higher-order phenotypes.</p>
<p>Spatial graphs connect naturally to other graph types: cells can be linked not only by physical proximity but also by shared pathways (constructing a hybrid spatial-molecular graph) or by temporal trajectories (linking spatial snapshots across developmental time or disease progression). This multi-graph view is explored further in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>.</p>
</section>
<section id="molecular-association-graphs" class="level3" data-number="16.2.5">
<h3 data-number="16.2.5" class="anchored" data-anchor-id="molecular-association-graphs"><span class="header-section-number">16.2.5</span> Molecular Association Graphs</h3>
<p>Beyond protein-coding genes, many studies construct graphs over non-coding RNAs (microRNAs, long non-coding RNAs, circular RNAs) and their associations with diseases, drugs, or other molecular entities. In a typical molecular association graph, nodes represent molecules and diseases, and edges indicate known associations or similarities. For example, a microRNA-disease graph might connect miRNAs to diseases they regulate, with additional edges connecting similar miRNAs (based on sequence or target overlap) or related diseases (based on phenotypic similarity or shared genetic architecture).</p>
<p>Graph neural networks on these heterogeneous molecular association graphs have become a popular approach for predicting novel associations. The premise is that if a miRNA is connected to diseases A and B, and disease B shares many associations with disease C, then the miRNA is a plausible candidate for disease C. GNNs formalize this transitive reasoning by propagating embeddings across the graph, learning to weigh different paths and evidence types.</p>
<p>However, molecular association graphs also illustrate important pitfalls. If similarity edges are constructed using features derived from the same data used for training (such as sequence similarity computed from sequences also used as node features), this can introduce <strong>information leakage</strong> where the model exploits shortcuts rather than learning generalizable patterns. Additionally, if train-test splits are performed naively without accounting for graph connectivity, the model may have indirect access to test labels through neighboring nodes. These issues are discussed extensively in <a href="p5-ch21-confound.html" class="quarto-xref"><span>Chapter 21</span></a> regarding confounding and leakage, and underscore the importance of careful experimental design when evaluating GNNs on biological graphs.</p>
</section>
<section id="variant-gene-phenotype-graphs" class="level3" data-number="16.2.6">
<h3 data-number="16.2.6" class="anchored" data-anchor-id="variant-gene-phenotype-graphs"><span class="header-section-number">16.2.6</span> Variant-Gene-Phenotype Graphs</h3>
<p>Clinical variant interpretation often relies on structured knowledge linking variants to genes, genes to pathways or protein complexes, and genes to phenotypes. Resources such as the Gene2Phenotype (G2P) database curate variant-gene-phenotype relationships for Mendelian disorders, providing a graph backbone for diagnostic filtering. More broadly, one can construct graphs where nodes represent variants (or haplotypes), genes, molecular functions, tissue contexts, and clinical phenotypes, with edges encoding relationships like “variant disrupts gene,” “gene participates in pathway,” or “pathway perturbation causes phenotype.”</p>
<p>Graph neural networks on such hierarchical graphs enable several applications. One is <strong>variant prioritization</strong>: given a patient’s genotype and clinical phenotype (represented as a set of Human Phenotype Ontology terms), a GNN can propagate phenotype information backward through the gene and pathway layers to score which variants are most likely causal. This connects to variant effect prediction (<a href="p5-ch20-vep.html" class="quarto-xref"><span>Chapter 20</span></a>) but extends it to consider not just the molecular impact of each variant in isolation but also how variants interact through shared genes, pathways, or phenotypic consequences.</p>
<p>Another application is <strong>phenotype prediction from genotype</strong>: given a set of variants, propagate their effects forward through genes and pathways to predict clinical outcomes. This is related to polygenic risk scores (<a href="p1-ch03-pgs.html" class="quarto-xref"><span>Chapter 3</span></a>) but leverages network structure to model non-additive effects and pathway-level perturbations. Hierarchical graphs provide natural interpretability, as attention weights or activation patterns at each layer can highlight which genes, pathways, or tissues mediate risk.</p>
<p>Variant-gene-phenotype graphs also support <strong>knowledge graph completion</strong>: predicting missing edges such as uncharacterized gene-disease associations or novel variant-phenotype links. This is particularly valuable in rare diseases where direct evidence is limited but indirect evidence from related genes or pathways can guide discovery.</p>
<p>These applications illustrate a general pattern where GNNs bridge molecular and clinical scales by reasoning over multi-level biological graphs. This theme is expanded in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>, where we consider how such graphs integrate with multi-omic data, and in <a href="p6-ch23-clinical.html" class="quarto-xref"><span>Chapter 23</span></a>, where we discuss deployment in diagnostic workflows.</p>
</section>
</section>
<section id="key-applications" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="key-applications"><span class="header-section-number">16.3</span> Key Applications</h2>
<section id="disease-gene-prioritization" class="level3" data-number="16.3.1">
<h3 data-number="16.3.1" class="anchored" data-anchor-id="disease-gene-prioritization"><span class="header-section-number">16.3.1</span> Disease Gene Prioritization</h3>
<p>One of the earliest and most successful applications of GNNs in genomics is disease gene prioritization. The task is to rank genes by their likelihood of being involved in a disease, given known disease-associated genes and features such as expression, sequence, and network context. Traditional approaches relied on guilt-by-association heuristics: genes connected to known disease genes in PPI or co-expression networks were ranked higher. GNNs formalize and extend this intuition by learning how to propagate and weight signals across networks.</p>
<p>A typical workflow involves constructing a PPI or multi-omic network, initializing node features with gene expression or sequence embeddings, labeling known disease genes as positive examples, and training a GNN to classify nodes as disease-associated or not. The trained model can then score genes lacking direct annotations. Early studies demonstrated that GNN-based prioritization outperforms simpler network diffusion methods and can identify candidate genes that are later validated experimentally.</p>
<p>More sophisticated variants use heterogeneous graphs that integrate multiple evidence types. For example, one might combine PPI networks, gene co-expression networks, shared pathway membership, and sequence similarity into a multi-layer graph, then train a heterogeneous GNN that learns type-specific transformations for each edge type. This allows the model to flexibly combine complementary signals: expression correlations might be most informative for regulatory relationships, while physical interactions are key for complex membership.</p>
<p>Disease gene prioritization connects to variant effect prediction by providing a complementary lens. While variant effect models (<a href="p5-ch20-vep.html" class="quarto-xref"><span>Chapter 20</span></a>) score the impact of individual genetic changes, disease gene prioritization scores whether a gene, if perturbed, is likely to contribute to disease. Integrating both can improve clinical interpretation: a variant with a high deleteriousness score in a highly prioritized disease gene is a stronger candidate than one in a gene with no network or functional support.</p>
</section>
<section id="pathway-and-module-discovery" class="level3" data-number="16.3.2">
<h3 data-number="16.3.2" class="anchored" data-anchor-id="pathway-and-module-discovery"><span class="header-section-number">16.3.2</span> Pathway and Module Discovery</h3>
<p>Understanding complex diseases often requires moving beyond individual genes to identify dysregulated pathways, modules, or processes. Graph neural networks provide a natural framework for learning such modular structure. By training GNNs with regularization that encourages sparsity or community structure, one can extract subgraphs or clusters of nodes that coherently contribute to a phenotype.</p>
<p>For example, consider a GNN trained to predict cancer subtype from multi-omic node features on a pathway graph. After training, attention weights or gradient-based attribution can highlight edges and nodes that are most informative for the classification. These may correspond to known cancer pathways (such as cell cycle or apoptosis) or novel modules whose coherence was not previously appreciated. Hierarchical GNNs that pool nodes into super-nodes at intermediate layers provide an explicit mechanism for discovering such modules.</p>
<p>Another approach is unsupervised or self-supervised training, where GNNs are trained to reconstruct graph structure, predict masked node features, or align multi-omic embeddings (as in GLUE; <a href="p4-ch15-sc-epi.html" class="quarto-xref"><span>Chapter 15</span></a>). The learned embeddings can then be clustered to identify modules. This has been applied to single-cell data to discover cell types and states, to spatial data to identify tissue niches, and to molecular networks to find functional modules that are perturbed in disease.</p>
<p>Pathway and module discovery is particularly valuable for rare diseases and precision medicine, where patient-specific perturbations may affect unique combinations of pathways. Rather than relying solely on population-level pathway enrichment, GNN-based methods can score pathway activity for individual patients, enabling more personalized interpretation of multi-omic profiles.</p>
</section>
<section id="integration-with-sequence-foundation-models" class="level3" data-number="16.3.3">
<h3 data-number="16.3.3" class="anchored" data-anchor-id="integration-with-sequence-foundation-models"><span class="header-section-number">16.3.3</span> Integration with Sequence Foundation Models</h3>
<p>A recurring theme in biological GNN applications is the integration of sequence-based foundation models with graph structure. Sequence models such as protein language models (<a href="p3-ch13-plm.html" class="quarto-xref"><span>Chapter 13</span></a>), DNA foundation models (<a href="p3-ch11-dna.html" class="quarto-xref"><span>Chapter 11</span></a>), or single-cell foundation models (<a href="p4-ch15-sc-epi.html" class="quarto-xref"><span>Chapter 15</span></a>) provide rich, context-aware embeddings of biological sequences. However, these models typically operate on individual sequences without explicit relational information. Graph neural networks provide a natural way to augment sequence embeddings with network context.</p>
<p>The typical workflow is a two-stage process. First, a sequence foundation model is applied to each entity in the graph (such as proteins in a PPI network or genes in a regulatory network) to generate node features. These embeddings already capture a wealth of information, such as protein structure propensity, regulatory motifs, or cell type-specific expression patterns. Second, a GNN is trained on top of these embeddings, using the graph structure to propagate and refine information. The GNN layers are often relatively shallow (two to four layers), as the heavy lifting of feature extraction has already been done by the sequence model.</p>
<p>This approach yields several benefits. It improves sample efficiency, as the sequence model is pretrained on large datasets and transfers to the graph task with limited labeled examples. It provides modularity, allowing practitioners to swap in better sequence models as they become available without retraining the entire pipeline. It also enhances interpretability, as one can separately analyze what the sequence model captures versus what the graph structure adds.</p>
<p>For example, in variant effect prediction, one might use a DNA foundation model to embed sequence context around a variant, then use a GNN over a variant-gene-regulatory element graph to aggregate effects across multiple variants or regulatory sites. In protein function prediction, one might use ESM embeddings as initial node features in a PPI network GNN, allowing the model to reason about both intrinsic sequence properties and extrinsic network roles.</p>
<p>This integration strategy connects to the multi-modal foundation models discussed in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>, where sequence, network, and other data types are jointly modeled. It also illustrates a broader principle: foundation models need not be monolithic end-to-end systems but can serve as modular components in larger pipelines that incorporate structured biological knowledge.</p>
</section>
</section>
<section id="architecture-patterns-for-biological-gnns" class="level2" data-number="16.4">
<h2 data-number="16.4" class="anchored" data-anchor-id="architecture-patterns-for-biological-gnns"><span class="header-section-number">16.4</span> Architecture Patterns for Biological GNNs</h2>
<section id="heterogeneous-and-multi-relational-graphs" class="level3" data-number="16.4.1">
<h3 data-number="16.4.1" class="anchored" data-anchor-id="heterogeneous-and-multi-relational-graphs"><span class="header-section-number">16.4.1</span> Heterogeneous and Multi-Relational Graphs</h3>
<p>Most biological systems involve multiple types of entities and relationships. A gene regulatory network might include nodes for transcription factors, target genes, enhancers, and chromatin loops, with edges representing binding, activation, repression, and physical contact. A disease network might include nodes for genes, variants, pathways, and phenotypes, with edges encoding causal relationships, pathway membership, and phenotypic associations. Standard GNNs that treat all nodes and edges homogeneously may miss important distinctions between these types.</p>
<p>Heterogeneous GNNs address this by maintaining type-specific parameters. For each node type, there is a separate embedding lookup or encoder. For each edge type, there is a separate message function. Aggregation functions may also be type-aware, combining messages from different relation types using learned weights or hierarchical attention. This allows the model to learn, for example, that physical protein interactions should be aggregated differently from co-expression correlations, or that activating regulatory edges should have opposite effects from repressing edges.</p>
<p>Multi-relational graph convolutional networks and relational GCNs provide canonical architectures for this setting. These models extend message passing to operate separately on each edge type, then combine the resulting embeddings. Attention-based variants learn to weight different relation types dynamically based on the task and node context. Heterogeneous graph transformers further generalize this by allowing cross-type attention, enabling reasoning about indirect relationships (such as a variant affecting a gene that participates in a pathway that influences a phenotype).</p>
<p>Designing heterogeneous GNNs requires careful thought about which distinctions matter. Too many node or edge types can fragment training data and lead to overfitting, while too few can obscure important biological differences. Domain knowledge and exploratory analysis are essential for choosing an appropriate level of granularity.</p>
</section>
<section id="hierarchical-pooling-and-coarsening" class="level3" data-number="16.4.2">
<h3 data-number="16.4.2" class="anchored" data-anchor-id="hierarchical-pooling-and-coarsening"><span class="header-section-number">16.4.2</span> Hierarchical Pooling and Coarsening</h3>
<p>Many biological questions involve reasoning at multiple scales. Individual proteins assemble into complexes, complexes participate in pathways, and pathways coordinate in tissues to produce organismal phenotypes. Similarly, cells cluster into tissue regions, regions into organs, and organs into systems. Hierarchical GNNs provide a natural way to model such multi-scale structure.</p>
<p>The core idea is to iteratively coarsen the graph by grouping nodes into super-nodes. At each level of the hierarchy, a pooling operation selects which nodes to merge, and a readout operation computes features for the new super-nodes. The resulting coarser graph becomes the input to the next layer, allowing the model to reason at progressively higher levels of abstraction.</p>
<p>Several pooling strategies exist. Top-k pooling selects the most important nodes based on learned scores, discarding the rest. Differentiable pooling learns soft cluster assignments and produces super-nodes as weighted combinations of original nodes. Graph U-Net architectures alternate between coarsening (pooling) and refining (unpooling), enabling information to flow both bottom-up and top-down.</p>
<p>In biological applications, pooling often incorporates prior knowledge. For example, in a gene-pathway-disease graph, one might pool genes into their annotated pathways, then pathways into broader biological processes, creating a hierarchy aligned with Gene Ontology or Reactome. In spatial transcriptomics, cells might be pooled into tissue regions based on spatial clustering, then regions into anatomical structures. This biologically informed pooling provides both computational efficiency and interpretability, as each level of the hierarchy corresponds to a meaningful biological unit.</p>
<p>Hierarchical models connect naturally to the multi-omics integration strategies discussed in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>, where molecular measurements at different scales (variants, genes, pathways, phenotypes) need to be coherently combined.</p>
</section>
<section id="dynamic-and-temporal-graphs" class="level3" data-number="16.4.3">
<h3 data-number="16.4.3" class="anchored" data-anchor-id="dynamic-and-temporal-graphs"><span class="header-section-number">16.4.3</span> Dynamic and Temporal Graphs</h3>
<p>Biological systems are dynamic. Gene regulatory networks change during development and in response to stimuli. Protein-protein interactions are context-dependent and temporally regulated. Disease progression involves evolving states of cells and tissues. Static graph models that assume a fixed topology may miss crucial temporal dynamics.</p>
<p>Dynamic GNNs extend standard architectures to handle time-varying graphs. One approach is to snapshot the graph at different time points, train independent GNNs on each snapshot, and link them through recurrent connections or temporal smoothing. Another is to explicitly model edge appearance and disappearance, treating the graph as a temporal point process. Continuous-time dynamic graphs use neural ODEs or other differential equation solvers to model smooth trajectories of node embeddings over time.</p>
<p>In genomics, dynamic GNNs have been applied to model cell state transitions during differentiation, cancer progression through treatment and relapse, and longitudinal disease trajectories in patients. For example, one might model patient health records as a temporal graph where nodes represent clinical events (diagnoses, treatments, lab results) and edges represent temporal dependencies, then train a dynamic GNN to predict future outcomes or treatment responses.</p>
<p>Temporal modeling is particularly relevant for integrating multi-omic snapshots (such as baseline and post-treatment biopsies) or longitudinal single-cell data. The combination of single-cell foundation models (<a href="p4-ch15-sc-epi.html" class="quarto-xref"><span>Chapter 15</span></a>) for embedding cell states and dynamic GNNs for modeling trajectories is an active area of development.</p>
</section>
</section>
<section id="practical-considerations" class="level2" data-number="16.5">
<h2 data-number="16.5" class="anchored" data-anchor-id="practical-considerations"><span class="header-section-number">16.5</span> Practical Considerations</h2>
<section id="graph-construction-and-quality" class="level3" data-number="16.5.1">
<h3 data-number="16.5.1" class="anchored" data-anchor-id="graph-construction-and-quality"><span class="header-section-number">16.5.1</span> Graph Construction and Quality</h3>
<p>Constructing the graph is often the most consequential modeling choice, as it encodes strong inductive biases about what relationships matter. Several considerations arise.</p>
<p><strong>Source selection</strong>: Biological networks can be derived from curated databases, computational predictions, or data-driven inference. Curated databases (such as STRING for PPIs or Reactome for pathways) provide high-confidence interactions but are incomplete and biased toward well-studied genes. Computational predictions (such as co-expression networks or sequence-based interaction predictions) are more comprehensive but noisy. The choice depends on the task: high-precision curated networks may be preferable for disease gene prioritization, while high-recall predicted networks may be better for exploratory analysis.</p>
<p><strong>Thresholding</strong>: Many potential edges have associated confidence scores or distances. Choosing a threshold determines the graph’s density and structure. Too sparse a graph may fragment the network and prevent information propagation. Too dense a graph may introduce noise and obscure meaningful structure. Cross-validation or principled selection criteria (such as targeting a specific edge density or ensuring graph connectivity) are typically needed.</p>
<p><strong>Directionality and symmetry</strong>: Whether to treat edges as directed or undirected affects both model architecture and interpretation. Gene regulatory networks are inherently directed (transcription factors regulate targets, not vice versa), while PPI networks are often treated as undirected. In practice, many biological relationships have asymmetric strength even if conceptually bidirectional, and directed models can capture this nuance.</p>
<p><strong>Handling missing data</strong>: Biological networks are incomplete. Important interactions may be unmeasured, especially in less-studied contexts or organisms. Models should be robust to missing edges, which can be encouraged through edge dropout during training or by treating the graph as partially observed and jointly learning to predict missing edges alongside the primary task.</p>
<p>Graph construction often requires domain expertise and iterative refinement. Exploratory analyses of graph statistics (degree distributions, clustering coefficients, shortest path lengths) can reveal issues such as disconnected components or implausibly dense hubs that suggest artifacts.</p>
</section>
<section id="scalability-and-efficiency" class="level3" data-number="16.5.2">
<h3 data-number="16.5.2" class="anchored" data-anchor-id="scalability-and-efficiency"><span class="header-section-number">16.5.2</span> Scalability and Efficiency</h3>
<p>Biological graphs can be enormous: millions of cells in spatial transcriptomics datasets, hundreds of thousands of genomic bins in 3D genome contact maps, or comprehensive multi-omic patient cohorts. Full-batch training on such graphs is often infeasible due to memory constraints and computational cost.</p>
<p>Several strategies address scalability. <strong>Neighborhood sampling</strong> (as in GraphSAGE) restricts message passing to a fixed-size sample of neighbors per node, enabling mini-batch training. The sampling can be uniform or biased toward high-degree or high-confidence edges. <strong>Subgraph sampling</strong> trains on induced subgraphs corresponding to biologically meaningful units (such as patients, tissues, or pathways), then combines predictions or embeddings across subgraphs. <strong>Cluster-based training</strong> partitions the graph into clusters, trains on each cluster independently, and uses cross-cluster edges only for fine-tuning.</p>
<p>Efficient implementations matter. Sparse matrix operations, GPU-accelerated GNN libraries (such as PyTorch Geometric or DGL), and specialized kernels for graph operations can provide significant speedups. For extremely large graphs, distributed training or pre-aggregation of neighborhood features may be necessary.</p>
<p>An orthogonal consideration is whether the graph structure is static or needs to be learned or updated during training. Learning sparse or adaptive graphs via differentiable graph structure learning can improve performance but adds computational overhead. For many biological applications, using a fixed graph derived from prior knowledge is a reasonable and efficient starting point.</p>
</section>
<section id="robustness-to-noise-and-incompleteness" class="level3" data-number="16.5.3">
<h3 data-number="16.5.3" class="anchored" data-anchor-id="robustness-to-noise-and-incompleteness"><span class="header-section-number">16.5.3</span> Robustness to Noise and Incompleteness</h3>
<p>All biological networks are noisy and incomplete. Experimental methods for detecting interactions (such as yeast two-hybrid or co-immunoprecipitation for PPIs) have false positive and false negative rates. Computational predictions rely on proxies (such as co-expression or sequence similarity) that imperfectly reflect true biological relationships. Even curated databases are biased toward well-studied genes and processes.</p>
<p>GNNs must be robust to these imperfections. Several strategies help:</p>
<ul>
<li><strong>Edge dropout</strong>: Randomly dropping edges during training forces the model to not rely on any single edge, improving robustness to missing or false interactions.</li>
<li><strong>Node dropout</strong>: Randomly masking node features or entire nodes similarly encourages robustness and prevents overfitting to well-connected hubs.</li>
<li><strong>Adversarial training</strong>: Perturbing edge weights or adding noise to node features during training, then optimizing worst-case performance, can improve robustness.</li>
<li><strong>Uncertainty quantification</strong>: Using Bayesian GNNs or ensembles to estimate prediction uncertainty allows the model to flag low-confidence predictions for manual review.</li>
<li><strong>Multi-view graphs</strong>: Constructing multiple graphs from different data sources and training models that reason over all of them can compensate for noise in any single view.</li>
</ul>
<p>Evaluation on nodes or edges with varying connectivity and annotation quality is essential. Models should not simply perform well on highly connected, well-studied hubs but also generalize to peripheral and novel nodes.</p>
</section>
<section id="interpretability-and-biological-insight" class="level3" data-number="16.5.4">
<h3 data-number="16.5.4" class="anchored" data-anchor-id="interpretability-and-biological-insight"><span class="header-section-number">16.5.4</span> Interpretability and Biological Insight</h3>
<p>A key advantage of graph-based models is interpretability: the graph structure itself provides a scaffold for understanding model predictions. Several techniques extract biological insight from trained GNNs:</p>
<p><strong>Attention weight analysis</strong>: When using attention-based GNNs (such as GAT), attention coefficients indicate which neighbors most influenced each node’s prediction. Aggregating attention across nodes and predictions can highlight critical edges or subgraphs.</p>
<p><strong>Gradient-based attribution</strong>: Computing gradients of predictions with respect to node or edge features identifies which parts of the graph are most important. Integrated gradients or GradCAM-style methods extend this to provide smoother, more reliable attributions.</p>
<p><strong>Counterfactual interventions</strong>: Systematically removing edges, masking nodes, or perturbing features and observing changes in predictions reveals which parts of the graph are necessary or sufficient for a prediction. This can identify vulnerabilities in network structure or suggest therapeutic targets.</p>
<p><strong>Embedding analysis</strong>: Visualizing learned node or edge embeddings (via dimensionality reduction) can reveal clusters or gradients corresponding to biological categories such as pathways, cell types, or disease subtypes. Comparing embeddings across conditions or perturbations can identify context-specific rewiring.</p>
<p><strong>Module extraction</strong>: For hierarchical models, examining intermediate-layer representations or pooled super-nodes can identify emergent modules. These modules often correspond to known pathways or complexes but can also suggest novel functional groupings.</p>
<p>Interpretability is not an afterthought but a central goal for biological GNN applications. The most impactful models are those that not only improve predictions but also generate testable hypotheses and reveal new biological relationships.</p>
</section>
</section>
<section id="summary" class="level2" data-number="16.6">
<h2 data-number="16.6" class="anchored" data-anchor-id="summary"><span class="header-section-number">16.6</span> Summary</h2>
<p>Graphs provide a powerful and natural representation for the relational structure of biological systems. By encoding entities as nodes and their interactions as edges, graph representations enable us to reason about how perturbations propagate through networks, how pathways coordinate to produce phenotypes, and how spatial organization influences cell behavior. Graph neural networks extend deep learning to these irregular structures through message passing and neighborhood aggregation, learning task-specific transformations that integrate node features with topological context.</p>
<p>This chapter introduced core GNN concepts and architectures, surveyed major classes of biological graphs (protein-protein interactions, gene regulatory networks, pathways, spatial cell graphs, molecular association networks, and variant-gene-phenotype hierarchies), and examined key applications including disease gene prioritization, pathway discovery, and integration with sequence foundation models. We discussed practical considerations around graph construction, scalability, robustness to noise, and interpretability.</p>
<p>Graphs and GNNs form a complementary perspective to the sequence-based foundation models explored in earlier chapters. While sequence models excel at learning from the linear structure of DNA, RNA, and proteins, GNNs excel at learning from the relational structure of interactions, regulation, and spatial organization. The most powerful approaches often combine both: using sequence models to generate rich node features and GNNs to refine these features based on network context. This integration pattern recurs throughout the book and is central to the multi-omics and systems-level models discussed in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>.</p>
<p>The graph-based methods introduced here provide essential building blocks for moving beyond single-gene or single-sequence analysis toward systems-level understanding. As genomic foundation models continue to mature, the integration of sequence, structure, and network information promises to yield increasingly comprehensive and biologically grounded representations of complex traits and diseases.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-hamilton_graphsage_2017" class="csl-entry" role="listitem">
Hamilton, William L., Rex Ying, and Jure Leskovec. 2017. <span>“[<span>GraphSAGE</span>] <span>Inductive</span> <span>Representation</span> <span>Learning</span> on <span>Large</span> <span>Graphs</span>.”</span> <em>arXiv.org</em>. <a href="https://arxiv.org/abs/1706.02216v4">https://arxiv.org/abs/1706.02216v4</a>.
</div>
<div id="ref-kipf_gcn_2017" class="csl-entry" role="listitem">
Kipf, Thomas N., and Max Welling. 2017. <span>“Semi-<span>Supervised</span> <span>Classification</span> with <span>Graph</span> <span>Convolutional</span> <span>Networks</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1609.02907">https://doi.org/10.48550/arXiv.1609.02907</a>.
</div>
<div id="ref-velickovic_gat_2018" class="csl-entry" role="listitem">
Veličković, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. <span>“Graph <span>Attention</span> <span>Networks</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1710.10903">https://doi.org/10.48550/arXiv.1710.10903</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./p4-ch15-sc-epi.html" class="pagination-link" aria-label="Single-Cell &amp; Epigenomic Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Single-Cell &amp; Epigenomic Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./p4-ch17-systems.html" class="pagination-link" aria-label="Multi-Omics &amp; Systems Biology">
        <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Multi-Omics &amp; Systems Biology</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>