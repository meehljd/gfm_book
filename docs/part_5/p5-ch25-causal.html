<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>25&nbsp; Causal Inference with Foundation Models – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../part_5/p5-ch26-regulatory.html" rel="next">
<link href="../part_5/p5-ch24-interpretability.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_5/p5--responsible-deployment.html">Part V: Evaluation and Trust</a></li><li class="breadcrumb-item"><a href="../part_5/p5-ch25-causal.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Causal Inference with Foundation Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_1/p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Data Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch03-gwas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS and Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch04-vep-classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classical Variant Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_2/p2--principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Sequence Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch05-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Tokens and Embeddings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch06-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Convolutional Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch07-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transformers and Attention</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch08-pretraining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning Foundations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch10-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Adaptation Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch11-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarks and Evaluation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch12-confounding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Confounding and Data Leakage</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_3/p3--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Foundation Model Families</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch13-fm-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Foundation Model Paradigm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch14-dna-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">DNA Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch15-protein-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch16-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Regulatory Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch17-vep-fm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_4/p4--cellular-context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Cellular Context</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch18-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">RNA Structure and Function</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch19-single-cell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Single-Cell Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch20-3d-genome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">3D Genome Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch21-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Graph and Network Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch22-multi-omics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_5/p5--responsible-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Evaluation and Trust</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch23-uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch24-interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch25-causal.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Causal Inference with Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch26-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regulatory and Governance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_6/p6--applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI: Clinical Translation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch27-clinical-risk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch28-rare-disease.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Rare Disease Diagnosis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch29-drug-discovery.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Drug Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch30-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Sequence Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch31-frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Frontiers and Synthesis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bib/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-b-compute.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Deployment and Compute</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-c-data-curation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Data Curation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-d-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Model Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-e-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-f-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-ch25-prediction-vs-causation" id="toc-sec-ch25-prediction-vs-causation" class="nav-link active" data-scroll-target="#sec-ch25-prediction-vs-causation"><span class="header-section-number">25.1</span> Prediction vs.&nbsp;Causation</a>
  <ul class="collapse">
  <li><a href="#sec-ch25-ladder" id="toc-sec-ch25-ladder" class="nav-link" data-scroll-target="#sec-ch25-ladder"><span class="header-section-number">25.1.1</span> The Ladder of Causation</a></li>
  <li><a href="#sec-ch25-prediction-not-causation" id="toc-sec-ch25-prediction-not-causation" class="nav-link" data-scroll-target="#sec-ch25-prediction-not-causation"><span class="header-section-number">25.1.2</span> Why Predictive Accuracy Does Not Equal Causal Understanding</a></li>
  <li><a href="#sec-ch25-clinical-stakes" id="toc-sec-ch25-clinical-stakes" class="nav-link" data-scroll-target="#sec-ch25-clinical-stakes"><span class="header-section-number">25.1.3</span> The Clinical Stakes</a></li>
  </ul></li>
  <li><a href="#sec-ch25-causal-methods" id="toc-sec-ch25-causal-methods" class="nav-link" data-scroll-target="#sec-ch25-causal-methods"><span class="header-section-number">25.2</span> Causal Methods in Genomics</a>
  <ul class="collapse">
  <li><a href="#sec-ch25-mendelian-randomization" id="toc-sec-ch25-mendelian-randomization" class="nav-link" data-scroll-target="#sec-ch25-mendelian-randomization"><span class="header-section-number">25.2.1</span> Mendelian Randomization</a></li>
  <li><a href="#sec-ch25-knockoffs" id="toc-sec-ch25-knockoffs" class="nav-link" data-scroll-target="#sec-ch25-knockoffs"><span class="header-section-number">25.2.2</span> Model-X Knockoffs for Controlled Variable Selection</a></li>
  <li><a href="#sec-ch25-fine-mapping" id="toc-sec-ch25-fine-mapping" class="nav-link" data-scroll-target="#sec-ch25-fine-mapping"><span class="header-section-number">25.2.3</span> Fine-Mapping for Causal Variants</a></li>
  <li><a href="#sec-ch25-gwas-to-genes" id="toc-sec-ch25-gwas-to-genes" class="nav-link" data-scroll-target="#sec-ch25-gwas-to-genes"><span class="header-section-number">25.2.4</span> From GWAS to Causal Genes</a></li>
  </ul></li>
  <li><a href="#sec-ch25-fm-causality" id="toc-sec-ch25-fm-causality" class="nav-link" data-scroll-target="#sec-ch25-fm-causality"><span class="header-section-number">25.3</span> Foundation Models and Causality</a>
  <ul class="collapse">
  <li><a href="#sec-ch25-fm-causal-structure" id="toc-sec-ch25-fm-causal-structure" class="nav-link" data-scroll-target="#sec-ch25-fm-causal-structure"><span class="header-section-number">25.3.1</span> Can Foundation Models Learn Causal Structure?</a></li>
  <li><a href="#sec-ch25-in-silico-perturbation" id="toc-sec-ch25-in-silico-perturbation" class="nav-link" data-scroll-target="#sec-ch25-in-silico-perturbation"><span class="header-section-number">25.3.2</span> In-Silico Perturbation Prediction</a></li>
  <li><a href="#sec-ch25-counterfactual-limits" id="toc-sec-ch25-counterfactual-limits" class="nav-link" data-scroll-target="#sec-ch25-counterfactual-limits"><span class="header-section-number">25.3.3</span> Counterfactual Reasoning Limitations</a></li>
  </ul></li>
  <li><a href="#sec-ch25-intervention-prediction" id="toc-sec-ch25-intervention-prediction" class="nav-link" data-scroll-target="#sec-ch25-intervention-prediction"><span class="header-section-number">25.4</span> Intervention Prediction</a>
  <ul class="collapse">
  <li><a href="#sec-ch25-crispr-screens" id="toc-sec-ch25-crispr-screens" class="nav-link" data-scroll-target="#sec-ch25-crispr-screens"><span class="header-section-number">25.4.1</span> CRISPR Screen Analysis with Foundation Models</a></li>
  <li><a href="#sec-ch25-drug-response" id="toc-sec-ch25-drug-response" class="nav-link" data-scroll-target="#sec-ch25-drug-response"><span class="header-section-number">25.4.2</span> Drug Response Prediction</a></li>
  <li><a href="#sec-ch25-closed-loop" id="toc-sec-ch25-closed-loop" class="nav-link" data-scroll-target="#sec-ch25-closed-loop"><span class="header-section-number">25.4.3</span> Closed-Loop Experimental Validation</a></li>
  </ul></li>
  <li><a href="#sec-ch25-causal-discovery" id="toc-sec-ch25-causal-discovery" class="nav-link" data-scroll-target="#sec-ch25-causal-discovery"><span class="header-section-number">25.5</span> Causal Discovery</a>
  <ul class="collapse">
  <li><a href="#sec-ch25-regulatory-networks" id="toc-sec-ch25-regulatory-networks" class="nav-link" data-scroll-target="#sec-ch25-regulatory-networks"><span class="header-section-number">25.5.1</span> Learning Regulatory Networks</a></li>
  <li><a href="#sec-ch25-temporal-causality" id="toc-sec-ch25-temporal-causality" class="nav-link" data-scroll-target="#sec-ch25-temporal-causality"><span class="header-section-number">25.5.2</span> Temporal Causality</a></li>
  <li><a href="#sec-ch25-multi-omics-causal" id="toc-sec-ch25-multi-omics-causal" class="nav-link" data-scroll-target="#sec-ch25-multi-omics-causal"><span class="header-section-number">25.5.3</span> Multi-Omics Causal Structure</a></li>
  </ul></li>
  <li><a href="#sec-ch25-clinical-implications" id="toc-sec-ch25-clinical-implications" class="nav-link" data-scroll-target="#sec-ch25-clinical-implications"><span class="header-section-number">25.6</span> Clinical Implications</a>
  <ul class="collapse">
  <li><a href="#sec-ch25-target-validation" id="toc-sec-ch25-target-validation" class="nav-link" data-scroll-target="#sec-ch25-target-validation"><span class="header-section-number">25.6.1</span> Drug Target Validation Evidence Hierarchy</a></li>
  <li><a href="#sec-ch25-regulatory-requirements" id="toc-sec-ch25-regulatory-requirements" class="nav-link" data-scroll-target="#sec-ch25-regulatory-requirements"><span class="header-section-number">25.6.2</span> Regulatory Requirements for Causal Claims</a></li>
  </ul></li>
  <li><a href="#sec-ch25-conclusion" id="toc-sec-ch25-conclusion" class="nav-link" data-scroll-target="#sec-ch25-conclusion"><span class="header-section-number">25.7</span> Looking Forward</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_5/p5--responsible-deployment.html">Part V: Evaluation and Trust</a></li><li class="breadcrumb-item"><a href="../part_5/p5-ch25-causal.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Causal Inference with Foundation Models</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ch25-causal" class="quarto-section-identifier"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Causal Inference with Foundation Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>If you change the input, will the biology change the way the model predicts?</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Prerequisites</strong>: This chapter builds on uncertainty quantification (<a href="p5-ch23-uncertainty.html" class="quarto-xref"><span>Chapter 23</span></a>), interpretability methods (<a href="p5-ch24-interpretability.html" class="quarto-xref"><span>Chapter 24</span></a>), and an understanding of population confounding (<a href="../part_2/p2-ch12-confounding.html" class="quarto-xref"><span>Chapter 12</span></a>). Familiarity with GWAS and fine-mapping concepts from <a href="../part_1/p1-ch03-gwas.html" class="quarto-xref"><span>Chapter 3</span></a> is assumed.</p>
<p><strong>Learning Objectives</strong>: After completing this chapter, you should be able to:</p>
<ol type="1">
<li>Distinguish between association, intervention, and counterfactual reasoning using Pearl’s ladder of causation</li>
<li>Explain why predictive accuracy does not guarantee causal validity</li>
<li>Apply Mendelian randomization concepts to assess causal claims from genomic data</li>
<li>Evaluate when foundation model predictions support causal versus merely correlational conclusions</li>
<li>Design validation strategies that test causal rather than predictive claims</li>
</ol>
<p><strong>Key Insight</strong>: Foundation models excel at learning associations from observational data, but clinical intervention requires causal reasoning. The gap between prediction (what do we observe?) and causation (what happens if we intervene?) is not a matter of model scale or data quantity—it reflects fundamentally different types of knowledge.</p>
</div>
</div>
<p>This question separates prediction from causation. A model can accurately predict that patients with a particular variant have worse outcomes without telling you whether correcting that variant would help them. The variant might cause disease, or it might merely correlate with ancestry, environment, or another genetic factor that actually causes disease. Predictive accuracy—even exceptional predictive accuracy—cannot distinguish between these possibilities.</p>
<p>The preceding chapters addressed how to trust model predictions: calibrated uncertainty tells us when models are confident (<a href="p5-ch23-uncertainty.html" class="quarto-xref"><span>Chapter 23</span></a>), and interpretability reveals what patterns drive predictions (<a href="p5-ch24-interpretability.html" class="quarto-xref"><span>Chapter 24</span></a>). But clinical action requires more. It requires knowing that intervening on a predicted target will produce the intended effect.</p>
<section id="sec-ch25-prediction-vs-causation" class="level2" data-number="25.1">
<h2 data-number="25.1" class="anchored" data-anchor-id="sec-ch25-prediction-vs-causation"><span class="header-section-number">25.1</span> Prediction vs.&nbsp;Causation</h2>
<section id="sec-ch25-ladder" class="level3" data-number="25.1.1">
<h3 data-number="25.1.1" class="anchored" data-anchor-id="sec-ch25-ladder"><span class="header-section-number">25.1.1</span> The Ladder of Causation</h3>
<div class="callout callout-style-default callout-note callout-titled" title="Predict Before You Look">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Predict Before You Look
</div>
</div>
<div class="callout-body-container callout-body">
<p>Judea Pearl proposed three levels of causal reasoning. Before reading about them, what do you think distinguishes “seeing” (observation) from “doing” (intervention) from “imagining” (counterfactual)? Why might a model that can answer observational questions fail at interventional ones?</p>
</div>
</div>
<p>Judea Pearl’s “ladder of causation” provides a framework for understanding the gap between prediction and intervention <span class="citation" data-cites="pearl_book_2018">(<a href="../bib/references.html#ref-pearl_book_2018" role="doc-biblioref"><strong>pearl_book_2018?</strong></a>)</span>. The ladder has three rungs, each representing a qualitatively different type of reasoning:</p>
<p><strong>Rung 1: Association</strong> answers questions of the form “What does seeing X tell me about Y?” This is the domain of standard predictive modeling. A foundation model that predicts gene expression from sequence operates at this level: given a sequence pattern, what expression level do we expect? Association captures correlation but remains agnostic about mechanism.</p>
<p><strong>Rung 2: Intervention</strong> answers questions of the form “What happens to Y if I change X?” This requires understanding not just correlation but causal structure. Intervening on X breaks its correlations with upstream causes while preserving its effects on downstream variables. A model capable of intervention reasoning can predict not just what expression we observe given a sequence, but what expression would result if we edited the sequence.</p>
<p><strong>Rung 3: Counterfactual</strong> answers questions of the form “What would Y have been if X had been different, given that we observed specific values?” Counterfactuals require reasoning about alternative histories for specific individuals, not just population-level effects. This is the realm of “What if this patient had received treatment A instead of treatment B?”</p>
<p>Most machine learning, including foundation models, operates at rung 1. Models learn associations from training data and predict outcomes for new inputs. Moving to rung 2 requires additional structure, typically assumptions about causal relationships encoded in directed acyclic graphs (DAGs) or identified through experimental interventions. Rung 3 remains largely out of reach for current methods outside carefully controlled settings.</p>
<div id="fig-ladder-causation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ladder-causation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch25/01-fig-ladder-causation.svg" class="img-fluid figure-img"></p>
<figcaption>Pearl’s ladder of causation applied to genomics</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ladder-causation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.1: Pearl’s ladder of causation applied to genomics. <strong>Rung 1 (Association)</strong>: Foundation models learn P(Y|X)—observing variant V, predict phenotype P. <strong>Rung 2 (Intervention)</strong>: P(Y|do(X))—if we edit V, what happens to P? Requires causal structure, not just correlations. <strong>Rung 3 (Counterfactual)</strong>: For this specific patient, what would have happened under alternative conditions? The gaps are qualitative: predictive accuracy at Rung 1 provides no guarantee of accuracy at Rungs 2-3.
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: The Rung Gap is Qualitative, Not Quantitative
</div>
</div>
<div class="callout-body-container callout-body">
<p>A common misconception is that better predictions (rung 1) eventually enable intervention reasoning (rung 2). This is false. No amount of observational data can, by itself, distinguish correlation from causation. A model trained only on observational data cannot reliably predict intervention effects, regardless of its predictive accuracy. Moving up the ladder requires either (1) experimental intervention data, (2) causal assumptions encoded in the model, or (3) natural experiments like genetic randomization. Scale and accuracy at rung 1 do not substitute for the structural knowledge needed for rung 2.</p>
</div>
</div>
</section>
<section id="sec-ch25-prediction-not-causation" class="level3" data-number="25.1.2">
<h3 data-number="25.1.2" class="anchored" data-anchor-id="sec-ch25-prediction-not-causation"><span class="header-section-number">25.1.2</span> Why Predictive Accuracy Does Not Equal Causal Understanding</h3>
<p>A model can achieve excellent predictive accuracy while learning entirely non-causal relationships. Consider a gene expression predictor trained on population data. The model might learn that expression of gene A correlates with expression of gene B, and accurately predict B given A. But this prediction may reflect:</p>
<ul>
<li><strong>Direct causation</strong>: A regulates B</li>
<li><strong>Reverse causation</strong>: B regulates A, and the model uses A as a proxy</li>
<li><strong>Common cause</strong>: Both A and B are regulated by an unmeasured factor C</li>
<li><strong>Selection bias</strong>: The training population was selected in a way that induces correlation</li>
<li><strong>Confounding</strong>: Population structure or batch effects create spurious associations (<span class="quarto-unresolved-ref">?sec-ch12-population-structure</span>)</li>
</ul>
<p>The distinction matters for intervention. If A directly causes B, then editing A will change B. If the correlation reflects a common cause, editing A will have no effect on B. A model that achieves 95% accuracy predicting B from A provides no information about which causal structure generated the correlation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think: Diagnosing Causal Structure
</div>
</div>
<div class="callout-body-container callout-body">
<p>A foundation model accurately predicts that patients with high expression of gene X have poor cancer prognosis. Before targeting gene X therapeutically, what evidence would you want?</p>
<p>Consider: (1) Does X drive poor prognosis, or does aggressive cancer drive both X expression and poor prognosis? (2) What experimental or genetic evidence could distinguish these scenarios? (3) How would you test whether X is a driver versus a passenger?</p>
</div>
</div>
<p>Foundation models are particularly susceptible to learning non-causal patterns because they are trained on massive observational datasets that contain all of these correlation sources. The very scale that enables their predictive power also exposes them to more spurious associations. Confounding in genomic data is pervasive (<a href="../part_2/p2-ch12-confounding.html" class="quarto-xref"><span>Chapter 12</span></a>), and foundation models lack architectural mechanisms to distinguish causal from confounded relationships.</p>
</section>
<section id="sec-ch25-clinical-stakes" class="level3" data-number="25.1.3">
<h3 data-number="25.1.3" class="anchored" data-anchor-id="sec-ch25-clinical-stakes"><span class="header-section-number">25.1.3</span> The Clinical Stakes</h3>
<p>The distinction between association and causation is not merely philosophical when models inform clinical decisions. A risk prediction model can be useful even if it captures only associations: knowing that a patient is high-risk enables closer monitoring regardless of whether we understand why (<a href="../part_6/p6-ch27-clinical-risk.html" class="quarto-xref"><span>Chapter 27</span></a>). But treatment decisions require causal reasoning.</p>
<p>Consider drug target selection. A gene whose expression is associated with disease progression might be a target, a biomarker, or neither. If the gene causally drives progression, inhibiting it could slow disease. If it is merely correlated (perhaps because both expression and progression reflect an upstream driver), inhibiting it will not help. If the association is confounded by treatment patterns in the training data, the gene may have no biological relationship to the disease at all.</p>
<p>The same logic applies to polygenic risk scores, variant interpretation, and therapeutic recommendations. Association supports screening and stratification. Causation supports intervention. Confusing the two leads to treatments that do not work, resources wasted on non-causal targets, and potential patient harm.</p>
<p>The table below summarizes when association versus causation matters for different clinical applications:</p>
<div id="tbl-assoc-causal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-assoc-causal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;25.1: When causal reasoning is required for clinical applications. Association-based predictions suffice for stratification and prognosis but not for treatment decisions.
</figcaption>
<div aria-describedby="tbl-assoc-causal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 35%">
<col style="width: 31%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Application</th>
<th>Association Sufficient?</th>
<th>Causation Required?</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Risk stratification</td>
<td>Yes</td>
<td>No</td>
<td>Identifying high-risk patients for closer monitoring</td>
</tr>
<tr class="even">
<td>Biomarker for prognosis</td>
<td>Yes</td>
<td>No</td>
<td>Predicting disease progression</td>
</tr>
<tr class="odd">
<td>Diagnostic classification</td>
<td>Yes</td>
<td>No</td>
<td>Classifying tumor subtypes</td>
</tr>
<tr class="even">
<td>Drug target selection</td>
<td>No</td>
<td>Yes</td>
<td>Choosing which gene to inhibit</td>
</tr>
<tr class="odd">
<td>Treatment recommendation</td>
<td>No</td>
<td>Yes</td>
<td>Selecting therapy for a patient</td>
</tr>
<tr class="even">
<td>Variant pathogenicity for intervention</td>
<td>No</td>
<td>Yes</td>
<td>Gene therapy target selection</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="sec-ch25-causal-methods" class="level2" data-number="25.2">
<h2 data-number="25.2" class="anchored" data-anchor-id="sec-ch25-causal-methods"><span class="header-section-number">25.2</span> Causal Methods in Genomics</h2>
<p>Genomics has developed specialized methods for causal inference that leverage the unique properties of genetic data. Unlike typical observational studies where confounding is ubiquitous, genetic variants are assigned at conception through meiosis—a natural randomization process that makes genetics uniquely suited for certain causal inference approaches.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Recall and Connect">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recall and Connect
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>From <a href="../part_2/p2-ch12-confounding.html" class="quarto-xref"><span>Chapter 12</span></a></strong>: We learned that population structure creates spurious associations in GWAS. Before reading about Mendelian randomization, consider: How might the random assignment of alleles at conception help overcome confounding? What makes genetic variants different from environmental exposures?</p>
</div>
</div>
<section id="sec-ch25-mendelian-randomization" class="level3" data-number="25.2.1">
<h3 data-number="25.2.1" class="anchored" data-anchor-id="sec-ch25-mendelian-randomization"><span class="header-section-number">25.2.1</span> Mendelian Randomization</h3>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Conceptual Difficulty
</div>
</div>
<div class="callout-body-container callout-body">
<p>Mendelian randomization involves subtle causal reasoning. If the three core assumptions and their violation modes are unfamiliar, consider reviewing the causal inference literature before proceeding. The key insight is that genetic variants serve as “natural experiments” because their assignment at conception is random with respect to most confounders.</p>
</div>
</div>
<p><strong>Mendelian randomization (MR)</strong> exploits the random assortment of alleles during meiosis to create natural experiments <span class="citation" data-cites="davey_smith_mendelian_2003 lawlor_mendelian_2008">(<a href="../bib/references.html#ref-davey_smith_mendelian_2003" role="doc-biblioref">Davey Smith and Ebrahim 2003</a>; <a href="../bib/references.html#ref-lawlor_mendelian_2008" role="doc-biblioref"><strong>lawlor_mendelian_2008?</strong></a>)</span>. If a genetic variant affects an exposure (e.g., gene expression, protein level, metabolite concentration), and that variant is associated with an outcome, then under certain assumptions we can infer that the exposure causally affects the outcome.</p>
<p>Think of the genetic variant as a randomly assigned ticket at birth. Imagine a lottery where some people receive tickets that increase their coffee consumption (a variant affecting caffeine metabolism). If ticket holders—who drink more coffee by chance of genetics, not by lifestyle choice—also have different heart disease rates, we have evidence that coffee consumption itself affects heart disease, not just that coffee drinkers happen to live differently in other ways. The “ticket” (genetic variant) was assigned before any confounders could arise, isolating the effect of the exposure.</p>
<p>The logic parallels randomized controlled trials. In an RCT, random treatment assignment ensures that treatment groups differ only in treatment received, not in confounders. In MR, random allele assignment at conception ensures that genotype groups differ only in genotype-driven exposure levels, not in confounders. The genetic variant acts as an “instrumental variable” that isolates the causal effect of the exposure.</p>
<p>MR relies on three core assumptions:</p>
<ol type="1">
<li><strong>Relevance</strong>: The genetic variant must be associated with the exposure</li>
<li><strong>Independence</strong>: The variant must not be associated with confounders of the exposure-outcome relationship</li>
<li><strong>Exclusion restriction</strong>: The variant must affect the outcome only through the exposure, not through other pathways (no <strong>horizontal pleiotropy</strong>—the situation where a genetic variant affects multiple traits through independent biological mechanisms, rather than through a single causal pathway)</li>
</ol>
<p>Why are these three assumptions necessary? Relevance ensures the genetic variant actually affects the exposure of interest; without it, the variant provides no information about the exposure’s causal effect. Independence is why genetics provides a causal inference advantage: because alleles are randomly assigned at conception before environmental confounders arise, genetic instruments satisfy independence naturally for most confounders (though population structure can violate it). The exclusion restriction ensures we measure the exposure’s effect rather than some other effect of the variant—if a variant affects the outcome through multiple pathways, we cannot isolate which pathway matters.</p>
<p>Violations of these assumptions, particularly pleiotropy, limit MR’s applicability. Modern MR methods address this through multiple instruments, median-based estimators, mode-based estimators, and outlier detection that are robust to some violations <span class="citation" data-cites="bowden_mendelian_2015 hartwig_robust_2017">(<a href="../bib/references.html#ref-bowden_mendelian_2015" role="doc-biblioref">Bowden, Davey Smith, and Burgess 2015</a>; <a href="../bib/references.html#ref-hartwig_robust_2017" role="doc-biblioref">Hartwig, Davey Smith, and Bowden 2017</a>)</span>. Integration with foundation models, discussed below, offers new possibilities for instrument selection and pleiotropy detection.</p>
</section>
<section id="sec-ch25-knockoffs" class="level3" data-number="25.2.2">
<h3 data-number="25.2.2" class="anchored" data-anchor-id="sec-ch25-knockoffs"><span class="header-section-number">25.2.2</span> Model-X Knockoffs for Controlled Variable Selection</h3>
<p>Mendelian randomization exploits random allele assignment to isolate causal effects; fine-mapping exploits LD structure to identify causal variants. A third approach—<strong>Model-X knockoffs</strong>—provides a complementary framework for causal variable selection that addresses a specific limitation of standard GWAS: the inability to distinguish marginal association from conditional independence <span class="citation" data-cites="candes_panning_2018">(<a href="../bib/references.html#ref-candes_panning_2018" role="doc-biblioref">Candès et al. 2018</a>)</span>.</p>
<p>Standard GWAS tests each variant marginally: is this variant associated with the outcome? But in the presence of linkage disequilibrium, marginal p-values conflate direct effects with indirect correlation. A non-causal variant in high LD with a causal variant will show significant marginal association even though it provides no information about the outcome beyond what other variants already provide. This distinction—marginal versus conditional association—is precisely what causal inference requires.</p>
<p>Model-X knockoffs construct synthetic “knockoff” variables that preserve the correlation structure among features but are conditionally independent of the outcome given the original features. By comparing how strongly each original variant predicts the outcome versus its knockoff, the method identifies variants that provide genuine predictive signal beyond what their LD neighbors explain. The framework provides finite-sample false discovery rate (FDR) control without requiring knowledge of how the outcome depends on the variants—a model-free property that distinguishes it from parametric approaches.</p>
<p>Applied to Crohn’s disease GWAS data (~400,000 SNPs), knockoffs identified twice as many discoveries as marginal association testing while maintaining FDR control. Several discoveries were subsequently validated in larger meta-analyses, demonstrating that the method identifies true positives that marginal testing misses due to conservative thresholding across correlated variants.</p>
<p>For foundation model applications, knockoffs offer several advantages. First, they provide principled feature selection for high-dimensional embeddings where standard regularization may be insufficient—selecting which embedding dimensions carry genuine predictive signal versus which reflect noise that degrades performance through the dimensionality trap (<span class="quarto-unresolved-ref">?sec-ch21-noise-accumulation</span>). Second, they can distinguish true epistasis from “phantom epistasis” created by LD confounding: apparent variant interactions that actually reflect joint tagging of single causal variants. Third, the framework extends naturally to testing whether foundation model attention patterns identify conditionally important positions rather than merely correlated ones.</p>
<p>The practical limitation is computational: knockoff construction requires estimating or specifying the joint distribution of variants, which scales poorly with variant count. Approximate methods using block-diagonal LD structure make genome-scale application tractable, but the approach is most powerful for targeted analysis of fine-mapped regions or selected feature sets rather than whole-genome screening.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Worked Example: Mendelian Randomization for Drug Target Validation
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Scenario</strong>: A foundation model predicts that inhibiting protein P will reduce cardiovascular disease (CVD) risk because P levels correlate with CVD in observational data. How would MR validate this?</p>
<p><strong>Step 1: Identify genetic instruments</strong>. Find variants associated with P levels (pQTLs). Suppose variant rs12345 reduces P levels by 10%.</p>
<p><strong>Step 2: Test association with outcome</strong>. In GWAS data, does rs12345 associate with reduced CVD risk?</p>
<p><strong>Step 3: Calculate causal estimate</strong>. If rs12345 reduces P by 10% and CVD risk by 5%, the implied causal effect is: 5%/10% = 0.5 (50% reduction in CVD per unit reduction in P).</p>
<p><strong>Step 4: Check assumptions</strong>. Is rs12345 pleiotropic? Does it affect CVD through other pathways? MR-Egger and weighted median methods can test for pleiotropy.</p>
<p><strong>Interpretation</strong>: If MR supports causality, P is a promising drug target. If not, the observational correlation may reflect confounding, and inhibiting P may not reduce CVD.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Predict Before You Look">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Predict Before You Look
</div>
</div>
<div class="callout-body-container callout-body">
<p>GWAS identifies regions containing multiple correlated variants. Before reading about fine-mapping, predict: What information would help us identify which specific variant is causal? Why might simply choosing the variant with the strongest p-value be misleading?</p>
</div>
</div>
</section>
<section id="sec-ch25-fine-mapping" class="level3" data-number="25.2.3">
<h3 data-number="25.2.3" class="anchored" data-anchor-id="sec-ch25-fine-mapping"><span class="header-section-number">25.2.3</span> Fine-Mapping for Causal Variants</h3>
<p>Genome-wide association studies identify genomic loci associated with traits but typically cannot pinpoint causal variants. Most GWAS signals arise from common variants in linkage disequilibrium (LD) with the true causal variant(s), creating “association signals” that span many correlated SNPs (<a href="../part_1/p1-ch03-gwas.html#sec-ch03-ld" class="quarto-xref"><span>Section 3.3</span></a>). <strong>Fine-mapping</strong> aims to identify which variant(s) within an associated locus are causal.</p>
<p>Statistical fine-mapping methods compute posterior probabilities that each variant is causal given the observed association statistics and LD structure <span class="citation" data-cites="maller_bayesian_2012 benner_finemap_2016">(<a href="../bib/references.html#ref-maller_bayesian_2012" role="doc-biblioref">Maller et al. 2012</a>; <a href="../bib/references.html#ref-benner_finemap_2016" role="doc-biblioref">Benner et al. 2016</a>)</span>. These methods output <strong>credible sets</strong>: minimal sets of variants that contain the causal variant(s) with high probability (typically 95%). Smaller credible sets indicate more confident localization.</p>
<p>Why does fine-mapping work, and why does it sometimes fail? Fine-mapping exploits the fact that causal variants generate stronger association signals than non-causal variants that merely correlate through LD. By modeling the LD structure explicitly, fine-mapping can disentangle which variant is most likely causal. The method fails when LD is too tight (multiple variants are nearly perfectly correlated, making them statistically indistinguishable) or when multiple causal variants exist in the same region (violating the typical single-causal-variant assumption).</p>
<p>Functional annotations dramatically improve fine-mapping. Variants in regulatory elements, coding regions, or conserved sequences are more likely to be causal than variants in unconstrained regions. Foundation models can provide these annotations at unprecedented resolution, predicting variant effects on chromatin accessibility, transcription factor binding, splicing, and protein function (<a href="../part_3/p3-ch17-vep-fm.html" class="quarto-xref"><span>Chapter 17</span></a>). Integrating foundation model predictions with statistical fine-mapping creates more powerful methods for causal variant identification.</p>
</section>
<section id="sec-ch25-gwas-to-genes" class="level3" data-number="25.2.4">
<h3 data-number="25.2.4" class="anchored" data-anchor-id="sec-ch25-gwas-to-genes"><span class="header-section-number">25.2.4</span> From GWAS to Causal Genes</h3>
<p>Even after fine-mapping identifies likely causal variants, connecting variants to causal genes remains challenging. Most GWAS signals fall in non-coding regions, often affecting expression of genes other than the nearest gene through long-range enhancer-promoter interactions. The “GWAS-to-gene” problem asks: given a causal variant, which gene(s) does it affect, and how?</p>
<p>Multiple lines of evidence inform gene assignment:</p>
<ul>
<li><p><strong>Expression quantitative trait loci (eQTLs)</strong>: Variants that affect expression of nearby genes suggest regulatory mechanisms. Colocalization of GWAS and eQTL signals supports a shared causal variant affecting both expression and phenotype <span class="citation" data-cites="giambartolomei_bayesian_2014">(<a href="../bib/references.html#ref-giambartolomei_bayesian_2014" role="doc-biblioref"><strong>giambartolomei_bayesian_2014?</strong></a>)</span>.</p></li>
<li><p><strong>Chromatin interaction data</strong>: Hi-C and related methods identify physical contacts between enhancers and promoters (<a href="../part_4/p4-ch20-3d-genome.html#sec-ch20-hic-matrices" class="quarto-xref"><span>Section 20.2.1</span></a>), enabling annotation of which genes regulatory variants might contact.</p></li>
<li><p><strong>Coding variant enrichment</strong>: When fine-mapped variants include coding variants, the affected gene is immediately implicated.</p></li>
<li><p><strong>Foundation model predictions</strong>: DNA sequence models can predict effects of non-coding variants on regulatory element activity and gene expression, providing computational support for regulatory mechanisms (<a href="../part_3/p3-ch16-regulatory.html" class="quarto-xref"><span>Chapter 16</span></a>, <a href="../part_3/p3-ch17-vep-fm.html" class="quarto-xref"><span>Chapter 17</span></a>).</p></li>
</ul>
<p>Integrating these evidence types into coherent gene prioritization frameworks remains an active area. No single method provides definitive causal gene assignment; converging evidence across multiple approaches provides the strongest support.</p>
<div id="fig-gwas-to-gene" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gwas-to-gene-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch25/02-fig-gwas-to-gene.svg" class="img-fluid figure-img"></p>
<figcaption>From GWAS to causal gene identification</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gwas-to-gene-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.2: From GWAS to causal gene. <strong>Stage 1</strong>: GWAS identifies associated locus with multiple variants in linkage disequilibrium. <strong>Stage 2</strong>: Fine-mapping with foundation model functional annotations narrows to credible set. <strong>Stage 3</strong>: Multiple evidence integration—eQTL colocalization, chromatin contacts, FM variant predictions—prioritizes target gene. <strong>Stage 4</strong>: Experimental validation provides causal ground truth. Foundation models accelerate stages 2-3 but cannot substitute for experimental validation.
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Recall and Connect">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recall and Connect
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>From <a href="../part_1/p1-ch03-gwas.html" class="quarto-xref"><span>Chapter 3</span></a></strong>: Recall that linkage disequilibrium (LD) causes multiple variants to be correlated. Now consider: How does fine-mapping use LD structure to identify causal variants? Why would tight LD make causal variant identification harder even with perfect statistical power?</p>
</div>
</div>
</section>
</section>
<section id="sec-ch25-fm-causality" class="level2" data-number="25.3">
<h2 data-number="25.3" class="anchored" data-anchor-id="sec-ch25-fm-causality"><span class="header-section-number">25.3</span> Foundation Models and Causality</h2>
<section id="sec-ch25-fm-causal-structure" class="level3" data-number="25.3.1">
<h3 data-number="25.3.1" class="anchored" data-anchor-id="sec-ch25-fm-causal-structure"><span class="header-section-number">25.3.1</span> Can Foundation Models Learn Causal Structure?</h3>
<p>Foundation models are trained on observational data through objectives like next-token prediction or masked element reconstruction. These objectives do not distinguish causal from correlational relationships. A DNA language model trained on sequences across species learns patterns that reflect evolutionary conservation, but conservation conflates multiple causal processes: purifying selection against deleterious mutations, hitchhiking of neutral variants with beneficial ones, and mutational biases that vary across the genome.</p>
<p>Recent theoretical work examines conditions under which causal structure emerges from observational learning. In language models, there is evidence that models trained on sufficiently diverse text corpora learn something resembling causal structure, because text describes causal relationships and generating coherent text requires modeling them <span class="citation" data-cites="kiciman_causal_2023">(<a href="../bib/references.html#ref-kiciman_causal_2023" role="doc-biblioref"><strong>kiciman_causal_2023?</strong></a>)</span>. Whether similar arguments apply to genomic sequence is unclear. Genomic sequences do not describe causal relationships; they embody them. A regulatory element’s sequence determines its function, but this determination is mediated by cellular machinery that the sequence model never observes.</p>
<p>Empirical evidence suggests foundation models capture aspects of causal structure but do not reliably distinguish causal from correlational patterns. Models trained on expression data learn gene-gene relationships that sometimes reflect regulatory causation and sometimes reflect co-regulation by shared factors. Models trained on perturbation data (e.g., CRISPR screens) show improved ability to predict intervention effects, suggesting that interventional training data is necessary for interventional prediction capability.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Knowledge Check: Observational vs.&nbsp;Interventional Learning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider two foundation models: Model A is trained on observational gene expression data (measuring expression without perturbations). Model B is trained on Perturb-seq data (expression measured after CRISPR knockouts).</p>
<ol type="1">
<li>Which model is more likely to learn causal gene-gene relationships? Why?</li>
<li>If Model A learns that genes X and Y are co-expressed, what causal scenarios could explain this?</li>
<li>If Model B learns that knocking out X changes Y expression, what does this tell us about causality?</li>
</ol>
<p>The key distinction: Model A learns associations that could reflect common causes; Model B learns from interventions that directly test causal relationships.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Model B is more likely to learn causal relationships because interventional data (CRISPR knockouts) directly tests causation by breaking correlations with confounders. (2) X and Y co-expression in observational data could reflect: X regulates Y, Y regulates X, both are regulated by a common upstream factor, or spurious correlation from batch effects. (3) If knocking out X changes Y expression, this provides strong evidence that X causally influences Y (either directly or through intermediates), because the intervention breaks non-causal correlations.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-ch25-in-silico-perturbation" class="level3" data-number="25.3.2">
<h3 data-number="25.3.2" class="anchored" data-anchor-id="sec-ch25-in-silico-perturbation"><span class="header-section-number">25.3.2</span> In-Silico Perturbation Prediction</h3>
<p>You want to know if editing a regulatory element will increase expression of a therapeutic gene. The experiment would take months and cost thousands of dollars. Can you get a useful prediction first? If a model could accurately predict the effect of your edit before you make it, you could prioritize the most promising candidates and avoid wasting resources on variants that will not work.</p>
<p><strong>In-silico perturbation prediction</strong> uses foundation models to predict effects of genetic or molecular changes without performing experiments. This directly addresses rung 2 of the causal ladder: “What happens if we change X?”</p>
<p>Several approaches exist:</p>
<p><strong>Sequence-level perturbation</strong>: DNA and RNA foundation models can predict effects of sequence mutations on molecular phenotypes like chromatin accessibility, transcription factor binding, and splicing (<a href="../part_3/p3-ch17-vep-fm.html" class="quarto-xref"><span>Chapter 17</span></a>). These predictions are inherently counterfactual: the model compares predicted output for reference vs.&nbsp;alternate allele. When validated against experimental perturbations, such predictions can support causal reasoning about regulatory mechanisms.</p>
<p><strong>Gene-level perturbation</strong>: Single-cell foundation models trained on expression data can be prompted with in-silico gene knockouts or overexpression, generating predictions of downstream expression changes <span class="citation" data-cites="theodoris_transfer_2023">(<a href="../bib/references.html#ref-theodoris_transfer_2023" role="doc-biblioref"><strong>theodoris_transfer_2023?</strong></a>)</span>. These predictions extrapolate from patterns learned in observational data, with accuracy depending on whether observational patterns reflect causal regulation.</p>
<p><strong>Embedding-space perturbation</strong>: Models that embed cells, genes, or sequences in latent spaces enable perturbation by arithmetic operations on embeddings. Subtracting a “disease” direction and adding a “healthy” direction generates predictions of therapeutic effects. Such approaches assume linear structure in embedding space that may not hold.</p>
<p>All in-silico perturbation methods face a fundamental limitation: they cannot validate their own causal accuracy. A model that predicts X causes Y might be correct (X causes Y), might be learning reverse causation (Y causes X, so perturbing X in the model disrupts learned correlations), or might be learning confounded correlations (neither causes the other). External validation through experimental perturbation is necessary to establish causal accuracy.</p>
<p>The table below compares different in-silico perturbation approaches:</p>
<div id="tbl-perturbation-methods" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-perturbation-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;25.2: Comparison of in-silico perturbation methods. Validation against experimental interventions is essential for all approaches.
</figcaption>
<div aria-describedby="tbl-perturbation-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 11%">
<col style="width: 12%">
<col style="width: 26%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Input</th>
<th>Output</th>
<th>Causal Validity</th>
<th>Validation Required</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sequence-level (e.g., Enformer)</td>
<td>Reference vs.&nbsp;alternate allele</td>
<td>Predicted molecular phenotype change</td>
<td>Moderate—predicts direct sequence effects</td>
<td>MPRA, allelic expression</td>
</tr>
<tr class="even">
<td>Gene-level (e.g., Geneformer)</td>
<td>In-silico knockout</td>
<td>Predicted expression changes</td>
<td>Low—extrapolates from correlations</td>
<td>Perturb-seq, CRISPR screens</td>
</tr>
<tr class="odd">
<td>Embedding arithmetic</td>
<td>Vector operations in latent space</td>
<td>Transformed cell state</td>
<td>Low—assumes linear embedding structure</td>
<td>Experimental perturbation</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-ch25-counterfactual-limits" class="level3" data-number="25.3.3">
<h3 data-number="25.3.3" class="anchored" data-anchor-id="sec-ch25-counterfactual-limits"><span class="header-section-number">25.3.3</span> Counterfactual Reasoning Limitations</h3>
<p>A patient received drug A and her tumor progressed. Her oncologist wonders: would drug B have worked better? This is not a question about average treatment effects in a population—it is about what <em>would have happened</em> to this specific patient under a different treatment. No dataset contains this answer because it requires observing the same patient under two mutually exclusive conditions simultaneously. This is the counterfactual problem, and it represents a fundamental barrier even for the most sophisticated models.</p>
<p>Counterfactual reasoning—rung 3 of the causal ladder—asks what would have happened under alternative circumstances for a specific individual or instance. This is qualitatively harder than intervention reasoning, which asks about population-level effects of interventions.</p>
<p>Foundation models face fundamental barriers to counterfactual reasoning:</p>
<p><strong>Identifiability</strong>: Counterfactual quantities are often not identifiable from observational data even with perfect knowledge of the joint distribution. Learning from data cannot overcome this barrier.</p>
<p><strong>Individual-level noise</strong>: Counterfactuals require reasoning about stochastic processes at the individual level. What would this specific cell’s expression have been if a specific gene were knocked out? The answer depends on molecular noise that models cannot capture from population-level training.</p>
<p><strong>Temporal specificity</strong>: Counterfactuals often involve specific timepoints and histories. “What would this patient’s outcome have been if treatment started earlier?” requires reasoning about patient-specific trajectories that models trained on cross-sectional data cannot address.</p>
<p>These limitations suggest that foundation models can at best approximate counterfactual reasoning for population-level interventions but cannot provide reliable individual-level counterfactuals without additional assumptions or data. Clinical applications requiring individual counterfactual reasoning (e.g., precision treatment optimization) must acknowledge this fundamental limitation.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: The Counterfactual Barrier
</div>
</div>
<div class="callout-body-container callout-body">
<p>Individual counterfactuals (“What would have happened to this patient if…?”) require information that does not exist in any dataset: the outcome under the path not taken. This is not a data limitation that more training can overcome—it is a logical impossibility. Foundation models can estimate population-average treatment effects (how do patients like this one respond on average?) but cannot answer individual counterfactuals without additional structural assumptions. Clinical systems claiming to provide personalized counterfactual predictions should be scrutinized for what assumptions they make to bridge this logical gap.</p>
</div>
</div>
</section>
</section>
<section id="sec-ch25-intervention-prediction" class="level2" data-number="25.4">
<h2 data-number="25.4" class="anchored" data-anchor-id="sec-ch25-intervention-prediction"><span class="header-section-number">25.4</span> Intervention Prediction</h2>
<p>Despite the limitations above, foundation models can contribute substantially to intervention prediction when combined with appropriate experimental data, validation frameworks, and acknowledgment of causal assumptions.</p>
<section id="sec-ch25-crispr-screens" class="level3" data-number="25.4.1">
<h3 data-number="25.4.1" class="anchored" data-anchor-id="sec-ch25-crispr-screens"><span class="header-section-number">25.4.1</span> CRISPR Screen Analysis with Foundation Models</h3>
<p>You have run a genome-wide CRISPR screen and identified 200 genes whose knockout affects cancer cell viability. But which of these are direct drivers versus downstream consequences? Which hits will replicate in patients rather than just in cell lines? And for the thousands of genes you could not include in this screen, can you predict which would have shown effects?</p>
<p>CRISPR screens provide large-scale interventional data: systematic gene knockouts or knockdowns across cells, with readouts including viability, expression, and phenotype <span class="citation" data-cites="shalem_genome-scale_2014 adamson_multiplexed_2016">(<a href="../bib/references.html#ref-shalem_genome-scale_2014" role="doc-biblioref"><strong>shalem_genome-scale_2014?</strong></a>; <a href="../bib/references.html#ref-adamson_multiplexed_2016" role="doc-biblioref"><strong>adamson_multiplexed_2016?</strong></a>)</span>. This data is inherently causal—it captures effects of interventions rather than mere associations. Foundation models can help interpret, extend, and transfer insights from these screens.</p>
<p>Foundation models enhance CRISPR screen analysis in several ways:</p>
<p><strong>Screen design</strong>: Models can predict which guide RNAs will effectively perturb target genes, improving screen efficiency. Expression foundation models can predict baseline expression levels that affect perturbation detectability.</p>
<p><strong>Hit interpretation</strong>: When screens identify genes whose perturbation affects a phenotype, foundation models help interpret mechanism. Which regulatory networks are affected? What downstream targets change? Integration with interaction networks (<a href="../part_4/p4-ch21-networks.html#sec-ch21-canonical-architectures" class="quarto-xref"><span>Section 21.2.2</span></a>) contextualizes screen hits.</p>
<p><strong>Transfer and extrapolation</strong>: Foundation models trained on screens in one context (cell type, condition) can predict perturbation effects in new contexts. This transfer capability enables virtual screens that guide experimental prioritization.</p>
<p><strong>Combination effects</strong>: Predicting effects of multi-gene perturbations from single-gene data is a key challenge. Foundation models that learn gene-gene relationships from expression data can model epistatic interactions, though prediction accuracy for combinations remains limited.</p>
<p>Importantly, foundation models trained on CRISPR screen data acquire interventional rather than merely associational patterns. This provides a path toward causal prediction capability: train on interventional data to learn interventional structure.</p>
</section>
<section id="sec-ch25-drug-response" class="level3" data-number="25.4.2">
<h3 data-number="25.4.2" class="anchored" data-anchor-id="sec-ch25-drug-response"><span class="header-section-number">25.4.2</span> Drug Response Prediction</h3>
<p>A patient has a tumor with an unusual mutation profile. Several drugs might work, but which one? Testing all options experimentally would take months the patient may not have. If you could predict which drugs the tumor would respond to based on its molecular profile, you could prioritize the most promising option first. But here lies the challenge: observed correlations between tumor features and drug response might reflect the drugs actually used (selection bias), patient characteristics that affect both tumor biology and outcomes (confounding), or genuine causal sensitivity—and only the last matters for choosing therapy.</p>
<p>Predicting how patients or tumors will respond to drugs is a central challenge in precision oncology and pharmacogenomics. Drug response has clear causal structure: the drug causes the response. Foundation models can contribute to response prediction by learning patterns that generalize across drugs, cell lines, and patients.</p>
<p>Approaches include:</p>
<p><strong>Chemical-biological foundation models</strong>: Models that jointly embed drug structures and biological contexts (gene expression, mutations) can predict response to drugs not seen during training <span class="citation" data-cites="zitnik_modeling_2018">(<a href="../bib/references.html#ref-zitnik_modeling_2018" role="doc-biblioref"><strong>zitnik_modeling_2018?</strong></a>)</span>. Transfer from chemical structure to biological effect leverages foundation model representations of both domains.</p>
<p><strong>Expression-based response models</strong>: Single-cell foundation models can predict expression changes induced by drug treatment, enabling in-silico drug screening. The accuracy of these predictions depends on whether training data captures the relevant drug-gene relationships.</p>
<p><strong>Genomic response predictors</strong>: Foundation models pretrained on DNA sequence can be fine-tuned to predict drug response from tumor genomes, learning patterns of sensitivity-conferring and resistance-conferring mutations.</p>
<p>Drug response prediction illustrates both the promise and limitations of foundation models for causal tasks. Models can learn generalizable patterns of drug-gene interaction, but validation requires clinical trials that are expensive and slow. The gap between in-silico prediction and validated clinical utility remains substantial (<a href="../part_6/p6-ch29-drug-discovery.html" class="quarto-xref"><span>Chapter 29</span></a>).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think: Validating Drug Response Predictions
</div>
</div>
<div class="callout-body-container callout-body">
<p>A foundation model predicts that tumors with mutation M will respond to drug D. Before using this prediction clinically:</p>
<ol type="1">
<li>What training data would make this prediction more trustworthy? (Hint: observational vs.&nbsp;interventional)</li>
<li>How would you distinguish whether M predicts response because M causes sensitivity, or because M correlates with some other feature that causes sensitivity?</li>
<li>What validation hierarchy would you design? Consider in-vitro, in-vivo, and clinical evidence.</li>
</ol>
</div>
</div>
</section>
<section id="sec-ch25-closed-loop" class="level3" data-number="25.4.3">
<h3 data-number="25.4.3" class="anchored" data-anchor-id="sec-ch25-closed-loop"><span class="header-section-number">25.4.3</span> Closed-Loop Experimental Validation</h3>
<p>A foundation model predicts that knocking out gene X will sensitize cancer cells to drug Y. You test this prediction experimentally and find it is wrong. What now? You could dismiss the model, but a smarter approach is to use this failure to improve future predictions. The model was wrong because its training data lacked the relevant causal relationship. By feeding the experimental result back into training, you give the model interventional ground truth it could never learn from observational data alone.</p>
<p>The most powerful paradigm for developing causally accurate foundation models is <strong>closed-loop integration</strong> of prediction and experiment. Rather than training models on fixed datasets and deploying them for prediction, closed-loop systems iterate between:</p>
<ol type="1">
<li><strong>Prediction</strong>: Model proposes interventions likely to be informative or effective</li>
<li><strong>Experiment</strong>: Proposed interventions are tested in automated assay platforms</li>
<li><strong>Observation</strong>: Experimental outcomes are recorded</li>
<li><strong>Update</strong>: Results update model parameters or inform next predictions</li>
</ol>
<p>This design-build-test-learn (DBTL) cycle is discussed extensively in <a href="../part_6/p6-ch30-design.html#sec-ch30-dbtl" class="quarto-xref"><span>Section 30.6</span></a> for sequence design applications. The same framework applies to causal learning: by iterating between prediction and experimental validation, models can accumulate interventional data that supports increasingly accurate causal predictions.</p>
<p>Closed-loop systems face practical challenges: experimental throughput limits iteration speed, costs constrain scale, and defining informative interventions requires balancing exploration and exploitation. But the fundamental advantage—learning from interventional rather than observational data—addresses the core limitation of standard foundation model training.</p>
<div id="fig-closed-loop-causal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-closed-loop-causal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch25/03-fig-closed-loop-causal.svg" class="img-fluid figure-img"></p>
<figcaption>Closed-loop causal learning for foundation models</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-closed-loop-causal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.3: Closed-loop causal learning for foundation models. The cycle iterates between: (1) Predicting intervention effects from current knowledge, (2) Executing prioritized interventions on automated platforms, (3) Capturing experimental readouts, and (4) Updating the model with interventional data. Unlike standard training on observational data, closed-loop systems accumulate interventional ground truth that progressively improves causal accuracy—providing a path from Rung 1 (association) toward Rung 2 (intervention) of the causal ladder.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-ch25-causal-discovery" class="level2" data-number="25.5">
<h2 data-number="25.5" class="anchored" data-anchor-id="sec-ch25-causal-discovery"><span class="header-section-number">25.5</span> Causal Discovery</h2>
<p>Suppose you measure expression of 20,000 genes across thousands of cells and find that genes A and B are correlated. Does A regulate B? Does B regulate A? Are both controlled by an upstream regulator C that you did not measure? Without perturbation experiments—which are expensive and cannot test all 400 million possible pairwise relationships—how would you even begin to answer this question?</p>
<p><strong>Causal discovery</strong> aims to learn causal structure itself from observational data: which variables cause which others? In genomics, this includes learning regulatory networks, identifying driver mutations, and discovering mechanistic relationships. The challenge is extracting directional, causal information from data that only shows correlation.</p>
<section id="sec-ch25-regulatory-networks" class="level3" data-number="25.5.1">
<h3 data-number="25.5.1" class="anchored" data-anchor-id="sec-ch25-regulatory-networks"><span class="header-section-number">25.5.1</span> Learning Regulatory Networks</h3>
<p>A cancer researcher identifies a transcription factor that is consistently overexpressed in aggressive tumors. Is this factor driving tumor progression, or is it merely a downstream consequence of some other oncogenic program? If you could reconstruct the regulatory network—the web of cause-and-effect relationships among genes—you could trace the chain of causation and identify the true driver. But how do you learn such a network from expression data alone?</p>
<p>Gene regulatory networks describe causal relationships among genes: transcription factors regulate targets, signaling molecules activate pathways, metabolic enzymes control flux. Learning these networks from data is a foundational problem in systems biology—one where foundation models offer new approaches but also face fundamental limitations.</p>
<p>Classical approaches infer networks from expression correlation, mutual information, or regression-based methods like GENIE3 <span class="citation" data-cites="huynh-thu_inferring_2010">(<a href="../bib/references.html#ref-huynh-thu_inferring_2010" role="doc-biblioref"><strong>huynh-thu_inferring_2010?</strong></a>)</span>. These methods identify associations but struggle to distinguish causal direction and are confounded by common regulators.</p>
<p>Foundation models offer new approaches to regulatory network inference:</p>
<p><strong>Attention-based structure learning</strong>: Transformer foundation models learn attention patterns over genes. These attention weights can be interpreted as soft regulatory relationships, with attention from gene A to gene B suggesting A influences B’s representation. However, attention weights reflect model computation, not necessarily biological causation <span class="citation" data-cites="jain_attention_2019">(<a href="../bib/references.html#ref-jain_attention_2019" role="doc-biblioref"><strong>jain_attention_2019?</strong></a>)</span>.</p>
<p><strong>Perturbation-guided learning</strong>: Training foundation models on perturbation data (e.g., Perturb-seq, which combines CRISPR perturbation with single-cell RNA-seq) enables learning of directed regulatory relationships. If knocking out A changes B, A to B is supported. Foundation models scale this reasoning across thousands of perturbations.</p>
<p><strong>Multi-task learning</strong>: Models trained to simultaneously predict multiple molecular phenotypes (expression, chromatin state, binding) may learn shared structure reflecting underlying regulatory networks.</p>
<p>Network inference from foundation models remains an active research area. Validation against gold-standard regulatory relationships (e.g., ChIP-seq, perturbation experiments) is essential for assessing accuracy.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Recall and Connect">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recall and Connect
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>From <a href="p5-ch24-interpretability.html" class="quarto-xref"><span>Chapter 24</span></a></strong>: We learned that attention weights in transformers show which inputs the model considers important. Now think critically: If attention from gene A to gene B is high, does this prove A regulates B? What’s the difference between computational attention and biological causation?</p>
</div>
</div>
</section>
<section id="sec-ch25-temporal-causality" class="level3" data-number="25.5.2">
<h3 data-number="25.5.2" class="anchored" data-anchor-id="sec-ch25-temporal-causality"><span class="header-section-number">25.5.2</span> Temporal Causality</h3>
<p>You observe that in differentiating stem cells, transcription factor A rises before gene B is expressed. Does A activate B? Or do both respond to an earlier signal, with A simply responding faster? In cross-sectional snapshots, you cannot tell—both scenarios produce identical correlations. But in time-series data, the ordering matters: if A consistently rises <em>before</em> B changes across many conditions, this temporal precedence provides evidence for causal direction that pure correlation cannot.</p>
<p>Time provides a strong constraint on causal direction: causes precede effects. Time-series data in genomics—developmental trajectories, drug response time courses, circadian cycles—enable causal inference approaches that exploit temporal structure.</p>
<p><strong>Granger causality</strong> tests whether past values of X improve prediction of future Y beyond what past Y alone provides <span class="citation" data-cites="granger_investigating_1969">(<a href="../bib/references.html#ref-granger_investigating_1969" role="doc-biblioref"><strong>granger_investigating_1969?</strong></a>)</span>. The underlying logic is that causes must precede their effects—like how dark clouds appear before rain, not after. If you can better predict tomorrow’s rain by knowing today’s cloud patterns than by knowing only yesterday’s rain, clouds are “Granger-causing” rain. In genomics, this approach identifies genes whose expression changes precede changes in other genes: if knowing gene A’s expression at time 1 helps predict gene B’s expression at time 2 (beyond what B’s own history provides), this suggests A may regulate B.</p>
<p><strong>Dynamical foundation models</strong> trained on time-series single-cell data (e.g., RNA velocity measurements) learn temporal dynamics and can be queried for causal relationships <span class="citation" data-cites="la_manno_rna_2018">(<a href="../bib/references.html#ref-la_manno_rna_2018" role="doc-biblioref"><strong>la_manno_rna_2018?</strong></a>)</span>. By modeling how expression states evolve, these models implicitly learn which genes drive transitions.</p>
<p><strong>Structural causal models with temporal constraints</strong> encode the assumption that causes precede effects, enabling stronger causal conclusions from time-series observational data. Foundation models can be trained with temporal structure as an architectural prior.</p>
<p>Temporal approaches require appropriate data: longitudinal measurements, developmental time courses, or perturbation time series. Cross-sectional data, which comprises most genomic datasets, cannot support temporal causal inference directly.</p>
</section>
<section id="sec-ch25-multi-omics-causal" class="level3" data-number="25.5.3">
<h3 data-number="25.5.3" class="anchored" data-anchor-id="sec-ch25-multi-omics-causal"><span class="header-section-number">25.5.3</span> Multi-Omics Causal Structure</h3>
<p>A genetic variant associates with both mRNA levels of gene X and disease risk. Does the variant cause disease by altering X’s expression? Or does it affect disease through some other pathway entirely, with the mRNA association being a red herring? If you also measure protein levels and find the variant affects mRNA but <em>not</em> protein—perhaps due to post-transcriptional regulation—you have learned something crucial: the mRNA association cannot explain the disease effect, and you should look elsewhere.</p>
<p>Different molecular modalities (DNA, RNA, protein, metabolite) are linked by known causal relationships: DNA encodes RNA, RNA is translated to protein, proteins catalyze metabolic reactions. Multi-omics data that measures multiple modalities simultaneously enables causal inference that leverages this structure.</p>
<p>For example, eQTL analysis identifies genetic variants that causally affect expression. Extending to protein quantitative trait loci (pQTLs) and metabolite QTLs (mQTLs) traces causal effects from genome through transcriptome to proteome to metabolome. Discordance between levels (e.g., an eQTL without corresponding pQTL) suggests post-transcriptional regulation.</p>
<p>Foundation models trained on multi-omic data can learn cross-modality relationships. Whether these relationships are causal depends on training: models trained on QTL data learn causal structure because genetic variation is the instrument; models trained on matched multi-omic profiles learn associations that may reflect common causes.</p>
<p>Multi-omic integration for causal inference is discussed further in <a href="../part_4/p4-ch22-multi-omics.html" class="quarto-xref"><span>Chapter 22</span></a>. Foundation models can integrate across modalities but require causal validation as for single-modality models.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think: Causal Structure Across Omics Layers
</div>
</div>
<div class="callout-body-container callout-body">
<p>The central dogma (DNA to RNA to protein) provides causal direction: genetic variants cause expression changes, which cause protein level changes.</p>
<ol type="1">
<li>If a variant associates with both mRNA and protein levels, what additional evidence would distinguish direct transcriptional effects from post-transcriptional regulation?</li>
<li>If a variant associates with mRNA but not protein levels, what biological mechanisms might explain this?</li>
<li>How could a foundation model leverage this multi-omic structure to improve causal predictions?</li>
</ol>
</div>
</div>
</section>
</section>
<section id="sec-ch25-clinical-implications" class="level2" data-number="25.6">
<h2 data-number="25.6" class="anchored" data-anchor-id="sec-ch25-clinical-implications"><span class="header-section-number">25.6</span> Clinical Implications</h2>
<section id="sec-ch25-target-validation" class="level3" data-number="25.6.1">
<h3 data-number="25.6.1" class="anchored" data-anchor-id="sec-ch25-target-validation"><span class="header-section-number">25.6.1</span> Drug Target Validation Evidence Hierarchy</h3>
<p>Your foundation model identifies protein X as strongly associated with disease progression. Should you invest $50 million to develop a drug targeting X? Association alone cannot answer this question. What if X is merely a biomarker of aggressive disease, not a driver? What if inhibiting X has no effect—or makes things worse? Before committing to expensive clinical development, you need to climb from association toward causal evidence.</p>
<p>Drug development requires confidence that a target is causally involved in disease—that modulating the target will affect disease outcomes. Foundation model predictions contribute to this evidence base but sit within a broader hierarchy of target validation evidence:</p>
<p><strong>Weakest evidence</strong>: Association. The target’s expression or activity correlates with disease in observational data. Foundation models excel at identifying such associations but cannot distinguish causal from confounded relationships.</p>
<p><strong>Moderate evidence</strong>: Mendelian randomization. Genetic instruments affecting the target causally affect disease risk. This provides human in-vivo evidence of causation but may reflect effects of lifetime exposure rather than therapeutic intervention.</p>
<p><strong>Strong evidence</strong>: Perturbation experiments. Knocking out or modulating the target in cellular or animal models affects disease-relevant phenotypes. Foundation models trained on perturbation data can predict such effects but require experimental validation.</p>
<p><strong>Strongest evidence</strong>: Clinical intervention. Drugs targeting the mechanism show efficacy in clinical trials. This is the ultimate validation but comes late in development.</p>
<p>Foundation models can accelerate target validation by integrating across evidence types: identifying associations, predicting perturbation effects, and prioritizing candidates for experimental validation (<a href="../part_6/p6-ch29-drug-discovery.html" class="quarto-xref"><span>Chapter 29</span></a>). But they cannot substitute for experimental and clinical evidence—they can only prioritize which targets receive experimental investment.</p>
<div id="fig-evidence-hierarchy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-evidence-hierarchy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch25/04-fig-evidence-hierarchy.svg" class="img-fluid figure-img"></p>
<figcaption>Evidence hierarchy for drug target validation</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-evidence-hierarchy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.4: Evidence hierarchy for drug target validation. <strong>Weakest</strong>: observational association—foundation models excel here but associations may be confounded. <strong>Moderate</strong>: Mendelian randomization provides human in-vivo causal evidence. <strong>Strong</strong>: Experimental perturbation directly tests causation in model systems. <strong>Strongest</strong>: Clinical trial efficacy is definitive but expensive. Foundation models accelerate association discovery, MR instrument selection, and perturbation prioritization, but cannot substitute for the experimental and clinical evidence required for confident target validation.
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical Guidance: Communicating Causal Claims
</div>
</div>
<div class="callout-body-container callout-body">
<p>When presenting foundation model predictions to clinical collaborators or in publications:</p>
<ol type="1">
<li><p><strong>Distinguish association from causation explicitly</strong>: “The model predicts that variant X associates with outcome Y” is different from “inhibiting X will improve Y.”</p></li>
<li><p><strong>State what validation would be needed</strong>: “This prediction suggests X as a candidate target; validation would require [MR analysis / perturbation experiment / clinical trial].”</p></li>
<li><p><strong>Quantify confidence appropriately</strong>: Predictive confidence (model calibration) is not causal confidence. A well-calibrated association prediction may still reflect confounding.</p></li>
<li><p><strong>Acknowledge the evidence tier</strong>: “This is associational evidence; stronger causal evidence would require genetic instruments or experimental perturbation.”</p></li>
</ol>
</div>
</div>
</section>
<section id="sec-ch25-regulatory-requirements" class="level3" data-number="25.6.2">
<h3 data-number="25.6.2" class="anchored" data-anchor-id="sec-ch25-regulatory-requirements"><span class="header-section-number">25.6.2</span> Regulatory Requirements for Causal Claims</h3>
<p>You have built an AI system that predicts which patients will benefit from a particular therapy. Is this a risk stratification tool that flags high-risk patients for clinical review? Or is it a treatment recommendation system that claims to know what intervention will help? The distinction matters enormously for regulatory approval: the first requires demonstration of predictive accuracy, while the second requires evidence that following the recommendations actually improves outcomes.</p>
<p>Regulatory agencies evaluate medical AI systems based on their intended use. Systems that make causal claims face higher evidentiary standards than purely predictive systems.</p>
<p>A risk stratification model that identifies high-risk patients without claiming to identify treatable causes requires validation of predictive accuracy: does the model correctly identify who is at risk? This is achievable through retrospective validation on held-out data.</p>
<p>A treatment recommendation model that suggests interventions based on predicted causal effects requires validation of causal accuracy: do the recommended interventions actually produce the predicted effects? This requires prospective trials comparing outcomes for patients who receive model-guided vs.&nbsp;standard treatment.</p>
<p>Current regulatory frameworks (<a href="p5-ch26-regulatory.html#sec-ch26-regulatory" class="quarto-xref"><span>Section 26.1</span></a>) do not fully distinguish predictive from causal validation, but the distinction has practical implications. Foundation model predictions deployed as associational tools (risk scores, phenotype predictions) face achievable validation requirements. The same models deployed as causal tools (treatment recommendations, target prioritization) face requirements that may be impractical without substantial prospective evidence.</p>
<p>Developers of foundation model systems should consider intended use carefully. Claiming causal capabilities that cannot be validated creates both regulatory risk and potential patient harm. Limiting claims to predictive performance, while acknowledging causal limitations, provides a more defensible regulatory path while appropriately caveating clinical use.</p>
</section>
</section>
<section id="sec-ch25-conclusion" class="level2" data-number="25.7">
<h2 data-number="25.7" class="anchored" data-anchor-id="sec-ch25-conclusion"><span class="header-section-number">25.7</span> Looking Forward</h2>
<p>Causal inference remains one of the deepest challenges in genomic foundation models. The gap between prediction (rung 1) and intervention (rung 2) is not merely a matter of scale or compute—it reflects fundamental differences in what can be learned from observational vs.&nbsp;interventional data. Foundation models trained on observational genomic sequences can achieve remarkable predictive accuracy while remaining unreliable for causal reasoning.</p>
<p>Three paths forward seem most promising:</p>
<p><strong>Training on interventional data</strong>: Foundation models trained on CRISPR screens, drug response data, and other perturbation experiments acquire interventional rather than merely associational patterns. As high-throughput perturbation platforms generate more data, foundation models trained on this data will become increasingly capable of causal prediction.</p>
<p><strong>Integration with causal inference methods</strong>: Combining foundation model predictions with established causal inference frameworks (Mendelian randomization, fine-mapping, structural causal models) leverages the complementary strengths of each approach. Foundation models provide scale and pattern recognition; causal frameworks provide principled reasoning about intervention.</p>
<p><strong>Closed-loop experimental systems</strong>: Iterating between foundation model prediction and experimental validation creates feedback loops that progressively improve causal accuracy. Such systems require infrastructure investment but offer a path to causally validated foundation models.</p>
<p>The frontier challenges in causal reasoning are examined further in <a href="../part_6/p6-ch31-frontiers.html#sec-ch31-causality" class="quarto-xref"><span>Section 31.1.3</span></a>. For now, practitioners should approach foundation model predictions with appropriate epistemic humility: impressive predictive accuracy does not imply causal validity, and clinical interventions require causal rather than merely correlational evidence.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Test Yourself">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Test Yourself
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before reviewing the summary, test your recall:</p>
<ol type="1">
<li>Describe Pearl’s three rungs of the ladder of causation. Why can’t you reach Rung 2 (intervention) from Rung 1 (association) through more data or better prediction accuracy alone?</li>
<li>A foundation model achieves 95% accuracy predicting disease outcome from gene expression. List three different causal structures that could produce this correlation, and explain why they matter for treatment decisions.</li>
<li>What is Mendelian randomization, and what properties of genetic variants make it a valid causal inference tool?</li>
<li>How can foundation models be trained to support causal reasoning? What types of training data would enable movement from associational to interventional predictions?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Rung 1 (Association)</strong>: P(Y|X)—observing X tells us about Y. <strong>Rung 2 (Intervention)</strong>: P(Y|do(X))—changing X affects Y. <strong>Rung 3 (Counterfactual)</strong>: What would Y have been for this individual if X were different? More data at Rung 1 cannot reach Rung 2 because observational data conflates causal and confounded associations; no amount of correlation data distinguishes causation from common causes without interventional data or causal assumptions. (2) Three causal structures: (a) Gene expression directly causes disease—treatment targeting the gene would work; (b) Disease causes gene expression—targeting the gene would not help; (c) Both are caused by an unmeasured factor—gene is a biomarker but not a therapeutic target. These distinctions are critical for choosing whether to develop therapies targeting the gene. (3) Mendelian randomization uses genetic variants as instrumental variables to infer causation. Key properties: alleles are randomly assigned at conception (independence from confounders), variants affect an exposure (relevance), and under the exclusion restriction, variants affect outcomes only through the exposure. This creates a natural experiment analogous to randomized trials. (4) Train on interventional data: CRISPR screens, drug response experiments, and other perturbation data where effects of interventions are directly observed. Models trained on observational data learn associations; models trained on interventional data learn causal effects. Closed-loop systems that iterate between prediction and experimental validation provide the strongest path.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Summary
</div>
</div>
<div class="callout-body-container callout-body">
<p>This chapter examined the gap between association (what we observe) and causation (what happens if we intervene)—a distinction critical for clinical application of foundation models.</p>
<p><strong>Key takeaways</strong>:</p>
<ol type="1">
<li><p><strong>Pearl’s ladder of causation</strong> distinguishes association (rung 1), intervention (rung 2), and counterfactual reasoning (rung 3). Foundation models trained on observational data operate at rung 1; moving higher requires interventional data or causal assumptions.</p></li>
<li><p><strong>Predictive accuracy does not imply causal validity</strong>. A model that perfectly predicts Y from X may be learning direct causation, reverse causation, common causes, or confounding. Only external validation can distinguish these scenarios.</p></li>
<li><p><strong>Genomics offers unique causal inference tools</strong>. Mendelian randomization exploits genetic randomization at conception; fine-mapping localizes causal variants; multi-omic QTL analysis traces causal chains across molecular layers.</p></li>
<li><p><strong>Foundation models can contribute to causal inference</strong> through in-silico perturbation prediction, CRISPR screen analysis, and drug response modeling—but only when combined with appropriate validation against experimental ground truth.</p></li>
<li><p><strong>Clinical stakes are high</strong>. Association-based predictions support screening and stratification. Causal claims support intervention. Confusing the two leads to ineffective treatments and potential patient harm.</p></li>
<li><p><strong>Three paths forward</strong>: Training on interventional data, integrating with causal inference frameworks, and building closed-loop experimental systems all offer routes toward causally valid foundation models.</p></li>
</ol>
<p><strong>Looking ahead</strong>: <a href="p5-ch26-regulatory.html#sec-ch26-regulatory" class="quarto-xref"><span>Section 26.1</span></a> examines how regulatory frameworks evaluate AI systems, with implications for causal claims. <a href="../part_6/p6-ch29-drug-discovery.html" class="quarto-xref"><span>Chapter 29</span></a> applies these concepts to drug target identification. <a href="../part_6/p6-ch31-frontiers.html#sec-ch31-causality" class="quarto-xref"><span>Section 31.1.3</span></a> explores frontier challenges in causal reasoning for genomics.</p>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-benner_finemap_2016" class="csl-entry" role="listitem">
Benner, Christian, Chris C. A. Spencer, Aki S. Havulinna, Veikko Salomaa, Samuli Ripatti, and Matti Pirinen. 2016. <span>“<span>FINEMAP</span>: Efficient Variable Selection Using Summary Data from Genome-Wide Association Studies.”</span> <em>Bioinformatics</em> 32 (10): 1493–1501. <a href="https://doi.org/10.1093/bioinformatics/btw018">https://doi.org/10.1093/bioinformatics/btw018</a>.
</div>
<div id="ref-bowden_mendelian_2015" class="csl-entry" role="listitem">
Bowden, Jack, George Davey Smith, and Stephen Burgess. 2015. <span>“Mendelian Randomization with Invalid Instruments: Effect Estimation and Bias Detection Through <span>Egger</span> Regression.”</span> <em>International Journal of Epidemiology</em> 44 (2): 512–25. <a href="https://doi.org/10.1093/ije/dyv080">https://doi.org/10.1093/ije/dyv080</a>.
</div>
<div id="ref-candes_panning_2018" class="csl-entry" role="listitem">
Candès, Emmanuel, Yingying Fan, Lucas Janson, and Jinchi Lv. 2018. <span>“Panning for Gold: ’<span>Model</span>-<span>X</span>’ Knockoffs for High Dimensional Controlled Variable Selection.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 80 (3): 551–77. <a href="https://doi.org/10.1111/rssb.12265">https://doi.org/10.1111/rssb.12265</a>.
</div>
<div id="ref-davey_smith_mendelian_2003" class="csl-entry" role="listitem">
Davey Smith, George, and Shah Ebrahim. 2003. <span>“<span>‘<span>Mendelian</span> Randomization’</span>: Can Genetic Epidemiology Contribute to Understanding Environmental Determinants of Disease?*.”</span> <em>International Journal of Epidemiology</em> 32 (1): 1–22. <a href="https://doi.org/10.1093/ije/dyg070">https://doi.org/10.1093/ije/dyg070</a>.
</div>
<div id="ref-hartwig_robust_2017" class="csl-entry" role="listitem">
Hartwig, Fernando Pires, George Davey Smith, and Jack Bowden. 2017. <span>“Robust Inference in Summary Data <span>Mendelian</span> Randomization via the Zero Modal Pleiotropy Assumption.”</span> <em>International Journal of Epidemiology</em> 46 (6): 1985–98. <a href="https://doi.org/10.1093/ije/dyx102">https://doi.org/10.1093/ije/dyx102</a>.
</div>
<div id="ref-maller_bayesian_2012" class="csl-entry" role="listitem">
Maller, Julian B., Gilean McVean, Jake Byrnes, Damjan Vukcevic, Kimmo Palin, Zhan Su, Joanna M. M. Howson, et al. 2012. <span>“Bayesian Refinement of Association Signals for 14 Loci in 3 Common Diseases.”</span> <em>Nature Genetics</em> 44 (12): 1294–1301. <a href="https://doi.org/10.1038/ng.2435">https://doi.org/10.1038/ng.2435</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../part_5/p5-ch24-interpretability.html" class="pagination-link" aria-label="Interpretability">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Interpretability</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../part_5/p5-ch26-regulatory.html" class="pagination-link" aria-label="Regulatory and Governance">
        <span class="nav-page-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regulatory and Governance</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025-2026, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>