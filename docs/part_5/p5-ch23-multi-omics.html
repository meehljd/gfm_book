<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>23&nbsp; Multi-Omics Integration – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../part_6/p6--responsible-deployment.html" rel="next">
<link href="../part_5/p5-ch22-networks.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_5/p5--cellular-context.html">Part V: Cellular Context</a></li><li class="breadcrumb-item"><a href="../part_5/p5-ch23-multi-omics.html"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_1/p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Data Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch03-gwas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS and Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch04-vep-classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classical Variant Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_2/p2--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch05-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Tokens and Embeddings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch06-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Convolutional Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch07-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transformers and Attention</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_3/p3--learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Learning &amp; Evaluation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch08-pretraining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning Foundations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch10-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Adaptation Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch11-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmark Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch12-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Evaluation Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch13-confounding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Confounding and Data Leakage</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_4/p4--fm-families.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Foundation Model Families</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch14-fm-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Foundation Model Paradigm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch15-dna-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">DNA Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch16-protein-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch17-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Regulatory Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch18-vep-fm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_5/p5--cellular-context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Cellular Context</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch19-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">RNA Structure and Function</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch20-single-cell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Single-Cell Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch21-3d-genome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">3D Genome Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch22-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Graph and Network Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch23-multi-omics.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_6/p6--responsible-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI: Responsible Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch24-uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch25-interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch26-causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Causality</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch27-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regulatory and Governance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_7/p7--applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VII: Applications &amp; Frontiers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch28-clinical-risk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch29-rare-disease.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Rare Disease Diagnosis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch30-drug-discovery.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Drug Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch31-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Sequence Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch32-frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Frontiers and Synthesis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bib/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-b-compute.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Deployment and Compute</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-c-data-curation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Data Curation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-d-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Model Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-e-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-f-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-ch23-limits" id="toc-sec-ch23-limits" class="nav-link active" data-scroll-target="#sec-ch23-limits"><span class="header-section-number">23.1</span> Limits of Single-Modality Models</a></li>
  <li><a href="#sec-ch23-strategies" id="toc-sec-ch23-strategies" class="nav-link" data-scroll-target="#sec-ch23-strategies"><span class="header-section-number">23.2</span> Integration Strategies and Their Tradeoffs</a>
  <ul class="collapse">
  <li><a href="#sec-ch23-early-fusion" id="toc-sec-ch23-early-fusion" class="nav-link" data-scroll-target="#sec-ch23-early-fusion"><span class="header-section-number">23.2.1</span> Early Fusion</a></li>
  <li><a href="#sec-ch23-late-fusion" id="toc-sec-ch23-late-fusion" class="nav-link" data-scroll-target="#sec-ch23-late-fusion"><span class="header-section-number">23.2.2</span> Late Fusion</a></li>
  <li><a href="#sec-ch23-intermediate-fusion" id="toc-sec-ch23-intermediate-fusion" class="nav-link" data-scroll-target="#sec-ch23-intermediate-fusion"><span class="header-section-number">23.2.3</span> Intermediate Fusion</a></li>
  </ul></li>
  <li><a href="#sec-ch23-foundation-models" id="toc-sec-ch23-foundation-models" class="nav-link" data-scroll-target="#sec-ch23-foundation-models"><span class="header-section-number">23.3</span> Multi-Omics Foundation Models</a>
  <ul class="collapse">
  <li><a href="#sec-ch23-factor-integration" id="toc-sec-ch23-factor-integration" class="nav-link" data-scroll-target="#sec-ch23-factor-integration"><span class="header-section-number">23.3.1</span> Factor-Based Integration</a></li>
  <li><a href="#sec-ch23-deep-generative" id="toc-sec-ch23-deep-generative" class="nav-link" data-scroll-target="#sec-ch23-deep-generative"><span class="header-section-number">23.3.2</span> Deep Generative Multi-Omics Models</a></li>
  <li><a href="#sec-ch23-contrastive" id="toc-sec-ch23-contrastive" class="nav-link" data-scroll-target="#sec-ch23-contrastive"><span class="header-section-number">23.3.3</span> Contrastive Multi-Modal Learning</a></li>
  <li><a href="#sec-ch23-lm-multiomics" id="toc-sec-ch23-lm-multiomics" class="nav-link" data-scroll-target="#sec-ch23-lm-multiomics"><span class="header-section-number">23.3.4</span> Language Models for Multi-Omics</a></li>
  </ul></li>
  <li><a href="#sec-ch23-clinical-integration" id="toc-sec-ch23-clinical-integration" class="nav-link" data-scroll-target="#sec-ch23-clinical-integration"><span class="header-section-number">23.4</span> Clinical Integration: EHR, Imaging, and Molecular Data</a>
  <ul class="collapse">
  <li><a href="#sec-ch23-ehr" id="toc-sec-ch23-ehr" class="nav-link" data-scroll-target="#sec-ch23-ehr"><span class="header-section-number">23.4.1</span> Electronic Health Records as a Modality</a></li>
  <li><a href="#sec-ch23-imaging" id="toc-sec-ch23-imaging" class="nav-link" data-scroll-target="#sec-ch23-imaging"><span class="header-section-number">23.4.2</span> Imaging Integration</a></li>
  <li><a href="#sec-ch23-multimodal-clinical" id="toc-sec-ch23-multimodal-clinical" class="nav-link" data-scroll-target="#sec-ch23-multimodal-clinical"><span class="header-section-number">23.4.3</span> Multi-Modal Clinical Prediction Models</a></li>
  </ul></li>
  <li><a href="#sec-ch23-systems-view" id="toc-sec-ch23-systems-view" class="nav-link" data-scroll-target="#sec-ch23-systems-view"><span class="header-section-number">23.5</span> Systems View: From Variant to Phenotype</a>
  <ul class="collapse">
  <li><a href="#sec-ch23-information-cascade" id="toc-sec-ch23-information-cascade" class="nav-link" data-scroll-target="#sec-ch23-information-cascade"><span class="header-section-number">23.5.1</span> Information Cascade</a></li>
  <li><a href="#sec-ch23-bottleneck" id="toc-sec-ch23-bottleneck" class="nav-link" data-scroll-target="#sec-ch23-bottleneck"><span class="header-section-number">23.5.2</span> Bottleneck Modalities</a></li>
  <li><a href="#sec-ch23-causal-correlational" id="toc-sec-ch23-causal-correlational" class="nav-link" data-scroll-target="#sec-ch23-causal-correlational"><span class="header-section-number">23.5.3</span> Causal vs.&nbsp;Correlational Integration</a></li>
  </ul></li>
  <li><a href="#sec-ch23-missing-modalities" id="toc-sec-ch23-missing-modalities" class="nav-link" data-scroll-target="#sec-ch23-missing-modalities"><span class="header-section-number">23.6</span> Handling Missing Modalities</a>
  <ul class="collapse">
  <li><a href="#sec-ch23-incomplete-training" id="toc-sec-ch23-incomplete-training" class="nav-link" data-scroll-target="#sec-ch23-incomplete-training"><span class="header-section-number">23.6.1</span> Training with Incomplete Data</a></li>
  <li><a href="#sec-ch23-imputation" id="toc-sec-ch23-imputation" class="nav-link" data-scroll-target="#sec-ch23-imputation"><span class="header-section-number">23.6.2</span> Cross-Modal Imputation</a></li>
  <li><a href="#sec-ch23-zero-shot" id="toc-sec-ch23-zero-shot" class="nav-link" data-scroll-target="#sec-ch23-zero-shot"><span class="header-section-number">23.6.3</span> Zero-Shot Cross-Modal Transfer</a></li>
  </ul></li>
  <li><a href="#sec-ch23-practical-challenges" id="toc-sec-ch23-practical-challenges" class="nav-link" data-scroll-target="#sec-ch23-practical-challenges"><span class="header-section-number">23.7</span> Practical Challenges</a>
  <ul class="collapse">
  <li><a href="#sec-ch23-batch-effects" id="toc-sec-ch23-batch-effects" class="nav-link" data-scroll-target="#sec-ch23-batch-effects"><span class="header-section-number">23.7.1</span> Batch Effects Across Modalities</a></li>
  <li><a href="#sec-ch23-sample-size" id="toc-sec-ch23-sample-size" class="nav-link" data-scroll-target="#sec-ch23-sample-size"><span class="header-section-number">23.7.2</span> Sample Size and Power</a></li>
  <li><a href="#sec-ch23-interpretability" id="toc-sec-ch23-interpretability" class="nav-link" data-scroll-target="#sec-ch23-interpretability"><span class="header-section-number">23.7.3</span> Interpretability Across Modalities</a></li>
  <li><a href="#sec-ch23-evaluation" id="toc-sec-ch23-evaluation" class="nav-link" data-scroll-target="#sec-ch23-evaluation"><span class="header-section-number">23.7.4</span> Evaluation Complexity</a></li>
  </ul></li>
  <li><a href="#sec-ch23-conclusion" id="toc-sec-ch23-conclusion" class="nav-link" data-scroll-target="#sec-ch23-conclusion"><span class="header-section-number">23.8</span> Integration as Means, Not End</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_5/p5--cellular-context.html">Part V: Cellular Context</a></li><li class="breadcrumb-item"><a href="../part_5/p5-ch23-multi-omics.html"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ch23-multi-omics" class="quarto-section-identifier"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>More data can mean worse predictions. Understanding why is prerequisite to making multi-omics work.</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Estimated reading time:</strong> 35-45 minutes</p>
<p><strong>Prerequisites:</strong> This chapter builds on foundation model concepts from <a href="../part_4/p4-ch14-fm-principles.html" class="quarto-xref"><span>Chapter 14</span></a>, single-cell integration methods from <a href="p5-ch20-single-cell.html" class="quarto-xref"><span>Chapter 20</span></a>, and assumes familiarity with attention mechanisms (<a href="../part_2/p2-ch07-attention.html" class="quarto-xref"><span>Chapter 7</span></a>) and transfer learning (<a href="../part_3/p3-ch09-transfer.html" class="quarto-xref"><span>Chapter 9</span></a>). Understanding of GWAS (<a href="../part_1/p1-ch03-gwas.html" class="quarto-xref"><span>Chapter 3</span></a>) and expression quantitative trait loci helps but is not essential.</p>
<p><strong>Learning Objectives:</strong> After completing this chapter, you should be able to:</p>
<ol type="1">
<li>Explain why naive concatenation of multi-omics features often degrades prediction performance</li>
<li>Compare and contrast early, late, and intermediate fusion strategies, selecting the appropriate approach for different data characteristics</li>
<li>Design multi-omics integration pipelines that handle missing modalities gracefully</li>
<li>Trace information flow from genetic variants through molecular layers to clinical phenotypes</li>
<li>Identify when multi-omics integration will likely help versus hurt prediction accuracy</li>
</ol>
</div>
</div>
<p>Combining data types should improve prediction. If genomic variants provide one signal and transcriptomic measurements provide another, their combination ought to be more informative than either alone. This intuition, while reasonable, proves frequently wrong in practice. Naive concatenation of multi-omics features often degrades performance relative to single-modality models. Noise from uninformative features overwhelms signal from informative ones. Batch effects between modalities create spurious correlations that models exploit. The curse of dimensionality intensifies when features from multiple assays are stacked without principled integration. The paradox is real: more data can mean worse predictions, and understanding why is prerequisite to making multi-omics integration work.</p>
<p>Each molecular layer captures part of the biological story but not all of it. Genomic variants identify predisposition; transcriptomics reveals which genes respond; proteomics shows which proteins change; metabolomics measures downstream biochemical consequences. A patient with a <em>BRCA1</em> variant may show altered DNA repair gene expression, deficient homologous recombination protein activity, and characteristic metabolic signatures. No single layer provides the complete picture. Effective integration traces this causal cascade from genetic variation through molecular intermediates to clinical phenotype, distinguishing primary effects from downstream consequences and noise from signal.</p>
<div id="fig-integration-paradox" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-integration-paradox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/01-A-fig-integration-paradox.svg" class="img-fluid figure-img"></p>
<figcaption>Different modalities capture different biological aspects</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/01-B-fig-integration-paradox.svg" class="img-fluid figure-img"></p>
<figcaption>More modalities can mean worse predictions</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/01-C-fig-integration-paradox.svg" class="img-fluid figure-img"></p>
<figcaption>When integration helps: complementary information</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/01-D-fig-integration-paradox.svg" class="img-fluid figure-img"></p>
<figcaption>When integration hurts: redundancy and batch effects</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-integration-paradox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23.1: The multi-omics integration paradox. (A) Promise: each modality captures different aspects of biology: genomics shows heritable potential, transcriptomics reveals current state, proteomics measures functional complement, metabolomics tracks downstream biochemistry. (B) Paradox: more modalities can mean worse predictions when noise overwhelms signal. (C) When integration helps: complementary information, cross-modality validation, and mechanistic interpretation. (D) When integration hurts: redundant features, batch effects, and sample size reduction from incomplete overlap.
</figcaption>
</figure>
</div>
<p>The integration strategy matters as much as the data itself. <strong>Early fusion</strong> concatenates features before modeling, <strong>intermediate fusion</strong> learns joint representations across modalities, and <strong>late fusion</strong> combines predictions from modality-specific models. Each approach carries distinct tradeoffs for different applications and data characteristics. Multi-omics foundation models attempt to learn unified representations across genomics, transcriptomics, proteomics, and other modalities simultaneously, while clinical integration extends further still, combining electronic health records, imaging data, and molecular measurements for patient-level prediction. The practical challenges are substantial: missing modalities when not every patient has every assay, batch effects from technical variation between measurement platforms, and a persistent gap between multi-omics potential and deployment reality.</p>
<section id="sec-ch23-limits" class="level2" data-number="23.1">
<h2 data-number="23.1" class="anchored" data-anchor-id="sec-ch23-limits"><span class="header-section-number">23.1</span> Limits of Single-Modality Models</h2>
<p>Each molecular layer tells an incomplete story. DNA sequence is static; it encodes potential but not state. A variant’s presence says nothing about whether the gene is expressed, whether the protein is active, or whether the pathway is perturbed. Transcriptomic data captures expression state but misses post-transcriptional regulation, protein modifications, and metabolic flux. Proteomic measurements reveal protein abundance but not necessarily activity or localization. Methylation profiles indicate epigenetic state but require expression data to understand functional consequences.</p>
<p>The incompleteness becomes concrete when modeling complex traits. Genome-wide association studies (see <a href="../part_1/p1-ch03-gwas.html" class="quarto-xref"><span>Chapter 3</span></a> for GWAS methodology) explain a fraction of total <strong>heritability</strong> for most common diseases through currently identified variants, with the gap between explained and estimated heritability forming the <strong>missing heritability problem</strong> <span class="citation" data-cites="manolio_finding_2009">(<a href="../bib/references.html#ref-manolio_finding_2009" role="doc-biblioref">Manolio et al. 2009</a>)</span>. Adding <strong>expression quantitative trait loci (eQTLs)</strong> improves <strong>fine-mapping</strong> by suggesting which variants affect gene expression (see <a href="../part_1/p1-ch03-gwas.html#sec-ch03-fine-mapping" class="quarto-xref"><span>Section 3.4</span></a>), but many causal mechanisms operate through splicing, translation, or post-translational modification rather than expression level. <strong>Single-cell RNA sequencing</strong> reveals cellular heterogeneity invisible to bulk measurements, but the same cell cannot simultaneously undergo RNA-seq and <strong>assay for transposase-accessible chromatin sequencing (ATAC-seq)</strong>, forcing computational integration across modalities measured in different cells (see <a href="p5-ch20-single-cell.html" class="quarto-xref"><span>Chapter 20</span></a> for approaches to this challenge).</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before reading further, consider a patient with type 2 diabetes. Which molecular layers would you expect to provide independent information about their disease state? Would genomic variants, gene expression, protein levels, and metabolite concentrations all be equally informative, or would some layers be redundant with others?</p>
</div>
</div>
<p>Consider the challenge of predicting drug response. Germline variants in drug-metabolizing enzymes explain some inter-individual variation (see <a href="../part_1/p1-ch02-data.html#sec-ch02-pharmacogenomics" class="quarto-xref"><span>Section 2.8.4</span></a>), but tumor-specific somatic mutations, expression programs, and microenvironment all influence therapeutic efficacy. A genomics-only model sees the inherited component; a transcriptomics-only model sees the current expression state; neither captures the full picture. Multi-omics integration promises to bridge these gaps by learning representations that span molecular layers.</p>
<p>Foundation models address each molecular layer individually: sequence models predict regulatory effects from DNA (see <a href="../part_4/p4-ch17-regulatory.html" class="quarto-xref"><span>Chapter 17</span></a>), expression models capture transcriptional programs (see <a href="p5-ch19-rna.html" class="quarto-xref"><span>Chapter 19</span></a>), and protein language models predict structure and function from amino acid sequence (see <a href="../part_4/p4-ch16-protein-lm.html" class="quarto-xref"><span>Chapter 16</span></a>). Multi-omics integration asks how these modality-specific representations can be combined into unified patient or cell representations.</p>
<p>The promise comes with caveats. Adding modalities increases the number of parameters that must be estimated, potentially worsening overfitting when sample sizes are limited. Different modalities have different noise characteristics, batch structures, and missingness patterns. The same patient’s measurements across platforms may not align perfectly due to sample handling, timing, or technical variation. Naive concatenation of features often performs worse than single-modality models because the signal-to-noise ratio degrades when noisy features outnumber informative ones.</p>
<p>These challenges motivate careful consideration of integration strategy. The question is not whether to integrate, but how.</p>
</section>
<section id="sec-ch23-strategies" class="level2" data-number="23.2">
<h2 data-number="23.2" class="anchored" data-anchor-id="sec-ch23-strategies"><span class="header-section-number">23.2</span> Integration Strategies and Their Tradeoffs</h2>
<p>Three broad strategies have emerged for combining multi-omics data, each with distinct strengths and limitations.</p>
<div id="fig-fusion-strategies" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fusion-strategies-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/02-A-fig-fusion-strategies.svg" class="img-fluid figure-img"></p>
<figcaption>Early fusion: concatenate features before modeling</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/02-B-fig-fusion-strategies.svg" class="img-fluid figure-img"></p>
<figcaption>Late fusion: combine model predictions</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/02-C-fig-fusion-strategies.svg" class="img-fluid figure-img"></p>
<figcaption>Intermediate fusion: shared latent space</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fusion-strategies-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23.2: Multi-omics fusion strategies. (A) Early fusion: concatenate features before modeling. Enables cross-modal interaction learning but requires complete data and suffers from dimensionality. (B) Late fusion: train separate models and combine predictions. Handles missing modalities but cannot learn feature interactions. (C) Intermediate fusion: modality-specific encoders project to shared latent space. Balances interaction learning with missing data robustness.
</figcaption>
</figure>
</div>
<section id="sec-ch23-early-fusion" class="level3" data-number="23.2.1">
<h3 data-number="23.2.1" class="anchored" data-anchor-id="sec-ch23-early-fusion"><span class="header-section-number">23.2.1</span> Early Fusion</h3>
<p>If you concatenate genomic, transcriptomic, and epigenomic data into one giant feature vector, you are betting that their interactions matter from the very first layer. When does this bet pay off, and when does it fail?</p>
<p>Early fusion concatenates features from multiple modalities before any modeling, creating a single high-dimensional input vector that contains genomic variants, expression values, methylation levels, and any other available measurements. A classifier or regressor then learns directly from this concatenated representation.</p>
<p>The appeal of early fusion lies in its simplicity and flexibility. Any downstream model architecture can operate on concatenated features, from linear regression to deep neural networks. The model can learn arbitrary interactions between features from different modalities, since all information is present in the input. Implementation requires only normalization and alignment of features across samples.</p>
<p>The limitations become apparent at scale. Dimensionality explodes when combining genome-wide variants (millions of features), gene expression (tens of thousands of genes), methylation (hundreds of thousands of CpG sites), and protein abundance (thousands of proteins). Most samples have far fewer observations than features, creating severe overfitting risk. Why does high dimensionality cause overfitting even with regularization? Consider the geometry: with p features and n samples (p &gt;&gt; n), the training points lie in a low-dimensional subspace of the feature space. The model can perfectly fit training data by assigning any prediction to training points and interpolating arbitrarily between them; countless solutions achieve zero training error, and most generalize poorly. Regularization constrains the solution space but cannot eliminate the fundamental problem that vastly more parameters exist than constraints. When each modality adds millions of features while sample counts remain in the thousands, the curse of dimensionality overwhelms any regularization scheme.</p>
<p>Missing data creates additional complications. If any modality is missing for a sample, early fusion requires either excluding that sample (reducing effective sample size) or imputing the missing modality (introducing noise and potential bias). Since multi-omics studies often have incomplete overlap between modalities, with some patients having genomics and transcriptomics but not proteomics, early fusion frequently operates on substantially reduced cohorts.</p>
<p>Scale differences between modalities pose another challenge. Expression values span orders of magnitude; methylation beta values range from zero to one; variant encodings are typically binary. Without careful normalization, modalities with larger variance can dominate the learned representation regardless of biological relevance. Batch effects within each modality add further complexity, since batch correction must precede concatenation but may interact with cross-modal relationships.</p>
<p>Despite these limitations, early fusion remains appropriate when sample sizes are large relative to feature counts, when all modalities are available for all samples, and when the downstream task is well-defined enough to guide feature selection. Biobank-scale studies with thousands of participants and focused feature sets can succeed with early fusion approaches.</p>
</section>
<section id="sec-ch23-late-fusion" class="level3" data-number="23.2.2">
<h3 data-number="23.2.2" class="anchored" data-anchor-id="sec-ch23-late-fusion"><span class="header-section-number">23.2.2</span> Late Fusion</h3>
<p>What if each modality truly provides independent information, like separate witnesses to the same event? Late fusion bets that combining final verdicts outperforms forcing witnesses to deliberate together from the start. This independence assumption buys you robustness to missing data but costs you the ability to detect when witnesses are describing the same thing from different angles.</p>
<p>Late fusion trains separate models for each modality and combines their predictions at the output level. A genomics model produces a risk score; a transcriptomics model produces another risk score; these modality-specific predictions are then combined into a final output.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Late Fusion vs.&nbsp;Ensemble Learning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Late fusion is related to but distinct from <strong>ensemble learning</strong>. Traditional ensembles combine multiple models trained on the <em>same</em> data to reduce variance and improve robustness: bagging averages diverse trees, boosting sequences weak learners, and stacking learns optimal combination weights. Late fusion, by contrast, combines models trained on <em>different</em> data modalities. Each model sees fundamentally different features (genomic variants vs.&nbsp;expression levels vs.&nbsp;protein abundance), not just different views or subsets of the same features. The modality-specific models may themselves be ensembles, and the combination layer may use ensemble techniques (weighted averaging, stacking), but the defining characteristic of late fusion is the separation of modalities during model training. This distinction matters because ensemble theory (bias-variance decomposition, diversity requirements) does not directly transfer: late fusion’s value comes from information complementarity across modalities rather than from variance reduction through model diversity.</p>
</div>
</div>
<p>This approach handles missing modalities gracefully. If a patient lacks proteomic data, the proteomics model simply does not contribute to the ensemble. Sample sizes for each modality-specific model can differ, since training requires only samples with that modality rather than complete multi-omics profiles. Each modality can use whatever architecture works best for its data type: deep networks for imaging, gradient boosting for tabular omics, convolutional architectures for sequence.</p>
<p>Late fusion cannot capture cross-modal interactions at the feature level. If a variant’s effect on disease depends on expression level of a regulatory gene, neither the genomics model nor the transcriptomics model alone can detect this interaction. The ensemble sees only the modality-specific predictions, not the underlying features. This limitation is fundamental: late fusion assumes that each modality provides independent signal that can be additively combined. Mathematically, if the true risk depends on an interaction term like <span class="math inline">\(\text{variant} \times \text{expression}\)</span>, late fusion can only approximate this with <span class="math inline">\(f_1(\text{variant}) + f_2(\text{expression})\)</span>, which cannot capture the non-additive structure regardless of how sophisticated the individual models become.</p>
<p>The assumption of independence often fails in biological systems. Gene expression depends on genetic variants through eQTLs. Protein levels depend on both transcription and post-transcriptional regulation. Methylation states influence and are influenced by transcription. The molecular layers are not independent information sources but coupled components of a dynamic system. Late fusion ignores this coupling.</p>
<p><strong>Calibration</strong> presents a practical challenge. For ensemble predictions to be meaningful, the modality-specific models must produce well-calibrated probability estimates (see <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-calibration" class="quarto-xref"><span>Section 24.2</span></a> for calibration methods). If the genomics model is overconfident and the transcriptomics model is underconfident, naive averaging produces biased predictions. Calibration techniques help but add complexity to the modeling pipeline.</p>
<p>Late fusion works well when modalities genuinely provide independent signals, when sample sizes for each modality differ substantially, or when interpretability requires understanding each modality’s contribution separately. Clinical deployment often favors late fusion because it gracefully handles the reality that not all patients will have all measurements.</p>
</section>
<section id="sec-ch23-intermediate-fusion" class="level3" data-number="23.2.3">
<h3 data-number="23.2.3" class="anchored" data-anchor-id="sec-ch23-intermediate-fusion"><span class="header-section-number">23.2.3</span> Intermediate Fusion</h3>
<p>Early fusion demands complete data and cannot scale. Late fusion ignores cross-modal interactions entirely. Is there a middle path that learns how modalities relate to each other while gracefully handling the messy reality of incomplete measurements?</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think
</div>
</div>
<div class="callout-body-container callout-body">
<p>You are designing a multi-omics model that must work even when patients are missing some data types. Early fusion requires all modalities; late fusion cannot capture cross-modal interactions. What properties would an ideal intermediate approach have? How might you encode different modalities into a common representation while preserving modality-specific structure?</p>
</div>
</div>
<p>Intermediate fusion learns modality-specific encoders that map each data type into a shared latent space, then operates on the aligned representations for downstream tasks. This approach combines the flexibility of early fusion with the robustness of late fusion.</p>
<p>Each modality has its own encoder architecture tailored to its characteristics. A variational autoencoder might encode single-cell expression data, handling sparsity and dropout noise. A convolutional network might process methylation profiles along chromosomal coordinates. A <strong>graph neural network</strong> might encode protein interaction data (see <a href="p5-ch22-networks.html#sec-ch22-gnn-fundamentals" class="quarto-xref"><span>Section 22.2</span></a>). These diverse architectures share nothing except their output dimensionality: all encoders produce <strong>embeddings</strong> in a common latent space.</p>
<p>Alignment between modalities is encouraged through multiple mechanisms. Reconstruction losses require each encoder’s latent representation to support decoding back to the original features, ensuring that the embeddings retain modality-specific information. Contrastive terms pull together representations of the same biological entity across modalities: the expression embedding for a cell should be similar to the ATAC-seq embedding for the same cell. Graph constraints enforce consistency with known biological relationships: genes connected in interaction networks should have similar embeddings.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight
</div>
</div>
<div class="callout-body-container callout-body">
<p>The power of intermediate fusion lies in the shared latent space. By forcing different modalities to project into the same embedding space, the model learns that expression patterns and chromatin accessibility in the same cell should map to nearby points. This alignment enables cross-modal reasoning: a classifier operating on this shared space can effectively learn from both modalities simultaneously, even when predicting for samples with only one modality available.</p>
</div>
</div>
<p>The shared latent space enables cross-modal reasoning. A classifier operating on the shared space can learn interactions between genomic and transcriptomic features, since both are present in the same representation. Transfer becomes possible: a model trained on expression data can be applied to samples with only ATAC-seq by encoding through the ATAC-seq encoder into the shared space.</p>
<p>Missing modalities no longer require imputation or exclusion. If a sample lacks proteomics, only the available encoders fire, producing a partial representation in the shared space. The downstream model operates on whatever representation is available, degrading gracefully as modalities are missing rather than failing entirely.</p>
<p><em>GLUE</em>, introduced in <a href="p5-ch20-single-cell.html#sec-ch20-glue" class="quarto-xref"><span>Section 20.5.2</span></a> for single-cell multi-omics integration, exemplifies this approach. Separate variational autoencoders encode RNA-seq and ATAC-seq data into a shared cell embedding space. A feature graph links ATAC-seq peaks to genes based on genomic proximity and transcription factor binding, providing biological constraints on the alignment. The result enables integration of measurements from different cells, not just different modalities in the same cell.</p>
<p>Intermediate fusion dominates modern multi-omics deep learning because it balances flexibility with robustness. The modality-specific encoders can be pretrained on large single-modality datasets, then fine-tuned for alignment (see <a href="../part_3/p3-ch09-transfer.html" class="quarto-xref"><span>Chapter 9</span></a> for transfer learning strategies). New modalities can be added by training new encoders without retraining existing components. The shared space provides a natural target for interpretation and visualization.</p>
<p>The approach is not without limitations. The quality of alignment depends heavily on the training objective and the availability of paired samples where multiple modalities are measured in the same biological entity. Without sufficient anchoring, the shared space may fail to capture true biological correspondence. Hyperparameter choices for balancing reconstruction against alignment losses require careful tuning.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Predict Before You Look">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Predict Before You Look
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before viewing the comparison table below, make a prediction: Which fusion strategy (early, late, or intermediate) do you think would handle missing modalities best? Which would be most computationally expensive? Which would be best for learning interactions between genomic variants and gene expression levels? Write down your predictions, then check them against the table.</p>
</div>
</div>
<div id="tbl-fusion-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-fusion-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;23.1: Comparison of multi-omics fusion strategies. The choice depends on data characteristics, sample sizes, and downstream application requirements.
</figcaption>
<div aria-describedby="tbl-fusion-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 28%">
<col style="width: 25%">
<col style="width: 21%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th>Strategy</th>
<th>Cross-Modal Interactions</th>
<th>Missing Data Handling</th>
<th>Computational Cost</th>
<th>Best When</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Early Fusion</td>
<td>Can learn arbitrary interactions</td>
<td>Poor: requires complete data</td>
<td>Low to moderate</td>
<td>Large samples, complete data, focused features</td>
</tr>
<tr class="even">
<td>Late Fusion</td>
<td>None: predictions combined only</td>
<td>Excellent: uses available modalities</td>
<td>Low: independent models</td>
<td>Independent signals, variable coverage, interpretability needed</td>
</tr>
<tr class="odd">
<td>Intermediate Fusion</td>
<td>Learns in shared space</td>
<td>Good: graceful degradation</td>
<td>High: alignment training</td>
<td>Coupled modalities, transfer learning, paired training data</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="fig-intermediate-fusion" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-intermediate-fusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/03-A-fig-intermediate-fusion.svg" class="img-fluid figure-img"></p>
<figcaption>Modality-specific encoders tailored to each data type</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/03-B-fig-intermediate-fusion.svg" class="img-fluid figure-img"></p>
<figcaption>Shared latent space with alignment losses</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/03-C-fig-intermediate-fusion.svg" class="img-fluid figure-img"></p>
<figcaption>Downstream task heads operate on shared representation</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/03-D-fig-intermediate-fusion.svg" class="img-fluid figure-img"></p>
<figcaption>Missing modalities enable graceful degradation</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-intermediate-fusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23.3: Intermediate fusion architecture in detail. (A) Modality-specific encoders tailored to each data type: VAE for expression handling sparsity, CNN for methylation along genomic coordinates, MLP for proteomics. (B) Shared latent space: encoders produce embeddings aligned through reconstruction loss, contrastive terms, and biological graph constraints. (C) Downstream task heads operate on the shared representation, enabling cross-modal reasoning. (D) Missing modality handling: partial samples use only available encoders, enabling graceful degradation rather than sample exclusion.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-ch23-foundation-models" class="level2" data-number="23.3">
<h2 data-number="23.3" class="anchored" data-anchor-id="sec-ch23-foundation-models"><span class="header-section-number">23.3</span> Multi-Omics Foundation Models</h2>
<p>The <strong>foundation model</strong> paradigm, introduced in <a href="../part_4/p4-ch14-fm-principles.html" class="quarto-xref"><span>Chapter 14</span></a>, extends naturally to multi-omics settings. Rather than training task-specific models that integrate modalities for a single downstream application, multi-omics foundation models learn general-purpose representations that transfer across tasks.</p>
<section id="sec-ch23-factor-integration" class="level3" data-number="23.3.1">
<h3 data-number="23.3.1" class="anchored" data-anchor-id="sec-ch23-factor-integration"><span class="header-section-number">23.3.1</span> Factor-Based Integration</h3>
<p>Before diving into deep learning, consider a simpler question: can we explain the variation across modalities with a small number of shared factors? If inflammation drives coordinated changes in both gene expression and DNA methylation, a single factor might capture both effects. Factor-based methods test whether multi-omics complexity reduces to interpretable dimensions.</p>
<p>Multi-Omics Factor Analysis (<em>MOFA</em> and its successor <em>MOFA+</em>) provides a probabilistic framework for learning shared and modality-specific factors from multi-omics data <span class="citation" data-cites="argelaguet_multiomics_2018">(<a href="../bib/references.html#ref-argelaguet_multiomics_2018" role="doc-biblioref">Argelaguet et al. 2018</a>)</span>. The approach assumes that observed measurements across modalities can be explained by a small number of latent factors, some shared across modalities and others specific to individual data types.</p>
<p><em>MOFA+</em> extends this framework to handle multiple sample groups (such as different tissues or conditions), non-Gaussian likelihoods appropriate for count data, and scalable inference for large datasets . The factors learned by <em>MOFA+</em> capture sources of variation that span modalities, enabling biological interpretation: a factor that loads heavily on inflammatory genes in expression data and on hypomethylation at immune loci in methylation data suggests coordinated epigenetic-transcriptional regulation of inflammation.</p>
<p>While <em>MOFA+</em> is not a deep learning method in the strict sense, its factor-based decomposition provides a foundation for understanding what multi-omics integration should capture. The shared factors correspond to biological processes that manifest across molecular layers; the modality-specific factors capture technical variation or layer-specific biology.</p>
</section>
<section id="sec-ch23-deep-generative" class="level3" data-number="23.3.2">
<h3 data-number="23.3.2" class="anchored" data-anchor-id="sec-ch23-deep-generative"><span class="header-section-number">23.3.2</span> Deep Generative Multi-Omics Models</h3>
<p>RNA and protein measurements have fundamentally different noise characteristics: RNA suffers from dropout, proteins from background binding. Should a model treat them identically, or explicitly account for how each modality was generated? Deep generative approaches choose the latter, building the measurement process into the model itself.</p>
<p><em>totalVI</em> (Total Variational Inference) integrates protein abundance from CITE-seq with gene expression in single-cell data through a hierarchical Bayesian model <span class="citation" data-cites="gayoso_joint_2021">(<a href="../bib/references.html#ref-gayoso_joint_2021" role="doc-biblioref">Gayoso et al. 2021</a>)</span>. The approach learns a joint latent space that captures cell state while properly modeling the distinct noise characteristics of RNA and protein measurements. Protein abundance follows a negative binomial distribution with technical factors including background binding; RNA counts follow a zero-inflated negative binomial accounting for dropout. The choice of these specific likelihood functions reflects the data-generating process: RNA-seq suffers from technical dropout where some transcripts fail to be captured despite being present (hence zero-inflation), while protein measurements from antibody-based methods have background binding noise but less zero-inflation. Using the wrong likelihood would force the model to distort its latent space to accommodate systematic errors, degrading biological interpretability.</p>
<p>The generative model structure enables imputation of missing modalities. Given RNA expression alone, <em>totalVI</em> can predict expected protein abundance by sampling from the learned joint distribution. This imputation is not mere correlation-based prediction but reflects the full posterior distribution over protein levels given expression.</p>
<p><em>MultiVI</em> extends this framework to integrate gene expression with chromatin accessibility <span class="citation" data-cites="ashuach_multivi_2023">(<a href="../bib/references.html#ref-ashuach_multivi_2023" role="doc-biblioref">Ashuach et al. 2023</a>)</span>. The model learns to align measurements from different cells, enabling construction of unified cell atlases from studies that measured different modalities. The alignment relies on the biological assumption that gene expression and chromatin state reflect the same underlying cell state, even when measured in different cells.</p>
<p>These Bayesian deep generative models exemplify intermediate fusion with principled uncertainty quantification. The posterior distributions over latent variables capture not just point estimates but confidence in the learned representations (see <a href="../part_6/p6-ch24-uncertainty.html" class="quarto-xref"><span>Chapter 24</span></a> for uncertainty quantification methods). This property becomes important for clinical applications where prediction uncertainty must inform decision-making.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Knowledge Check
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider <em>totalVI</em> integrating RNA and protein measurements from single-cell CITE-seq data. The model learns a joint latent space where cells map based on both modalities.</p>
<ol type="1">
<li>Why does <em>totalVI</em> use different likelihood functions for RNA (zero-inflated negative binomial) versus protein (negative binomial)?</li>
<li>If you had a new sample with only RNA measurements, how would the model generate a protein abundance prediction?</li>
<li>What advantage does the Bayesian approach provide over simply training a regression from RNA to protein?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>RNA-seq suffers from technical dropout where transcripts fail to be captured despite being present (requiring zero-inflation), while protein measurements from antibody-based methods have background binding noise but less zero-inflation. Using the correct likelihood prevents the model from distorting its latent space to accommodate systematic errors.</p></li>
<li><p>The model maps the RNA measurements into the shared latent space, then samples from the learned posterior distribution over protein levels conditioned on that latent representation.</p></li>
<li><p>The Bayesian approach provides full posterior distributions capturing uncertainty in predictions, not just point estimates, critical for clinical decisions where knowing confidence matters as much as the prediction itself.</p></li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-ch23-contrastive" class="level3" data-number="23.3.3">
<h3 data-number="23.3.3" class="anchored" data-anchor-id="sec-ch23-contrastive"><span class="header-section-number">23.3.3</span> Contrastive Multi-Modal Learning</h3>
<p>What if you do not need to model the full data-generating process, but only need to learn that a cell’s expression profile and its methylation profile should map to nearby points? Contrastive learning takes this shortcut: instead of reconstructing measurements, it simply learns to recognize which observations came from the same biological entity across modalities.</p>
<p><strong>Contrastive learning</strong> provides another path to multi-omics integration. The <em>CLIP</em> model for vision-language demonstrated that contrastive objectives can align embeddings from fundamentally different data types (images and text) into a shared space <span class="citation" data-cites="radford_learning_2021">(<a href="../bib/references.html#ref-radford_learning_2021" role="doc-biblioref">Radford et al. 2021</a>)</span>. Similar approaches apply to biological modalities.</p>
<p>The contrastive objective is straightforward: embeddings of the same biological entity across modalities should be similar, while embeddings of different entities should be dissimilar. A cell’s expression embedding should be close to its methylation embedding and far from other cells’ methylation embeddings. A patient’s genomic embedding should be close to their transcriptomic embedding across the cohort.</p>
<p>Why does this objective produce biologically meaningful alignment rather than arbitrary correspondence? The key is that biological state is the common cause underlying both modalities. A cell’s expression profile and its methylation profile are both consequences of the same underlying regulatory state (active enhancers, bound transcription factors, chromatin accessibility). By forcing the encoders to map the same cell to similar embeddings across modalities, the contrastive loss encourages representations that capture this shared biological state rather than modality-specific artifacts. Features that vary randomly between modalities (technical noise, batch effects) cannot satisfy the objective; only features reflecting genuine cellular identity survive the alignment pressure.</p>
<p>This objective requires paired samples for training: the same cells or patients measured across modalities. Anchor pairs define the positive examples; negative examples come from non-matching pairs within a batch. The encoders learn to produce embeddings where cross-modal correspondence emerges from training dynamics rather than explicit feature engineering.</p>
<p>Contrastive approaches scale well and can incorporate foundation model encoders pretrained on single modalities. An expression encoder pretrained on millions of cells via masked gene prediction can be fine-tuned with contrastive objectives to align with an ATAC-seq encoder. The <strong>pretraining</strong> provides rich initial representations; the contrastive <strong>fine-tuning</strong> establishes cross-modal correspondence (see <a href="../part_3/p3-ch08-pretraining.html#sec-ch08-contrastive" class="quarto-xref"><span>Section 8.5</span></a> for contrastive pretraining strategies).</p>
</section>
<section id="sec-ch23-lm-multiomics" class="level3" data-number="23.3.4">
<h3 data-number="23.3.4" class="anchored" data-anchor-id="sec-ch23-lm-multiomics"><span class="header-section-number">23.3.4</span> Language Models for Multi-Omics</h3>
<p>Recent work extends the language model paradigm to multi-omics integration, treating different molecular modalities as distinct “languages” amenable to joint modeling. <span class="citation" data-cites="zhu_gpt_2024">Zhu et al. (<a href="../bib/references.html#ref-zhu_gpt_2024" role="doc-biblioref">2024</a>)</span> apply GPT-style autoregressive modeling to learn unified representations across genomic, transcriptomic, and proteomic data. Similarly, <span class="citation" data-cites="hwang_glm_2024">Hwang et al. (<a href="../bib/references.html#ref-hwang_glm_2024" role="doc-biblioref">2024</a>)</span> demonstrate that generative language models can capture cross-modal dependencies that escape modality-specific approaches.</p>
<p>This paradigm shift reframes multi-omics integration from a feature engineering problem to a representation learning problem, potentially discovering latent biological relationships that manual feature design would miss.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Research Opportunity
</div>
</div>
<div class="callout-body-container callout-body">
<p>The multi-omics language model paradigm remains nascent. Key open questions include optimal tokenization across modalities, handling missing data, and whether joint pretraining outperforms modality-specific models with late fusion.</p>
</div>
</div>
</section>
</section>
<section id="sec-ch23-clinical-integration" class="level2" data-number="23.4">
<h2 data-number="23.4" class="anchored" data-anchor-id="sec-ch23-clinical-integration"><span class="header-section-number">23.4</span> Clinical Integration: EHR, Imaging, and Molecular Data</h2>
<p>The ultimate goal of multi-omics modeling for many applications is patient-level prediction: disease risk, treatment response, prognosis. Achieving this goal requires integrating molecular measurements with clinical data that directly captures patient state and outcomes.</p>
<section id="sec-ch23-ehr" class="level3" data-number="23.4.1">
<h3 data-number="23.4.1" class="anchored" data-anchor-id="sec-ch23-ehr"><span class="header-section-number">23.4.1</span> Electronic Health Records as a Modality</h3>
<p>Molecular measurements capture mechanism; clinical records capture manifestation. A patient’s genomic risk score tells you their inherited predisposition, but their ten-year history of diagnoses, medications, and lab values tells you what actually happened. When should you trust the molecular signal, and when does the clinical trajectory override it?</p>
<p>Electronic health records contain decades of longitudinal observations for millions of patients: diagnoses, procedures, medications, laboratory values, vital signs, clinical notes. This wealth of phenotypic information complements molecular data by capturing disease manifestation rather than molecular mechanism.</p>
<p>Integrating EHR with genomics poses distinct challenges. The data types differ fundamentally: structured codes, continuous lab values, free-text notes, and time-stamped events versus static or slowly-changing molecular measurements. Temporal structure matters: the sequence of diagnoses and treatments contains prognostic information that static snapshots miss. Missingness is informative: the absence of a laboratory test may indicate that a clinician deemed it unnecessary, which itself conveys information about patient state (<a href="../part_1/p1-ch02-data.html#sec-ch02-ehr" class="quarto-xref"><span>Section 2.7.2</span></a>). The phenotype quality challenges introduced there cascade through multi-omics integration, where EHR-derived labels may introduce systematic biases that <a href="../part_3/p3-ch13-confounding.html#sec-ch13-label-bias" class="quarto-xref"><span>Section 13.2.4</span></a> examines in detail.</p>
<p>Foundation models for EHR data learn representations from the longitudinal event sequences. These models, often based on transformer architectures that process sequences of medical codes (see <a href="../part_2/p2-ch07-attention.html" class="quarto-xref"><span>Chapter 7</span></a>), capture temporal dependencies and co-occurrence patterns in clinical trajectories. The resulting patient embeddings encode disease state and prognosis in a form amenable to integration with molecular data.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Handling the Time Series Nature of EHR Data
</div>
</div>
<div class="callout-body-container callout-body">
<p>EHR data presents distinct time series challenges that affect multi-omics integration:</p>
<p><strong>Irregular sampling.</strong> Clinical events occur at irregular intervals driven by patient visits, not a fixed measurement schedule. Lab values might be measured daily during hospitalization, monthly during stable periods, and not at all when patients feel healthy. Standard time series methods assuming regular intervals require adaptation.</p>
<p><strong>Event sequences vs.&nbsp;continuous signals.</strong> EHR contains both discrete events (diagnoses, procedures) and continuous measurements (vital signs, lab values). Effective architectures must handle both: transformers that process event sequences, recurrent networks that interpolate continuous signals, or hybrid approaches.</p>
<p><strong>Variable-length histories.</strong> Patients have clinical histories spanning days to decades. Encoding must handle this variability, whether through truncation to recent windows, hierarchical summarization, or attention mechanisms that learn which distant events remain relevant.</p>
<p><strong>Censoring and outcome timing.</strong> For survival analysis and risk prediction, the timing of outcome events matters as much as their occurrence. Integration with molecular data requires careful alignment: when was the molecular sample collected relative to the clinical trajectory? Predictions should not use future clinical events that post-date the molecular measurement.</p>
<p>For specialized EHR modeling architectures including BEHRT, Med-BERT, and clinical transformer variants, see the clinical risk modeling discussion in <a href="../part_7/p7-ch28-clinical-risk.html#sec-ch28-ehr-integration" class="quarto-xref"><span>Section 28.4</span></a>.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight
</div>
</div>
<div class="callout-body-container callout-body">
<p>Combining EHR embeddings with genomic features requires handling different temporal scales. Genetic variants are constant throughout life; EHR observations accumulate over years. The integration must determine which clinical observations are relevant to a given molecular measurement, accounting for the time between sample collection and clinical events. A patient’s genomic risk for a disease does not change, but their clinical trajectory unfolds over time, and the relevance of past clinical events depends on when the molecular sample was collected.</p>
</div>
</div>
</section>
<section id="sec-ch23-imaging" class="level3" data-number="23.4.2">
<h3 data-number="23.4.2" class="anchored" data-anchor-id="sec-ch23-imaging"><span class="header-section-number">23.4.2</span> Imaging Integration</h3>
<p>Molecular assays homogenize tissue into measurements that lose spatial context. Imaging preserves that context: where is the tumor, how heterogeneous is it, what does the tissue architecture reveal? The tradeoff is clear, but how do you align a three-dimensional scan with a bulk RNA-seq measurement that averaged over a small biopsy region?</p>
<p>Medical imaging provides spatial information that molecular assays lack. A CT scan reveals tumor location, size, and heterogeneity; histopathology slides show cellular morphology and tissue architecture; MRI captures organ structure and function. These spatial data complement molecular measurements that aggregate over dissected tissue regions.</p>
<p>Radiogenomics links imaging features to genetic and molecular characteristics. Glioblastoma tumors with specific imaging signatures have distinct methylation patterns and expression programs . Radiomic features extracted from CT scans correlate with mutational burden and immune infiltration in lung cancer . These associations enable prediction of molecular state from non-invasive imaging, potentially guiding treatment decisions when biopsy is impractical.</p>
<p>Foundation models for medical imaging, pretrained on millions of scans through self-supervised objectives, provide rich representations for downstream tasks . Integrating these imaging embeddings with molecular data follows the intermediate fusion paradigm: modality-specific encoders produce representations in a shared latent space where multi-modal classifiers operate.</p>
<p>The integration must account for correspondence between imaging regions and molecular samples. A tumor may be molecularly heterogeneous, with different subclones in different spatial locations. A biopsy samples one location; imaging captures the entire lesion. Alignment requires either spatial registration of biopsy location to imaging coordinates or acceptance that the correspondence is imperfect.</p>
</section>
<section id="sec-ch23-multimodal-clinical" class="level3" data-number="23.4.3">
<h3 data-number="23.4.3" class="anchored" data-anchor-id="sec-ch23-multimodal-clinical"><span class="header-section-number">23.4.3</span> Multi-Modal Clinical Prediction Models</h3>
<p>In clinical practice, patients arrive with whatever data they have: complete molecular workups for some, imaging only for others, extensive EHR histories for many. A practical clinical model cannot demand all modalities. How do you build a unified prediction system that improves with more data but still works with less?</p>
<p>Combining EHR, imaging, and molecular data for clinical prediction follows the intermediate fusion pattern. Each data type has a specialized encoder: a transformer for longitudinal EHR events, a vision encoder for imaging, domain-specific encoders for expression, methylation, and other molecular modalities. All encoders produce embeddings in a common patient representation space.</p>
<p>The training objective typically combines modality-specific reconstruction losses with alignment terms that encourage consistency across data types. A patient’s EHR embedding should be predictive of their molecular state; their imaging embedding should be consistent with their clinical trajectory. Downstream classifiers for outcomes like survival, treatment response, or disease progression operate on the combined representation.</p>
<p>Missing modalities are common in clinical settings. Not all patients have genomic data; imaging may be unavailable for some conditions; the depth of EHR history varies by healthcare system and patient engagement. Multi-modal clinical models must handle this missingness gracefully, producing useful predictions from whatever data are available while leveraging cross-modal information when present.</p>
<p>The clinical deployment path for such models requires validation on external cohorts, prospective evaluation, and regulatory clearance. These practical considerations, addressed in <a href="../part_7/p7-ch28-clinical-risk.html" class="quarto-xref"><span>Chapter 28</span></a>, shape model development from the outset. A model that performs well on a research cohort but requires modalities unavailable in clinical workflows provides little value. The practical deployment considerations, including feature availability and model calibration requirements, are examined in <a href="../part_7/p7-ch28-clinical-risk.html#sec-ch28-feature-integration" class="quarto-xref"><span>Section 28.3</span></a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical Guidance
</div>
</div>
<div class="callout-body-container callout-body">
<p>When designing clinical multi-modal models, start from deployment constraints:</p>
<ol type="1">
<li><strong>Identify available modalities</strong>: Which data types will be available for the target patient population? Not all patients in a research cohort have all modalities available in routine clinical care.</li>
<li><strong>Design for graceful degradation</strong>: Choose intermediate fusion architectures that can produce useful predictions even with incomplete data.</li>
<li><strong>Validate across missingness patterns</strong>: Test performance not just on complete cases but on realistic subsets reflecting clinical data availability.</li>
<li><strong>Consider timing</strong>: When is each modality available relative to the clinical decision point? A model requiring data not yet collected provides no clinical value.</li>
</ol>
</div>
</div>
<div id="fig-clinical-multimodal" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clinical-multimodal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/04-A-fig-clinical-multimodal.svg" class="img-fluid figure-img"></p>
<figcaption>Data modalities: longitudinal EHR, spatial imaging, static molecular</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/04-B-fig-clinical-multimodal.svg" class="img-fluid figure-img"></p>
<figcaption>Modality-specific encoders for each data type</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/04-C-fig-clinical-multimodal.svg" class="img-fluid figure-img"></p>
<figcaption>Patient representation space unifies all modalities</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/04-D-fig-clinical-multimodal.svg" class="img-fluid figure-img"></p>
<figcaption>Clinical prediction tasks with missing modality handling</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clinical-multimodal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23.4: Clinical multi-modal integration. (A) Data modalities: longitudinal EHR (diagnoses, procedures, labs), spatial imaging (CT, MRI, histopathology), and static molecular measurements (genomics, expression, proteomics). (B) Modality-specific encoders: EHR transformer for event sequences, vision encoder for imaging, foundation model embeddings for molecular data. (C) Patient representation space: unified embedding where EHR predicts molecular state and imaging is consistent with clinical trajectory. (D) Clinical prediction tasks: risk stratification, treatment response, and prognosis, with the practical requirement of handling incomplete data.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-ch23-systems-view" class="level2" data-number="23.5">
<h2 data-number="23.5" class="anchored" data-anchor-id="sec-ch23-systems-view"><span class="header-section-number">23.5</span> Systems View: From Variant to Phenotype</h2>
<p>Multi-omics integration gains conceptual clarity from a systems biology perspective that traces information flow from genetic variation through molecular intermediates to clinical phenotypes. This cascade view organizes the molecular layers into a causal hierarchy and identifies where integration should occur.</p>
<section id="sec-ch23-information-cascade" class="level3" data-number="23.5.1">
<h3 data-number="23.5.1" class="anchored" data-anchor-id="sec-ch23-information-cascade"><span class="header-section-number">23.5.1</span> Information Cascade</h3>
<p>Genetic variants are the starting point: heritable differences in DNA sequence that perturb downstream molecular processes. Some variants directly alter protein structure through missense or nonsense mutations. Others affect regulation: promoter variants change expression level, splice site variants alter transcript isoforms, enhancer variants modulate tissue-specific expression.</p>
<p>These primary effects propagate through molecular layers. Expression changes alter the cellular protein complement. Protein level changes affect enzyme activity, signaling cascades, and transcriptional feedback. Metabolic flux shifts in response to enzyme availability. Cell behavior changes as the integrated molecular state crosses thresholds for proliferation, differentiation, or death.</p>
<p>Tissue-level phenotypes emerge from cellular behavior aggregated across the organ. Tumor growth reflects altered cell proliferation; fibrosis reflects aberrant extracellular matrix deposition; inflammation reflects immune cell recruitment and activation. These tissue phenotypes manifest as clinical symptoms, laboratory abnormalities, and imaging findings.</p>
<p>The cascade view suggests where different modalities provide information. Genomics captures the inherited potential and somatic alterations. Transcriptomics and epigenomics capture the current regulatory state. Proteomics and metabolomics capture the functional molecular complement. Clinical data captures the phenotypic consequences.</p>
<div id="fig-information-cascade" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-information-cascade-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/05-A-fig-information-cascade.svg" class="img-fluid figure-img"></p>
<figcaption>The causal cascade from variant to phenotype</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/05-B-fig-information-cascade.svg" class="img-fluid figure-img"></p>
<figcaption>Where each modality provides information</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/05-C-fig-information-cascade.svg" class="img-fluid figure-img"></p>
<figcaption>Bottleneck modalities vary by variant type</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_5/ch23/05-D-fig-information-cascade.svg" class="img-fluid figure-img"></p>
<figcaption>Integration guided by causal architecture</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-information-cascade-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23.5: Systems biology view of multi-omics integration. (A) The causal cascade: genetic variants propagate through molecular layers (expression, protein, metabolite, cellular behavior) to clinical phenotype. (B) Where each modality provides information: genomics captures the starting point, transcriptomics the current state, proteomics the functional complement, metabolomics downstream effects. (C) Bottleneck modalities: coding variants bottleneck at protein level, regulatory variants at expression level, determining which modality is most informative. (D) Integration implications: the causal architecture guides which modalities to prioritize for different biological questions.
</figcaption>
</figure>
</div>
</section>
<section id="sec-ch23-bottleneck" class="level3" data-number="23.5.2">
<h3 data-number="23.5.2" class="anchored" data-anchor-id="sec-ch23-bottleneck"><span class="header-section-number">23.5.2</span> Bottleneck Modalities</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider two different variants: (1) a missense variant in <em>TP53</em> that disrupts DNA binding, and (2) an enhancer variant that reduces <em>TP53</em> expression by 30%. For which variant would expression data provide more information beyond genomic sequence alone? Why?</p>
</div>
</div>
<p>Not all modalities are equally informative for all questions. The concept of bottleneck modalities identifies which molecular layers most directly mediate the relationship between genetic variation and phenotype.</p>
<p>For many coding variants, protein structure is the bottleneck. A missense variant’s effect on disease depends primarily on how it alters protein function, which depends on how the amino acid substitution affects folding, stability, and activity. Expression level matters less than structural consequence. Protein language models that predict structural effects from sequence directly address this bottleneck (see <a href="../part_4/p4-ch16-protein-lm.html" class="quarto-xref"><span>Chapter 16</span></a>).</p>
<p>For regulatory variants, expression is closer to the bottleneck. An enhancer variant affects disease through its effect on target gene expression, which affects downstream processes. Chromatin accessibility and transcription factor binding are intermediate steps; expression level is the more proximal readout. Models that predict expression effects from sequence address this bottleneck (see <a href="../part_4/p4-ch17-regulatory.html" class="quarto-xref"><span>Chapter 17</span></a>).</p>
<p>For some phenotypes, the bottleneck may lie downstream of molecular measurements entirely. Behavioral traits depend on neural circuit function that emerges from complex cellular and network dynamics. Metabolic traits depend on flux through interconnected pathways that may not be apparent from enzyme abundance alone. These cases suggest that molecular measurements provide incomplete information regardless of integration sophistication.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight
</div>
</div>
<div class="callout-body-container callout-body">
<p>The bottleneck concept provides practical guidance for integration strategy. If you know that a phenotype is driven primarily by coding variants affecting protein structure, investing in proteomics may be less valuable than deploying state-of-the-art protein structure prediction from sequence. Conversely, if regulatory variants dominate, expression or chromatin accessibility measurements add substantial information beyond genomic sequence. Understanding the causal architecture helps prioritize which modalities to measure and integrate.</p>
</div>
</div>
</section>
<section id="sec-ch23-causal-correlational" class="level3" data-number="23.5.3">
<h3 data-number="23.5.3" class="anchored" data-anchor-id="sec-ch23-causal-correlational"><span class="header-section-number">23.5.3</span> Causal vs.&nbsp;Correlational Integration</h3>
<p>Multi-omics data are pervasively correlated. Genes in the same pathway have correlated expression. Methylation and expression are anti-correlated at many promoters. Clinical variables cluster by disease category. These correlations can improve prediction even without causal understanding.</p>
<p>When integrating high-dimensional multi-omics features, controlling false discoveries becomes critical. <strong>Model-X knockoffs</strong> provide a framework for variable selection with false discovery rate (FDR) control, applicable to any covariate matrix regardless of the response type <span class="citation" data-cites="candes_panning_2018">(<a href="../bib/references.html#ref-candes_panning_2018" role="doc-biblioref">Candès et al. 2018</a>)</span>. The approach constructs synthetic “knockoff” variables that mimic the correlation structure of original features without containing signal, then selects only features whose importance exceeds their knockoffs. This is particularly valuable for multi-omics integration where thousands of correlated features across modalities could generate spurious associations. For genomics specifically, knockoffs have been applied to fine-mapping, identifying causal variants with FDR guarantees. The statistical foundations and genomic applications are discussed in <a href="../part_6/p6-ch26-causal.html#sec-ch26-knockoffs" class="quarto-xref"><span>Section 26.2.2</span></a>.</p>
<p>Causal integration seeks to identify the mechanistic relationships between molecular layers. If a variant causes reduced expression, which causes protein deficiency, which causes metabolic dysfunction, this causal chain suggests intervention targets: expression restoration or enzyme supplementation might address the downstream effects. Correlational integration might achieve the same predictive performance without identifying this chain, since all layers correlate with the phenotype.</p>
<p>Distinguishing causal from correlational relationships requires experimental perturbation or careful causal inference from observational data. Mendelian randomization uses genetic variants as instruments to infer causal effects of expression on outcomes (see <a href="../part_1/p1-ch03-gwas.html#sec-ch03-mechanism" class="quarto-xref"><span>Section 3.9</span></a> for integration of GWAS with mechanism). CRISPR screens directly perturb gene function and measure consequences. Multi-omics integration methods increasingly incorporate causal assumptions or validation against perturbation data.</p>
<p>The distinction matters for interpretation and intervention. A predictive model based on correlations may fail when the data distribution shifts (see <a href="../part_3/p3-ch13-confounding.html" class="quarto-xref"><span>Chapter 13</span></a>) or when interventions alter the causal structure. A causally informed model captures mechanism that persists across contexts.</p>
</section>
</section>
<section id="sec-ch23-missing-modalities" class="level2" data-number="23.6">
<h2 data-number="23.6" class="anchored" data-anchor-id="sec-ch23-missing-modalities"><span class="header-section-number">23.6</span> Handling Missing Modalities</h2>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Challenging Section
</div>
</div>
<div class="callout-body-container callout-body">
<p>Handling missing modalities requires understanding both the mathematical framework of intermediate fusion and the biological assumptions underlying cross-modal imputation. If the shared latent space concepts from <a href="#sec-ch23-intermediate-fusion" class="quarto-xref"><span>Section 23.2.3</span></a> are not yet clear, review that section before proceeding.</p>
</div>
</div>
<p>Real-world multi-omics data are incomplete. Different studies measure different modalities. Within studies, technical failures, sample limitations, and cost constraints create missing data. Clinical deployment must handle patients with incomplete molecular profiles. Robust multi-omics methods must address missingness directly.</p>
<section id="sec-ch23-incomplete-training" class="level3" data-number="23.6.1">
<h3 data-number="23.6.1" class="anchored" data-anchor-id="sec-ch23-incomplete-training"><span class="header-section-number">23.6.1</span> Training with Incomplete Data</h3>
<p>Intermediate fusion architectures handle missing modalities naturally during inference: only the available encoders contribute to the shared representation. Training is more complex because alignment terms require paired measurements across modalities.</p>
<p>One approach trains on the subset of samples with complete data, then applies the trained encoders to samples with partial data during inference. This wastes information from the samples with incomplete profiles and may learn representations that fail to generalize to the missing-modality setting.</p>
<p>A better approach incorporates missingness into training. Modality dropout randomly masks modalities during training, forcing the model to learn representations robust to missing inputs. The mechanism works analogously to standard dropout: by training the model to succeed even when some information is unavailable, modality dropout encourages the shared latent space to encode biological state redundantly across modalities rather than relying on any single data type. The reconstruction and alignment losses are computed only for available modalities, so samples with partial data can still contribute to training.</p>
<p>Curriculum learning strategies may first train with complete data to establish alignment, then gradually increase modality dropout to improve robustness. The curriculum matters because alignment and robustness have opposing requirements: strong alignment needs paired data to learn which expression patterns correspond to which accessibility patterns, but robustness needs the model to practice predicting with missing inputs. Starting with complete data establishes the cross-modal correspondences, then increasing dropout teaches the model to function without them. The balance between alignment quality (which benefits from complete data) and robustness (which requires training on partial data) requires empirical tuning.</p>
</section>
<section id="sec-ch23-imputation" class="level3" data-number="23.6.2">
<h3 data-number="23.6.2" class="anchored" data-anchor-id="sec-ch23-imputation"><span class="header-section-number">23.6.2</span> Cross-Modal Imputation</h3>
<p>Intermediate fusion enables principled imputation of missing modalities. Given a sample’s available modalities encoded into the shared latent space, decoders for missing modalities can predict expected values. If a patient has expression data but not methylation, the expression encoder produces a latent embedding, and the methylation decoder generates predicted methylation values from that embedding.</p>
<p>The imputation quality depends on how well the shared space captures the biological factors underlying both modalities. If expression and methylation reflect the same cell state, the imputation may be accurate. If they capture distinct aspects of biology, imputation will smooth over true variation.</p>
<p>Uncertainty in imputation matters for downstream use. Point estimates of missing values provide no indication of confidence. Generative models that produce distributions over missing values enable propagation of uncertainty through downstream analyses (see <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-uq-methods" class="quarto-xref"><span>Section 24.4</span></a>). A risk prediction that depends heavily on imputed values should have wider confidence intervals than one based entirely on measured data. The selective prediction and uncertainty communication strategies that could implement this appropriate caution are developed in <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-selective-prediction" class="quarto-xref"><span>Section 24.7</span></a>.</p>
</section>
<section id="sec-ch23-zero-shot" class="level3" data-number="23.6.3">
<h3 data-number="23.6.3" class="anchored" data-anchor-id="sec-ch23-zero-shot"><span class="header-section-number">23.6.3</span> Zero-Shot Cross-Modal Transfer</h3>
<p>The most ambitious application of multi-omics integration is zero-shot prediction across modalities: using a model trained on one set of modalities to make predictions for samples measured with entirely different modalities.</p>
<p>This transfer relies on the shared latent space capturing biological state independently of measurement modality. If the space truly represents cell state, then a classifier trained on expression-derived embeddings should work on ATAC-seq-derived embeddings, since both encoders map to the same biological meaning. The alignment training enables this transfer by ensuring that the same biological entity maps to the same latent location regardless of which modality was measured.</p>
<p>Zero-shot transfer is rarely perfect. The modalities may capture somewhat different aspects of biology, and the alignment may be imprecise. But partial transfer can still be valuable: a model achieving 80% of supervised performance without any labeled examples in the new modality saves substantial annotation effort (see <a href="../part_3/p3-ch10-adaptation.html#sec-ch10-zero-shot" class="quarto-xref"><span>Section 10.6.2</span></a> for zero-shot transfer in other contexts).</p>
</section>
</section>
<section id="sec-ch23-practical-challenges" class="level2" data-number="23.7">
<h2 data-number="23.7" class="anchored" data-anchor-id="sec-ch23-practical-challenges"><span class="header-section-number">23.7</span> Practical Challenges</h2>
<p>The gap between multi-omics potential and deployed reality reflects obstacles that compound across modalities. Technical variation that is manageable within a single assay type becomes intractable when batch structures differ across genomics, transcriptomics, and proteomics. Sample sizes that support single-modality analysis may be insufficient when the effective dimensionality grows with each added data type. Interpretability, already challenging for deep learning on individual modalities, becomes harder still when attributions must be compared across features with different scales and semantics. These practical challenges determine whether integration improves predictions or merely adds complexity.</p>
<section id="sec-ch23-batch-effects" class="level3" data-number="23.7.1">
<h3 data-number="23.7.1" class="anchored" data-anchor-id="sec-ch23-batch-effects"><span class="header-section-number">23.7.1</span> Batch Effects Across Modalities</h3>
<p>Batch effects, systematic technical variation between experimental batches, are endemic in high-throughput biology. Multi-omics integration faces compounded batch effects: each modality may have its own batch structure, batches may be correlated or anti-correlated across modalities, and batch correction methods designed for single modalities may not extend to multi-modal settings.</p>
<p>Consider a study where expression data were generated at three sequencing centers and proteomics data were generated at two mass spectrometry facilities. The batch effects in each modality are independent. Samples from expression batch 1 are spread across proteomics batches. Correcting expression batch effects does not address proteomics batch effects, and vice versa.</p>
<p>Integration must either correct batch effects within each modality before combining (risking removal of real biology that correlates with batch) or incorporate batch as a covariate in the integrated model (requiring that batch structure be known and modeled correctly). Domain adaptation techniques treat batches as domains and learn representations invariant to domain while retaining biological signal. The systematic strategies for detecting batch-driven confounding appear in <a href="../part_3/p3-ch13-confounding.html#sec-ch13-detection" class="quarto-xref"><span>Section 13.8</span></a>, while mitigation approaches including adversarial domain adaptation are detailed in <a href="../part_3/p3-ch13-confounding.html#sec-ch13-mitigation" class="quarto-xref"><span>Section 13.9</span></a>.</p>
</section>
<section id="sec-ch23-sample-size" class="level3" data-number="23.7.2">
<h3 data-number="23.7.2" class="anchored" data-anchor-id="sec-ch23-sample-size"><span class="header-section-number">23.7.2</span> Sample Size and Power</h3>
<p>Multi-omics studies typically have smaller sample sizes than single-modality studies due to cost constraints. Each additional modality increases per-sample cost, trading breadth for depth. This tradeoff has implications for statistical power and model complexity.</p>
<p>The effective sample size for multi-omics integration may be smaller than for any single modality. If 1000 patients have expression data and 800 have methylation data but only 600 have both, intermediate fusion sees 600 fully informative samples. Late fusion can use all 1000 expression samples and all 800 methylation samples, avoiding the intersection penalty.</p>
<p>Power analyses for multi-omics studies must account for the specific integration strategy and the expected missingness pattern. A study designed for early fusion needs larger sample sizes (relative to feature count) than one designed for late fusion. Grant applications and study planning should explicitly consider how integration choices affect required sample sizes.</p>
</section>
<section id="sec-ch23-interpretability" class="level3" data-number="23.7.3">
<h3 data-number="23.7.3" class="anchored" data-anchor-id="sec-ch23-interpretability"><span class="header-section-number">23.7.3</span> Interpretability Across Modalities</h3>
<p>Multi-omics models compound the interpretability challenges inherent in deep learning. When a model predicts disease risk from integrated genomic, transcriptomic, and proteomic features, clinicians need to understand which modalities and which features drive the prediction. A black-box risk score, however accurate, provides little guidance for understanding mechanism or identifying intervention targets.</p>
<p>Attribution methods that work for single-modality models do not automatically extend to multi-modal settings (see <a href="../part_6/p6-ch25-interpretability.html" class="quarto-xref"><span>Chapter 25</span></a> for attribution methods). Gradient-based attribution can identify important features within each modality, but comparing importance across modalities requires careful normalization. A genomic variant and an expression value operate on different scales with different effect size distributions; raw attribution scores are not directly comparable.</p>
<p>The intermediate fusion architecture offers some interpretability advantages. The shared latent space can be visualized to understand how samples cluster and which modalities contribute to separation. Attention weights in cross-modal transformers indicate which features from each modality the model considers when making predictions. Modality ablation studies quantify each data type’s contribution to overall performance.</p>
<p>Biological interpretability requires connecting learned representations to known biology. Do the latent dimensions correspond to pathways, cell types, or disease processes? Are cross-modal attention patterns consistent with known regulatory relationships? These questions demand validation against external biological knowledge, not just introspection of model parameters.</p>
</section>
<section id="sec-ch23-evaluation" class="level3" data-number="23.7.4">
<h3 data-number="23.7.4" class="anchored" data-anchor-id="sec-ch23-evaluation"><span class="header-section-number">23.7.4</span> Evaluation Complexity</h3>
<p>Evaluating multi-omics models is more complex than evaluating single-modality models. Multiple dimensions of performance matter: prediction accuracy, calibration, cross-modality transfer, robustness to missing modalities, biological plausibility of learned representations, and clinical utility.</p>
<p>A model might achieve high prediction accuracy by memorizing batch effects or leveraging shortcuts in the data. Evaluation should include cross-batch and cross-cohort validation to assess generalization (<a href="../part_3/p3-ch12-evaluation.html" class="quarto-xref"><span>Chapter 12</span></a>), with particular attention to homology-aware splitting strategies (<a href="../part_3/p3-ch12-evaluation.html#sec-ch12-homology-aware-splitting" class="quarto-xref"><span>Section 12.2</span></a>) that prevent information leakage across data partitions. Ablation studies that remove each modality quantify the contribution of each data type and identify whether the model genuinely integrates information or relies predominantly on one modality.</p>
<p>Biological validation through comparison to known biology provides another evaluation axis. Do the learned factors correspond to known pathways? Are attention patterns consistent with regulatory relationships? Do imputed values match held-out measurements? These checks assess whether the model captures biological signal rather than technical artifacts.</p>
<p>Clinical evaluation, addressed in <a href="../part_7/p7-ch28-clinical-risk.html" class="quarto-xref"><span>Chapter 28</span></a>, requires prospective validation in real deployment settings. A model that improves prediction in research cohorts may not improve clinical decisions if the predictions do not change management or if the required modalities are unavailable in clinical workflows.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Knowledge Check
</div>
</div>
<div class="callout-body-container callout-body">
<p>A research team trains a multi-omics model integrating genomics, transcriptomics, and proteomics for cancer prognosis. The model achieves excellent cross-validation performance but fails when tested on data from a different hospital.</p>
<ol type="1">
<li>What are three possible reasons for this failure?</li>
<li>What evaluation strategies should have been included to detect this problem earlier?</li>
<li>How might the fusion strategy choice (early, late, intermediate) affect robustness to this kind of distribution shift?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Three likely reasons: batch effects differing between hospitals (different sequencing platforms, sample processing), population differences (ancestry, age distribution, disease subtypes), or the model memorizing hospital-specific technical artifacts rather than biological signal.</p></li>
<li><p>Cross-batch validation, cross-cohort validation with held-out external datasets, and ablation studies to verify each modality contributes genuine biological information rather than batch-correlated shortcuts.</p></li>
<li><p>Late fusion may be more robust because each modality is processed independently before combination, limiting how batch effects in one modality can corrupt others. Early fusion concatenates raw features, allowing batch effects to propagate across modalities. Intermediate fusion balances these; shared latent spaces can either amplify or mitigate batch effects depending on training objectives.</p></li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-ch23-conclusion" class="level2" data-number="23.8">
<h2 data-number="23.8" class="anchored" data-anchor-id="sec-ch23-conclusion"><span class="header-section-number">23.8</span> Integration as Means, Not End</h2>
<p>Multi-omics integration is not an end in itself but a means to improved prediction, understanding, and intervention. The integration strategies and foundation models surveyed here produce representations; downstream applications convert those representations to actionable outputs. Risk prediction combines multi-omic embeddings with clinical variables for individualized prognosis. Treatment response models predict which patients will benefit from specific therapies based on their integrated molecular profiles. Drug discovery uses multi-omics to inform target identification and patient stratification for clinical trials (see <a href="../part_7/p7-ch30-drug-discovery.html" class="quarto-xref"><span>Chapter 30</span></a>). In each case, integration provides the substrate; clinical or scientific goals provide the purpose.</p>
<p>The systems view that multi-omics enables shapes how predictions should be interpreted. A risk prediction based on integrated features inherits explanatory power from the causal relationships linking molecular layers to phenotype. Understanding which modalities drive predictions, and how those modalities relate to underlying biology, supports clinical reasoning about mechanism and intervention. This explanatory capacity distinguishes multi-omics from single-modality approaches that may predict equally well but provide less insight into why predictions succeed or fail.</p>
<p>The path from research models to clinical deployment requires addressing practical challenges that intensify with integration: batch effects across modalities and institutions, missing measurements that differ systematically across patients, sample size limitations that grow with feature dimensionality, and evaluation complexity when outcomes depend on multiple data types. The clinical applications examined in <a href="../part_7/p7-ch28-clinical-risk.html" class="quarto-xref"><span>Chapter 28</span></a> and <a href="../part_7/p7-ch29-rare-disease.html" class="quarto-xref"><span>Chapter 29</span></a> confront these realities. As the field advances toward whole-patient foundation models that jointly encode genomics, transcriptomics, proteomics, imaging, and clinical data, the integration principles established here provide the foundation. The trade-offs between fusion strategies, the importance of shared latent spaces, the challenge of missing modalities, and the systems biology perspective on information flow will remain relevant as scale and scope expand. The interpretability challenges that compound across modalities (<a href="../part_6/p6-ch25-interpretability.html" class="quarto-xref"><span>Chapter 25</span></a>) and the calibration requirements for clinical deployment (<a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-calibration" class="quarto-xref"><span>Section 24.2</span></a>) add further dimensions that shape how multi-omics models should be developed and evaluated.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Test Yourself">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Test Yourself
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before reviewing the summary, test your recall:</p>
<ol type="1">
<li>What is the “integration paradox” and why can more data sometimes lead to worse predictions in multi-omics?</li>
<li>Compare the three fusion strategies (early, intermediate, late) and explain when each is most appropriate.</li>
<li>Why does intermediate fusion dominate modern multi-omics approaches?</li>
<li>What is meant by “bottleneck modalities” and why should you identify them when designing multi-omics integration?</li>
<li>Explain the difference between causal and correlational integration, and why this distinction matters for clinical interventions.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answers">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answers
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Integration Paradox</strong>: The paradox is that naive concatenation of multi-omics features often degrades performance relative to single-modality models. This occurs because noise from uninformative features overwhelms signal from informative ones, batch effects between modalities create spurious correlations that models exploit, and the curse of dimensionality intensifies when features from multiple assays are stacked without principled integration, resulting in more parameters to estimate than training samples can constrain.</p></li>
<li><p><strong>Fusion Strategy Comparison</strong>: Early fusion concatenates features before modeling, enabling arbitrary cross-modal interactions but requiring complete data and suffering from dimensionality issues; best for large samples with complete data. Late fusion trains separate models per modality and combines predictions, handling missing data excellently but unable to learn feature-level interactions; best when modalities provide independent signals. Intermediate fusion uses modality-specific encoders projecting to a shared latent space, balancing interaction learning with missing data robustness; best when modalities are coupled and paired training data exists.</p></li>
<li><p><strong>Intermediate Fusion Dominance</strong>: Intermediate fusion dominates because it balances flexibility with robustness by learning modality-specific encoders that can be pretrained on large single-modality datasets, then aligned through shared latent spaces that enable cross-modal reasoning. The architecture handles missing modalities gracefully (encoders fire only for available data), allows new modalities to be added without retraining existing components, and provides a natural target for interpretation and visualization, addressing the key limitations of both early fusion (dimensionality, missing data) and late fusion (no feature-level interactions).</p></li>
<li><p><strong>Bottleneck Modalities</strong>: Bottleneck modalities are the molecular layers that most directly mediate the relationship between genetic variation and phenotype for a specific question. For coding variants affecting protein structure, the bottleneck is at the protein level (structure matters more than expression). For regulatory variants, expression is closer to the bottleneck (enhancer effects operate through gene expression changes). Identifying bottlenecks guides which modalities to prioritize for measurement and integration; investing in proteomics provides little value if protein structure prediction from sequence already captures the critical information.</p></li>
<li><p><strong>Causal vs.&nbsp;Correlational Integration</strong>: Causal integration identifies mechanistic relationships between molecular layers (e.g., variant causes reduced expression, which causes protein deficiency, which causes metabolic dysfunction), suggesting intervention targets like expression restoration or enzyme supplementation. Correlational integration exploits statistical associations to improve prediction without identifying mechanism, achieving similar predictive performance but lacking explanatory power. The distinction matters clinically because causal models capture mechanisms that persist across contexts and guide interventions, while correlational models may fail when data distributions shift or when interventions alter the causal structure.</p></li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Summary
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Core Concepts:</strong></p>
<ul>
<li>The integration paradox: more data can mean worse predictions when noise overwhelms signal, batch effects create spurious correlations, or dimensionality outpaces sample size</li>
<li>Three fusion strategies (early, intermediate, late) offer different tradeoffs between cross-modal interaction learning and missing data robustness</li>
<li>Intermediate fusion dominates modern approaches by learning modality-specific encoders projecting to a shared latent space</li>
</ul>
<p><strong>Key Methods:</strong></p>
<ul>
<li><em>MOFA+</em> for probabilistic factor-based integration</li>
<li><em>totalVI</em> and <em>MultiVI</em> for deep generative single-cell integration</li>
<li>Contrastive multi-modal learning for aligning embeddings across modalities</li>
</ul>
<p><strong>Design Principles:</strong></p>
<ul>
<li>Identify bottleneck modalities: which molecular layers most directly mediate genotype-phenotype relationships for your question</li>
<li>Design for graceful degradation: models should produce useful predictions even with incomplete modality coverage</li>
<li>Distinguish causal from correlational integration: causal understanding enables intervention, correlation enables prediction</li>
</ul>
<p><strong>Practical Considerations:</strong></p>
<ul>
<li>Batch effects compound across modalities and require per-modality correction or domain adaptation</li>
<li>Effective sample size shrinks with each required modality due to incomplete overlap</li>
<li>Interpretability requires cross-modal attribution normalization and validation against known biology</li>
</ul>
<p><strong>Looking Ahead:</strong> <a href="../part_6/p6-ch24-uncertainty.html" class="quarto-xref"><span>Chapter 24</span></a> addresses how to quantify and communicate uncertainty in these complex models, while <a href="../part_7/p7-ch28-clinical-risk.html" class="quarto-xref"><span>Chapter 28</span></a> examines the deployment path from research to clinical practice.</p>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-argelaguet_multiomics_2018" class="csl-entry" role="listitem">
Argelaguet, Ricard, Britta Velten, Damien Arnol, Sascha Dietrich, Thorsten Zenz, John C. Marioni, Florian Buettner, Wolfgang Huber, and Oliver Stegle. 2018. <span>“Multi‐<span>Omics</span> <span>Factor</span> <span>Analysis</span>—a Framework for Unsupervised Integration of Multi‐omics Data Sets.”</span> <em>Molecular Systems Biology</em> 14 (6): MSB178124. <a href="https://doi.org/10.15252/msb.20178124">https://doi.org/10.15252/msb.20178124</a>.
</div>
<div id="ref-ashuach_multivi_2023" class="csl-entry" role="listitem">
Ashuach, Tal, Mariano I. Gabitto, Michael I. Koodber, Valentine Svensson, Michael I. Jordan, and Nir Yosef. 2023. <span>“<span>MultiVI</span>: Deep Generative Model for the Integration of Multimodal Data.”</span> <em>Nature Methods</em> 20 (8): 1232–40. <a href="https://doi.org/10.1038/s41592-023-01909-9">https://doi.org/10.1038/s41592-023-01909-9</a>.
</div>
<div id="ref-candes_panning_2018" class="csl-entry" role="listitem">
Candès, Emmanuel, Yingying Fan, Lucas Janson, and Jinchi Lv. 2018. <span>“Panning for <span>Gold</span>: <span>‘<span>Model</span>-<span>X</span>’</span> <span>Knockoffs</span> for <span>High</span> <span>Dimensional</span> <span>Controlled</span> <span>Variable</span> <span>Selection</span>.”</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 80 (3): 551–77. <a href="https://doi.org/10.1111/rssb.12265">https://doi.org/10.1111/rssb.12265</a>.
</div>
<div id="ref-gayoso_joint_2021" class="csl-entry" role="listitem">
Gayoso, Adam, Zoë Steier, Romain Lopez, Jeffrey Regier, Kristopher L. Nazor, Aaron Streets, and Nir Yosef. 2021. <span>“Joint Probabilistic Modeling of Single-Cell Multi-Omic Data with <span class="nocase">totalVI</span>.”</span> <em>Nature Methods</em> 18 (3): 272–82. <a href="https://doi.org/10.1038/s41592-020-01050-x">https://doi.org/10.1038/s41592-020-01050-x</a>.
</div>
<div id="ref-hwang_glm_2024" class="csl-entry" role="listitem">
Hwang, Yunha, Andre L. Cornman, Elizabeth H. Kellogg, Sergey Ovchinnikov, and Peter R. Girguis. 2024. <span>“Genomic Language Model Predicts Protein Co-Regulation and Function.”</span> <em>Nature Communications</em> 15 (1): 2880. <a href="https://doi.org/10.1038/s41467-024-46947-9">https://doi.org/10.1038/s41467-024-46947-9</a>.
</div>
<div id="ref-manolio_finding_2009" class="csl-entry" role="listitem">
Manolio, Teri A., Francis S. Collins, Nancy J. Cox, David B. Goldstein, Lucia A. Hindorff, David J. Hunter, Mark I. McCarthy, et al. 2009. <span>“Finding the Missing Heritability of Complex Diseases.”</span> <em>Nature</em> 461 (7265): 747–53. <a href="https://doi.org/10.1038/nature08494">https://doi.org/10.1038/nature08494</a>.
</div>
<div id="ref-radford_learning_2021" class="csl-entry" role="listitem">
Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. <span>“Learning <span>Transferable</span> <span>Visual</span> <span>Models</span> <span>From</span> <span>Natural</span> <span>Language</span> <span>Supervision</span>.”</span> In <em>Proceedings of the 38th <span>International</span> <span>Conference</span> on <span>Machine</span> <span>Learning</span></em>, 8748–63.
</div>
<div id="ref-zhu_gpt_2024" class="csl-entry" role="listitem">
Zhu, Xiao, Chenchen Qin, Fang Wang, Fan Yang, Bing He, Yu Zhao, and Jianhua Yao. 2024. <span>“<span>CD</span>-<span>GPT</span>: <span>A</span> <span>Biological</span> <span>Foundation</span> <span>Model</span> <span>Bridging</span> the <span>Gap</span> Between <span>Molecular</span> <span>Sequences</span> <span>Through</span> <span>Central</span> <span>Dogma</span>.”</span> bioRxiv. <a href="https://doi.org/10.1101/2024.06.24.600337">https://doi.org/10.1101/2024.06.24.600337</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../part_5/p5-ch22-networks.html" class="pagination-link" aria-label="Graph and Network Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Graph and Network Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../part_6/p6--responsible-deployment.html" class="pagination-link" aria-label="Part VI: Responsible Deployment">
        <span class="nav-page-text">Part VI: Responsible Deployment</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025-2026, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>