<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; Protein Language Models – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ch-p3-glm.html" rel="next">
<link href="./ch-p3-tokens.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch-p3-tokens.html">Part III: Transformers Models</a></li><li class="breadcrumb-item"><a href="./ch-p3-plm.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Protein Language Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Genomic Foundation Models</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Data &amp; Pre-DL Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p1-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">NGS &amp; Variant Calling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p1-prs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">PRS &amp; GWAS Basics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p1-cadd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Deleteriousness Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p1-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Foundational Genomics Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: CNN Seq-to-Function Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p2-reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regulatory Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p2-transc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Transcriptional Effects</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p2-splice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Splicing Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Transformers Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p3-tokens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p3-plm.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p3-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">DNA Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p3-hybrid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Part IV: GFMs &amp; Multi-omics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p4-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Genomic FMs: Principles &amp; Practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p4-vep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p4-omics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Multi-omics and Systems Context</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p4-confound.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p4-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Part V: Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p5-clinical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p5-variants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Pathogenic Variant Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch-p5-drugs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Drug Discovery &amp; Biotech</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer for Genomics</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#evolutionary-sequences-as-natural-language" id="toc-evolutionary-sequences-as-natural-language" class="nav-link active" data-scroll-target="#evolutionary-sequences-as-natural-language"><span class="header-section-number">9.1</span> Evolutionary Sequences as Natural Language</a></li>
  <li><a href="#the-esm-model-family" id="toc-the-esm-model-family" class="nav-link" data-scroll-target="#the-esm-model-family"><span class="header-section-number">9.2</span> The ESM Model Family</a>
  <ul class="collapse">
  <li><a href="#esm-1b-establishing-the-paradigm" id="toc-esm-1b-establishing-the-paradigm" class="nav-link" data-scroll-target="#esm-1b-establishing-the-paradigm"><span class="header-section-number">9.2.1</span> ESM-1b: Establishing the Paradigm</a></li>
  <li><a href="#what-esm-learns" id="toc-what-esm-learns" class="nav-link" data-scroll-target="#what-esm-learns"><span class="header-section-number">9.2.2</span> What ESM Learns</a></li>
  <li><a href="#esm-2-scaling-up" id="toc-esm-2-scaling-up" class="nav-link" data-scroll-target="#esm-2-scaling-up"><span class="header-section-number">9.2.3</span> ESM-2: Scaling Up</a></li>
  </ul></li>
  <li><a href="#prottrans-alternative-architectures" id="toc-prottrans-alternative-architectures" class="nav-link" data-scroll-target="#prottrans-alternative-architectures"><span class="header-section-number">9.3</span> ProtTrans: Alternative Architectures</a></li>
  <li><a href="#esm-1v-zero-shot-variant-effect-prediction" id="toc-esm-1v-zero-shot-variant-effect-prediction" class="nav-link" data-scroll-target="#esm-1v-zero-shot-variant-effect-prediction"><span class="header-section-number">9.4</span> ESM-1v: Zero-Shot Variant Effect Prediction</a>
  <ul class="collapse">
  <li><a href="#the-zero-shot-approach" id="toc-the-zero-shot-approach" class="nav-link" data-scroll-target="#the-zero-shot-approach"><span class="header-section-number">9.4.1</span> The Zero-Shot Approach</a></li>
  <li><a href="#genome-wide-prediction" id="toc-genome-wide-prediction" class="nav-link" data-scroll-target="#genome-wide-prediction"><span class="header-section-number">9.4.2</span> Genome-Wide Prediction</a></li>
  <li><a href="#benchmarking-on-proteingym" id="toc-benchmarking-on-proteingym" class="nav-link" data-scroll-target="#benchmarking-on-proteingym"><span class="header-section-number">9.4.3</span> Benchmarking on ProteinGym</a></li>
  </ul></li>
  <li><a href="#esmfold-structure-from-sequence" id="toc-esmfold-structure-from-sequence" class="nav-link" data-scroll-target="#esmfold-structure-from-sequence"><span class="header-section-number">9.5</span> ESMFold: Structure from Sequence</a>
  <ul class="collapse">
  <li><a href="#from-language-model-to-structure-predictor" id="toc-from-language-model-to-structure-predictor" class="nav-link" data-scroll-target="#from-language-model-to-structure-predictor"><span class="header-section-number">9.5.1</span> From Language Model to Structure Predictor</a></li>
  <li><a href="#what-this-reveals-about-plms" id="toc-what-this-reveals-about-plms" class="nav-link" data-scroll-target="#what-this-reveals-about-plms"><span class="header-section-number">9.5.2</span> What This Reveals About PLMs</a></li>
  </ul></li>
  <li><a href="#transfer-to-genomics-cadd-and-alphamissense" id="toc-transfer-to-genomics-cadd-and-alphamissense" class="nav-link" data-scroll-target="#transfer-to-genomics-cadd-and-alphamissense"><span class="header-section-number">9.6</span> Transfer to Genomics: CADD and AlphaMissense</a>
  <ul class="collapse">
  <li><a href="#cadd-v1.7-plm-features-for-variant-prioritization" id="toc-cadd-v1.7-plm-features-for-variant-prioritization" class="nav-link" data-scroll-target="#cadd-v1.7-plm-features-for-variant-prioritization"><span class="header-section-number">9.6.1</span> CADD v1.7: PLM Features for Variant Prioritization</a></li>
  <li><a href="#alphamissense-combining-plm-and-structure" id="toc-alphamissense-combining-plm-and-structure" class="nav-link" data-scroll-target="#alphamissense-combining-plm-and-structure"><span class="header-section-number">9.6.2</span> AlphaMissense: Combining PLM and Structure</a></li>
  <li><a href="#performance-comparison" id="toc-performance-comparison" class="nav-link" data-scroll-target="#performance-comparison"><span class="header-section-number">9.6.3</span> Performance Comparison</a></li>
  </ul></li>
  <li><a href="#lessons-for-genomic-language-models" id="toc-lessons-for-genomic-language-models" class="nav-link" data-scroll-target="#lessons-for-genomic-language-models"><span class="header-section-number">9.7</span> Lessons for Genomic Language Models</a>
  <ul class="collapse">
  <li><a href="#self-supervision-works" id="toc-self-supervision-works" class="nav-link" data-scroll-target="#self-supervision-works"><span class="header-section-number">9.7.1</span> Self-Supervision Works</a></li>
  <li><a href="#scale-matters" id="toc-scale-matters" class="nav-link" data-scroll-target="#scale-matters"><span class="header-section-number">9.7.2</span> Scale Matters</a></li>
  <li><a href="#transfer-learning-is-effective" id="toc-transfer-learning-is-effective" class="nav-link" data-scroll-target="#transfer-learning-is-effective"><span class="header-section-number">9.7.3</span> Transfer Learning is Effective</a></li>
  <li><a href="#architecture-choices" id="toc-architecture-choices" class="nav-link" data-scroll-target="#architecture-choices"><span class="header-section-number">9.7.4</span> Architecture Choices</a></li>
  <li><a href="#integration-with-other-modalities" id="toc-integration-with-other-modalities" class="nav-link" data-scroll-target="#integration-with-other-modalities"><span class="header-section-number">9.7.5</span> Integration with Other Modalities</a></li>
  </ul></li>
  <li><a href="#limitations-and-ongoing-challenges" id="toc-limitations-and-ongoing-challenges" class="nav-link" data-scroll-target="#limitations-and-ongoing-challenges"><span class="header-section-number">9.8</span> Limitations and Ongoing Challenges</a>
  <ul class="collapse">
  <li><a href="#sequence-length" id="toc-sequence-length" class="nav-link" data-scroll-target="#sequence-length"><span class="header-section-number">9.8.1</span> Sequence Length</a></li>
  <li><a href="#orphan-proteins" id="toc-orphan-proteins" class="nav-link" data-scroll-target="#orphan-proteins"><span class="header-section-number">9.8.2</span> Orphan Proteins</a></li>
  <li><a href="#epistasis" id="toc-epistasis" class="nav-link" data-scroll-target="#epistasis"><span class="header-section-number">9.8.3</span> Epistasis</a></li>
  <li><a href="#interpretability" id="toc-interpretability" class="nav-link" data-scroll-target="#interpretability"><span class="header-section-number">9.8.4</span> Interpretability</a></li>
  </ul></li>
  <li><a href="#significance" id="toc-significance" class="nav-link" data-scroll-target="#significance"><span class="header-section-number">9.9</span> Significance</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch-p3-tokens.html">Part III: Transformers Models</a></li><li class="breadcrumb-item"><a href="./ch-p3-plm.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Protein Language Models</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Protein Language Models</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="evolutionary-sequences-as-natural-language" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="evolutionary-sequences-as-natural-language"><span class="header-section-number">9.1</span> Evolutionary Sequences as Natural Language</h2>
<p>Before transformers revolutionized genomic sequence modeling, they first transformed our ability to model proteins. The success of protein language models (PLMs) established a paradigm that would later inspire genomic foundation models: treat biological sequences as a form of natural language, train large transformer models on massive unlabeled sequence databases, and extract functional knowledge through self-supervised learning.</p>
<p>The analogy between protein sequences and natural language runs deeper than mere metaphor. Both encode complex information in linear strings of discrete tokens (amino acids or words). Both exhibit hierarchical structure—motifs combine into domains as words combine into phrases. Both have syntax (structural constraints) and semantics (functional meaning). And crucially, both are shaped by evolutionary pressure: natural selection filters protein sequences just as cultural selection shapes language.</p>
<p>This chapter examines how protein language models pioneered biological foundation modeling, from the ESM family’s demonstration that transformers can learn protein structure and function from sequence alone, to their application in variant effect prediction and structure determination. Understanding PLMs provides essential context for the genomic language models covered in subsequent chapters, as many architectural choices and training strategies transfer directly from proteins to DNA.</p>
</section>
<section id="the-esm-model-family" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="the-esm-model-family"><span class="header-section-number">9.2</span> The ESM Model Family</h2>
<section id="esm-1b-establishing-the-paradigm" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="esm-1b-establishing-the-paradigm"><span class="header-section-number">9.2.1</span> ESM-1b: Establishing the Paradigm</h3>
<p>The Evolutionary Scale Modeling (ESM) project, developed at Meta AI Research, demonstrated that transformer language models trained on protein sequences learn biologically meaningful representations without explicit supervision <span class="citation" data-cites="rives_esm_2021">(<a href="references.html#ref-rives_esm_2021" role="doc-biblioref">Rives et al. 2021</a>)</span>.</p>
<p><strong>Training data</strong>: ESM-1b was trained on UniRef50, a clustered database of ~33 million protein sequences covering the known diversity of protein families. UniRef50 clusters sequences at 50% identity, providing broad coverage while reducing redundancy.</p>
<p><strong>Architecture</strong>: ESM-1b uses a BERT-style bidirectional transformer with 650 million parameters:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Component</th>
<th>Specification</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Layers</td>
<td>33</td>
</tr>
<tr class="even">
<td>Hidden dimension</td>
<td>1,280</td>
</tr>
<tr class="odd">
<td>Attention heads</td>
<td>20</td>
</tr>
<tr class="even">
<td>Parameters</td>
<td>650M</td>
</tr>
<tr class="odd">
<td>Max sequence length</td>
<td>1,024 amino acids</td>
</tr>
</tbody>
</table>
<p><strong>Training objective</strong>: Masked language modeling (MLM)—the model learns to predict randomly masked amino acids given surrounding context. This is analogous to BERT’s masked token prediction, but operating on amino acids rather than words.</p>
</section>
<section id="what-esm-learns" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="what-esm-learns"><span class="header-section-number">9.2.2</span> What ESM Learns</h3>
<p>Despite never seeing structural or functional labels during training, ESM learns representations that capture:</p>
<p><strong>Secondary structure</strong>: Attention patterns in ESM correlate with alpha helices and beta sheets. The model implicitly learns that certain amino acid patterns form specific structural elements.</p>
<p><strong>Contact prediction</strong>: ESM’s attention heads capture residue-residue contacts—amino acids that are distant in sequence but close in 3D space. This emergent capability suggests the model learns aspects of protein folding from sequence statistics alone.</p>
<p><strong>Evolutionary conservation</strong>: Masked token predictions correlate with position-specific conservation scores from multiple sequence alignments. ESM effectively learns which positions tolerate variation and which are constrained.</p>
<p><strong>Functional sites</strong>: Attention concentrates on catalytic residues, binding sites, and other functionally important positions, even without explicit functional annotation.</p>
</section>
<section id="esm-2-scaling-up" class="level3" data-number="9.2.3">
<h3 data-number="9.2.3" class="anchored" data-anchor-id="esm-2-scaling-up"><span class="header-section-number">9.2.3</span> ESM-2: Scaling Up</h3>
<p>ESM-2 extended the ESM approach with larger models and improved training <span class="citation" data-cites="lin_esm-2_2022">(<a href="references.html#ref-lin_esm-2_2022" role="doc-biblioref">Lin et al. 2022</a>)</span>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Parameters</th>
<th>Layers</th>
<th>Performance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ESM-2 (8M)</td>
<td>8M</td>
<td>6</td>
<td>Baseline</td>
</tr>
<tr class="even">
<td>ESM-2 (35M)</td>
<td>35M</td>
<td>12</td>
<td>+5% contact prediction</td>
</tr>
<tr class="odd">
<td>ESM-2 (150M)</td>
<td>150M</td>
<td>30</td>
<td>+8% contact prediction</td>
</tr>
<tr class="even">
<td>ESM-2 (650M)</td>
<td>650M</td>
<td>33</td>
<td>+12% contact prediction</td>
</tr>
<tr class="odd">
<td>ESM-2 (3B)</td>
<td>3B</td>
<td>36</td>
<td>+15% contact prediction</td>
</tr>
<tr class="even">
<td>ESM-2 (15B)</td>
<td>15B</td>
<td>48</td>
<td>State-of-the-art</td>
</tr>
</tbody>
</table>
<p>Performance scales smoothly with model size across structure prediction, contact prediction, and variant effect tasks—a phenomenon mirroring the scaling laws observed in natural language processing.</p>
</section>
</section>
<section id="prottrans-alternative-architectures" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="prottrans-alternative-architectures"><span class="header-section-number">9.3</span> ProtTrans: Alternative Architectures</h2>
<p>The ProtTrans family explored multiple transformer architectures for protein sequences:</p>
<p><strong>ProtBERT</strong>: BERT-style bidirectional encoder trained on BFD (Big Fantastic Database), comprising ~2.1 billion protein sequences.</p>
<p><strong>ProtT5</strong>: Encoder-decoder architecture based on T5, enabling both understanding and generation tasks.</p>
<p><strong>ProtXLNet</strong>: XLNet-style permutation language modeling, capturing bidirectional context without the [MASK] token artifact.</p>
<p>ProtTrans models demonstrated that the protein language modeling paradigm generalizes across architectures. The choice between encoder-only (BERT-style) and encoder-decoder (T5-style) models depends on the downstream application: encoders excel at classification and embedding tasks, while encoder-decoders enable sequence generation.</p>
</section>
<section id="esm-1v-zero-shot-variant-effect-prediction" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="esm-1v-zero-shot-variant-effect-prediction"><span class="header-section-number">9.4</span> ESM-1v: Zero-Shot Variant Effect Prediction</h2>
<p>A critical application of protein language models is predicting the effects of amino acid substitutions—missense variants that are the most common type of protein-coding mutation.</p>
<section id="the-zero-shot-approach" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="the-zero-shot-approach"><span class="header-section-number">9.4.1</span> The Zero-Shot Approach</h3>
<p>ESM-1v (2021) demonstrated that PLMs can predict variant effects without any training on variant labels. The approach exploits masked language modeling: for a variant at position <span class="math inline">\(i\)</span> changing amino acid <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>, compute:</p>
<p><span class="math display">\[\Delta \text{score} = \log P(b | \text{context}) - \log P(a | \text{context})\]</span></p>
<p>If the model assigns higher probability to the mutant amino acid than the wild-type, the variant is predicted benign; if lower, deleterious. This “zero-shot” prediction requires no labeled training data—the model’s evolutionary knowledge, learned from sequence databases, directly informs variant interpretation.</p>
</section>
<section id="genome-wide-prediction" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="genome-wide-prediction"><span class="header-section-number">9.4.2</span> Genome-Wide Prediction</h3>
<p>Brandes et al.&nbsp;(2023) applied ESM-1b to predict effects for all ~450 million possible missense variants in the human genome <span class="citation" data-cites="brandes_genome-wide_2023">(<a href="references.html#ref-brandes_genome-wide_2023" role="doc-biblioref">Brandes et al. 2023</a>)</span>:</p>
<p><strong>Scale</strong>: Every position × every possible substitution across all human proteins</p>
<p><strong>Performance on ClinVar</strong>: ESM-1b outperformed existing methods in classifying ~150,000 ClinVar/HGMD missense variants as pathogenic or benign</p>
<p><strong>Deep mutational scanning</strong>: Strong correlation with experimental measurements across 28 DMS datasets</p>
<p><strong>Isoform-specific effects</strong>: ~2 million variants annotated as damaging only in specific protein isoforms, highlighting the importance of considering alternative splicing</p>
<p>This work established PLMs as practical tools for clinical variant interpretation, capable of scoring variants that lack experimental characterization or evolutionary homologs.</p>
</section>
<section id="benchmarking-on-proteingym" class="level3" data-number="9.4.3">
<h3 data-number="9.4.3" class="anchored" data-anchor-id="benchmarking-on-proteingym"><span class="header-section-number">9.4.3</span> Benchmarking on ProteinGym</h3>
<p>ProteinGym provides a comprehensive benchmark for variant effect predictors, aggregating 217 deep mutational scanning assays covering diverse proteins <span class="citation" data-cites="notin_proteingym_2023">(<a href="references.html#ref-notin_proteingym_2023" role="doc-biblioref">Notin et al. 2023</a>)</span>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Mean Spearman ρ</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ESM-1v</td>
<td>0.48</td>
</tr>
<tr class="even">
<td>EVE (evolutionary model)</td>
<td>0.46</td>
</tr>
<tr class="odd">
<td>DeepSequence</td>
<td>0.44</td>
</tr>
<tr class="even">
<td>PolyPhen-2</td>
<td>0.32</td>
</tr>
<tr class="odd">
<td>SIFT</td>
<td>0.30</td>
</tr>
</tbody>
</table>
<p>PLMs achieve competitive or superior performance to methods that explicitly model evolutionary conservation from multiple sequence alignments, despite using only single sequences as input.</p>
</section>
</section>
<section id="esmfold-structure-from-sequence" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="esmfold-structure-from-sequence"><span class="header-section-number">9.5</span> ESMFold: Structure from Sequence</h2>
<section id="from-language-model-to-structure-predictor" class="level3" data-number="9.5.1">
<h3 data-number="9.5.1" class="anchored" data-anchor-id="from-language-model-to-structure-predictor"><span class="header-section-number">9.5.1</span> From Language Model to Structure Predictor</h3>
<p>The most dramatic demonstration of PLM capabilities came with ESMFold, which predicts protein 3D structure directly from ESM-2 embeddings <span class="citation" data-cites="lin_esm-2_2022">(<a href="references.html#ref-lin_esm-2_2022" role="doc-biblioref">Lin et al. 2022</a>)</span>.</p>
<p>Traditional structure prediction (including AlphaFold2) relies heavily on multiple sequence alignments (MSAs)—computationally expensive searches against sequence databases that can take hours per protein. ESMFold eliminates this requirement:</p>
<p><strong>Architecture</strong>: ESMFold couples ESM-2 (15B parameters) with a structure module adapted from AlphaFold2. The language model embeddings replace MSA-derived features.</p>
<p><strong>Speed</strong>: ~60× faster than AlphaFold2 for typical proteins, enabling metagenomic-scale structure prediction</p>
<p><strong>Accuracy</strong>: Achieves atomic-level accuracy for many proteins, though slightly below AlphaFold2 for proteins that benefit from MSA information</p>
</section>
<section id="what-this-reveals-about-plms" class="level3" data-number="9.5.2">
<h3 data-number="9.5.2" class="anchored" data-anchor-id="what-this-reveals-about-plms"><span class="header-section-number">9.5.2</span> What This Reveals About PLMs</h3>
<p>ESMFold’s success demonstrates that ESM-2’s internal representations encode sufficient information to determine 3D structure. The language model has learned not just local sequence patterns but global folding principles—what makes a sequence fold into a particular shape.</p>
<p>This has profound implications: the “attention” that transformers pay to distant sequence positions during masked prediction is, in some sense, learning the physics of protein folding. Residues that need to be close in 3D space attend to each other in the transformer’s attention matrices.</p>
</section>
</section>
<section id="transfer-to-genomics-cadd-and-alphamissense" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="transfer-to-genomics-cadd-and-alphamissense"><span class="header-section-number">9.6</span> Transfer to Genomics: CADD and AlphaMissense</h2>
<section id="cadd-v1.7-plm-features-for-variant-prioritization" class="level3" data-number="9.6.1">
<h3 data-number="9.6.1" class="anchored" data-anchor-id="cadd-v1.7-plm-features-for-variant-prioritization"><span class="header-section-number">9.6.1</span> CADD v1.7: PLM Features for Variant Prioritization</h3>
<p>The Combined Annotation Dependent Depletion (CADD) framework integrates diverse annotations to score variant deleteriousness (Chapter 3). CADD v1.7 incorporated ESM-1v predictions as features <span class="citation" data-cites="schubach_cadd_2024">(<a href="references.html#ref-schubach_cadd_2024" role="doc-biblioref">Schubach et al. 2024</a>)</span>:</p>
<p><strong>Integration approach</strong>: ESM-1v scores are computed for all missense variants and included alongside conservation scores, functional annotations, and regulatory predictions.</p>
<p><strong>Performance gains</strong>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Benchmark</th>
<th>CADD v1.6</th>
<th>CADD v1.7</th>
<th>Improvement</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ClinVar pathogenic vs.&nbsp;common</td>
<td>0.94</td>
<td>0.95</td>
<td>+1%</td>
</tr>
<tr class="even">
<td>Deep mutational scanning (31 datasets)</td>
<td>0.78</td>
<td>0.81</td>
<td>+3%</td>
</tr>
</tbody>
</table>
<p>The PLM features particularly improve scoring for variants in regions with limited evolutionary conservation data, where traditional methods struggle.</p>
</section>
<section id="alphamissense-combining-plm-and-structure" class="level3" data-number="9.6.2">
<h3 data-number="9.6.2" class="anchored" data-anchor-id="alphamissense-combining-plm-and-structure"><span class="header-section-number">9.6.2</span> AlphaMissense: Combining PLM and Structure</h3>
<p>AlphaMissense represents the state-of-the-art in missense variant effect prediction, combining PLM representations with structural context <span class="citation" data-cites="cheng_alphamissense_2023">(<a href="references.html#ref-cheng_alphamissense_2023" role="doc-biblioref">Cheng et al. 2023</a>)</span>:</p>
<p><strong>Architecture</strong>: AlphaMissense adapts AlphaFold’s architecture, fine-tuning on human and primate variant population frequency databases. The model learns to predict pathogenicity by combining:</p>
<ul>
<li>Sequence embeddings from ESM-style language modeling</li>
<li>Structural context from predicted protein structures</li>
<li>Evolutionary information from cross-species comparisons</li>
</ul>
<p><strong>Training data</strong>: Population frequency databases (gnomAD) provide weak labels—common variants are likely benign, absent variants may be deleterious. Critically, AlphaMissense never trains on clinical pathogenicity labels (ClinVar), yet achieves state-of-the-art performance on clinical benchmarks.</p>
<p><strong>Scale</strong>: Predictions for all ~71 million possible single amino acid substitutions across the human proteome</p>
<p><strong>Classification</strong>: 89% of missense variants classified as either likely benign or likely pathogenic, providing actionable predictions for the vast majority of possible variants</p>
</section>
<section id="performance-comparison" class="level3" data-number="9.6.3">
<h3 data-number="9.6.3" class="anchored" data-anchor-id="performance-comparison"><span class="header-section-number">9.6.3</span> Performance Comparison</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>ClinVar AUC</th>
<th>DMS Correlation</th>
<th>Training Data</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SIFT</td>
<td>0.78</td>
<td>0.30</td>
<td>Conservation</td>
</tr>
<tr class="even">
<td>PolyPhen-2</td>
<td>0.82</td>
<td>0.32</td>
<td>Conservation + structure</td>
</tr>
<tr class="odd">
<td>CADD v1.7</td>
<td>0.95</td>
<td>0.81</td>
<td>Multi-feature integration</td>
</tr>
<tr class="even">
<td>ESM-1v</td>
<td>0.89</td>
<td>0.48</td>
<td>Sequence only (zero-shot)</td>
</tr>
<tr class="odd">
<td>AlphaMissense</td>
<td>0.94</td>
<td>0.52</td>
<td>PLM + structure + population</td>
</tr>
</tbody>
</table>
<p>AlphaMissense achieves top performance by integrating the strengths of multiple approaches: PLM-derived sequence understanding, AlphaFold-derived structural context, and population genetics-derived evolutionary constraint signals.</p>
</section>
</section>
<section id="lessons-for-genomic-language-models" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="lessons-for-genomic-language-models"><span class="header-section-number">9.7</span> Lessons for Genomic Language Models</h2>
<p>The success of protein language models established several principles that inform genomic foundation modeling:</p>
<section id="self-supervision-works" class="level3" data-number="9.7.1">
<h3 data-number="9.7.1" class="anchored" data-anchor-id="self-supervision-works"><span class="header-section-number">9.7.1</span> Self-Supervision Works</h3>
<p>PLMs demonstrated that massive amounts of biological knowledge can be learned from unlabeled sequences. The same evolutionary pressures that shape proteins also shape DNA—purifying selection removes deleterious variants, leaving statistical signatures in sequence databases.</p>
</section>
<section id="scale-matters" class="level3" data-number="9.7.2">
<h3 data-number="9.7.2" class="anchored" data-anchor-id="scale-matters"><span class="header-section-number">9.7.2</span> Scale Matters</h3>
<p>Performance improves predictably with model size, motivating the development of larger genomic models. The 8M → 15B parameter progression in ESM-2 showed consistent gains across tasks.</p>
</section>
<section id="transfer-learning-is-effective" class="level3" data-number="9.7.3">
<h3 data-number="9.7.3" class="anchored" data-anchor-id="transfer-learning-is-effective"><span class="header-section-number">9.7.3</span> Transfer Learning is Effective</h3>
<p>Representations learned for one task (masked token prediction) transfer to other tasks (structure prediction, variant effects). This suggests that self-supervised pretraining captures fundamental biological knowledge rather than task-specific shortcuts.</p>
</section>
<section id="architecture-choices" class="level3" data-number="9.7.4">
<h3 data-number="9.7.4" class="anchored" data-anchor-id="architecture-choices"><span class="header-section-number">9.7.4</span> Architecture Choices</h3>
<p>The BERT-style bidirectional encoder proved highly effective for proteins, where the entire sequence context is available. However, genomic sequences present different challenges: much longer lengths (genes span kilobases, genomes span gigabases), different information density (proteins are information-dense, intergenic regions less so), and different symmetries (DNA has reverse-complement structure absent in proteins).</p>
</section>
<section id="integration-with-other-modalities" class="level3" data-number="9.7.5">
<h3 data-number="9.7.5" class="anchored" data-anchor-id="integration-with-other-modalities"><span class="header-section-number">9.7.5</span> Integration with Other Modalities</h3>
<p>AlphaMissense showed that PLM embeddings combine effectively with structural information. Similarly, genomic models benefit from integration with epigenomic data, gene annotations, and other biological context.</p>
</section>
</section>
<section id="limitations-and-ongoing-challenges" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="limitations-and-ongoing-challenges"><span class="header-section-number">9.8</span> Limitations and Ongoing Challenges</h2>
<section id="sequence-length" class="level3" data-number="9.8.1">
<h3 data-number="9.8.1" class="anchored" data-anchor-id="sequence-length"><span class="header-section-number">9.8.1</span> Sequence Length</h3>
<p>Most PLMs handle sequences up to ~1,000–2,000 amino acids. While sufficient for most individual proteins, this limits modeling of large protein complexes and doesn’t directly transfer to the much longer sequences in genomics.</p>
</section>
<section id="orphan-proteins" class="level3" data-number="9.8.2">
<h3 data-number="9.8.2" class="anchored" data-anchor-id="orphan-proteins"><span class="header-section-number">9.8.2</span> Orphan Proteins</h3>
<p>PLMs struggle with proteins that have few homologs in training databases. “Orphan” or “dark” proteins—those unique to specific lineages—lack the evolutionary signal that PLMs exploit.</p>
</section>
<section id="epistasis" class="level3" data-number="9.8.3">
<h3 data-number="9.8.3" class="anchored" data-anchor-id="epistasis"><span class="header-section-number">9.8.3</span> Epistasis</h3>
<p>Most variant effect predictions assume independence—the effect of mutation A doesn’t depend on whether mutation B is present. Real proteins exhibit epistasis, where variant effects depend on sequence context.</p>
</section>
<section id="interpretability" class="level3" data-number="9.8.4">
<h3 data-number="9.8.4" class="anchored" data-anchor-id="interpretability"><span class="header-section-number">9.8.4</span> Interpretability</h3>
<p>While attention patterns correlate with biological features, understanding exactly what PLMs learn remains challenging. The field is developing interpretation methods (Chapter 15), but PLMs remain partially “black box.”</p>
</section>
</section>
<section id="significance" class="level2" data-number="9.9">
<h2 data-number="9.9" class="anchored" data-anchor-id="significance"><span class="header-section-number">9.9</span> Significance</h2>
<p>Protein language models established that transformer architectures can learn deep biological knowledge from sequence data alone. ESM’s ability to predict structure, function, and variant effects without explicit labels demonstrated the power of self-supervised learning on evolutionary data.</p>
<p>This success directly motivated the development of genomic language models. If proteins are a language that transformers can learn, perhaps DNA is too. The genomic language models covered in Chapter 10 adapt PLM architectures and training strategies to the distinct challenges of DNA sequences—longer contexts, different alphabets, and the full complexity of gene regulation.</p>
<p>The integration path also continues: just as CADD v1.7 and AlphaMissense incorporate PLM predictions, future models will integrate genomic and proteomic language models into unified frameworks (Chapter 13, Chapter 16). The central dogma of molecular biology—DNA → RNA → protein—suggests that models capturing all three modalities may achieve the deepest understanding of how genomes encode life.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-brandes_genome-wide_2023" class="csl-entry" role="listitem">
Brandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. <span>“Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.”</span> <em>Nature Genetics</em> 55 (9): 1512–22. <a href="https://doi.org/10.1038/s41588-023-01465-0">https://doi.org/10.1038/s41588-023-01465-0</a>.
</div>
<div id="ref-cheng_alphamissense_2023" class="csl-entry" role="listitem">
Cheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. <span>“[<span>AlphaMissense</span>] <span>Accurate</span> Proteome-Wide Missense Variant Effect Prediction with <span>AlphaMissense</span>.”</span> <em>Science</em> 381 (6664): eadg7492. <a href="https://doi.org/10.1126/science.adg7492">https://doi.org/10.1126/science.adg7492</a>.
</div>
<div id="ref-lin_esm-2_2022" class="csl-entry" role="listitem">
Lin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, et al. 2022. <span>“[<span>ESM</span>-2] <span>Language</span> Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction.”</span> bioRxiv. <a href="https://doi.org/10.1101/2022.07.20.500902">https://doi.org/10.1101/2022.07.20.500902</a>.
</div>
<div id="ref-notin_proteingym_2023" class="csl-entry" role="listitem">
Notin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. <span>“<span>ProteinGym</span>: <span>Large</span>-<span>Scale</span> <span>Benchmarks</span> for <span>Protein</span> <span>Fitness</span> <span>Prediction</span> and <span>Design</span>.”</span> <em>Advances in Neural Information Processing Systems</em> 36 (December): 64331–79. <a href="https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html">https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html</a>.
</div>
<div id="ref-rives_esm_2021" class="csl-entry" role="listitem">
Rives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. <span>“[<span>ESM</span>-1b] <span>Biological</span> Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.”</span> <em>Proceedings of the National Academy of Sciences of the United States of America</em> 118 (15): e2016239118. <a href="https://doi.org/10.1073/pnas.2016239118">https://doi.org/10.1073/pnas.2016239118</a>.
</div>
<div id="ref-schubach_cadd_2024" class="csl-entry" role="listitem">
Schubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. <span>“<span>CADD</span> V1.7: Using Protein Language Models, Regulatory <span>CNNs</span> and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.”</span> <em>Nucleic Acids Research</em> 52 (D1): D1143–54. <a href="https://doi.org/10.1093/nar/gkad989">https://doi.org/10.1093/nar/gkad989</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch-p3-tokens.html" class="pagination-link" aria-label="Sequence Representation &amp; Tokens">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ch-p3-glm.html" class="pagination-link" aria-label="DNA Foundation Models">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">DNA Foundation Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>