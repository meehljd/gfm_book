<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>22&nbsp; Interpretability &amp; Mechanisms – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./p6--translation.html" rel="next">
<link href="./p5-ch21-confound.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-d1e9b63c6b6094879b9f94a7628e3370.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p5--eval-interp.html">Part V: Evaluation and Reliability</a></li><li class="breadcrumb-item"><a href="./p5-ch22-interp.html"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sequencing: From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Genomic Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch03-pgs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS &amp; Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch04-cadd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deleteriousness Scores</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p2--principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Core Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch05-tokens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch06-transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Transformer Architecture for Genomics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch07-foundation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Genomic Foundation Models: Concepts &amp; Taxonomy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch08-pretrain.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Objectives &amp; Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning &amp; Deployment</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p3--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Deep Learning Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch10-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">CNN Sequence-to-Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch11-dna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">DNA and Genomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch12-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RNA &amp; Transcript-Level Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch13-plm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch14-hybrid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">p4–multi-modal_multi-scale.qmd</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch15-sc-epi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Single-Cell &amp; Epigenomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch16-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Graphs, Networks, and Biology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch17-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Multi-Omics &amp; Systems Biology</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p5--eval-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Evaluation and Reliability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch18-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Benchmarks for Genomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch19-eval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Evaluation of Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch20-vep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch21-confound.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch22-interp.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p6--translation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI — Translation and Application</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch23-clinical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch24-variants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Pathogenic Variant Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch25-drugs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Drug Discovery &amp; Biotech</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch26-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Sequence Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch27-future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Future Work &amp; Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-b-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Model Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-c-model-list.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Referenced Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-d-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Additional Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-e-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#why-interpretability-matters-for-genomic-models" id="toc-why-interpretability-matters-for-genomic-models" class="nav-link active" data-scroll-target="#why-interpretability-matters-for-genomic-models"><span class="header-section-number">22.1</span> Why Interpretability Matters for Genomic Models</a></li>
  <li><a href="#interpreting-convolutional-filters-as-motifs" id="toc-interpreting-convolutional-filters-as-motifs" class="nav-link" data-scroll-target="#interpreting-convolutional-filters-as-motifs"><span class="header-section-number">22.2</span> Interpreting Convolutional Filters as Motifs</a>
  <ul class="collapse">
  <li><a href="#from-filters-to-motif-logos" id="toc-from-filters-to-motif-logos" class="nav-link" data-scroll-target="#from-filters-to-motif-logos"><span class="header-section-number">22.2.1</span> From Filters to Motif Logos</a></li>
  <li><a href="#beyond-first-layer-filters" id="toc-beyond-first-layer-filters" class="nav-link" data-scroll-target="#beyond-first-layer-filters"><span class="header-section-number">22.2.2</span> Beyond First-Layer Filters</a></li>
  </ul></li>
  <li><a href="#attribution-methods-connecting-bases-to-predictions" id="toc-attribution-methods-connecting-bases-to-predictions" class="nav-link" data-scroll-target="#attribution-methods-connecting-bases-to-predictions"><span class="header-section-number">22.3</span> Attribution Methods: Connecting Bases to Predictions</a>
  <ul class="collapse">
  <li><a href="#in-silico-mutagenesis" id="toc-in-silico-mutagenesis" class="nav-link" data-scroll-target="#in-silico-mutagenesis"><span class="header-section-number">22.3.1</span> In Silico Mutagenesis</a></li>
  <li><a href="#gradient-based-methods" id="toc-gradient-based-methods" class="nav-link" data-scroll-target="#gradient-based-methods"><span class="header-section-number">22.3.2</span> Gradient-Based Methods</a></li>
  </ul></li>
  <li><a href="#from-attributions-to-motifs-tf-modisco" id="toc-from-attributions-to-motifs-tf-modisco" class="nav-link" data-scroll-target="#from-attributions-to-motifs-tf-modisco"><span class="header-section-number">22.4</span> From Attributions to Motifs: TF-MoDISco</a></li>
  <li><a href="#interpreting-attention-and-long-range-context" id="toc-interpreting-attention-and-long-range-context" class="nav-link" data-scroll-target="#interpreting-attention-and-long-range-context"><span class="header-section-number">22.5</span> Interpreting Attention and Long-Range Context</a>
  <ul class="collapse">
  <li><a href="#attention-in-genomic-language-models" id="toc-attention-in-genomic-language-models" class="nav-link" data-scroll-target="#attention-in-genomic-language-models"><span class="header-section-number">22.5.1</span> Attention in Genomic Language Models</a></li>
  <li><a href="#distal-regulatory-elements-in-enformer-like-models" id="toc-distal-regulatory-elements-in-enformer-like-models" class="nav-link" data-scroll-target="#distal-regulatory-elements-in-enformer-like-models"><span class="header-section-number">22.5.2</span> Distal Regulatory Elements in Enformer-Like Models</a></li>
  </ul></li>
  <li><a href="#global-regulatory-vocabularies-sei-sequence-classes" id="toc-global-regulatory-vocabularies-sei-sequence-classes" class="nav-link" data-scroll-target="#global-regulatory-vocabularies-sei-sequence-classes"><span class="header-section-number">22.6</span> Global Regulatory Vocabularies: Sei Sequence Classes</a></li>
  <li><a href="#a-case-study-from-base-pair-attributions-to-regulatory-grammar" id="toc-a-case-study-from-base-pair-attributions-to-regulatory-grammar" class="nav-link" data-scroll-target="#a-case-study-from-base-pair-attributions-to-regulatory-grammar"><span class="header-section-number">22.7</span> A Case Study: From Base-Pair Attributions to Regulatory Grammar</a></li>
  <li><a href="#evaluating-interpretations-faithfulness-versus-plausibility" id="toc-evaluating-interpretations-faithfulness-versus-plausibility" class="nav-link" data-scroll-target="#evaluating-interpretations-faithfulness-versus-plausibility"><span class="header-section-number">22.8</span> Evaluating Interpretations: Faithfulness versus Plausibility</a></li>
  <li><a href="#a-practical-interpretability-toolbox" id="toc-a-practical-interpretability-toolbox" class="nav-link" data-scroll-target="#a-practical-interpretability-toolbox"><span class="header-section-number">22.9</span> A Practical Interpretability Toolbox</a></li>
  <li><a href="#outlook-from-explanations-to-mechanistic-models" id="toc-outlook-from-explanations-to-mechanistic-models" class="nav-link" data-scroll-target="#outlook-from-explanations-to-mechanistic-models"><span class="header-section-number">22.10</span> Outlook: From Explanations to Mechanistic Models</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p5--eval-interp.html">Part V: Evaluation and Reliability</a></li><li class="breadcrumb-item"><a href="./p5-ch22-interp.html"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-interp" class="quarto-section-identifier"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="why-interpretability-matters-for-genomic-models" class="level2" data-number="22.1">
<h2 data-number="22.1" class="anchored" data-anchor-id="why-interpretability-matters-for-genomic-models"><span class="header-section-number">22.1</span> Why Interpretability Matters for Genomic Models</h2>
<p>Deep learning models in genomics increasingly operate as systems-level surrogates for biology. They predict chromatin features, gene expression, and variant effects directly from sequence, achieving accuracy that would have seemed implausible a decade ago. When such models drive mechanistic hypotheses or inform clinical decisions, understanding how they make predictions becomes as important as understanding how well they perform.</p>
<p>Interpretability in this context serves several distinct but interconnected roles. The most scientifically compelling is mechanistic insight: extracting sequence motifs, regulatory grammars, and long-range interaction patterns directly from trained models. A well-designed interpretability analysis can turn a black-box predictor into a source of candidate mechanisms that can be tested experimentally. When a model trained to predict chromatin accessibility learns filters that match known transcription factor binding motifs, this validates that the model has discovered biologically meaningful patterns. When the same analysis reveals novel motif variants or unexpected spacing constraints, it generates hypotheses that extend beyond what was known before training.</p>
<p>Interpretability also serves as a tool for model debugging and confounder detection. Deep networks can achieve high benchmark accuracy by learning spurious correlations rather than genuine regulatory signals. A model might learn that certain k-mers correlate with peak calls because of batch effects in the training data, or that GC content predicts chromatin accessibility because GC-rich regions tend to be more mappable and thus better covered by sequencing. Interpretability methods can reveal such shortcuts by showing what features the model actually relies upon. This diagnostic function complements the data-level confounder analyses discussed in <a href="p5-ch21-confound.html" class="quarto-xref"><span>Chapter 21</span></a> by interrogating model internals directly.</p>
<p>In clinical and translational settings, interpretability supports variant interpretation workflows by explaining why specific rare or de novo variants are predicted to be damaging. A pathogenicity score alone may be insufficient for clinical decision-making; knowing that a variant disrupts a specific transcription factor binding motif in a disease-relevant enhancer provides interpretable evidence that can be combined with family history, functional assays, and literature review. These adoption barriers extend beyond clinical genomics. A systematic review of machine learning in agricultural genomics found that despite promising benchmark performance, interpretability concerns remain a primary obstacle to real-world deployment in livestock breeding programs, where traditional statistical methods continue to dominate despite their theoretical limitations <span class="citation" data-cites="chafai_review_2023">(<a href="references.html#ref-chafai_review_2023" role="doc-biblioref">Chafai et al. 2023</a>)</span>.</p>
<p>Finally, interpretability enables scientific communication by condensing high-dimensional latent representations into human-readable abstractions. Motifs, regulatory sequence classes, and interaction graphs can be shared across laboratories and applications in ways that raw model weights cannot. A published motif vocabulary derived from a foundation model becomes a reusable resource for the community, even if the original model is computationally expensive to run or subject to access restrictions.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Four pillars of interpretability</strong></p>
<p>A conceptual figure showing four pillars of interpretability for genomics: (1) Mechanistic insight (illustrated with motif discovery), (2) Debugging and confound detection (showing artifact identification), (3) Reliability and clinical translation (variant prioritization workflow), and (4) Scientific communication (motif vocabulary and grammar diagrams). Each pillar could include a small vignette demonstrating its application.</p>
</div>
</div>
</section>
<section id="interpreting-convolutional-filters-as-motifs" class="level2" data-number="22.2">
<h2 data-number="22.2" class="anchored" data-anchor-id="interpreting-convolutional-filters-as-motifs"><span class="header-section-number">22.2</span> Interpreting Convolutional Filters as Motifs</h2>
<p>Convolutional neural networks remain a workhorse for modeling cis-regulatory sequence, as described in earlier chapters. In many of these models, first-layer convolutional filters act as motif detectors. A filter slides along the one-hot encoded sequence, computing a dot product between its learned weights and the local sequence window at each position. High activation indicates that the subsequence closely matches the filter’s preferred pattern.</p>
<section id="from-filters-to-motif-logos" class="level3" data-number="22.2.1">
<h3 data-number="22.2.1" class="anchored" data-anchor-id="from-filters-to-motif-logos"><span class="header-section-number">22.2.1</span> From Filters to Motif Logos</h3>
<p>Converting learned filters into interpretable motifs follows a standard workflow. The trained model is run on a large sequence set, typically the training data or genome-wide tiles, and for each filter the positions where its activation exceeds a threshold are recorded. The fixed-length windows around these high-activation positions are then extracted and aligned, and base frequencies at each position are computed to build a position weight matrix. This PWM can be visualized as a sequence logo, where letter heights reflect information content, and compared to known motif databases like JASPAR or HOCOMOCO using similarity scores. Filters that produce PWMs resembling characterized transcription factors can be annotated with candidate TF identities.</p>
<p>This procedure has been applied extensively to models like DeepSEA and its successors, demonstrating that early convolutional layers learn motifs for canonical transcription factors and chromatin-associated patterns. Such validation confirms that models are discovering biologically meaningful sequence features rather than arbitrary patterns that happen to correlate with training labels.</p>
<p>Several practical considerations affect filter interpretation. DNA is double-stranded, and filters may learn forward and reverse-complement versions of the same motif. Architectures and analysis pipelines should account for this RC symmetry. Some filters capture technical artifacts such as homopolymer runs or general sequence composition like GC-rich regions. These can be biologically meaningful in contexts such as nucleosome positioning, or purely artifactual. Interpretability must distinguish between them.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Filter-to-motif workflow</strong></p>
<p>A multi-panel figure showing: (1) A convolutional filter as a small weight matrix, (2) Its activation track along a sequence, (3) Extracted high-activation hits aligned into a PWM, (4) A resulting motif logo aligned against a canonical TF motif from JASPAR. This visualization demonstrates the complete pipeline from learned weights to biological annotation.</p>
</div>
</div>
</section>
<section id="beyond-first-layer-filters" class="level3" data-number="22.2.2">
<h3 data-number="22.2.2" class="anchored" data-anchor-id="beyond-first-layer-filters"><span class="header-section-number">22.2.2</span> Beyond First-Layer Filters</h3>
<p>Deeper convolutional layers aggregate lower-level motifs into more complex representations. These layers can encode combinatorial motifs that respond to pairs or clusters of transcription factor binding sites, grammar patterns involving distance or orientation constraints, and contextual preferences that depend on surrounding sequence composition. However, directly interpreting deeper layers becomes increasingly difficult because receptive fields expand and nonlinearities accumulate. The activation of a deep-layer filter depends on intricate combinations of early-layer patterns, making it hard to summarize what the filter means in simple biological terms.</p>
<p>In practice, deeper filters are often interpreted indirectly by examining attribution maps for specific sequences, clustering high-importance subsequences discovered by attribution methods, or analyzing in silico perturbation experiments that probe combinatorial effects of motifs. This motivates the attribution-based approaches described in the next section.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Deeper filter grammar</strong></p>
<p>A small panel showing: (1) A first-layer motif logo, (2) A deeper-layer grammar filter that responds to pairs of motifs with fixed spacing, (3) A cartoon of how these patterns map to regulatory architecture such as TF cooperativity at enhancers. This could be reused in case study sections to illustrate compositional learning.</p>
</div>
</div>
</section>
</section>
<section id="attribution-methods-connecting-bases-to-predictions" class="level2" data-number="22.3">
<h2 data-number="22.3" class="anchored" data-anchor-id="attribution-methods-connecting-bases-to-predictions"><span class="header-section-number">22.3</span> Attribution Methods: Connecting Bases to Predictions</h2>
<p>Attribution methods assign an importance score to each input base, reflecting how much that position contributes to a prediction for a specific task and sequence. If a model <span class="math inline">\(f(x)\)</span> predicts some output from sequence <span class="math inline">\(x\)</span>, attribution methods estimate the contribution of each base <span class="math inline">\(x_i\)</span> to <span class="math inline">\(f(x)\)</span>, typically for a specific output neuron such as chromatin accessibility in a particular cell type. The resulting attribution maps can reveal which sequence positions drive a prediction, highlighting candidate motifs and regulatory elements.</p>
<section id="in-silico-mutagenesis" class="level3" data-number="22.3.1">
<h3 data-number="22.3.1" class="anchored" data-anchor-id="in-silico-mutagenesis"><span class="header-section-number">22.3.1</span> In Silico Mutagenesis</h3>
<p>In silico mutagenesis (ISM) is conceptually the most straightforward attribution method and works with any model, regardless of architecture. For each position <span class="math inline">\(i\)</span> and alternative base <span class="math inline">\(b\)</span>, ISM creates a mutated sequence <span class="math inline">\(x^{(i \rightarrow b)}\)</span> and computes the change in prediction: <span class="math inline">\(\Delta f_{i,b} = f(x^{(i \rightarrow b)}) - f(x)\)</span>. These changes can be aggregated across non-reference alleles to obtain a per-base importance score, typically by taking the maximum or mean absolute change.</p>
<p>ISM provides true counterfactual information about how the model responds to sequence perturbations. Unlike gradient-based methods that estimate local sensitivity, ISM directly measures what happens when a base is changed. This makes ISM the gold standard for faithfulness: if ISM shows that mutating a position changes the prediction, that is a direct observation rather than an approximation.</p>
<p>The primary limitation of ISM is computational cost. Scoring all possible single-nucleotide substitutions requires <span class="math inline">\(L \times 3\)</span> forward passes for a sequence of length <span class="math inline">\(L\)</span>, which becomes expensive for long sequences or large models. Variants of ISM can reduce this cost by focusing on specific regions of interest or by using saturation mutagenesis only in targeted windows. For variant effect prediction specifically, ISM reduces to computing the difference between reference and alternative allele predictions, which requires only two forward passes per variant.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Code suggestion: Minimal ISM implementation</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pseudocode: in silico mutagenesis for a single sequence and output</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>ref_pred <span class="op">=</span> model(seq)[task_idx]</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>ism_scores <span class="op">=</span> np.zeros_like(seq_onehot)  <span class="co"># shape: L × 4</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(L):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> b <span class="op">==</span> np.argmax(seq_onehot[i]):  <span class="co"># skip original base</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        seq_mut <span class="op">=</span> seq_onehot.copy()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        seq_mut[i, :] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        seq_mut[i, b] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        pred_mut <span class="op">=</span> model(seq_mut)[task_idx]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        ism_scores[i, b] <span class="op">=</span> pred_mut <span class="op">-</span> ref_pred</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This snippet demonstrates the core ISM loop and can be adapted to any framework.</p>
</div>
</div>
</section>
<section id="gradient-based-methods" class="level3" data-number="22.3.2">
<h3 data-number="22.3.2" class="anchored" data-anchor-id="gradient-based-methods"><span class="header-section-number">22.3.2</span> Gradient-Based Methods</h3>
<p>Gradient-based methods approximate how much the prediction would change if each input base were perturbed, using backpropagation rather than explicit perturbation. The simplest approach computes the gradient of the output with respect to the input: <span class="math inline">\(s_i = \partial f(x) / \partial x_i\)</span>. With one-hot encoding, this gradient can be interpreted as the sensitivity to changing the nucleotide at position <span class="math inline">\(i\)</span>. A common variant multiplies the gradient by the input to focus on positions where the current nucleotide (rather than hypothetical alternatives) is important.</p>
<p>Vanilla gradients require only a single backward pass per sequence, making them computationally efficient. However, they are susceptible to gradient saturation, where gradients vanish in regions where the model is already confident. Saturated regions may be functionally important but show near-zero gradients because small perturbations do not change the prediction.</p>
<p>DeepLIFT (Deep Learning Important FeaTures) addresses saturation by comparing neuron activations between an input and a reference sequence, distributing differences back to inputs using layer-wise rules rather than raw gradients. This approach avoids gradient saturation and enforces a consistency constraint: the sum of input contributions matches the difference in output between input and reference. DeepLIFT has been widely used for genomic models, particularly in conjunction with TF-MoDISco, where its base-level importance scores serve as inputs for motif discovery.</p>
<p>Integrated gradients (IG) compute the path integral of gradients along a linear interpolation from a reference sequence <span class="math inline">\(x'\)</span> to the input <span class="math inline">\(x\)</span>: <span class="math display">\[\text{IG}_i(x) = (x_i - x'_i) \int_{\alpha=0}^1 \frac{\partial f\left(x' + \alpha(x - x')\right)}{\partial x_i} d\alpha.\]</span> This integral is approximated via a Riemann sum over discrete interpolation steps. Integrated gradients satisfy desirable theoretical properties including sensitivity (if changing an input changes the output, that input receives nonzero attribution) and implementation invariance (functionally equivalent networks produce identical attributions). In practice, IG tends to be less noisy than raw gradients.</p>
<p>All gradient-based methods require choosing a reference sequence, which significantly affects the resulting attributions. Common choices include random genomic sequence, dinucleotide-shuffled versions of the input that preserve local composition, or an average non-functional sequence. Different references emphasize different aspects of the signal. A shuffled reference highlights features that differ from random sequence with matched composition, while a zero reference treats any informative position as important.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Attribution method comparison</strong></p>
<p>A multi-panel figure and accompanying table showing: (A) A sequence with a known CTCF motif and its ground-truth binding track, (B) Base-level ISM scores, (C) Gradient × input scores, (D) Integrated gradients scores. The table compares methods across dimensions: computational cost, reference dependency, sensitivity to saturation, robustness to noise, and typical use cases. This provides practitioners with guidance on method selection.</p>
</div>
</div>
</section>
</section>
<section id="from-attributions-to-motifs-tf-modisco" class="level2" data-number="22.4">
<h2 data-number="22.4" class="anchored" data-anchor-id="from-attributions-to-motifs-tf-modisco"><span class="header-section-number">22.4</span> From Attributions to Motifs: TF-MoDISco</h2>
<p>Attribution maps highlight where the model focuses, but they do not automatically yield consistent motifs or regulatory grammars. A DeepLIFT attribution track might show high importance at scattered positions throughout a sequence without revealing that those positions collectively form instances of the same transcription factor binding site. TF-MoDISco (Transcription Factor Motif Discovery from Importance Scores) was developed to bridge this gap by discovering motifs from attribution scores rather than from raw sequences.</p>
<p>The core insight of TF-MoDISco is that operating on importance-weighted sequences rather than raw sequences focuses motif discovery on positions the model actually uses. Traditional motif discovery algorithms applied to regulatory sequences must contend with the fact that most positions are not part of functional motifs. By extracting seqlets (short windows where total importance exceeds a threshold) and clustering them based on both sequence and importance profiles, TF-MoDISco identifies the specific patterns that drive model predictions.</p>
<p>The workflow begins by computing importance scores for many sequences using DeepLIFT, ISM, or integrated gradients. Local windows where total importance exceeds a threshold are extracted as seqlets, each representing a candidate motif instance. These seqlets are then compared using similarity metrics that consider both sequence content and the importance score profile, and clustered into groups corresponding to putative motifs. Within each cluster, seqlets are aligned and consolidated into position weight matrices and importance-weighted logos. The resulting motifs can be matched to known transcription factor binding sites or flagged as novel patterns.</p>
<p>Beyond individual motifs, TF-MoDISco enables grammar inference by analyzing how motifs co-occur within sequences. Mapping motif instances back onto the genome reveals patterns of co-occurrence, characteristic spacing between motif pairs, and orientation preferences. These grammatical rules can be validated through in silico experiments: inserting or removing motifs in synthetic sequences and observing whether predictions change as expected.</p>
<p>When applied to models like BPNet trained on ChIP-seq data, TF-MoDISco has recovered known transcription factor motifs, discovered novel sequence variants, and revealed grammars such as directional spacing constraints that have been validated with synthetic reporter assays. In the context of genomic foundation models, an analogous workflow applies: use the model to produce base-level attributions for a downstream task, run TF-MoDISco to extract a task-specific motif vocabulary, and analyze how motif usage varies across cell types, conditions, or species.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: TF-MoDISco pipeline</strong></p>
<p>A schematic showing the following stages: (1) Base-level attribution map for a sequence, (2) Highlighted high-importance windows (seqlets), (3) Clustering of seqlets into motif families, (4) Motif logos representing each cluster, (5) A simple grammar diagram showing motif A followed by motif B with preferred spacing. This can be referenced in motif discovery sections elsewhere in the book.</p>
</div>
</div>
</section>
<section id="interpreting-attention-and-long-range-context" class="level2" data-number="22.5">
<h2 data-number="22.5" class="anchored" data-anchor-id="interpreting-attention-and-long-range-context"><span class="header-section-number">22.5</span> Interpreting Attention and Long-Range Context</h2>
<p>Transformer-based models use self-attention to mix information across long genomic contexts, enabling them to capture distal regulatory interactions and genomic organization that are invisible to models with narrow receptive fields. Interpretability for these models often centers on attention patterns and long-range attribution, asking which distant positions influence predictions at a given location.</p>
<section id="attention-in-genomic-language-models" class="level3" data-number="22.5.1">
<h3 data-number="22.5.1" class="anchored" data-anchor-id="attention-in-genomic-language-models"><span class="header-section-number">22.5.1</span> Attention in Genomic Language Models</h3>
<p>Genomic language models (gLMs) trained on prokaryotic genomes treat genes or genomic tokens as elements of a sequence and learn to predict masked tokens, analogous to protein or text language models. Work on gLMs trained on millions of metagenomic scaffolds has shown that these models learn non-trivial genomic structure that can be read out from attention patterns.</p>
<p>Certain attention heads specialize in connecting genes that are part of the same operon or functional module. When attention weights are visualized as edges between gene positions, they reveal networks of co-regulated genes that often align with known operon boundaries. Other heads capture functional semantics, with attention patterns that cluster genes by enzymatic function or gene ontology category. Still others encode taxonomic signals, separating clades and capturing clade-specific gene neighborhood patterns.</p>
<p>These findings suggest that the model has inferred a syntax of gene neighborhoods: which genes tend to co-occur, in what order, and conditioned on phylogenetic context. While attention weights are not universally faithful explanations of model decisions (high attention need not correspond to large causal influence on predictions), attention analysis in genomic language models reveals emergent mechanistic structure that is consistent with known biological organization.</p>
<p>A critical methodological note: raw attention weights should be interpreted with caution. Work on transformer interpretability in other domains <span class="citation" data-cites="consens_transformers_2023">(<a href="references.html#ref-consens_transformers_2023" role="doc-biblioref">Consens et al. 2023</a>)</span> has articulated why raw attention maps are not inherently interpretable. Issues include layer mixing effects, value vectors being ignored, and head averaging problems. More robust alternatives include attention rollout (which propagates attention across layers), attention flow (tracking information movement), layer-wise relevance propagation, and SHAP-based methods. For genomic applications, combining attention visualization with attribution methods or perturbation experiments provides more reliable mechanistic insights.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Attention head patterns</strong></p>
<p>A figure consisting of: (1) A genomic sequence with annotated features such as promoter, enhancer, or operon structure, (2) One or two attention maps for individual heads showing strong, structured connectivity between regulatory elements, (3) A small inset summarizing head specialization statistics (fraction of attention mass connecting enhancer to promoter). This can be cross-referenced in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a> when discussing multi-omic integration and regulatory networks.</p>
</div>
</div>
</section>
<section id="distal-regulatory-elements-in-enformer-like-models" class="level3" data-number="22.5.2">
<h3 data-number="22.5.2" class="anchored" data-anchor-id="distal-regulatory-elements-in-enformer-like-models"><span class="header-section-number">22.5.2</span> Distal Regulatory Elements in Enformer-Like Models</h3>
<p>Enformer and related architectures <span class="citation" data-cites="avsec_enformer_2021 cheng_dnalongbench_2024">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Avsec et al. 2021</a>; <a href="references.html#ref-cheng_dnalongbench_2024" role="doc-biblioref">Cheng et al. 2024</a>)</span> use convolutional layers and attention to aggregate information over long genomic regions (such as 200 kb windows) and predict many regulatory outputs. Long-range interpretability focuses on questions such as: Which distal regions contribute most to a gene’s predicted expression? Are known enhancers, super-enhancers, or CTCF-mediated loops reflected in contribution scores? How robust are these patterns across cell types and tasks?</p>
<p>Practical tools include contribution tracks that aggregate base-level or region-level attributions across the input window and visualize them as tracks aligned to genomic coordinates. Peaks in contribution tracks often correspond to putative enhancers or insulators that drive predictions. Region-level perturbations perform in silico deletions of candidate enhancers or CTCF sites and measure the effect on target gene predictions, validating whether long-range connections are actually used by the model. Integration with experimental data compares model-derived contribution tracks to Hi-C, ChIP-seq, and reporter assay data. Concordance suggests that the model’s internal representation aligns with known regulatory architecture; discordance can point to either model failure or previously unannotated elements.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Long-range contributions</strong></p>
<p>A multi-track genome browser-style figure showing: (1) Input sequence with gene and regulatory annotations, (2) Experimental tracks such as ATAC-seq and ChIP-seq, (3) Model prediction track for a target gene, (4) A contribution track highlighting distal regions whose deletion strongly alters the prediction. This figure can be cross-referenced in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a> as an example of how single-sequence interpretability interfaces with 3D regulatory models.</p>
</div>
</div>
</section>
</section>
<section id="global-regulatory-vocabularies-sei-sequence-classes" class="level2" data-number="22.6">
<h2 data-number="22.6" class="anchored" data-anchor-id="global-regulatory-vocabularies-sei-sequence-classes"><span class="header-section-number">22.6</span> Global Regulatory Vocabularies: Sei Sequence Classes</h2>
<p>Most motif-based interpretation operates at the local level, asking which motifs appear in a particular sequence and how they contribute to a specific prediction. Sei takes a complementary global approach by learning a vocabulary of regulatory sequence classes that summarize the vast diversity of chromatin profiles across the genome.</p>
<p>Sei trains a deep sequence model to predict tens of thousands of chromatin profiles covering transcription factor binding, histone modifications, and chromatin accessibility across many cell types. The key interpretability step is to compress these thousands of outputs into a few dozen sequence classes, each representing a characteristic regulatory activity pattern.</p>
<p>Sequence classes are derived by clustering genome-wide predictions. For each of millions of genomic positions, Sei computes predicted chromatin profiles and projects them into a lower-dimensional space using principal component analysis. These projections are then clustered to identify recurrent patterns of regulatory activity. The resulting classes include promoter-like patterns enriched for H3K4me3 and TSS proximity, enhancer-like patterns with H3K27ac and H3K4me1, repressive patterns dominated by H3K27me3 or H3K9me3, and cell-type-specific modules corresponding to neuronal, immune, or other lineage-specific regulatory programs.</p>
<p>Each input sequence or variant can be scored against all sequence classes, effectively mapping it to a point in a low-dimensional regulatory activity space. This representation has several interpretability advantages. Instead of reasoning about thousands of raw chromatin predictions, one can describe a sequence in terms of human-interpretable categories. Variants can be summarized by their shifts in sequence-class scores, yielding concise functional descriptions. GWAS loci can be enriched for specific sequence classes, revealing which tissues and regulatory programs are most relevant to a disease.</p>
<p>This notion of a regulatory vocabulary parallels word embeddings or topic models in natural language processing. It provides a bridge between highly multivariate model outputs and mechanistically interpretable axes of variation that can be communicated across studies and applications.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Sequence-class embedding</strong></p>
<p>A figure showing: (1) A UMAP or t-SNE of sequence features or loci colored by regulatory class (promoter, enhancer, insulator, repressed), (2) Example genomic loci annotated with their class assignments, (3) Example variants mapped as arrows showing movement between classes (such as enhancer to promoter-like). This can be cross-linked to variant interpretation chapters and to <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a> to emphasize multi-scale regulatory modeling.</p>
</div>
</div>
</section>
<section id="a-case-study-from-base-pair-attributions-to-regulatory-grammar" class="level2" data-number="22.7">
<h2 data-number="22.7" class="anchored" data-anchor-id="a-case-study-from-base-pair-attributions-to-regulatory-grammar"><span class="header-section-number">22.7</span> A Case Study: From Base-Pair Attributions to Regulatory Grammar</h2>
<p>Putting the pieces together, a typical mechanistic interpretability pipeline for a CNN or transformer-based regulatory model proceeds through several connected stages.</p>
<p>The starting point is a trained predictive model, for example one that predicts chromatin accessibility or transcription factor ChIP-seq tracks from sequence. For sequences where the model makes confident predictions in a target cell type, base-level attributions are computed using DeepLIFT or integrated gradients. These attributions are fed into TF-MoDISco, which extracts seqlets from high-attribution regions, clusters them, and derives motifs. The resulting motifs are matched to known transcription factors where possible, and novel motifs are flagged for further investigation.</p>
<p>Grammar inference follows from analyzing motif instances across the full set of high-confidence predictions. Motif co-occurrence patterns reveal which factors tend to operate together. Spacing distributions between motif pairs identify characteristic distances that may reflect cooperative binding or nucleosome constraints. Orientation analysis determines whether certain motif pairs require specific relative orientations to function. In silico knock-in and knock-out experiments confirm these grammatical dependencies: if the model predicts that two motifs must co-occur for high accessibility, deleting either motif from a sequence should reduce the prediction, while inserting both into a neutral background should increase it.</p>
<p>The local motif grammar can then be connected to global regulatory context. Motif-rich regions can be mapped to Sei sequence classes to understand what broader regulatory programs they participate in. For transformer-based models, attention patterns or long-range attributions can link local motif clusters to distal elements, revealing enhancer-promoter architectures or chromatin domain boundaries.</p>
<p>Validation closes the loop by connecting model-derived hypotheses to external evidence. Do motif disruptions align with reporter assay effects or allelic imbalance measured in functional genomics experiments? Do inferred enhancer-promoter links correspond to contacts observed in Hi-C or to effects measured in CRISPR perturbation screens? This integrated approach moves beyond descriptive saliency maps toward testable hypotheses about regulatory logic.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: End-to-end case study</strong></p>
<p>A multi-panel figure that: (1) Shows an input sequence and predicted TF binding profile, (2) Displays base-level attribution scores, (3) Summarizes discovered motifs as logos, (4) Depicts an inferred regulatory grammar (motif combinations with spacing), (5) Presents a schematic of experimental validation such as mutated motif in a reporter assay. This figure can be referenced whenever the book discusses mechanistic discovery from models, including in later translation chapters.</p>
</div>
</div>
</section>
<section id="evaluating-interpretations-faithfulness-versus-plausibility" class="level2" data-number="22.8">
<h2 data-number="22.8" class="anchored" data-anchor-id="evaluating-interpretations-faithfulness-versus-plausibility"><span class="header-section-number">22.8</span> Evaluating Interpretations: Faithfulness versus Plausibility</h2>
<p>Not all explanations are equally trustworthy. Effective interpretability work must grapple with the distinction between plausibility (does the explanation look biological?) and faithfulness (does the explanation accurately reflect the internal computation of the model?).</p>
<p>An explanation is plausible if it matches prior biological knowledge. Discovering a motif that resembles CTCF is plausible because CTCF is a well-characterized chromatin organizer. Plausibility provides reassuring sanity checks but does not guarantee that the model actually uses the plausible feature. An explanation is faithful if perturbing the identified features changes the model’s output as predicted. If removing a putative CTCF site from a sequence causes the model’s chromatin accessibility prediction to drop, the explanation has some degree of faithfulness.</p>
<p>Several pitfalls complicate the relationship between plausibility and faithfulness:</p>
<ul>
<li><p>Attention weights in transformer models need not correspond to large changes in output. High attention may reflect information routing rather than causal influence on predictions. A model might attend strongly to certain positions for bookkeeping purposes without those positions driving the final output.</p></li>
<li><p>Gradient-based attribution methods can produce noisy maps or miss important features in saturated regions where gradients are near zero. Comparing multiple methods (ISM, DeepLIFT, integrated gradients) and checking for consistency helps identify robust signals.</p></li>
<li><p>Models may learn shortcut features that produce clean, plausible-looking motifs but are not mechanistically meaningful. A model might learn that certain k-mers correlate with peak calls because of barcode sequences in the training data, or that GC content predicts accessibility because of mappability biases.</p></li>
</ul>
<p>Recommended practices for validating interpretations include sanity checks where model weights are randomized (attributions should degrade to noise) or training labels are scrambled (derived motifs should disappear or lose predictive power). Counterfactual tests delete or scramble high-attribution regions to confirm that predictions drop accordingly, or insert discovered motifs into neutral backgrounds to test gain-of-function effects. Benchmarking on synthetic datasets with known ground-truth grammar provides controlled settings where the ability of interpretability methods to recover planted motifs and interactions can be quantified.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Visual suggestion: Faithfulness versus plausibility</strong></p>
<p>A simple illustration with: (Left) An attribution map that looks biologically plausible (highlighting a canonical motif) but fails deletion tests (removing highlighted bases barely changes predictions). (Right) An attribution map that passes deletion tests (removing highlighted bases strongly changes predictions), possibly uncovering a less obvious secondary motif. Label the two panels as “plausible but unfaithful” and “faithful explanation” to reinforce the distinction.</p>
</div>
</div>
</section>
<section id="a-practical-interpretability-toolbox" class="level2" data-number="22.9">
<h2 data-number="22.9" class="anchored" data-anchor-id="a-practical-interpretability-toolbox"><span class="header-section-number">22.9</span> A Practical Interpretability Toolbox</h2>
<p>For practitioners working with genomic foundation models and their fine-tuned derivatives, several interpretability strategies form a practical toolbox.</p>
<p><strong>Local effect estimation</strong> focuses on individual variants or short sequence windows. For variant effect prediction, comparing reference and alternative allele scores provides direct effect estimates, while small-window ISM around variants reveals which nearby positions modulate the effect. Per-base attributions can be aggregated into per-variant or per-motif scores for summary statistics.</p>
<p><strong>Motif and grammar discovery</strong> begins with computing base-level attributions for sequences where the model makes high-confidence predictions. Running TF-MoDISco or similar algorithms builds a motif vocabulary that can be compared across tasks, cell types, or training conditions. Grammar analysis examines motif co-occurrence, spacing, and orientation to infer combinatorial rules.</p>
<p><strong>Global context visualization</strong> applies to transformer-based models, where attention patterns can reveal which distant positions the model considers when making predictions at a given location. For hybrid architectures like Enformer, combining long-range attributions with contact maps helps hypothesize regulatory architectures that span tens to hundreds of kilobases.</p>
<p><strong>Regulatory vocabularies and embeddings</strong> use frameworks like Sei to project sequences into interpretable regulatory activity spaces. Clustering variants, enhancers, or genomic regions by their sequence-class profiles reveals shared regulatory programs and enables compact summaries of complex predictions.</p>
<p><strong>Model and dataset auditing</strong> uses interpretability tools to identify reliance on confounded or undesirable features. Cross-referencing with the confounder taxonomy from <a href="p5-ch21-confound.html" class="quarto-xref"><span>Chapter 21</span></a> helps design deconfounded training and evaluation schemes. If interpretability reveals that a model relies heavily on GC content or batch-specific signals, this diagnoses a problem that evaluation metrics alone might miss.</p>
<p><strong>Human-in-the-loop analysis</strong> integrates motif and sequence-class outputs into visualization tools such as genome browsers with attribution tracks, motif annotations, and class scores. Domain experts can then iteratively refine hypotheses, identifying patterns that merit experimental follow-up and flagging predictions that seem biologically implausible.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Table suggestion: Interpretability toolbox summary</strong></p>
<p>A compact reference table with rows for common tasks (Variant effect prediction, TF motif discovery, Long-range regulation, Model debugging) and columns for: recommended attribution method(s), global summarization approach, and key evaluation tests. This provides practitioners with a quick-start guide for method selection.</p>
</div>
</div>
</section>
<section id="outlook-from-explanations-to-mechanistic-models" class="level2" data-number="22.10">
<h2 data-number="22.10" class="anchored" data-anchor-id="outlook-from-explanations-to-mechanistic-models"><span class="header-section-number">22.10</span> Outlook: From Explanations to Mechanistic Models</h2>
<p>Interpretability in genomic deep learning is evolving from post hoc explanation toward model-assisted mechanistic discovery. Foundation models provide rich latent spaces and long-range context that capture regulatory information at unprecedented scale. Attribution and motif discovery tools translate those representations into candidate regulatory grammars that can be tested experimentally. Global vocabularies like Sei’s sequence classes offer interpretable axes spanning thousands of assays, enabling systematic characterization of regulatory programs across the genome.</p>
<p>Attention analysis in genomic language models reveals emergent gene-level organization, suggesting that models trained on raw sequence implicitly learn operon structure, co-regulation patterns, and phylogenetic context. These findings hint at scalable ways to capture systems-level biology from sequence alone, complementing the multi-omic integration approaches discussed in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a>.</p>
<p>The next frontier is to close the loop between interpretability and model development. Insights from interpretability (motifs, grammars, sequence classes) can inform better architectures and training objectives. Experimentally validated grammars can be fed back into models as inductive biases, constraining the hypothesis space to biologically plausible solutions. Evaluation frameworks can measure not only predictive accuracy but also mechanistic fidelity: how well do model-derived hypotheses align with the causal structure of regulatory biology revealed by perturbation experiments?</p>
<p>Several trends point toward this integration:</p>
<ul>
<li><p><strong>Interpretability-guided experimental design</strong> uses model-derived motifs and grammars to prioritize which sequences to perturb, reducing experimental search space and accelerating mechanistic discovery.</p></li>
<li><p><strong>Multi-scale integration</strong> combines attention heads and long-range contribution patterns in Enformer-like models <span class="citation" data-cites="avsec_enformer_2021 cheng_dnalongbench_2024">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Avsec et al. 2021</a>; <a href="references.html#ref-cheng_dnalongbench_2024" role="doc-biblioref">Cheng et al. 2024</a>)</span> with network and systems-level analyses in <a href="p4-ch17-systems.html" class="quarto-xref"><span>Chapter 17</span></a> to move from single-sequence explanations to global regulatory circuitry.</p></li>
<li><p><strong>Foundation models and emergent structure</strong> reveal that genomic language models and multimodal models (sequence plus epigenomics plus 3D structure) encode increasingly sophisticated representations, shifting interpretability from individual features to representation geometry.</p></li>
<li><p><strong>Standardized benchmarks for interpretability</strong> will complement predictive performance benchmarks (<a href="p5-ch19-eval.html" class="quarto-xref"><span>Chapter 19</span></a>) by measuring faithfulness and biological utility of explanations through shared tasks and datasets.</p></li>
</ul>
<p>In this sense, interpretability is not merely a diagnostic for black-box models. It is a central tool for turning genomic foundation models into engines of biological discovery, capable of bridging the gap between sequence-level predictions and the mechanistic understanding that underpins robust clinical translation. When a model’s explanations match experimental observations and generate validated predictions, it becomes more than a predictor: it becomes a hypothesis-generating system that accelerates the scientific enterprise.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-avsec_enformer_2021" class="csl-entry" role="listitem">
Avsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. <span>“[<span>Enformer</span>] <span>Effective</span> Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.”</span> <em>Nature Methods</em> 18 (October): 1196–1203. <a href="https://doi.org/10.1038/s41592-021-01252-x">https://doi.org/10.1038/s41592-021-01252-x</a>.
</div>
<div id="ref-chafai_review_2023" class="csl-entry" role="listitem">
Chafai, Narjice, Ichrak Hayah, Isidore Houaga, and Bouabid Badaoui. 2023. <span>“A Review of Machine Learning Models Applied to Genomic Prediction in Animal Breeding.”</span> <em>Frontiers in Genetics</em> 14 (September). <a href="https://doi.org/10.3389/fgene.2023.1150596">https://doi.org/10.3389/fgene.2023.1150596</a>.
</div>
<div id="ref-cheng_dnalongbench_2024" class="csl-entry" role="listitem">
Cheng, Wenduo, Zhenqiao Song, Yang Zhang, Shike Wang, Danqing Wang, Muyu Yang, Lei Li, and Jian Ma. 2024. <span>“<span>DNALONGBENCH</span>: <span>A</span> <span>Benchmark</span> <span>Suite</span> <span>For</span> <span>Long</span>-<span>Range</span> <span>DNA</span> <span>Prediction</span> <span>Tasks</span>,”</span> October. <a href="https://openreview.net/forum?id=opv67PpqLS">https://openreview.net/forum?id=opv67PpqLS</a>.
</div>
<div id="ref-consens_transformers_2023" class="csl-entry" role="listitem">
Consens, Micaela E., Cameron Dufault, Michael Wainberg, Duncan Forster, Mehran Karimzadeh, Hani Goodarzi, Fabian J. Theis, Alan Moses, and Bo Wang. 2023. <span>“To <span>Transformers</span> and <span>Beyond</span>: <span>Large</span> <span>Language</span> <span>Models</span> for the <span>Genome</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2311.07621">https://doi.org/10.48550/arXiv.2311.07621</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./p5-ch21-confound.html" class="pagination-link" aria-label="Confounders in Model Training">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./p6--translation.html" class="pagination-link" aria-label="Part VI — Translation and Application">
        <span class="nav-page-text">Part VI — Translation and Application</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>