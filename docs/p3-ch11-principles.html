<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>11&nbsp; Genomic FMs: Principles &amp; Practice – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./p3-ch12-vep.html" rel="next">
<link href="./p3-ch10-tokens.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-d1e9b63c6b6094879b9f94a7628e3370.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p3--principles.html">Part III: Core Principles</a></li><li class="breadcrumb-item"><a href="./p3-ch11-principles.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Genomic FMs: Principles &amp; Practice</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sequencing: From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Genomic Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch03-pgs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS &amp; Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch04-cadd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deleteriousness Scores</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p2--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Deep Learning Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch05-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">CNN Sequence-to-Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch06-plm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch07-dna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Genomic Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch08-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">RNA &amp; Transcript-Level Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch09-hybrid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p3--principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Core Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch10-tokens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch11-principles.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Genomic FMs: Principles &amp; Practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch12-vep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Cross-Protein Transfer from Deep Mutational Scanning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p4--multi-scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Multi-Scale Modeling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch13-sc-epi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Single-Cell &amp; Epigenomic Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch14-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Chapter 14: Graphs, Networks, and Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch15-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Multi-Omics Integration &amp; Systems Biology</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p5--eval-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Evaluation and Reliability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch16-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Benchmarks in Genomic Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch17-eval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Evaluation &amp; Benchmarks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch18-confound.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch19-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p6--translation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI — Translation and Application</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch20-clinical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch21-variants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Pathogenic Variant Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch22-drugs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Drug Discovery &amp; Biotech</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch23-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Design Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch24-future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Chapter 24: Future Directions &amp; Ethical Considerations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-b-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Model Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-c-model-list.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Referenced Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-d-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Additional Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-e-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#from-task-specific-models-to-genomic-foundation-models" id="toc-from-task-specific-models-to-genomic-foundation-models" class="nav-link active" data-scroll-target="#from-task-specific-models-to-genomic-foundation-models"><span class="header-section-number">11.1</span> From Task-Specific Models to Genomic Foundation Models</a></li>
  <li><a href="#what-makes-a-model-a-genomic-foundation-model" id="toc-what-makes-a-model-a-genomic-foundation-model" class="nav-link" data-scroll-target="#what-makes-a-model-a-genomic-foundation-model"><span class="header-section-number">11.2</span> What Makes a Model a Genomic Foundation Model?</a>
  <ul class="collapse">
  <li><a href="#working-definition" id="toc-working-definition" class="nav-link" data-scroll-target="#working-definition"><span class="header-section-number">11.2.1</span> Working Definition</a></li>
  <li><a href="#foundation-models-versus-large-models" id="toc-foundation-models-versus-large-models" class="nav-link" data-scroll-target="#foundation-models-versus-large-models"><span class="header-section-number">11.2.2</span> Foundation Models Versus Large Models</a></li>
  </ul></li>
  <li><a href="#a-taxonomy-of-genomic-foundation-models" id="toc-a-taxonomy-of-genomic-foundation-models" class="nav-link" data-scroll-target="#a-taxonomy-of-genomic-foundation-models"><span class="header-section-number">11.3</span> A Taxonomy of Genomic Foundation Models</a>
  <ul class="collapse">
  <li><a href="#dna-language-models" id="toc-dna-language-models" class="nav-link" data-scroll-target="#dna-language-models"><span class="header-section-number">11.3.1</span> DNA Language Models</a></li>
  <li><a href="#sequence-to-function-genomic-foundation-models" id="toc-sequence-to-function-genomic-foundation-models" class="nav-link" data-scroll-target="#sequence-to-function-genomic-foundation-models"><span class="header-section-number">11.3.2</span> Sequence-to-Function Genomic Foundation Models</a></li>
  <li><a href="#variant-centric-genomic-foundation-models" id="toc-variant-centric-genomic-foundation-models" class="nav-link" data-scroll-target="#variant-centric-genomic-foundation-models"><span class="header-section-number">11.3.3</span> Variant-Centric Genomic Foundation Models</a></li>
  <li><a href="#multi-omic-and-cross-modal-foundation-models" id="toc-multi-omic-and-cross-modal-foundation-models" class="nav-link" data-scroll-target="#multi-omic-and-cross-modal-foundation-models"><span class="header-section-number">11.3.4</span> Multi-omic and Cross-Modal Foundation Models</a></li>
  </ul></li>
  <li><a href="#design-dimensions-of-genomic-foundation-models" id="toc-design-dimensions-of-genomic-foundation-models" class="nav-link" data-scroll-target="#design-dimensions-of-genomic-foundation-models"><span class="header-section-number">11.4</span> Design Dimensions of Genomic Foundation Models</a>
  <ul class="collapse">
  <li><a href="#data-what-does-the-model-see" id="toc-data-what-does-the-model-see" class="nav-link" data-scroll-target="#data-what-does-the-model-see"><span class="header-section-number">11.4.1</span> Data: What Does the Model See?</a></li>
  <li><a href="#architecture-how-does-the-model-process-sequence" id="toc-architecture-how-does-the-model-process-sequence" class="nav-link" data-scroll-target="#architecture-how-does-the-model-process-sequence"><span class="header-section-number">11.4.2</span> Architecture: How Does the Model Process Sequence?</a></li>
  <li><a href="#objectives-what-does-the-model-learn-to-predict" id="toc-objectives-what-does-the-model-learn-to-predict" class="nav-link" data-scroll-target="#objectives-what-does-the-model-learn-to-predict"><span class="header-section-number">11.4.3</span> Objectives: What Does the Model Learn to Predict?</a></li>
  <li><a href="#tokenization-and-representations" id="toc-tokenization-and-representations" class="nav-link" data-scroll-target="#tokenization-and-representations"><span class="header-section-number">11.4.4</span> Tokenization and Representations</a></li>
  </ul></li>
  <li><a href="#evaluating-genomic-foundation-models" id="toc-evaluating-genomic-foundation-models" class="nav-link" data-scroll-target="#evaluating-genomic-foundation-models"><span class="header-section-number">11.5</span> Evaluating Genomic Foundation Models</a>
  <ul class="collapse">
  <li><a href="#downstream-task-suites-and-benchmarks" id="toc-downstream-task-suites-and-benchmarks" class="nav-link" data-scroll-target="#downstream-task-suites-and-benchmarks"><span class="header-section-number">11.5.1</span> Downstream Task Suites and Benchmarks</a></li>
  <li><a href="#evaluation-modes" id="toc-evaluation-modes" class="nav-link" data-scroll-target="#evaluation-modes"><span class="header-section-number">11.5.2</span> Evaluation Modes</a></li>
  </ul></li>
  <li><a href="#practical-integration-of-genomic-foundation-models" id="toc-practical-integration-of-genomic-foundation-models" class="nav-link" data-scroll-target="#practical-integration-of-genomic-foundation-models"><span class="header-section-number">11.6</span> Practical Integration of Genomic Foundation Models</a>
  <ul class="collapse">
  <li><a href="#selecting-a-model-for-your-task" id="toc-selecting-a-model-for-your-task" class="nav-link" data-scroll-target="#selecting-a-model-for-your-task"><span class="header-section-number">11.6.1</span> Selecting a Model for Your Task</a></li>
  <li><a href="#integration-strategies" id="toc-integration-strategies" class="nav-link" data-scroll-target="#integration-strategies"><span class="header-section-number">11.6.2</span> Integration Strategies</a></li>
  </ul></li>
  <li><a href="#safety-robustness-and-responsible-use" id="toc-safety-robustness-and-responsible-use" class="nav-link" data-scroll-target="#safety-robustness-and-responsible-use"><span class="header-section-number">11.7</span> Safety, Robustness, and Responsible Use</a>
  <ul class="collapse">
  <li><a href="#robustness-and-adversarial-sensitivity" id="toc-robustness-and-adversarial-sensitivity" class="nav-link" data-scroll-target="#robustness-and-adversarial-sensitivity"><span class="header-section-number">11.7.1</span> Robustness and Adversarial Sensitivity</a></li>
  <li><a href="#bias-fairness-and-ancestry" id="toc-bias-fairness-and-ancestry" class="nav-link" data-scroll-target="#bias-fairness-and-ancestry"><span class="header-section-number">11.7.2</span> Bias, Fairness, and Ancestry</a></li>
  <li><a href="#data-governance-and-privacy" id="toc-data-governance-and-privacy" class="nav-link" data-scroll-target="#data-governance-and-privacy"><span class="header-section-number">11.7.3</span> Data Governance and Privacy</a></li>
  </ul></li>
  <li><a href="#open-challenges-and-future-directions" id="toc-open-challenges-and-future-directions" class="nav-link" data-scroll-target="#open-challenges-and-future-directions"><span class="header-section-number">11.8</span> Open Challenges and Future Directions</a>
  <ul class="collapse">
  <li><a href="#toward-unified-multi-omic-foundation-models" id="toc-toward-unified-multi-omic-foundation-models" class="nav-link" data-scroll-target="#toward-unified-multi-omic-foundation-models"><span class="header-section-number">11.8.1</span> Toward Unified Multi-omic Foundation Models</a></li>
  <li><a href="#integrating-causal-and-mechanistic-structure" id="toc-integrating-causal-and-mechanistic-structure" class="nav-link" data-scroll-target="#integrating-causal-and-mechanistic-structure"><span class="header-section-number">11.8.2</span> Integrating Causal and Mechanistic Structure</a></li>
  <li><a href="#efficient-and-accessible-deployment" id="toc-efficient-and-accessible-deployment" class="nav-link" data-scroll-target="#efficient-and-accessible-deployment"><span class="header-section-number">11.8.3</span> Efficient and Accessible Deployment</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">11.9</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p3--principles.html">Part III: Core Principles</a></li><li class="breadcrumb-item"><a href="./p3-ch11-principles.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Genomic FMs: Principles &amp; Practice</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-princ" class="quarto-section-identifier"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Genomic FMs: Principles &amp; Practice</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="content-visible callout callout-style-default callout-warning callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>TODO:</strong></p>
<ul>
<li>Add figure: taxonomy of genomic foundation models (DNA LM, seq→function, variant-centric, multi-omic) showing the four quadrants with representative models in each</li>
<li>Add figure: design dimensions diagram showing data, architecture, objectives, and tokenization as orthogonal axes</li>
<li>Add table: comparison of GFM families (context length, parameter count, pretraining objective, key applications)</li>
<li>Add figure: evaluation pyramid from molecular readouts to clinical decisions</li>
<li>Add decision tree flowchart for practitioners choosing appropriate GFM for their task</li>
<li>Add figure: adapter strategies (linear probe, LoRA, full fine-tune) with computational cost comparison</li>
</ul>
</div>
</div>
<p>Pretraining objectives (MLM, autoregressive, contrastive) Generative objectives (diffusion, flow matching, VAEs) Fine-tuning strategies Transfer and adaptation Scaling laws</p>
<p>Genomic foundation models represent the culmination of several threads developed across the earlier parts of this book: high-fidelity variant calling, regulatory sequence-to-function prediction, protein language models, and long-context transformers for DNA. These models extend the ideas presented in previous chapters into systems that are general-purpose, pretrained at scale, and reusable across a wide range of genomic and genetic tasks.</p>
<p>This chapter steps back from individual architectures to address a more fundamental question: what does it mean for a model to be a genomic foundation model? We organize the emerging ecosystem into a practical taxonomy, distill design principles that guide model selection and development, and provide guidance for practitioners seeking to integrate these models into their workflows. The conceptual framework established here will guide the remaining chapters of Part IV as we examine specific application domains.</p>
<section id="from-task-specific-models-to-genomic-foundation-models" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="from-task-specific-models-to-genomic-foundation-models"><span class="header-section-number">11.1</span> From Task-Specific Models to Genomic Foundation Models</h2>
<p>The earlier chapters traced a fairly linear progression through the history of computational approaches to genomic prediction. Hand-crafted scores and shallow models such as CADD and early pathogenicity predictors established the value of integrating diverse annotations for variant interpretation <span class="citation" data-cites="rentzsch_cadd_2019 schubach_cadd_2024">(<a href="references.html#ref-rentzsch_cadd_2019" role="doc-biblioref">Rentzsch et al. 2019</a>; <a href="references.html#ref-schubach_cadd_2024" role="doc-biblioref">Schubach et al. 2024</a>)</span>. Task-specific deep models such as DeepSEA, ExPecto, Sei, Enformer, and SpliceAI demonstrated that neural networks could learn regulatory and splicing effects directly from sequence, often surpassing the performance of feature-engineered approaches <span class="citation" data-cites="zhou_deepsea_2015 zhou_expecto_2018 chen_deepsea_2022 avsec_enformer_2021 jaganathan_spliceai_2019">(<a href="references.html#ref-zhou_deepsea_2015" role="doc-biblioref">J. Zhou and Troyanskaya 2015</a>; <a href="references.html#ref-zhou_expecto_2018" role="doc-biblioref">J. Zhou et al. 2018</a>; <a href="references.html#ref-chen_deepsea_2022" role="doc-biblioref">Chen et al. 2022</a>; <a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Avsec et al. 2021</a>; <a href="references.html#ref-jaganathan_spliceai_2019" role="doc-biblioref">Jaganathan et al. 2019</a>)</span>. Sequence language models over proteins and DNA, including ESM, DNABERT, Nucleotide Transformer, HyenaDNA, and GROVER, showed that general sequence representations could be learned via self-supervision and then transferred to diverse downstream tasks <span class="citation" data-cites="rives_esm_2021 lin_esm-2_2022 brandes_genome-wide_2023 ji_dnabert_2021 dalla-torre_nucleotide_2023 nguyen_hyenadna_2023 sanabria_grover_2024">(<a href="references.html#ref-rives_esm_2021" role="doc-biblioref">Rives et al. 2021</a>; <a href="references.html#ref-lin_esm-2_2022" role="doc-biblioref">Lin et al. 2022</a>; <a href="references.html#ref-brandes_genome-wide_2023" role="doc-biblioref">Brandes et al. 2023</a>; <a href="references.html#ref-ji_dnabert_2021" role="doc-biblioref">Ji et al. 2021</a>; <a href="references.html#ref-dalla-torre_nucleotide_2023" role="doc-biblioref">Dalla-Torre et al. 2023</a>; <a href="references.html#ref-nguyen_hyenadna_2023" role="doc-biblioref">Nguyen et al. 2023</a>; <a href="references.html#ref-sanabria_grover_2024" role="doc-biblioref">Sanabria et al. 2024</a>)</span>.</p>
<p>Foundation models build on these ingredients but fundamentally change the contract between model and user. The primary product of a genomic foundation model is not a task-specific prediction head but rather a reusable representation, and sometimes a general interface, that can be adapted to many downstream tasks with modest additional supervision. HyenaDNA exemplifies this paradigm: a genomic foundation model pretrained on the human reference genome with context lengths up to one million tokens at single-nucleotide resolution using a Hyena-based long-range architecture. DNABERT-2, Nucleotide Transformer V2, Caduceus-Ph, GROVER, and related models form a parallel family of transformer-style DNA foundation models. A recent benchmark comparing these five models across diverse tasks including classification, gene expression prediction, variant effect quantification, and TAD recognition illustrates both the promise and the limitations of current DNA foundation models <span class="citation" data-cites="manzo_comparative_2025">(<a href="references.html#ref-manzo_comparative_2025" role="doc-biblioref">Manzo, Borkowski, and Ovcharenko 2025</a>)</span>.</p>
<p>At a high level, genomic foundation models extend the pretrain-then-finetune paradigm from natural language processing and protein modeling into genomics, but with domain-specific constraints that distinguish them from their counterparts in other fields. These constraints include extreme context lengths necessary to capture distal regulatory interactions, single-nucleotide sensitivity required for variant effect prediction, and strong mechanistic priors that arise from decades of molecular biology research.</p>
</section>
<section id="what-makes-a-model-a-genomic-foundation-model" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="what-makes-a-model-a-genomic-foundation-model"><span class="header-section-number">11.2</span> What Makes a Model a Genomic Foundation Model?</h2>
<p>The term “foundation model” is sometimes used loosely in the genomics literature, applied to any large neural network trained on genomic data. For practical purposes, it is useful to establish working criteria that separate true genomic foundation models from ordinary deep models that happen to operate on biological sequences.</p>
<section id="working-definition" class="level3" data-number="11.2.1">
<h3 data-number="11.2.1" class="anchored" data-anchor-id="working-definition"><span class="header-section-number">11.2.1</span> Working Definition</h3>
<p>A genomic foundation model is a pretrained model that satisfies several key properties. First, it learns from large-scale genomic data with minimal task-specific supervision, typically through pretraining on entire genomes or large portions thereof across species or populations. The objectives employed during pretraining include masked language modeling, next-token prediction, denoising, or multi-task sequence-to-function prediction.</p>
<p>Second, a genomic foundation model produces general-purpose representations. These take the form of embeddings of sequences, variants, loci, or genes that prove useful across many downstream tasks. Critically, these representations can be extracted and reused with light adapters or linear probes rather than requiring full model retraining.</p>
<p>Third, genomic foundation models are designed for broad transfer. They support many downstream tasks without retraining the full model, enabling transfer across assays (from chromatin marks to gene expression), across tissues, across species, and across variant types.</p>
<p>Fourth, these models scale along at least one dimension. Some scale context length, as in HyenaDNA’s million-token window. Others scale parameter count, as in the ESM and Nucleotide Transformer families. Still others scale data diversity through pan-genomic pretraining or cross-species corpora.</p>
<p>Fifth, genomic foundation models typically expose a relatively standardized interface. This includes a common API for embeddings, sequence scoring, and mask-based perturbation, and models are often distributed via model hubs such as Hugging Face with documented recipes for downstream applications.</p>
<p>Many excellent deep models for genomics fail one or more of these criteria. Early versions of DeepSEA or SpliceAI, for instance, were trained for specific assays or tasks, used narrowly scoped inputs and outputs, and were not designed for broad reuse beyond their original application domains.</p>
</section>
<section id="foundation-models-versus-large-models" class="level3" data-number="11.2.2">
<h3 data-number="11.2.2" class="anchored" data-anchor-id="foundation-models-versus-large-models"><span class="header-section-number">11.2.2</span> Foundation Models Versus Large Models</h3>
<p>Scale alone does not make a model a foundation model. A very large Enformer-like model trained solely on human chromatin tracks is powerful but remains strongly bound to a specific prediction interface that maps sequence to a fixed set of chromatin tracks. By contrast, a DNA language model like HyenaDNA or DNABERT-2 is explicitly trained to model raw sequence using a general objective and is naturally repurposed as an embedding engine for diverse downstream applications.</p>
<p>This distinction matters because it affects how models should be evaluated. Foundation models must be assessed across families of tasks rather than single benchmarks, using resources like TraitGym for trait-level performance and ProteinGym for variant effect prediction <span class="citation" data-cites="benegas_traitgym_2025 notin_proteingym_2023">(<a href="references.html#ref-benegas_traitgym_2025" role="doc-biblioref">Benegas, Eraslan, and Song 2025</a>; <a href="references.html#ref-notin_proteingym_2023" role="doc-biblioref">Notin et al. 2023</a>)</span>. The distinction also affects how models should be integrated into existing pipelines, since foundation models serve as feature extractors while task-specific models typically serve as end-to-end predictors.</p>
</section>
</section>
<section id="a-taxonomy-of-genomic-foundation-models" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="a-taxonomy-of-genomic-foundation-models"><span class="header-section-number">11.3</span> A Taxonomy of Genomic Foundation Models</h2>
<p>The landscape of genomic foundation models can be organized into four broad families, each with distinct characteristics, strengths, and typical applications. Understanding this taxonomy helps practitioners select appropriate models for their specific needs and helps researchers position new contributions within the broader field.</p>
<section id="dna-language-models" class="level3" data-number="11.3.1">
<h3 data-number="11.3.1" class="anchored" data-anchor-id="dna-language-models"><span class="header-section-number">11.3.1</span> DNA Language Models</h3>
<p>The first family comprises DNA language models that learn sequence representations from raw nucleotide strings. Representative examples include DNABERT and DNABERT-2, which apply BERT-style masked language modeling to DNA sequences <span class="citation" data-cites="ji_dnabert_2021 zhou_dnabert-2_2024">(<a href="references.html#ref-ji_dnabert_2021" role="doc-biblioref">Ji et al. 2021</a>; <a href="references.html#ref-zhou_dnabert-2_2024" role="doc-biblioref">Z. Zhou et al. 2024</a>)</span>. The Nucleotide Transformer family scales this approach to larger models and cross-species training corpora <span class="citation" data-cites="dalla-torre_nucleotide_2023">(<a href="references.html#ref-dalla-torre_nucleotide_2023" role="doc-biblioref">Dalla-Torre et al. 2023</a>)</span>. HyenaDNA uses implicit convolutions rather than attention to achieve subquadratic complexity, enabling context lengths up to one million nucleotides <span class="citation" data-cites="nguyen_hyenadna_2023">(<a href="references.html#ref-nguyen_hyenadna_2023" role="doc-biblioref">Nguyen et al. 2023</a>)</span>. Caduceus incorporates bidirectional processing and reverse-complement equivariance as architectural inductive biases. GROVER combines BPE-style tokenization with training on regulatory tracks rather than raw sequence alone <span class="citation" data-cites="sanabria_grover_2024">(<a href="references.html#ref-sanabria_grover_2024" role="doc-biblioref">Sanabria et al. 2024</a>)</span>.</p>
<p>These models share several characteristics. They are typically trained on reference genomes with self-supervised objectives, they produce embeddings that can be probed or fine-tuned for diverse tasks, and they vary primarily in context length, architectural family (transformer versus state space model versus hybrid), and tokenization strategy.</p>
</section>
<section id="sequence-to-function-genomic-foundation-models" class="level3" data-number="11.3.2">
<h3 data-number="11.3.2" class="anchored" data-anchor-id="sequence-to-function-genomic-foundation-models"><span class="header-section-number">11.3.2</span> Sequence-to-Function Genomic Foundation Models</h3>
<p>The second family comprises sequence-to-function models that predict molecular readouts directly from sequence. These models blur into foundation model territory when their output space is sufficiently broad and their internal representations are reused for tasks beyond the original assay set. Examples include Enformer, which predicts thousands of chromatin and expression tracks from 200 kb sequence windows <span class="citation" data-cites="avsec_enformer_2021">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Avsec et al. 2021</a>)</span>, and Sei, which organizes predictions into interpretable sequence classes that capture regulatory grammar <span class="citation" data-cites="chen_deepsea_2022">(<a href="references.html#ref-chen_deepsea_2022" role="doc-biblioref">Chen et al. 2022</a>)</span>. These models typically operate over longer context windows of 100 kb or more and provide variant effect scores by computing delta-predictions between reference and alternative alleles.</p>
<p>Enformer serves as a prototypical example of a sequence-to-function model that has been widely reused as a feature extractor for downstream tasks including gene expression prediction and fine-mapping of regulatory variants. While these models were originally trained for specific assays, they approximate foundation models when the output space spans many cell types and assays and when their internal representations prove useful for tasks beyond the original prediction targets.</p>
</section>
<section id="variant-centric-genomic-foundation-models" class="level3" data-number="11.3.3">
<h3 data-number="11.3.3" class="anchored" data-anchor-id="variant-centric-genomic-foundation-models"><span class="header-section-number">11.3.3</span> Variant-Centric Genomic Foundation Models</h3>
<p>A third class of foundation models focuses not on raw sequence but on genetic variants as the fundamental unit. These models embed variants using contextual information from local sequence, gene structure, and external annotations, and they predict variant pathogenicity, molecular consequences, or trait-level effect sizes.</p>
<p>Examples in this space include CADD and its deep-learning-enhanced successor models, which integrate annotations and sequence features for broad variant pathogenicity scoring <span class="citation" data-cites="rentzsch_cadd_2019 schubach_cadd_2024">(<a href="references.html#ref-rentzsch_cadd_2019" role="doc-biblioref">Rentzsch et al. 2019</a>; <a href="references.html#ref-schubach_cadd_2024" role="doc-biblioref">Schubach et al. 2024</a>)</span>. AlphaMissense repurposes ESM-style protein language models to predict missense pathogenicity at scale <span class="citation" data-cites="cheng_alphamissense_2023">(<a href="references.html#ref-cheng_alphamissense_2023" role="doc-biblioref">Cheng et al. 2023</a>)</span>. Delphi, MIFM, and related models couple genomic foundation model embeddings with polygenic score estimation for complex traits <span class="citation" data-cites="georgantas_delphi_2024 rakowski_mifm_2025 wu_genome-wide_2024">(<a href="references.html#ref-georgantas_delphi_2024" role="doc-biblioref">Georgantas, Kutalik, and Richiardi 2024</a>; <a href="references.html#ref-rakowski_mifm_2025" role="doc-biblioref">Rakowski and Lippert 2025</a>; <a href="references.html#ref-wu_genome-wide_2024" role="doc-biblioref">Wu et al. 2024</a>)</span>. Emerging variant representation learning datasets and benchmarks such as GV-Rep explicitly probe how well foundation models represent genetic variants and clinical annotations.</p>
<p>Variant-centric foundation models blur the line between feature extractors and trait models. Their predictions can be plugged directly into polygenic score pipelines, risk stratification tools, or rare disease interpretation workflows, making them particularly relevant for clinical applications.</p>
</section>
<section id="multi-omic-and-cross-modal-foundation-models" class="level3" data-number="11.3.4">
<h3 data-number="11.3.4" class="anchored" data-anchor-id="multi-omic-and-cross-modal-foundation-models"><span class="header-section-number">11.3.4</span> Multi-omic and Cross-Modal Foundation Models</h3>
<p>Finally, a growing set of models aim to natively integrate multiple modalities. These include models that jointly process DNA sequence, chromatin state, and gene expression; models that incorporate sequence and 3D genome structure from Hi-C or Micro-C experiments; and models that combine DNA with non-sequence modalities such as images or free text descriptions of function.</p>
<p>Recent work on architectures like Omni-DNA explores transformer-based auto-regressive models that jointly handle DNA and task-specific tokens, enabling multi-task learning over sequence, epigenetic marks, and even textual descriptions of function. These models move genomic foundation models closer to a unified interface for genome biology, though at the cost of more complex training objectives and data engineering requirements.</p>
</section>
</section>
<section id="design-dimensions-of-genomic-foundation-models" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="design-dimensions-of-genomic-foundation-models"><span class="header-section-number">11.4</span> Design Dimensions of Genomic Foundation Models</h2>
<p>When designing or selecting a genomic foundation model, it is helpful to think in terms of several orthogonal design dimensions. Each dimension involves trade-offs that affect model performance, computational requirements, and suitability for specific applications.</p>
<section id="data-what-does-the-model-see" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1" class="anchored" data-anchor-id="data-what-does-the-model-see"><span class="header-section-number">11.4.1</span> Data: What Does the Model See?</h3>
<p>The choice of training data fundamentally shapes what a model can learn. Key decisions include species coverage, assay diversity, population diversity, and sampling strategies.</p>
<p>Regarding species coverage, models may be trained on human genomes only, focusing on clinical and human genetics applications, or they may incorporate cross-species pretraining on dozens or hundreds of species. Cross-species training, as employed by Nucleotide Transformer and many protein language models, encourages discovery of conserved regulatory code and can improve out-of-domain generalization <span class="citation" data-cites="dalla-torre_nucleotide_2023 rives_esm_2021">(<a href="references.html#ref-dalla-torre_nucleotide_2023" role="doc-biblioref">Dalla-Torre et al. 2023</a>; <a href="references.html#ref-rives_esm_2021" role="doc-biblioref">Rives et al. 2021</a>)</span>.</p>
<p>Assay diversity matters for sequence-to-function models. The choice of which epigenomic assays, cell types, and perturbation datasets to include during training determines what molecular readouts the model can predict and, more subtly, what regulatory patterns it learns to recognize. Collections like Cistrome provide rich training data spanning transcription factor binding, histone modifications, and chromatin accessibility across many cell types <span class="citation" data-cites="zheng_cistrome_2019">(<a href="references.html#ref-zheng_cistrome_2019" role="doc-biblioref">Zheng et al. 2019</a>)</span>.</p>
<p>Population diversity is crucial for avoiding biased models. Inclusion of genomes from diverse ancestries is necessary to prevent embedding population-specific biases into foundation models and downstream risk scores. Early deep learning approaches to polygenic score estimation, including Delphi and MIFM, explicitly tackle ancestry-aware evaluation to quantify and mitigate these biases <span class="citation" data-cites="georgantas_delphi_2024 rakowski_mifm_2025 wu_genome-wide_2024">(<a href="references.html#ref-georgantas_delphi_2024" role="doc-biblioref">Georgantas, Kutalik, and Richiardi 2024</a>; <a href="references.html#ref-rakowski_mifm_2025" role="doc-biblioref">Rakowski and Lippert 2025</a>; <a href="references.html#ref-wu_genome-wide_2024" role="doc-biblioref">Wu et al. 2024</a>)</span>.</p>
<p>Context length and sampling strategies also play important roles. Some models randomly slice long chromosomes into training windows, as in HyenaDNA. Others use targeted sampling around genes, enhancers, or known variants. Warm-up schedules that gradually increase context length can stabilize training for long-context models.</p>
</section>
<section id="architecture-how-does-the-model-process-sequence" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2" class="anchored" data-anchor-id="architecture-how-does-the-model-process-sequence"><span class="header-section-number">11.4.2</span> Architecture: How Does the Model Process Sequence?</h3>
<p>Architectural choices determine the computational properties of a model, including maximum practical context length, memory and compute requirements, and ease of adaptation for different tasks.</p>
<p>Transformer architectures dominate current genomic foundation models and come in several flavors. Encoder-only models following the BERT design, such as DNABERT and Nucleotide Transformer, are well-suited for classification and embedding tasks. Decoder-only models following the GPT design, such as GROVER and some Omni-DNA variants, align naturally with generative tasks. Encoder-decoder hybrids support tasks requiring explicit outputs such as sequence-to-text explanations.</p>
<p>Attention-free long-range models address the quadratic complexity of standard attention. Hyena-based models like HyenaDNA use implicit convolutions to achieve subquadratic complexity, enabling million-token contexts. State space models and related architectures trade exact attention for scalable long-range interactions while maintaining competitive performance on many tasks.</p>
<p>Dense-attention long-range transformers demonstrate that with careful engineering and context extension schedules, dense-attention transformers can also reach approximately 200 kb contexts at single-nucleotide resolution. Models like Gene42 show that the attention-versus-efficiency trade-off is not absolute.</p>
<p>Hybrid architectures combine multiple approaches. CNN-plus-transformer stacks use local convolutions followed by global attention, as seen in Enformer-like models <span class="citation" data-cites="avsec_enformer_2021">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Avsec et al. 2021</a>)</span>. Cross-attention mechanisms can integrate DNA with auxiliary modalities such as chromatin state or 3D contact maps.</p>
</section>
<section id="objectives-what-does-the-model-learn-to-predict" class="level3" data-number="11.4.3">
<h3 data-number="11.4.3" class="anchored" data-anchor-id="objectives-what-does-the-model-learn-to-predict"><span class="header-section-number">11.4.3</span> Objectives: What Does the Model Learn to Predict?</h3>
<p>The training objective shapes the representations a model learns and its suitability for different downstream applications.</p>
<p>Masked token prediction randomly masks nucleotides or k-mers and trains the model to predict them given surrounding context. This approach, used by DNABERT, DNABERT-2, and many transformer-based models, encourages learning of local and medium-range dependencies <span class="citation" data-cites="ji_dnabert_2021 zhou_dnabert-2_2024">(<a href="references.html#ref-ji_dnabert_2021" role="doc-biblioref">Ji et al. 2021</a>; <a href="references.html#ref-zhou_dnabert-2_2024" role="doc-biblioref">Z. Zhou et al. 2024</a>)</span>.</p>
<p>Next-token prediction uses an autoregressive language model objective, as in GROVER and HyenaDNA. This approach naturally aligns with generative tasks and in-context learning, and it leverages techniques developed for large language models in natural language processing.</p>
<p>Denoising and span corruption objectives replace or permute spans of sequence and train the model to reconstruct them. These approaches encourage robustness to small perturbations and attention to long-range structure.</p>
<p>Multi-task sequence-to-function prediction directly predicts chromatin profiles, transcription factor binding, accessibility, expression, and other molecular readouts from sequence. Models like DeepSEA, Enformer, and Sei use this approach, which functions as a powerful regularizer and provides a direct bridge between sequence patterns and molecular phenotypes <span class="citation" data-cites="zhou_deepsea_2015 avsec_enformer_2021 chen_deepsea_2022">(<a href="references.html#ref-zhou_deepsea_2015" role="doc-biblioref">J. Zhou and Troyanskaya 2015</a>; <a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Avsec et al. 2021</a>; <a href="references.html#ref-chen_deepsea_2022" role="doc-biblioref">Chen et al. 2022</a>)</span>.</p>
<p>Cross-modal objectives jointly predict sequence features and other modalities. Examples include contrastive alignment between DNA slices and 3D contacts or histone marks, and joint prediction of sequence, epigenetic tracks, and textual function labels in Omni-DNA-like architectures.</p>
</section>
<section id="tokenization-and-representations" class="level3" data-number="11.4.4">
<h3 data-number="11.4.4" class="anchored" data-anchor-id="tokenization-and-representations"><span class="header-section-number">11.4.4</span> Tokenization and Representations</h3>
<p>Tokenization presents a non-trivial design choice for DNA models, with different approaches offering distinct trade-offs.</p>
<p>Character-level tokenization treats each nucleotide as a separate token. This is the simplest approach and maintains single-nucleotide resolution, making it compatible with precise variant effect prediction. HyenaDNA and many sequence-to-function models use this approach <span class="citation" data-cites="nguyen_hyenadna_2023">(<a href="references.html#ref-nguyen_hyenadna_2023" role="doc-biblioref">Nguyen et al. 2023</a>)</span>.</p>
<p>K-mer tokenization groups nucleotides into overlapping or non-overlapping k-mers, creating vocabularies of size <span class="math inline">\(4^k\)</span>. For 6-mers, this yields 4,096 tokens. K-mer tokenization reduces sequence length and helps transformers reach longer effective contexts, but at the cost of positional ambiguity and reduced resolution <span class="citation" data-cites="ji_dnabert_2021">(<a href="references.html#ref-ji_dnabert_2021" role="doc-biblioref">Ji et al. 2021</a>)</span>.</p>
<p>Learned tokenization approaches, such as BPE-style methods used in BioToken, discover subsequence units optimized for downstream performance rather than using fixed vocabularies <span class="citation" data-cites="medvedev_biotoken_2025">(<a href="references.html#ref-medvedev_biotoken_2025" role="doc-biblioref">Medvedev et al. 2025</a>)</span>. These approaches can allocate vocabulary capacity efficiently, representing common patterns compactly while maintaining the ability to encode rare sequences.</p>
<p>Internally, genomic foundation models typically produce per-position embeddings <span class="math inline">\(h_i \in \mathbb{R}^d\)</span> for each nucleotide or token, pooled sequence embeddings that summarize an entire region through mean pooling, CLS tokens, or learned pooling operations, and variant embeddings constructed by contrasting reference versus alternative alleles, sometimes augmented with structural context. The choice of pooling strategy can significantly influence downstream performance, and benchmarking studies have found that simple mean pooling of per-token embeddings often outperforms more elaborate strategies across many tasks <span class="citation" data-cites="manzo_comparative_2025">(<a href="references.html#ref-manzo_comparative_2025" role="doc-biblioref">Manzo, Borkowski, and Ovcharenko 2025</a>)</span>.</p>
</section>
</section>
<section id="evaluating-genomic-foundation-models" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="evaluating-genomic-foundation-models"><span class="header-section-number">11.5</span> Evaluating Genomic Foundation Models</h2>
<p>Because genomic foundation models are intended to serve as foundations for many applications, their evaluation must be broader than single-task metrics. A model that excels at one benchmark may fail on others, and performance on standard benchmarks may not predict utility for real-world applications.</p>
<section id="downstream-task-suites-and-benchmarks" class="level3" data-number="11.5.1">
<h3 data-number="11.5.1" class="anchored" data-anchor-id="downstream-task-suites-and-benchmarks"><span class="header-section-number">11.5.1</span> Downstream Task Suites and Benchmarks</h3>
<p>Emerging benchmark suites provide structured evaluations across diverse tasks. ProteinGym evaluates variant effect prediction across many proteins for protein language models <span class="citation" data-cites="notin_proteingym_2023">(<a href="references.html#ref-notin_proteingym_2023" role="doc-biblioref">Notin et al. 2023</a>)</span>. TraitGym assesses trait-level performance of regulatory and genomic models across complex trait prediction tasks <span class="citation" data-cites="benegas_traitgym_2025">(<a href="references.html#ref-benegas_traitgym_2025" role="doc-biblioref">Benegas, Eraslan, and Song 2025</a>)</span>. Comparative evaluations of DNA language models and regulatory models, such as the work by Manzo and colleagues, compare models across regulatory genomics tasks <span class="citation" data-cites="manzo_comparative_2025">(<a href="references.html#ref-manzo_comparative_2025" role="doc-biblioref">Manzo, Borkowski, and Ovcharenko 2025</a>)</span>. DNA foundation model benchmarks systematically compare models like DNABERT-2, Nucleotide Transformer V2, HyenaDNA, Caduceus-Ph, and GROVER across classification, variant effect, and TAD recognition tasks. Variant-centric benchmarks like GV-Rep probe models’ ability to represent clinical variants and their genomic contexts.</p>
<p>A key lesson from these benchmarks is that no single model dominates all tasks. General-purpose DNA foundation models often perform well overall but may lag specialized architectures for gene expression and eQTL prediction, while excelling for variant prioritization and regulatory element annotation.</p>
</section>
<section id="evaluation-modes" class="level3" data-number="11.5.2">
<h3 data-number="11.5.2" class="anchored" data-anchor-id="evaluation-modes"><span class="header-section-number">11.5.2</span> Evaluation Modes</h3>
<p>Genomic foundation models can be evaluated in several regimes that test different aspects of their utility.</p>
<p>Zero-shot evaluation uses frozen embeddings with simple operations such as similarity computations or clustering, or with predefined scoring rules. This tests whether useful information is accessible without any task-specific training. An example would be using HyenaDNA embeddings directly for in-context learning on simple motif tasks.</p>
<p>Linear probes train shallow linear or logistic regression heads on top of frozen embeddings. This provides a quick measure of how easily information is linearly decodable from the model’s representations and is often used as a diagnostic for representation quality.</p>
<p>Lightweight adaptation includes approaches like low-rank adaptation (LoRA), prompt tuning, or small MLP heads fine-tuned on specific tasks. These methods balance performance with computational cost and stability, enabling adaptation without the full expense of end-to-end fine-tuning.</p>
<p>Full fine-tuning updates all model parameters on a downstream task. This typically yields the best task-specific performance but requires more data and computation, and risks overfitting to the specific task distribution.</p>
<p>The choice among these evaluation modes depends on the amount of labeled data available, computational constraints, and whether the goal is to assess representation quality or to achieve maximum task performance.</p>
</section>
</section>
<section id="practical-integration-of-genomic-foundation-models" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="practical-integration-of-genomic-foundation-models"><span class="header-section-number">11.6</span> Practical Integration of Genomic Foundation Models</h2>
<p>For practitioners seeking to use genomic foundation models in their work, several questions guide the choice of model and integration strategy.</p>
<section id="selecting-a-model-for-your-task" class="level3" data-number="11.6.1">
<h3 data-number="11.6.1" class="anchored" data-anchor-id="selecting-a-model-for-your-task"><span class="header-section-number">11.6.1</span> Selecting a Model for Your Task</h3>
<p>The appropriate model depends on the specific application. For missense variant interpretation, protein language models like ESM-2 or AlphaMissense provide strong baselines with well-characterized performance <span class="citation" data-cites="cheng_alphamissense_2023">(<a href="references.html#ref-cheng_alphamissense_2023" role="doc-biblioref">Cheng et al. 2023</a>)</span>. For non-coding variant interpretation, sequence-to-function models like Enformer or DNA language models fine-tuned on regulatory tasks are more appropriate <span class="citation" data-cites="avsec_enformer_2021">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Avsec et al. 2021</a>)</span>. For tasks requiring very long genomic context, such as enhancer-promoter linking or structural variant interpretation, models like HyenaDNA or long-context dense-attention models like Gene42 should be considered. For regulatory variant interpretation near genes, Enformer-like or DeepSEA-like models can be compared against DNA language models working via embeddings <span class="citation" data-cites="zhou_deepsea_2015 chen_deepsea_2022 ji_dnabert_2021">(<a href="references.html#ref-zhou_deepsea_2015" role="doc-biblioref">J. Zhou and Troyanskaya 2015</a>; <a href="references.html#ref-chen_deepsea_2022" role="doc-biblioref">Chen et al. 2022</a>; <a href="references.html#ref-ji_dnabert_2021" role="doc-biblioref">Ji et al. 2021</a>)</span>. For trait-level prediction with large cohorts, polygenic score pipelines incorporating GFM-based variant priors, such as Delphi or MIFM, offer promising approaches <span class="citation" data-cites="georgantas_delphi_2024 rakowski_mifm_2025 wu_genome-wide_2024">(<a href="references.html#ref-georgantas_delphi_2024" role="doc-biblioref">Georgantas, Kutalik, and Richiardi 2024</a>; <a href="references.html#ref-rakowski_mifm_2025" role="doc-biblioref">Rakowski and Lippert 2025</a>; <a href="references.html#ref-wu_genome-wide_2024" role="doc-biblioref">Wu et al. 2024</a>)</span>. For method development and benchmarking, standardized benchmark suites like TraitGym, ProteinGym, GV-Rep, and DNA foundation model comparison studies ensure that comparisons are meaningful <span class="citation" data-cites="benegas_traitgym_2025 notin_proteingym_2023 manzo_comparative_2025">(<a href="references.html#ref-benegas_traitgym_2025" role="doc-biblioref">Benegas, Eraslan, and Song 2025</a>; <a href="references.html#ref-notin_proteingym_2023" role="doc-biblioref">Notin et al. 2023</a>; <a href="references.html#ref-manzo_comparative_2025" role="doc-biblioref">Manzo, Borkowski, and Ovcharenko 2025</a>)</span>.</p>
</section>
<section id="integration-strategies" class="level3" data-number="11.6.2">
<h3 data-number="11.6.2" class="anchored" data-anchor-id="integration-strategies"><span class="header-section-number">11.6.2</span> Integration Strategies</h3>
<p>Once a model is selected, several integration strategies are available. The simplest approach uses the model as a feature extractor, computing embeddings or predictions for variants or sequences of interest and then feeding these features into downstream models or pipelines. This approach is computationally efficient and compatible with existing infrastructure.</p>
<p>Adapter-based fine-tuning keeps the foundation model frozen while training small adapter modules on task-specific data. This preserves the general knowledge in the foundation model while adapting its representations to the specific task.</p>
<p>End-to-end fine-tuning updates the entire model on task-specific data. This can achieve the best performance but requires more data and computation and may sacrifice generality.</p>
<p>Ensemble approaches combine predictions from multiple models, often achieving better performance and calibration than any single model. This is particularly valuable when different models have complementary strengths.</p>
</section>
</section>
<section id="safety-robustness-and-responsible-use" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="safety-robustness-and-responsible-use"><span class="header-section-number">11.7</span> Safety, Robustness, and Responsible Use</h2>
<p>As genomic foundation models become infrastructure for clinical and research pipelines, considerations of safety and robustness move from optional extras to essential requirements.</p>
<section id="robustness-and-adversarial-sensitivity" class="level3" data-number="11.7.1">
<h3 data-number="11.7.1" class="anchored" data-anchor-id="robustness-and-adversarial-sensitivity"><span class="header-section-number">11.7.1</span> Robustness and Adversarial Sensitivity</h3>
<p>Recent work on genomic foundation model robustness highlights that these models can be surprisingly sensitive to adversarial perturbations at both the input sequence level and through soft prompts in embedding space. Even when perturbations are hardly biologically plausible, they reveal fragility of decision boundaries in high-dimensional representation space and potential failure modes where small spurious changes strongly impact pathogenicity or variant effect predictions.</p>
<p>These findings suggest that adversarial testing should become part of genomic foundation model validation, especially for clinical use cases. Robust training approaches, including data augmentation, adversarial objectives, or distributionally robust optimization, may be needed for high-stakes applications.</p>
</section>
<section id="bias-fairness-and-ancestry" class="level3" data-number="11.7.2">
<h3 data-number="11.7.2" class="anchored" data-anchor-id="bias-fairness-and-ancestry"><span class="header-section-number">11.7.2</span> Bias, Fairness, and Ancestry</h3>
<p>Genomic foundation models trained predominantly on reference genomes or Euro-centric cohorts risk encoding biased priors. These biases can manifest as underestimation of risk in underrepresented ancestries and misclassification of benign variants that are common in certain populations but rare in training data.</p>
<p>Deep polygenic score and variant interpretation pipelines that incorporate genomic foundation models should perform ancestry-stratified evaluation and consider explicit debiasing through reweighting and careful calibration <span class="citation" data-cites="georgantas_delphi_2024 rakowski_mifm_2025 wu_genome-wide_2024">(<a href="references.html#ref-georgantas_delphi_2024" role="doc-biblioref">Georgantas, Kutalik, and Richiardi 2024</a>; <a href="references.html#ref-rakowski_mifm_2025" role="doc-biblioref">Rakowski and Lippert 2025</a>; <a href="references.html#ref-wu_genome-wide_2024" role="doc-biblioref">Wu et al. 2024</a>)</span>.</p>
</section>
<section id="data-governance-and-privacy" class="level3" data-number="11.7.3">
<h3 data-number="11.7.3" class="anchored" data-anchor-id="data-governance-and-privacy"><span class="header-section-number">11.7.3</span> Data Governance and Privacy</h3>
<p>Because genomic foundation models are often trained on large collections of genomic sequences, data use agreements and privacy protections must be respected. Some cohort-level datasets cannot be used for unrestricted pretraining due to consent restrictions. Even when training on reference genomes, leakage from labeled clinical datasets into training may complicate downstream evaluation.</p>
<p>To date, most published genomic foundation models emphasize training on public reference genomes or synthetic benchmarks, but clinical deployment will require stronger guarantees about data provenance and privacy protection.</p>
</section>
</section>
<section id="open-challenges-and-future-directions" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="open-challenges-and-future-directions"><span class="header-section-number">11.8</span> Open Challenges and Future Directions</h2>
<p>Genomic foundation models are still in their early days, and several open challenges stand out as important directions for future work.</p>
<section id="toward-unified-multi-omic-foundation-models" class="level3" data-number="11.8.1">
<h3 data-number="11.8.1" class="anchored" data-anchor-id="toward-unified-multi-omic-foundation-models"><span class="header-section-number">11.8.1</span> Toward Unified Multi-omic Foundation Models</h3>
<p>Current genomic foundation models remain fragmented across DNA-only language models, sequence-to-function models tied to specific assays, variant-centric pathogenicity models, and protein and RNA language models. A major frontier is the development of unified multi-omic foundation models that jointly model DNA, RNA, protein, chromatin, and 3D genome structure. Such models would support cross-modal queries, enabling questions like “given this variant, what is the likely impact on transcription factor binding, chromatin accessibility, and gene expression in a specific cell type?” They would also provide interpretable pathways connecting sequence variation to phenotypes. Models like Omni-DNA represent first steps in this direction, demonstrating that multi-task, cross-modal training is feasible at scale.</p>
</section>
<section id="integrating-causal-and-mechanistic-structure" class="level3" data-number="11.8.2">
<h3 data-number="11.8.2" class="anchored" data-anchor-id="integrating-causal-and-mechanistic-structure"><span class="header-section-number">11.8.2</span> Integrating Causal and Mechanistic Structure</h3>
<p>Most genomic foundation models are trained with purely predictive objectives. Incorporating more causal structure could improve robustness to distribution shift between cell types or interventions and enable counterfactual reasoning about hypothetical perturbations like enhancer knockouts.</p>
<p>Potential routes toward more causal models include causal representation learning on top of foundation model embeddings, mechanistic constraints derived from gene regulatory networks or biochemical kinetics, and joint modeling of perturbation data from CRISPR screens or gene knockouts with observational genomics.</p>
</section>
<section id="efficient-and-accessible-deployment" class="level3" data-number="11.8.3">
<h3 data-number="11.8.3" class="anchored" data-anchor-id="efficient-and-accessible-deployment"><span class="header-section-number">11.8.3</span> Efficient and Accessible Deployment</h3>
<p>Even if genomic foundation models train on large clusters, their deployment should be feasible in typical research labs and clinical environments. Approaches to improve accessibility include distillation into smaller student models, efficient inference via sparsity, quantization, and hardware-aware architectures, and task-specific adapters that keep the frozen backbone small enough for on-premise use.</p>
<p>The long-range efficiency of architectures like HyenaDNA and the emergence of dense-attention models like Gene42 suggest multiple viable paths to deployable genomic foundation models.</p>
</section>
</section>
<section id="summary" class="level2" data-number="11.9">
<h2 data-number="11.9" class="anchored" data-anchor-id="summary"><span class="header-section-number">11.9</span> Summary</h2>
<p>This chapter has provided a framework for understanding genomic foundation models as a distinct class of computational tools for genome biology. We defined what it means for a model to be a genomic foundation model, emphasizing the properties of scale, generality, and reusability that distinguish foundation models from task-specific deep models. We proposed a practical taxonomy organizing the field into DNA language models, sequence-to-function genomic foundation models, variant-centric genomic foundation models, and emerging multi-omic models.</p>
<p>We surveyed the core design dimensions along which models differ, including data composition, architecture, training objectives, and tokenization strategies. We discussed evaluation regimes and benchmark suites that assess genomic foundation models across diverse tasks and outlined how practitioners can integrate these models into variant interpretation, regulatory genomics, and trait prediction pipelines. Finally, we highlighted emerging concerns around robustness, bias, and responsible deployment that must be addressed as these models move toward clinical applications.</p>
<p>The remaining chapters of Part IV will dive deeper into specific application domains. <a href="p3-ch12-vep.html" class="quarto-xref"><span>Chapter 13</span></a> recasts variant effect prediction in the foundation model era, examining how protein and DNA-based approaches can be combined and calibrated. <a href="p4-ch15-systems.html" class="quarto-xref"><span>Chapter 15</span></a> broadens the view from isolated sequences to multi-omic and systems-level representations, exploring models that integrate genomic, transcriptomic, proteomic, and phenotype data. Throughout, the conceptual framework established here will help organize a rapidly evolving ecosystem of genomic foundation models.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-avsec_enformer_2021" class="csl-entry" role="listitem">
Avsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. <span>“[<span>Enformer</span>] <span>Effective</span> Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.”</span> <em>Nature Methods</em> 18 (October): 1196–1203. <a href="https://doi.org/10.1038/s41592-021-01252-x">https://doi.org/10.1038/s41592-021-01252-x</a>.
</div>
<div id="ref-benegas_traitgym_2025" class="csl-entry" role="listitem">
Benegas, Gonzalo, Gökcen Eraslan, and Yun S. Song. 2025. <span>“[<span>TraitGym</span>] <span>Benchmarking</span> <span>DNA</span> <span>Sequence</span> <span>Models</span> for <span>Causal</span> <span>Regulatory</span> <span>Variant</span> <span>Prediction</span> in <span>Human</span> <span>Genetics</span>.”</span> bioRxiv. <a href="https://doi.org/10.1101/2025.02.11.637758">https://doi.org/10.1101/2025.02.11.637758</a>.
</div>
<div id="ref-brandes_genome-wide_2023" class="csl-entry" role="listitem">
Brandes, Nadav, Grant Goldman, Charlotte H. Wang, Chun Jimmie Ye, and Vasilis Ntranos. 2023. <span>“Genome-Wide Prediction of Disease Variant Effects with a Deep Protein Language Model.”</span> <em>Nature Genetics</em> 55 (9): 1512–22. <a href="https://doi.org/10.1038/s41588-023-01465-0">https://doi.org/10.1038/s41588-023-01465-0</a>.
</div>
<div id="ref-chen_deepsea_2022" class="csl-entry" role="listitem">
Chen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. <span>“[<span>DeepSEA</span> <span>Sei</span>] <span>A</span> Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.”</span> <em>Nature Genetics</em> 54 (7): 940–49. <a href="https://doi.org/10.1038/s41588-022-01102-2">https://doi.org/10.1038/s41588-022-01102-2</a>.
</div>
<div id="ref-cheng_alphamissense_2023" class="csl-entry" role="listitem">
Cheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. <span>“[<span>AlphaMissense</span>] <span>Accurate</span> Proteome-Wide Missense Variant Effect Prediction with <span>AlphaMissense</span>.”</span> <em>Science</em> 381 (6664): eadg7492. <a href="https://doi.org/10.1126/science.adg7492">https://doi.org/10.1126/science.adg7492</a>.
</div>
<div id="ref-dalla-torre_nucleotide_2023" class="csl-entry" role="listitem">
Dalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. <span>“Nucleotide <span>Transformer</span>: Building and Evaluating Robust Foundation Models for Human Genomics.”</span> <em>Nature Methods</em> 22 (2): 287–97. <a href="https://doi.org/10.1038/s41592-024-02523-z">https://doi.org/10.1038/s41592-024-02523-z</a>.
</div>
<div id="ref-georgantas_delphi_2024" class="csl-entry" role="listitem">
Georgantas, Costa, Zoltán Kutalik, and Jonas Richiardi. 2024. <span>“Delphi: <span>A</span> <span>Deep</span>-Learning <span>Method</span> for <span>Polygenic</span> <span>Risk</span> <span>Prediction</span>.”</span> medRxiv. <a href="https://doi.org/10.1101/2024.04.19.24306079">https://doi.org/10.1101/2024.04.19.24306079</a>.
</div>
<div id="ref-jaganathan_spliceai_2019" class="csl-entry" role="listitem">
Jaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. <span>“[<span>SpliceAI</span>] <span>Predicting</span> <span>Splicing</span> from <span>Primary</span> <span>Sequence</span> with <span>Deep</span> <span>Learning</span>.”</span> <em>Cell</em> 176 (3): 535–548.e24. <a href="https://doi.org/10.1016/j.cell.2018.12.015">https://doi.org/10.1016/j.cell.2018.12.015</a>.
</div>
<div id="ref-ji_dnabert_2021" class="csl-entry" role="listitem">
Ji, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. <span>“<span>DNABERT</span>: Pre-Trained <span>Bidirectional</span> <span>Encoder</span> <span>Representations</span> from <span>Transformers</span> Model for <span>DNA</span>-Language in Genome.”</span> <em>Bioinformatics</em> 37 (15): 2112–20. <a href="https://doi.org/10.1093/bioinformatics/btab083">https://doi.org/10.1093/bioinformatics/btab083</a>.
</div>
<div id="ref-lin_esm-2_2022" class="csl-entry" role="listitem">
Lin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, et al. 2022. <span>“[<span>ESM</span>-2] <span>Language</span> Models of Protein Sequences at the Scale of Evolution Enable Accurate Structure Prediction.”</span> bioRxiv. <a href="https://doi.org/10.1101/2022.07.20.500902">https://doi.org/10.1101/2022.07.20.500902</a>.
</div>
<div id="ref-manzo_comparative_2025" class="csl-entry" role="listitem">
Manzo, Gaetano, Kathryn Borkowski, and Ivan Ovcharenko. 2025. <span>“Comparative <span>Analysis</span> of <span>Deep</span> <span>Learning</span> <span>Models</span> for <span>Predicting</span> <span>Causative</span> <span>Regulatory</span> <span>Variants</span>.”</span> <em>bioRxiv: The Preprint Server for Biology</em>, June, 2025.05.19.654920. <a href="https://doi.org/10.1101/2025.05.19.654920">https://doi.org/10.1101/2025.05.19.654920</a>.
</div>
<div id="ref-medvedev_biotoken_2025" class="csl-entry" role="listitem">
Medvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. <span>“<span>BioToken</span> and <span>BioFM</span> – <span>Biologically</span>-<span>Informed</span> <span>Tokenization</span> <span>Enables</span> <span>Accurate</span> and <span>Efficient</span> <span>Genomic</span> <span>Foundation</span> <span>Models</span>.”</span> bioRxiv. <a href="https://doi.org/10.1101/2025.03.27.645711">https://doi.org/10.1101/2025.03.27.645711</a>.
</div>
<div id="ref-nguyen_hyenadna_2023" class="csl-entry" role="listitem">
Nguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. <span>“<span>HyenaDNA</span>: <span>Long</span>-<span>Range</span> <span>Genomic</span> <span>Sequence</span> <span>Modeling</span> at <span>Single</span> <span>Nucleotide</span> <span>Resolution</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2306.15794">https://doi.org/10.48550/arXiv.2306.15794</a>.
</div>
<div id="ref-notin_proteingym_2023" class="csl-entry" role="listitem">
Notin, Pascal, Aaron Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, et al. 2023. <span>“<span>ProteinGym</span>: <span>Large</span>-<span>Scale</span> <span>Benchmarks</span> for <span>Protein</span> <span>Fitness</span> <span>Prediction</span> and <span>Design</span>.”</span> <em>Advances in Neural Information Processing Systems</em> 36 (December): 64331–79. <a href="https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html">https://papers.nips.cc/paper_files/paper/2023/hash/cac723e5ff29f65e3fcbb0739ae91bee-Abstract-Datasets_and_Benchmarks.html</a>.
</div>
<div id="ref-rakowski_mifm_2025" class="csl-entry" role="listitem">
Rakowski, Alexander, and Christoph Lippert. 2025. <span>“[<span>MIFM</span>] <span>Multiple</span> Instance Fine-Mapping: Predicting Causal Regulatory Variants with a Deep Sequence Model.”</span> medRxiv. <a href="https://doi.org/10.1101/2025.06.13.25329551">https://doi.org/10.1101/2025.06.13.25329551</a>.
</div>
<div id="ref-rentzsch_cadd_2019" class="csl-entry" role="listitem">
Rentzsch, Philipp, Daniela Witten, Gregory M Cooper, Jay Shendure, and Martin Kircher. 2019. <span>“<span>CADD</span>: Predicting the Deleteriousness of Variants Throughout the Human Genome.”</span> <em>Nucleic Acids Research</em> 47 (D1): D886–94. <a href="https://doi.org/10.1093/nar/gky1016">https://doi.org/10.1093/nar/gky1016</a>.
</div>
<div id="ref-rives_esm_2021" class="csl-entry" role="listitem">
Rives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. <span>“[<span>ESM</span>-1b] <span>Biological</span> Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.”</span> <em>Proceedings of the National Academy of Sciences of the United States of America</em> 118 (15): e2016239118. <a href="https://doi.org/10.1073/pnas.2016239118">https://doi.org/10.1073/pnas.2016239118</a>.
</div>
<div id="ref-sanabria_grover_2024" class="csl-entry" role="listitem">
Sanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. <span>“[<span>GROVER</span>] <span>DNA</span> Language Model <span>GROVER</span> Learns Sequence Context in the Human Genome.”</span> <em>Nature Machine Intelligence</em> 6 (8): 911–23. <a href="https://doi.org/10.1038/s42256-024-00872-0">https://doi.org/10.1038/s42256-024-00872-0</a>.
</div>
<div id="ref-schubach_cadd_2024" class="csl-entry" role="listitem">
Schubach, Max, Thorben Maass, Lusiné Nazaretyan, Sebastian Röner, and Martin Kircher. 2024. <span>“<span>CADD</span> V1.7: Using Protein Language Models, Regulatory <span>CNNs</span> and Other Nucleotide-Level Scores to Improve Genome-Wide Variant Predictions.”</span> <em>Nucleic Acids Research</em> 52 (D1): D1143–54. <a href="https://doi.org/10.1093/nar/gkad989">https://doi.org/10.1093/nar/gkad989</a>.
</div>
<div id="ref-wu_genome-wide_2024" class="csl-entry" role="listitem">
Wu, Yang, Zhili Zheng, Loic Thibaut2, Michael E. Goddard, Naomi R. Wray, Peter M. Visscher, and Jian Zeng. 2024. <span>“Genome-Wide Fine-Mapping Improves Identification of Causal Variants.”</span> <em>Research Square</em>, August, rs.3.rs–4759390. <a href="https://doi.org/10.21203/rs.3.rs-4759390/v1">https://doi.org/10.21203/rs.3.rs-4759390/v1</a>.
</div>
<div id="ref-zheng_cistrome_2019" class="csl-entry" role="listitem">
Zheng, Rongbin, Changxin Wan, Shenglin Mei, Qian Qin, Qiu Wu, Hanfei Sun, Chen-Hao Chen, et al. 2019. <span>“Cistrome <span>Data</span> <span>Browser</span>: Expanded Datasets and New Tools for Gene Regulatory Analysis.”</span> <em>Nucleic Acids Research</em> 47 (D1): D729–35. <a href="https://doi.org/10.1093/nar/gky1094">https://doi.org/10.1093/nar/gky1094</a>.
</div>
<div id="ref-zhou_expecto_2018" class="csl-entry" role="listitem">
Zhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. <span>“[<span>Expecto</span>] <span>Deep</span> Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.”</span> <em>Nature Genetics</em> 50 (8): 1171–79. <a href="https://doi.org/10.1038/s41588-018-0160-6">https://doi.org/10.1038/s41588-018-0160-6</a>.
</div>
<div id="ref-zhou_deepsea_2015" class="csl-entry" role="listitem">
Zhou, Jian, and Olga G. Troyanskaya. 2015. <span>“[<span>DeepSEA</span>] <span>Predicting</span> Effects of Noncoding Variants with Deep Learning–Based Sequence Model.”</span> <em>Nature Methods</em> 12 (10): 931–34. <a href="https://doi.org/10.1038/nmeth.3547">https://doi.org/10.1038/nmeth.3547</a>.
</div>
<div id="ref-zhou_dnabert-2_2024" class="csl-entry" role="listitem">
Zhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. <span>“<span>DNABERT</span>-2: <span>Efficient</span> <span>Foundation</span> <span>Model</span> and <span>Benchmark</span> <span>For</span> <span>Multi</span>-<span>Species</span> <span>Genome</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2306.15006">https://doi.org/10.48550/arXiv.2306.15006</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./p3-ch10-tokens.html" class="pagination-link" aria-label="Sequence Representation &amp; Tokens">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./p3-ch12-vep.html" class="pagination-link" aria-label="Cross-Protein Transfer from Deep Mutational Scanning">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Cross-Protein Transfer from Deep Mutational Scanning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>