<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>18&nbsp; Variant Effect Prediction – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../part_5/p5--cellular-context.html" rel="next">
<link href="../part_4/p4-ch17-regulatory.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_4/p4--fm-families.html">Part IV: Foundation Model Families</a></li><li class="breadcrumb-item"><a href="../part_4/p4-ch18-vep-fm.html"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_1/p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Data Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch03-gwas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS and Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch04-vep-classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classical Variant Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_2/p2--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch05-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Tokens and Embeddings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch06-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Convolutional Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch07-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transformers and Attention</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_3/p3--learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Learning &amp; Evaluation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch08-pretraining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning Foundations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch10-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Adaptation Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch11-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmark Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch12-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Evaluation Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch13-confounding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Confounding and Data Leakage</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_4/p4--fm-families.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Foundation Model Families</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch14-fm-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Foundation Model Paradigm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch15-dna-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">DNA Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch16-protein-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch17-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Regulatory Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch18-vep-fm.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_5/p5--cellular-context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Cellular Context</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch19-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">RNA Structure and Function</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch20-single-cell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Single-Cell Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch21-3d-genome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">3D Genome Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch22-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Graph and Network Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch23-multi-omics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_6/p6--responsible-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI: Responsible Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch24-uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch25-interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch26-causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Causality</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch27-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regulatory and Governance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_7/p7--applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VII: Applications &amp; Frontiers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch28-clinical-risk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch29-rare-disease.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Rare Disease Diagnosis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch30-drug-discovery.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Drug Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch31-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Sequence Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch32-frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Frontiers and Synthesis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bib/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-b-compute.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Deployment and Compute</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-c-data-curation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Data Curation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-d-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Model Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-e-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-f-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-ch18-fm-paradigm" id="toc-sec-ch18-fm-paradigm" class="nav-link active" data-scroll-target="#sec-ch18-fm-paradigm"><span class="header-section-number">18.1</span> Foundation Model Paradigm for Variant Interpretation</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-zeroshot-supervised" id="toc-sec-ch18-zeroshot-supervised" class="nav-link" data-scroll-target="#sec-ch18-zeroshot-supervised"><span class="header-section-number">18.1.1</span> Zero-Shot and Supervised Approaches</a></li>
  </ul></li>
  <li><a href="#sec-ch18-protein-vep" id="toc-sec-ch18-protein-vep" class="nav-link" data-scroll-target="#sec-ch18-protein-vep"><span class="header-section-number">18.2</span> Protein-Based Variant Effect Prediction</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-zeroshot-plm" id="toc-sec-ch18-zeroshot-plm" class="nav-link" data-scroll-target="#sec-ch18-zeroshot-plm"><span class="header-section-number">18.2.1</span> Zero-Shot Scoring with Protein Language Models</a></li>
  <li><a href="#sec-ch18-alignment-models" id="toc-sec-ch18-alignment-models" class="nav-link" data-scroll-target="#sec-ch18-alignment-models"><span class="header-section-number">18.2.2</span> Alignment-Based Models: EVE and popEVE</a></li>
  <li><a href="#sec-ch18-alphamissense" id="toc-sec-ch18-alphamissense" class="nav-link" data-scroll-target="#sec-ch18-alphamissense"><span class="header-section-number">18.2.3</span> AlphaMissense: Structure-Informed Pathogenicity Prediction</a></li>
  </ul></li>
  <li><a href="#sec-ch18-dna-vep" id="toc-sec-ch18-dna-vep" class="nav-link" data-scroll-target="#sec-ch18-dna-vep"><span class="header-section-number">18.3</span> DNA-Based Variant Effect Prediction</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-spliceai" id="toc-sec-ch18-spliceai" class="nav-link" data-scroll-target="#sec-ch18-spliceai"><span class="header-section-number">18.3.1</span> Splice Variant Prediction with SpliceAI</a></li>
  <li><a href="#sec-ch18-enformer-vep" id="toc-sec-ch18-enformer-vep" class="nav-link" data-scroll-target="#sec-ch18-enformer-vep"><span class="header-section-number">18.3.2</span> Regulatory Variant Prediction with Enformer</a></li>
  <li><a href="#sec-ch18-dna-lm-vep" id="toc-sec-ch18-dna-lm-vep" class="nav-link" data-scroll-target="#sec-ch18-dna-lm-vep"><span class="header-section-number">18.3.3</span> DNA Language Models: GPN-MSA and Evo 2</a></li>
  <li><a href="#sec-ch18-alphagenome" id="toc-sec-ch18-alphagenome" class="nav-link" data-scroll-target="#sec-ch18-alphagenome"><span class="header-section-number">18.3.4</span> AlphaGenome: Unified Multi-Omic Variant Effect Prediction</a></li>
  </ul></li>
  <li><a href="#sec-ch18-combining-evidence" id="toc-sec-ch18-combining-evidence" class="nav-link" data-scroll-target="#sec-ch18-combining-evidence"><span class="header-section-number">18.4</span> Combining Evidence Across Modalities</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-integration-strategies" id="toc-sec-ch18-integration-strategies" class="nav-link" data-scroll-target="#sec-ch18-integration-strategies"><span class="header-section-number">18.4.1</span> Integration Strategies</a></li>
  <li><a href="#sec-ch18-double-counting" id="toc-sec-ch18-double-counting" class="nav-link" data-scroll-target="#sec-ch18-double-counting"><span class="header-section-number">18.4.2</span> Avoiding Double-Counting</a></li>
  <li><a href="#sec-ch18-workflow-design" id="toc-sec-ch18-workflow-design" class="nav-link" data-scroll-target="#sec-ch18-workflow-design"><span class="header-section-number">18.4.3</span> Practical Workflow Design</a></li>
  </ul></li>
  <li><a href="#sec-ch18-calibration" id="toc-sec-ch18-calibration" class="nav-link" data-scroll-target="#sec-ch18-calibration"><span class="header-section-number">18.5</span> Calibration and Clinical Categories</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-assessing-calibration" id="toc-sec-ch18-assessing-calibration" class="nav-link" data-scroll-target="#sec-ch18-assessing-calibration"><span class="header-section-number">18.5.1</span> Assessing Calibration</a></li>
  <li><a href="#sec-ch18-calibration-methods" id="toc-sec-ch18-calibration-methods" class="nav-link" data-scroll-target="#sec-ch18-calibration-methods"><span class="header-section-number">18.5.2</span> Calibration Methods for Variant Effect Prediction</a></li>
  <li><a href="#sec-ch18-acmg-mapping" id="toc-sec-ch18-acmg-mapping" class="nav-link" data-scroll-target="#sec-ch18-acmg-mapping"><span class="header-section-number">18.5.3</span> Mapping to ACMG Categories</a></li>
  <li><a href="#sec-ch18-vus-challenge" id="toc-sec-ch18-vus-challenge" class="nav-link" data-scroll-target="#sec-ch18-vus-challenge"><span class="header-section-number">18.5.4</span> The Challenge of Uncertain Significance</a></li>
  </ul></li>
  <li><a href="#sec-ch18-uncertainty" id="toc-sec-ch18-uncertainty" class="nav-link" data-scroll-target="#sec-ch18-uncertainty"><span class="header-section-number">18.6</span> Uncertainty Quantification</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-uncertainty-sources" id="toc-sec-ch18-uncertainty-sources" class="nav-link" data-scroll-target="#sec-ch18-uncertainty-sources"><span class="header-section-number">18.6.1</span> Sources of Uncertainty</a></li>
  <li><a href="#sec-ch18-uncertainty-methods" id="toc-sec-ch18-uncertainty-methods" class="nav-link" data-scroll-target="#sec-ch18-uncertainty-methods"><span class="header-section-number">18.6.2</span> Uncertainty Estimation Methods</a></li>
  <li><a href="#sec-ch18-ood-detection" id="toc-sec-ch18-ood-detection" class="nav-link" data-scroll-target="#sec-ch18-ood-detection"><span class="header-section-number">18.6.3</span> Out-of-Distribution Detection</a></li>
  </ul></li>
  <li><a href="#sec-ch18-fm-gains" id="toc-sec-ch18-fm-gains" class="nav-link" data-scroll-target="#sec-ch18-fm-gains"><span class="header-section-number">18.7</span> What Foundation Models Add</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-improved-discrimination" id="toc-sec-ch18-improved-discrimination" class="nav-link" data-scroll-target="#sec-ch18-improved-discrimination"><span class="header-section-number">18.7.1</span> Improved Discrimination</a></li>
  <li><a href="#sec-ch18-extended-coverage" id="toc-sec-ch18-extended-coverage" class="nav-link" data-scroll-target="#sec-ch18-extended-coverage"><span class="header-section-number">18.7.2</span> Extended Coverage</a></li>
  <li><a href="#sec-ch18-mechanistic-interpretability" id="toc-sec-ch18-mechanistic-interpretability" class="nav-link" data-scroll-target="#sec-ch18-mechanistic-interpretability"><span class="header-section-number">18.7.3</span> Mechanistic Interpretability</a></li>
  <li><a href="#sec-ch18-persistent-limitations" id="toc-sec-ch18-persistent-limitations" class="nav-link" data-scroll-target="#sec-ch18-persistent-limitations"><span class="header-section-number">18.7.4</span> Persistent Limitations</a></li>
  </ul></li>
  <li><a href="#sec-ch18-clinical-integration" id="toc-sec-ch18-clinical-integration" class="nav-link" data-scroll-target="#sec-ch18-clinical-integration"><span class="header-section-number">18.8</span> Clinical Integration Considerations</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-lab-validation" id="toc-sec-ch18-lab-validation" class="nav-link" data-scroll-target="#sec-ch18-lab-validation"><span class="header-section-number">18.8.1</span> Laboratory Validation</a></li>
  <li><a href="#sec-ch18-workflow-integration" id="toc-sec-ch18-workflow-integration" class="nav-link" data-scroll-target="#sec-ch18-workflow-integration"><span class="header-section-number">18.8.2</span> Workflow Integration</a></li>
  <li><a href="#sec-ch18-clinical-communication" id="toc-sec-ch18-clinical-communication" class="nav-link" data-scroll-target="#sec-ch18-clinical-communication"><span class="header-section-number">18.8.3</span> Communication to Clinicians</a></li>
  </ul></li>
  <li><a href="#sec-ch18-open-challenges" id="toc-sec-ch18-open-challenges" class="nav-link" data-scroll-target="#sec-ch18-open-challenges"><span class="header-section-number">18.9</span> Open Challenges</a>
  <ul class="collapse">
  <li><a href="#sec-ch18-complex-variants" id="toc-sec-ch18-complex-variants" class="nav-link" data-scroll-target="#sec-ch18-complex-variants"><span class="header-section-number">18.9.1</span> Complex Variant Types</a></li>
  <li><a href="#sec-ch18-long-read" id="toc-sec-ch18-long-read" class="nav-link" data-scroll-target="#sec-ch18-long-read"><span class="header-section-number">18.9.2</span> Long-Read Sequencing and Variant Effect Prediction</a></li>
  <li><a href="#sec-ch18-combinatorial" id="toc-sec-ch18-combinatorial" class="nav-link" data-scroll-target="#sec-ch18-combinatorial"><span class="header-section-number">18.9.3</span> Combinatorial Effects</a></li>
  <li><a href="#sec-ch18-phenotype-specificity" id="toc-sec-ch18-phenotype-specificity" class="nav-link" data-scroll-target="#sec-ch18-phenotype-specificity"><span class="header-section-number">18.9.4</span> Phenotype Specificity</a></li>
  <li><a href="#sec-ch18-temporal-context" id="toc-sec-ch18-temporal-context" class="nav-link" data-scroll-target="#sec-ch18-temporal-context"><span class="header-section-number">18.9.5</span> Temporal and Environmental Context</a></li>
  <li><a href="#sec-ch18-equity" id="toc-sec-ch18-equity" class="nav-link" data-scroll-target="#sec-ch18-equity"><span class="header-section-number">18.9.6</span> Equity and Access</a></li>
  </ul></li>
  <li><a href="#sec-ch18-conclusion" id="toc-sec-ch18-conclusion" class="nav-link" data-scroll-target="#sec-ch18-conclusion"><span class="header-section-number">18.10</span> Tools for Interpretation, Not Oracles</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_4/p4--fm-families.html">Part IV: Foundation Model Families</a></li><li class="breadcrumb-item"><a href="../part_4/p4-ch18-vep-fm.html"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ch18-vep-fm" class="quarto-section-identifier"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>The variants that matter most are the variants we have never seen before.</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled" title="Chapter Overview">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Estimated reading time:</strong> 50-60 minutes</p>
<p><strong>Prerequisites:</strong> Before reading this chapter, you should be familiar with:</p>
<ul>
<li>Classical variant effect prediction approaches (<a href="../part_1/p1-ch04-vep-classical.html" class="quarto-xref"><span>Chapter 4</span></a>)</li>
<li>Protein language model architectures and training objectives (<a href="p4-ch16-protein-lm.html" class="quarto-xref"><span>Chapter 16</span></a>)</li>
<li>DNA language models and their representations (<a href="p4-ch15-dna-lm.html" class="quarto-xref"><span>Chapter 15</span></a>)</li>
<li>Regulatory genomics models like <em>Enformer</em> (<a href="p4-ch17-regulatory.html" class="quarto-xref"><span>Chapter 17</span></a>)</li>
<li>Basic understanding of the ACMG variant classification framework</li>
</ul>
<p><strong>Learning Objectives:</strong> After completing this chapter, you will be able to:</p>
<ol type="1">
<li>Explain how foundation models enable zero-shot variant effect prediction without pathogenicity labels</li>
<li>Compare protein-based approaches (<em>ESM-1v</em>, <em>EVE</em>, <em>AlphaMissense</em>) with DNA-based approaches (<em>SpliceAI</em>, <em>Enformer</em>, <em>GPN-MSA</em>)</li>
<li>Compute variant effect scores from language model likelihoods using masked marginal and pseudo-likelihood methods</li>
<li>Assess model calibration using reliability diagrams and apply appropriate thresholds for ACMG classification</li>
<li>Design multi-model VEP workflows that combine evidence across variant types while avoiding double-counting</li>
<li>Identify when foundation model predictions warrant high confidence versus when additional evidence is essential</li>
</ol>
<p><strong>Chapter roadmap:</strong> We begin with the paradigm shift from feature engineering to representation learning, then explore protein-based and DNA-based approaches in detail. The second half addresses practical deployment: combining evidence, calibration, uncertainty quantification, and the persistent limitations that require clinical judgment.</p>
</div>
</div>
<p>Classical variant effect prediction required labels: pathogenic variants to define one class, benign variants to define another, and enough examples of each to train a classifier. This requirement created a fundamental bottleneck. The variants most important to classify—those that are rare, never before observed, and located in poorly characterized genes—were precisely those for which labels did not exist. Foundation models offer a different paradigm: score variants using patterns learned from unlabeled sequences, without ever seeing a pathogenic/benign label during pretraining. A protein language model trained only to predict masked amino acids can distinguish damaging substitutions from benign polymorphisms because evolution has already encoded this distinction in the sequences that survived. A DNA language model can identify regulatory disruptions because it learned the grammar of functional elements from billions of nucleotides. The variants that violate learned patterns are the variants that disrupt function.</p>
<p>This zero-shot capability does not eliminate the need for labeled data but changes its role. Rather than training classifiers from scratch, practitioners fine-tune foundation models on modest variant datasets, leveraging pretrained knowledge to achieve performance impossible for models that start from random initialization. The combination of self-supervised pretraining and supervised fine-tuning produces variant effect predictors that outperform classical methods across most benchmarks while requiring far less task-specific data. <em>AlphaMissense</em>, <em>ESM-1v</em>, and similar systems demonstrate that foundation model representations capture variant effects across protein families, including families with no labeled variants in training data.</p>
<p>Yet significant challenges remain. Foundation models predict that variants are damaging without explaining why. Calibration varies across variant types, protein families, and populations, creating uncertainty about when predictions can be trusted. The distinction between “evolutionarily unusual” and “clinically pathogenic” is real: not every rare substitution causes disease, and not every disease-causing variant appears evolutionarily constrained.</p>
<section id="sec-ch18-fm-paradigm" class="level2" data-number="18.1">
<h2 data-number="18.1" class="anchored" data-anchor-id="sec-ch18-fm-paradigm"><span class="header-section-number">18.1</span> Foundation Model Paradigm for Variant Interpretation</h2>
<p>Classical variant effect predictors operate by aggregating hand-crafted features: conservation scores computed from multiple sequence alignments, amino acid property changes, protein domain annotations, and regulatory marks at genomic loci (<a href="../part_1/p1-ch04-vep-classical.html" class="quarto-xref"><span>Chapter 4</span></a>). Methods like <em>CADD</em> train machine learning models to distinguish pathogenic from benign variants using these features, achieving useful discrimination but ultimately limited by what features the developers chose to include. When a variant falls in a region poorly covered by existing annotations, classical methods have little to offer.</p>
<p>Foundation models invert this relationship. Rather than engineering features, they learn representations from raw sequence data during pretraining, then apply those representations to variant interpretation. A protein language model trained to predict masked amino acids implicitly learns which substitutions violate evolutionary constraints. A DNA language model trained to predict nucleotides in genomic context learns which changes disrupt sequence grammar. The representations encode information about structure, function, and constraint that was never explicitly labeled during training.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Key Insight: Evolution as a Massive Experiment">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: Evolution as a Massive Experiment
</div>
</div>
<div class="callout-body-container callout-body">
<p>Foundation models exploit a profound insight: evolution has already conducted billions of “experiments” testing which sequence variants are compatible with life. Protein sequences that survived natural selection represent the “passing” experiments; variants never observed in homologous proteins failed these tests. By learning to predict which amino acids or nucleotides are probable at each position, foundation models implicitly learn what evolution has permitted and, by contrast, what it has rejected. This is why a model trained only on masked token prediction can score variant pathogenicity without ever seeing disease labels.</p>
</div>
</div>
<p>This paradigm shift has practical consequences. Coverage extends to any variant in any gene, not just those with extensive prior annotation. Representations capture subtle patterns (co-evolution between distant residues, context-dependent motif strength) that resist manual feature engineering. <strong>Transfer learning</strong> enables rapid adaptation to new tasks and variant classes, with the specific strategies detailed in <a href="../part_3/p3-ch09-transfer.html" class="quarto-xref"><span>Chapter 9</span></a>. The cost is interpretability: understanding why a foundation model assigns a particular score requires specialized analysis techniques rather than simple inspection of feature weights (<a href="../part_6/p6-ch25-interpretability.html" class="quarto-xref"><span>Chapter 25</span></a>).</p>
<p>Three architectural families dominate current VEP applications. Protein language models (<a href="p4-ch16-protein-lm.html" class="quarto-xref"><span>Chapter 16</span></a>) encode amino acid sequences and score missense variants by measuring likelihood changes. DNA language models (<a href="p4-ch15-dna-lm.html" class="quarto-xref"><span>Chapter 15</span></a>) operate on nucleotide sequences and can score variants of any type. Regulatory models (<a href="p4-ch17-regulatory.html" class="quarto-xref"><span>Chapter 17</span></a>) predict molecular phenotypes (chromatin accessibility, gene expression, splicing) and score variants by their predicted impact on these phenotypes. The strongest-performing systems combine elements from multiple families.</p>
<div id="tbl-vep-approaches" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-vep-approaches-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;18.1: Comparison of foundation model approaches for variant effect prediction. Each approach offers distinct advantages depending on the variant type and desired output.
</figcaption>
<div aria-describedby="tbl-vep-approaches-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 10%">
<col style="width: 21%">
<col style="width: 18%">
<col style="width: 15%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Input</th>
<th>Variant Types</th>
<th>Key Methods</th>
<th>Strengths</th>
<th>Limitations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Protein LM</td>
<td>Amino acid sequence</td>
<td>Missense</td>
<td><em>ESM-1v</em>, <em>EVE</em>, <em>AlphaMissense</em></td>
<td>Captures evolutionary constraint, structural context</td>
<td>Coding only, requires translation</td>
</tr>
<tr class="even">
<td>DNA LM</td>
<td>Nucleotide sequence</td>
<td>All (SNV, indel, noncoding)</td>
<td><em>GPN-MSA</em>, <em>Evo 2</em></td>
<td>Genome-wide coverage</td>
<td>Less protein-specific information</td>
</tr>
<tr class="odd">
<td>Regulatory</td>
<td>DNA + epigenomic context</td>
<td>Noncoding, regulatory</td>
<td><em>Enformer</em>, <em>Sei</em>, <em>AlphaGenome</em></td>
<td>Mechanistic predictions</td>
<td>Cell-type specificity, calibration</td>
</tr>
<tr class="even">
<td>Structure-aware</td>
<td>Sequence + 3D structure</td>
<td>Missense</td>
<td><em>AlphaMissense</em></td>
<td>Explains why constraint exists</td>
<td>Requires structure prediction</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="fig-fm-vep-paradigm" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fm-vep-paradigm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/01-A-fig-fm-vep-paradigm.svg" class="img-fluid figure-img"></p>
<figcaption>Zero-shot scoring from PLM likelihoods</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/01-B-fig-fm-vep-paradigm.svg" class="img-fluid figure-img"></p>
<figcaption>Linear probing with frozen embeddings</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/01-C-fig-fm-vep-paradigm.svg" class="img-fluid figure-img"></p>
<figcaption>Full fine-tuning for maximum performance</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/01-D-fig-fm-vep-paradigm.svg" class="img-fluid figure-img"></p>
<figcaption>Multi-modal integration of sequence and structure</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fm-vep-paradigm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18.1: Foundation model paradigms for variant effect prediction. (A) Zero-shot scoring uses pretrained likelihoods directly, requiring no task-specific data but limited to what pretraining captured. (B) Linear probing adds a simple classifier on frozen embeddings, requiring minimal labeled data. (C) Full fine-tuning updates all parameters, achieving best performance but requiring substantial labeled data. (D) Multi-modal integration combines sequence (evolutionary) and structure information for comprehensive variant assessment. The appropriate paradigm depends on available labeled data and whether structure contributes to the variant’s effect mechanism.
</figcaption>
</figure>
</div>
<section id="sec-ch18-zeroshot-supervised" class="level3" data-number="18.1.1">
<h3 data-number="18.1.1" class="anchored" data-anchor-id="sec-ch18-zeroshot-supervised"><span class="header-section-number">18.1.1</span> Zero-Shot and Supervised Approaches</h3>
<p>Foundation model VEP methods divide into two paradigms. Zero-shot approaches apply pretrained models directly without task-specific training: <em>ESM-1v</em> scores variants by comparing amino acid likelihoods, requiring no pathogenicity labels. Think of it like a spell-checker that flags words it has never seen in well-edited text—it does not need a dictionary of “misspellings” because any word that looks unusual compared to normal usage stands out as potentially wrong. Similarly, the model’s pretraining objective (masked token prediction) implicitly teaches which substitutions violate evolutionary constraints by learning what “well-edited” (evolutionarily tested) sequences look like. Supervised approaches like <em>AlphaMissense</em> add task-specific training layers and optimize explicitly for pathogenicity prediction using labeled examples.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Stop and Think: Zero-Shot vs. Supervised Trade-offs">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think: Zero-Shot vs.&nbsp;Supervised Trade-offs
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before reading further, consider: If zero-shot methods avoid the biases present in labeled training data, why would anyone use supervised approaches at all? What advantages might supervised fine-tuning provide, and when might those advantages outweigh the risk of inheriting label biases?</p>
</div>
</div>
<p>The choice involves tradeoffs. Zero-shot methods avoid label bias entirely; they cannot learn to recapitulate existing predictor scores because they never see those scores during training. Supervised methods achieve stronger discrimination when high-quality labels exist but risk inheriting biases from training data. Zero-shot approaches generalize more reliably to novel proteins outside training distributions; supervised methods may overfit to well-studied gene families. In practice, the strongest current systems (<em>AlphaMissense</em>, <em>popEVE</em>) combine foundation model representations with some supervised adaptation, attempting to capture benefits of both paradigms.</p>
</section>
</section>
<section id="sec-ch18-protein-vep" class="level2" data-number="18.2">
<h2 data-number="18.2" class="anchored" data-anchor-id="sec-ch18-protein-vep"><span class="header-section-number">18.2</span> Protein-Based Variant Effect Prediction</h2>
<p>Missense variants (single amino acid substitutions) account for approximately half of known pathogenic variants in ClinVar, making protein-level prediction a central challenge <em>[Citation Needed]</em>. Foundation model approaches exploit a simple insight: evolution has already tested billions of amino acid substitutions across millions of years; variants that repeatedly survive natural selection are likely tolerable, while those never observed in homologous proteins likely disrupt function.</p>
<section id="sec-ch18-zeroshot-plm" class="level3" data-number="18.2.1">
<h3 data-number="18.2.1" class="anchored" data-anchor-id="sec-ch18-zeroshot-plm"><span class="header-section-number">18.2.1</span> Zero-Shot Scoring with Protein Language Models</h3>
<p>The simplest foundation model approach to missense VEP requires no task-specific training. A protein language model trained on masked token prediction assigns probabilities to each amino acid at each position given surrounding context. Variant effect scores emerge from comparing the probability of the reference amino acid to the probability of the variant amino acid.</p>
<p><em>ESM-1v</em> operationalizes this approach using the <em>ESM-2</em> architecture fine-tuned for single-sequence variant effect prediction <span class="citation" data-cites="meier_esm-1v_2021">(<a href="../bib/references.html#ref-meier_esm-1v_2021" role="doc-biblioref">Meier et al. 2021</a>)</span>. For a variant substituting amino acid <span class="math inline">\(a_\text{ref}\)</span> with <span class="math inline">\(a_\text{var}\)</span> at position <em>i</em>, the score is computed as:</p>
<p><span id="eq-18-01"><span class="math display">\[
\Delta \text{LLR} = \log P(\text{aa}_{\text{alt}} \mid \mathbf{x}_{-i}) - \log P(\text{aa}_{\text{ref}} \mid \mathbf{x}_{-i})
\tag{18.1}\]</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\text{aa}_{\text{ref}}\)</span> is the reference (wild-type) amino acid at position <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\text{aa}_{\text{alt}}\)</span> is the variant (mutant) amino acid</li>
<li><span class="math inline">\(\mathbf{x}_{-i}\)</span> is the protein sequence with position <span class="math inline">\(i\)</span> masked</li>
<li>Negative <span class="math inline">\(\Delta\text{LLR}\)</span> indicates the variant is evolutionarily disfavored (predicted deleterious)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Worked Example: Computing LLR Variant Scores">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Worked Example: Computing LLR Variant Scores
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a missense variant in <em>BRCA1</em> that substitutes leucine (L) with proline (P) at position 1780.</p>
<p><strong>Step 1:</strong> The protein language model examines the sequence context around position 1780 and predicts probabilities for each amino acid at that position:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Amino Acid</th>
<th>Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Leucine (L, reference)</td>
<td>0.35</td>
</tr>
<tr class="even">
<td>Proline (P, variant)</td>
<td>0.02</td>
</tr>
<tr class="odd">
<td>Isoleucine (I)</td>
<td>0.28</td>
</tr>
<tr class="even">
<td>Other residues</td>
<td>0.35</td>
</tr>
</tbody>
</table>
<p><strong>Step 2:</strong> Compute the log-likelihood ratio: <span class="math display">\[\Delta \text{LLR} = \log(0.02) - \log(0.35) = -3.91 - (-1.05) = -2.86\]</span></p>
<p><strong>Step 3:</strong> Interpret the score: A score of -2.86 indicates the variant amino acid (proline) is substantially less probable than the reference (leucine) given the evolutionary context. The model has learned that this position strongly favors aliphatic residues (L, I, V), and the rigid proline is unexpected—consistent with a functionally important position where proline would disrupt structure.</p>
</div>
</div>
<p>Negative scores indicate that the variant amino acid is less probable than reference in learned evolutionary context, suggesting potential deleteriousness. The model sees only the single query sequence, not multiple sequence alignments, yet achieves discrimination competitive with alignment-based methods on deep mutational scanning benchmarks. The emergence of this capability from masked token prediction, without explicit training on variant effects, exemplifies the emergent biological knowledge discussed in <a href="p4-ch16-protein-lm.html#sec-ch16-emergent-knowledge" class="quarto-xref"><span>Section 16.1.2</span></a>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Computing Variant Likelihoods from Language Models">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Computing Variant Likelihoods from Language Models
</div>
</div>
<div class="callout-body-container callout-body">
<p>Language models assign probabilities to sequences, but extracting variant effect scores requires specific computational strategies. Different approaches trade off between computational cost, theoretical justification, and empirical performance.</p>
<p><strong>Masked marginal likelihood</strong> (used by <em>ESM-1v</em>): Mask the position of interest and compute the probability of each amino acid given the unmasked context. The variant score is the log probability ratio of variant versus reference amino acid:</p>
<p><span id="eq-18-02"><span class="math display">\[
\text{Score} = \log P(\text{aa}_{\text{alt}} \mid \mathbf{x}_{-i}) - \log P(\text{aa}_{\text{ref}} \mid \mathbf{x}_{-i})
\tag{18.2}\]</span></span></p>
<p>where <span class="math inline">\(\mathbf{x}_{-i}\)</span> denotes the sequence with position <span class="math inline">\(i\)</span> masked. This approach requires a single forward pass per variant position. It directly measures how surprising each amino acid is given the local and global context the model learned during pretraining.</p>
<p><strong>Pseudo-likelihood</strong>: Sum the masked marginal log-probabilities across all positions in the sequence:</p>
<p><span id="eq-18-03"><span class="math display">\[
\text{PLL}(\mathbf{x}) = \sum_{i=1}^{L} \log P(x_i \mid \mathbf{x}_{-i})
\tag{18.3}\]</span></span></p>
<p>where <span class="math inline">\(L\)</span> is the sequence length and <span class="math inline">\(x_i\)</span> is the amino acid at position <span class="math inline">\(i\)</span>. The variant effect is the difference in pseudo-likelihood between mutant and wild-type sequences. This captures how the mutation affects sequence probability globally, not just at the mutated position, and may detect compensatory effects, but requires <em>L</em> forward passes (one per position).</p>
<p><strong>Autoregressive likelihood</strong> (for GPT-style models): Compute the probability of generating the sequence left-to-right:</p>
<p><span id="eq-18-04"><span class="math display">\[
\text{LL}(\mathbf{x}) = \sum_{i=1}^{L} \log P(x_i \mid x_1, \ldots, x_{i-1})
\tag{18.4}\]</span></span></p>
<p>This provides a proper generative probability but creates asymmetry: mutations early in the sequence affect more downstream predictions than mutations late in the sequence. Bidirectional models avoid this issue.</p>
<p><strong>Masked language model pseudo-perplexity</strong>: Average negative log-probability across positions, measuring how “surprising” the sequence appears to the model. Lower perplexity indicates more natural sequences.</p>
<p><strong>Practical considerations:</strong></p>
<ul>
<li>Masked marginal is computationally cheapest (one forward pass) and works well for local effects</li>
<li>Pseudo-likelihood is more thorough but expensive; often approximated by sampling positions</li>
<li>Autoregressive likelihood provides proper probabilities but with positional asymmetry</li>
<li>Multiple scoring strategies often correlate; choice depends on computational budget and task</li>
</ul>
<p>Most protein language model variant scoring uses masked marginal likelihood due to its efficiency and strong empirical performance. DNA language models use analogous strategies adapted for nucleotide sequences and longer contexts.</p>
</div>
</div>
<p>This zero-shot capability reflects what protein language models learn during pretraining: structural constraints (buried positions are hydrophobic), functional constraints (active sites are conserved), and co-evolutionary patterns (compensating mutations at contacting residues). The model has never seen pathogenicity labels, yet its predictions correlate with disease association because evolution and disease share underlying biology.</p>
</section>
<section id="sec-ch18-alignment-models" class="level3" data-number="18.2.2">
<h3 data-number="18.2.2" class="anchored" data-anchor-id="sec-ch18-alignment-models"><span class="header-section-number">18.2.2</span> Alignment-Based Models: EVE and popEVE</h3>
<p>An alternative approach explicitly models multiple sequence alignments rather than relying on implicit evolutionary information in single-sequence representations. <em>EVE</em> (Evolutionary Model of Variant Effect) fits a variational autoencoder to the MSA for each protein, learning a generative model that captures position-specific and pairwise constraints <span class="citation" data-cites="frazer_eve_2021">(<a href="../bib/references.html#ref-frazer_eve_2021" role="doc-biblioref">Frazer et al. 2021</a>)</span>. Variant scores derive from the change in sequence probability under this model.</p>
<p>The <em>EVE</em> architecture consists of an encoder that maps sequences to a latent space and a decoder that reconstructs sequences from latent representations. Training maximizes a lower bound on sequence likelihood across the MSA. For variant scoring, <em>EVE</em> computes the log-likelihood ratio between mutant and wild-type sequences, capturing how surprising the substitution appears given the evolutionary record for that specific protein.</p>
<p><em>popEVE</em> extends this framework with improved training procedures and explicit modeling of population allele frequencies <span class="citation" data-cites="orenbuch_popeve_2025">(<a href="../bib/references.html#ref-orenbuch_popeve_2025" role="doc-biblioref">Orenbuch et al. 2025</a>)</span>. By incorporating frequency information, <em>popEVE</em> better separates rare deleterious variants from common benign polymorphisms. The model achieves strong performance on ClinVar classification while providing uncertainty estimates through ensemble disagreement.</p>
<p>The tradeoff between single-sequence and MSA-based approaches involves coverage versus depth. <em>ESM-1v</em> scores any protein sequence without requiring alignment construction. <em>EVE</em> provides stronger performance when high-quality MSAs are available but cannot score proteins lacking sufficient homologs. For well-studied protein families with deep evolutionary sampling, MSA-based methods remain competitive; for orphan proteins or rapidly evolving sequences, single-sequence models offer the only foundation model option.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Knowledge Check: Single-Sequence vs. MSA-Based Models">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Knowledge Check: Single-Sequence vs.&nbsp;MSA-Based Models
</div>
</div>
<div class="callout-body-container callout-body">
<p>A patient carries a missense variant in <em>OBSCN</em>, an extremely large gene encoding a protein with few characterized homologs. The gene has only 12 sequences in its MSA, most from closely related mammals.</p>
<ol type="1">
<li>Would <em>ESM-1v</em> or <em>EVE</em> be more appropriate for scoring this variant? Why?</li>
<li>What fundamental limitation does this example illustrate about alignment-based approaches?</li>
<li>If the variant were in <em>BRCA1</em> instead (which has hundreds of homologs), would your answer change?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>ESM-1v would be more appropriate because it works on single sequences and doesn’t require a high-quality MSA. This illustrates that alignment-based methods fail for orphan proteins or those with sparse evolutionary sampling, where MSA-based approaches lack sufficient data. For BRCA1 with hundreds of homologs, EVE might perform better because the deep evolutionary sampling provides rich coevolution signals that EVE can exploit, though ESM-1v would still provide reliable predictions.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-ch18-alphamissense" class="level3" data-number="18.2.3">
<h3 data-number="18.2.3" class="anchored" data-anchor-id="sec-ch18-alphamissense"><span class="header-section-number">18.2.3</span> AlphaMissense: Structure-Informed Pathogenicity Prediction</h3>
<p><em>AlphaMissense</em> represents the current state of the art for proteome-wide missense pathogenicity prediction, combining protein language model representations with structural information from <em>AlphaFold2</em> <span class="citation" data-cites="cheng_alphamissense_2023">(<a href="../bib/references.html#ref-cheng_alphamissense_2023" role="doc-biblioref">Cheng et al. 2023</a>)</span>. The system provides precomputed scores for 71 million possible missense variants across the human proteome, enabling instant lookup for any variant in any protein-coding gene.</p>
<p>The architecture integrates multiple information sources. Sequence representations come from a protein language model encoding the wild-type sequence and mutation position. Structural representations derive from <em>AlphaFold2</em> predictions, capturing local geometry (secondary structure, solvent accessibility, packing density) and longer-range contacts. A neural network combines these representations to produce a pathogenicity probability between 0 and 1.</p>
<p>Why does combining sequence and structure information improve predictions beyond what either provides alone? Sequence-based evolutionary constraint tells you that a position is important, but structure explains why. Consider two equally conserved positions: one is buried in the hydrophobic core where any polar substitution destabilizes the fold, while the other forms a catalytic residue where even conservative substitutions abolish enzyme activity. A charge-preserving substitution (Asp to Glu) might be tolerable at a structural position but devastating at the catalytic one. Structure reveals these mechanistic differences that sequence conservation alone cannot distinguish. Similarly, two surface-exposed positions might show identical evolutionary constraint, but one forms a protein-protein interaction interface while the other faces solvent. Structural context disambiguates cases where sequence statistics are similar but mechanisms—and therefore tolerance for variation—differ substantially.</p>
<p>Training uses a carefully constructed dataset that avoids the circularity plaguing earlier predictors. Rather than training on ClinVar labels (which themselves derive from computational predictions), <em>AlphaMissense</em> uses population frequency as a proxy for pathogenicity: variants common in gnomAD are likely benign, while variants absent from large population samples and observed in disease contexts are likely pathogenic. This approach reduces the risk of learning features that simply recapitulate existing predictor scores.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Key Insight: Why Structure Matters for Variant Interpretation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: Why Structure Matters for Variant Interpretation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Protein language models capture that a position is evolutionarily constrained, but structural information explains <em>why</em>. A buried hydrophobic residue is constrained because substituting a charged amino acid would destabilize the fold. An active site residue is constrained because even subtle changes disrupt catalysis. An interface residue is constrained because substitutions abolish protein-protein interactions. By incorporating <em>AlphaFold2</em> structural features, <em>AlphaMissense</em> can distinguish variants at constrained positions where the constraint arises from different mechanisms, improving prediction for cases where sequence constraint alone is ambiguous.</p>
</div>
</div>
<p>Calibration receives explicit attention. Raw model outputs undergo isotonic regression calibration against held-out ClinVar variants, ensuring that predicted probabilities correspond to observed pathogenic proportions (<a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-calibration" class="quarto-xref"><span>Section 24.2</span></a>). A score of 0.8 should mean that 80% of variants with similar scores are pathogenic, enabling meaningful clinical interpretation. <em>AlphaMissense</em> reports calibrated scores along with discrete classifications (likely pathogenic, likely benign, uncertain) at thresholds chosen to achieve specific precision targets.</p>
<p>Performance on independent benchmarks substantially exceeds classical predictors. On deep mutational scanning datasets (where experimental fitness measurements provide ground truth independent of clinical labels), <em>AlphaMissense</em> achieves correlations of 0.5 to 0.7 depending on the assay, compared to 0.3 to 0.5 for <em>CADD</em> or <em>PolyPhen-2</em> <em>[Citation Needed]</em>. On ClinVar expert-reviewed variants held out from training, <em>AlphaMissense</em> achieves auROC values above 0.9, representing a meaningful improvement over the 0.85 to 0.88 typical of classical methods <em>[Citation Needed]</em>.</p>
<p>The structural component proves essential for this performance. Ablation experiments removing <em>AlphaFold2</em> features degrade performance substantially, particularly for variants at protein-protein interfaces and buried core positions where local geometry determines functional impact. The protein language model captures evolutionary constraint; structural information explains why that constraint exists.</p>
<div id="fig-alphamissense" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alphamissense-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/02-A-fig-alphamissense.svg" class="img-fluid figure-img"></p>
<figcaption>AlphaMissense integrates evolution and structure</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/02-B-fig-alphamissense.svg" class="img-fluid figure-img"></p>
<figcaption>Training strategy avoids circularity</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/02-C-fig-alphamissense.svg" class="img-fluid figure-img"></p>
<figcaption>Structural context determines pathogenicity</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/02-D-fig-alphamissense.svg" class="img-fluid figure-img"></p>
<figcaption>Proteome-wide classification of 71 million variants</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alphamissense-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18.2: AlphaMissense: integrating evolution and structure for variant pathogenicity. (A) Architecture combines ESM evolutionary embeddings with AlphaFold2 structural features. (B) Training avoids ClinVar circularity by using population frequency as a pathogenicity proxy—common gnomAD variants are presumed benign, rare variants in disease-associated contexts are presumed pathogenic. (C) Pathogenicity scores vary appropriately by structural context: core and active site variants score highest, surface variants score lowest. (D) Proteome-wide application classifies 71 million possible human missense variants, creating the largest pathogenicity prediction resource.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-ch18-dna-vep" class="level2" data-number="18.3">
<h2 data-number="18.3" class="anchored" data-anchor-id="sec-ch18-dna-vep"><span class="header-section-number">18.3</span> DNA-Based Variant Effect Prediction</h2>
<p>Approximately 98% of the human genome lies outside protein-coding regions, yet noncoding variants contribute substantially to disease risk through effects on gene regulation, splicing, and genome stability <em>[Citation Needed]</em>. Predicting the impact of these variants requires models that operate directly on DNA sequence rather than translated protein.</p>
<section id="sec-ch18-spliceai" class="level3" data-number="18.3.1">
<h3 data-number="18.3.1" class="anchored" data-anchor-id="sec-ch18-spliceai"><span class="header-section-number">18.3.1</span> Splice Variant Prediction with SpliceAI</h3>
<p>Splicing variants illustrate both the promise and current limitations of deep learning for noncoding VEP. Approximately 10% of pathogenic variants in ClinVar act through splicing mechanisms, disrupting the precise excision of introns from pre-mRNA <em>[Citation Needed]</em>. Classical approaches relied on position weight matrices matching consensus splice site sequences, achieving limited sensitivity for variants outside the core GT-AG dinucleotides.</p>
<p><em>SpliceAI</em> applies the dilated convolutional architecture introduced in <a href="../part_2/p2-ch06-cnn.html" class="quarto-xref"><span>Chapter 6</span></a> to predict splice site usage from raw DNA sequence <span class="citation" data-cites="jaganathan_spliceai_2019">(<a href="../bib/references.html#ref-jaganathan_spliceai_2019" role="doc-biblioref">Jaganathan, Kyriazopoulou Panagiotopoulou, McRae, Darbandi, et al. 2019</a>)</span>. The architecture processes 10,000 nucleotides of context through 32 residual blocks with dilated convolutions (dilation rates increasing from 1 to 128), enabling the <strong>receptive field</strong> to span several kilobases while maintaining nucleotide resolution. Output heads predict splice donor probability, splice acceptor probability, and junction usage at each position.</p>
<p>For variant effect prediction, <em>SpliceAI</em> compares predictions between reference and alternate sequences. The delta score quantifies the change in splice site probability, with positive values indicating gained splice sites and negative values indicating lost sites. Scores exceeding 0.2 correlate with experimentally validated splicing changes; scores above 0.5 have high specificity for pathogenic splicing variants <span class="citation" data-cites="jaganathan_predicting_2019">(<a href="../bib/references.html#ref-jaganathan_predicting_2019" role="doc-biblioref">Jaganathan, Kyriazopoulou Panagiotopoulou, McRae, Darbber, et al. 2019</a>)</span>.</p>
<p>Clinical deployment has validated <em>SpliceAI’s</em> utility. Illumina integrated the model into their clinical interpretation pipeline, and multiple diagnostic laboratories use <em>SpliceAI</em> scores as supporting evidence for ACMG classification. The architectural innovations that enable this performance, including the dilated convolution strategy for expanding receptive fields, are detailed in <a href="../part_2/p2-ch06-cnn.html#sec-ch06-spliceai" class="quarto-xref"><span>Section 6.5</span></a>. The model identifies pathogenic splicing variants missed by classical methods, particularly deep intronic variants that create novel splice sites through cryptic activation.</p>
<p>Limitations reflect the model’s training data. <em>SpliceAI</em> learned from annotated transcripts representing major isoforms in common tissues. Tissue-specific alternative splicing, rare isoforms, and developmental stage-specific patterns fall outside the training distribution. The model also does not capture downstream consequences: whether a predicted splicing change produces a functional protein, triggers nonsense-mediated decay, or has no phenotypic effect requires additional analysis.</p>
</section>
<section id="sec-ch18-enformer-vep" class="level3" data-number="18.3.2">
<h3 data-number="18.3.2" class="anchored" data-anchor-id="sec-ch18-enformer-vep"><span class="header-section-number">18.3.2</span> Regulatory Variant Prediction with Enformer</h3>
<p>While <em>SpliceAI</em> addresses one specific noncoding mechanism, regulatory variants that alter enhancer activity, promoter function, or chromatin organization require different approaches. <em>Enformer</em> (<a href="p4-ch17-regulatory.html" class="quarto-xref"><span>Chapter 17</span></a>) predicts multiple molecular phenotypes (histone modifications, transcription factor binding, chromatin accessibility, gene expression) from 196,608 base pairs of DNA sequence, providing a substrate for regulatory VEP <span class="citation" data-cites="avsec_enformer_2021">(<a href="../bib/references.html#ref-avsec_enformer_2021" role="doc-biblioref">Ž. Avsec et al. 2021</a>)</span>.</p>
<p>Variant effect prediction with <em>Enformer</em> compares predicted tracks between reference and alternate sequences. For a variant in an enhancer, the model might predict reduced H3K27ac signal and decreased CAGE expression at the target promoter. These molecular predictions can be aggregated into variant effect scores, with larger predicted changes indicating greater functional impact.</p>
<p>Several challenges complicate <em>Enformer</em>-based VEP. The model predicts relative effects (fold changes in predicted signal) rather than absolute deleteriousness. Calibrating these predictions against pathogenicity labels requires additional supervised training. Cell-type specificity adds complexity: a variant might strongly affect predictions in cardiac tissue while showing no effect in liver, requiring prior knowledge of relevant tissues for clinical interpretation.</p>
<p><em>Sei</em> extends this approach by learning a regulatory vocabulary: clusters of predicted effects that correspond to interpretable categories like “active promoter,” “strong enhancer,” or “CTCF binding site” <span class="citation" data-cites="chen_deepsea_2022">(<a href="../bib/references.html#ref-chen_deepsea_2022" role="doc-biblioref">Chen et al. 2022</a>)</span>. Variant scores reflect shifts between these categories, providing more interpretable outputs than raw track changes. A variant that converts an enhancer prediction to a quiescent state has clearer implications than one that reduces H3K27ac by 0.3 log-fold.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Stop and Think: Mechanism vs. Pathogenicity">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think: Mechanism vs.&nbsp;Pathogenicity
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Enformer</em> can predict that a variant reduces enhancer activity, and <em>SpliceAI</em> can predict that a variant creates a cryptic splice site. But neither model directly predicts whether these molecular changes cause disease.</p>
<p>Consider: A variant in an enhancer might reduce expression of the target gene by 30%. Under what circumstances would this reduction be: - Clearly pathogenic? - Clearly benign? - Uncertain in its clinical significance?</p>
<p>This exercise illustrates a fundamental gap between mechanistic prediction (what the variant does molecularly) and clinical prediction (whether it causes disease).</p>
</div>
</div>
</section>
<section id="sec-ch18-dna-lm-vep" class="level3" data-number="18.3.3">
<h3 data-number="18.3.3" class="anchored" data-anchor-id="sec-ch18-dna-lm-vep"><span class="header-section-number">18.3.3</span> DNA Language Models: GPN-MSA and Evo 2</h3>
<p>DNA language models provide an alternative to phenotype prediction: scoring variants by how unexpected they appear in learned sequence context, analogous to protein language model approaches for missense variants.</p>
<p><em>GPN-MSA</em> combines DNA language modeling with multi-species sequence alignments <span class="citation" data-cites="benegas_gpn-msa_2024">(<a href="../bib/references.html#ref-benegas_gpn-msa_2024" role="doc-biblioref">Benegas et al. 2024</a>)</span>. Building on the <em>GPN</em> approach introduced in <a href="p4-ch15-dna-lm.html#sec-ch15-gpn" class="quarto-xref"><span>Section 15.4</span></a>, the model processes aligned sequences from dozens of vertebrate species, learning which positions are conserved and which tolerate variation. Variant scores derive from likelihood ratios: how much less probable is the variant allele compared to reference given the alignment context? This approach captures deep evolutionary constraint missed by simple conservation scores while providing genome-wide coverage including noncoding regions.</p>
<p><em>Evo 2</em> pushes context length to approximately one megabase, enabling single models to capture local motifs and long-range dependencies simultaneously <span class="citation" data-cites="brixi_evo_2025">(<a href="../bib/references.html#ref-brixi_evo_2025" role="doc-biblioref">Brixi et al. 2025</a>)</span>. The StripedHyena architecture provides computational efficiency at this scale through state-space-based sequence modeling rather than quadratic attention, as detailed in <a href="p4-ch15-dna-lm.html#sec-ch15-evo2" class="quarto-xref"><span>Section 15.5.3</span></a> and <a href="../part_2/p2-ch07-attention.html" class="quarto-xref"><span>Chapter 7</span></a>. Training on diverse genomes across the tree of life teaches general principles of sequence organization that transfer to human variant interpretation.</p>
<p>Zero-shot variant scoring with <em>Evo 2</em> follows the standard likelihood ratio approach. Initial benchmarks show performance competitive with conservation-based scores for coding variants and potentially superior performance for noncoding variants where local sequence context matters more than position-specific conservation. The extremely long context enables modeling of effects mediated by distal elements, though whether this theoretical capability translates to improved VEP remains under investigation.</p>
</section>
<section id="sec-ch18-alphagenome" class="level3" data-number="18.3.4">
<h3 data-number="18.3.4" class="anchored" data-anchor-id="sec-ch18-alphagenome"><span class="header-section-number">18.3.4</span> AlphaGenome: Unified Multi-Omic Variant Effect Prediction</h3>
<p><em>AlphaGenome</em> (<a href="p4-ch17-regulatory.html#sec-ch17-alphagenome" class="quarto-xref"><span>Section 17.5</span></a>) represents the most ambitious current attempt at comprehensive VEP, predicting multiple molecular phenotypes from megabase-scale DNA sequence and using those predictions to assess variant effects across modalities <span class="citation" data-cites="avsec_alphagenome_2025">(<a href="../bib/references.html#ref-avsec_alphagenome_2025" role="doc-biblioref">Z. Avsec, Latysheva, and Cheng 2025</a>)</span>.</p>
<p>Variant effect prediction with <em>AlphaGenome</em> provides mechanistically interpretable outputs. A promoter variant might show reduced accessibility and decreased expression prediction. An enhancer variant might show weakened contact with its target promoter in addition to reduced local histone acetylation. A splicing variant triggers <em>SpliceAI</em>-like splice site changes while also affecting regulatory track predictions near the affected exon.</p>
<p>The multi-omic approach enables variant prioritization that considers multiple mechanisms simultaneously. A variant in a regulatory element that affects accessibility, expression, and chromatin contacts represents stronger evidence than one affecting only a single predicted phenotype. Conversely, variants with no predicted effect across modalities can be deprioritized despite proximity to disease genes.</p>
<p>Practical deployment involves tradeoffs. Evaluating a single variant requires forward passes through the full model, incurring substantial computational cost compared to lookup-based approaches like <em>AlphaMissense</em>. The model may exhibit overconfidence when extrapolating beyond training cell types. Calibrating multi-dimensional predictions into single pathogenicity scores remains an open problem. These constraints position <em>AlphaGenome</em> as a tool for detailed mechanistic investigation of prioritized variants rather than genome-wide screening.</p>
</section>
</section>
<section id="sec-ch18-combining-evidence" class="level2" data-number="18.4">
<h2 data-number="18.4" class="anchored" data-anchor-id="sec-ch18-combining-evidence"><span class="header-section-number">18.4</span> Combining Evidence Across Modalities</h2>
<p>No single model addresses all variant types and mechanisms. Missense variants in protein-coding regions call for protein-level predictors; splicing variants require splice-specific models; regulatory variants benefit from long-context DNA models. Practical VEP workflows combine multiple predictors to achieve comprehensive coverage.</p>
<section id="sec-ch18-integration-strategies" class="level3" data-number="18.4.1">
<h3 data-number="18.4.1" class="anchored" data-anchor-id="sec-ch18-integration-strategies"><span class="header-section-number">18.4.1</span> Integration Strategies</h3>
<p>The simplest integration approach applies different models to different variant classes. Missense variants receive <em>AlphaMissense</em> scores; synonymous and intronic variants near splice sites receive <em>SpliceAI</em> scores; promoter and enhancer variants receive <em>Enformer</em> or <em>AlphaGenome</em> predictions. This modular strategy ensures that each variant type receives predictions from an appropriate model.</p>
<div id="tbl-model-selection" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;18.2: Model selection guidance by variant type. The choice depends on variant location and suspected mechanism.
</figcaption>
<div aria-describedby="tbl-model-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 25%">
<col style="width: 29%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Variant Type</th>
<th>Primary Model(s)</th>
<th>Secondary/Supporting</th>
<th>Key Considerations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Missense</td>
<td><em>AlphaMissense</em></td>
<td><em>ESM-1v</em>, <em>EVE</em></td>
<td>Check for splicing effects if near exon boundary</td>
</tr>
<tr class="even">
<td>Synonymous</td>
<td><em>SpliceAI</em></td>
<td><em>Enformer</em> (regulatory)</td>
<td>Often dismissed but can affect splicing</td>
</tr>
<tr class="odd">
<td>Splice site (canonical)</td>
<td><em>SpliceAI</em></td>
<td></td>
<td>Very high pathogenicity for loss of function genes</td>
</tr>
<tr class="even">
<td>Deep intronic</td>
<td><em>SpliceAI</em></td>
<td><em>Enformer</em>, <em>GPN-MSA</em></td>
<td>Look for cryptic splice site activation</td>
</tr>
<tr class="odd">
<td>Promoter/5’UTR</td>
<td><em>Enformer</em>, <em>AlphaGenome</em></td>
<td><em>GPN-MSA</em></td>
<td>Consider tissue specificity</td>
</tr>
<tr class="even">
<td>Enhancer</td>
<td><em>Enformer</em>, <em>Sei</em></td>
<td><em>AlphaGenome</em></td>
<td>Need prior knowledge of target genes</td>
</tr>
<tr class="odd">
<td>Structural variants</td>
<td>Limited coverage</td>
<td></td>
<td>Gap in current foundation model capabilities</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>More sophisticated integration aggregates scores across models for the same variant. A missense variant might receive both <em>AlphaMissense</em> (protein impact) and <em>Enformer</em> (regulatory impact, relevant if the codon overlaps a regulatory element) predictions. Combining these requires decisions about weighting and potential double-counting of shared information.</p>
<p>Bayesian approaches offer principled integration. Priors encode beliefs about variant mechanism proportions; likelihoods incorporate model predictions given mechanism; posteriors combine evidence across models while respecting uncertainty. <em>REVEL</em> (Rare Exome Variant Ensemble Learner) demonstrated this approach for classical predictors <span class="citation" data-cites="ioannidis_revel_2016">(<a href="../bib/references.html#ref-ioannidis_revel_2016" role="doc-biblioref">Ioannidis et al. 2016</a>)</span>; extending it to foundation model outputs requires careful calibration of each component score.</p>
</section>
<section id="sec-ch18-double-counting" class="level3" data-number="18.4.2">
<h3 data-number="18.4.2" class="anchored" data-anchor-id="sec-ch18-double-counting"><span class="header-section-number">18.4.2</span> Avoiding Double-Counting</h3>
<p>Foundation models trained on overlapping data risk capturing correlated rather than independent information. <em>AlphaMissense</em> and <em>ESM-1v</em> both encode evolutionary constraint; combining their scores as independent evidence overweights evolutionary signal. Similarly, conservation-based DNA models like <em>GPN-MSA</em> share information with phyloP scores already incorporated in classical predictors.</p>
<p>Correlation analysis helps quantify redundancy. If two model scores correlate above 0.8 across a benchmark dataset, they likely provide similar information and should not be counted as independent evidence. Residual analysis can identify what unique signal each model contributes beyond shared components.</p>
<div class="callout callout-style-default callout-warning callout-titled" title="Practical Guidance: Evidence Independence in ACMG Classification">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical Guidance: Evidence Independence in ACMG Classification
</div>
</div>
<div class="callout-body-container callout-body">
<p>For ACMG classification, guidelines specifically address computational evidence weighting. The PP3 (computational evidence supporting pathogenicity) and BP4 (computational evidence supporting benignity) criteria apply when multiple tools agree. However, using five correlated predictors that all derive from evolutionary conservation should not count as five independent pieces of evidence.</p>
<p><strong>Recommended practice:</strong> 1. Group predictors by primary information source (evolutionary constraint, structural features, regulatory marks) 2. Select one representative tool from each group for ACMG evidence 3. Document tool correlations in your laboratory’s validation records 4. Update tool selection as new methods emerge and correlations are characterized</p>
<p>Clinical laboratories should develop local policies for which tools to consult and how to weight their outputs, ideally based on validation against known variants in their patient population.</p>
</div>
</div>
</section>
<section id="sec-ch18-workflow-design" class="level3" data-number="18.4.3">
<h3 data-number="18.4.3" class="anchored" data-anchor-id="sec-ch18-workflow-design"><span class="header-section-number">18.4.3</span> Practical Workflow Design</h3>
<p>An effective VEP workflow balances comprehensiveness against efficiency. Genome-wide screening might use fast, zero-shot models (DNA language model likelihood scores) to identify variants deviating from expected sequence patterns. Prioritized variants then receive detailed evaluation with computationally expensive models (<em>AlphaGenome</em> multi-omic predictions). Final interpretation combines computational scores with population frequency, gene-level constraint metrics, segregation data, and clinical phenotype.</p>
<p>The ordering matters for efficiency. Filtering the majority of variants with fast models before applying expensive models reduces computational cost by orders of magnitude. The choice of filtering threshold trades sensitivity against specificity: strict thresholds miss true pathogenic variants; lenient thresholds burden downstream analysis with false positives. Threshold selection should match intended use: diagnostic applications prioritize sensitivity while research screening may prioritize specificity.</p>
<p>Why does the tiered approach work biologically as well as computationally? Most variants in a genome are benign—purifying selection has eliminated severely deleterious variants from the population. A fast initial filter that correctly classifies the majority of benign variants reduces the candidate set to a manageable number for detailed analysis. The variants that pass the filter are enriched for those where predictions are uncertain or where multiple mechanisms may be at play, justifying the computational investment in multi-model evaluation. This mirrors clinical reasoning: common polymorphisms need not be scrutinized in depth, while rare variants in disease-relevant genes warrant comprehensive assessment.</p>
<div id="fig-multimodel-integration" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-multimodel-integration-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/03-A-fig-multimodel-integration.svg" class="img-fluid figure-img"></p>
<figcaption>Model selection by variant type</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/03-B-fig-multimodel-integration.svg" class="img-fluid figure-img"></p>
<figcaption>Non-coding variant integration pipeline</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/03-C-fig-multimodel-integration.svg" class="img-fluid figure-img"></p>
<figcaption>Ensemble scoring combines predictions</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/03-D-fig-multimodel-integration.svg" class="img-fluid figure-img"></p>
<figcaption>Uncertainty aggregation across models</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-multimodel-integration-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18.3: Multi-model integration for comprehensive variant assessment. (A) Coding variants are routed to appropriate models based on consequence type: missense to AlphaMissense/ESM, splice-proximal to SpliceAI, synonymous requiring both splicing and regulatory assessment. (B) Non-coding variants use specialized models for each region: promoters and enhancers use Enformer, splice regions use SpliceAI, deep intronic variants combine conservation with regulatory predictions. (C) Ensemble methods combine individual model scores through learned weights, typically outperforming any single model. (D) Uncertainty aggregation identifies variants where models disagree, flagging them for review. When models agree, predictions are confident; when models disagree, elevated uncertainty triggers manual review.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-ch18-calibration" class="level2" data-number="18.5">
<h2 data-number="18.5" class="anchored" data-anchor-id="sec-ch18-calibration"><span class="header-section-number">18.5</span> Calibration and Clinical Categories</h2>
<div class="callout callout-style-default callout-caution callout-titled" title="Difficulty Warning: Statistical Foundations Required">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Difficulty Warning: Statistical Foundations Required
</div>
</div>
<div class="callout-body-container callout-body">
<p>This section introduces calibration concepts that require familiarity with probability, Bayesian reasoning, and classification metrics. If terms like “reliability diagram,” “isotonic regression,” or “odds ratio” are unfamiliar, consider first reviewing the technical foundations in <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-calibration" class="quarto-xref"><span>Section 24.2</span></a>. The practical implications are accessible without deep statistical background, but understanding <em>why</em> these methods work requires the full treatment in Chapter 23.</p>
</div>
</div>
<p>A pathogenicity score of 0.73 means nothing in isolation. If that score reflects a well-calibrated model, approximately 73% of variants receiving similar scores are truly pathogenic, and clinical decisions can proceed accordingly. If the model is miscalibrated, the true pathogenic rate could be 40% or 95%, rendering the score unreliable for clinical interpretation. Model scores become clinically useful only when they map to actionable categories through calibration, the process of ensuring that predicted probabilities match observed frequencies.</p>
<section id="sec-ch18-assessing-calibration" class="level3" data-number="18.5.1">
<h3 data-number="18.5.1" class="anchored" data-anchor-id="sec-ch18-assessing-calibration"><span class="header-section-number">18.5.1</span> Assessing Calibration</h3>
<p>Calibration plots (reliability diagrams) visualize the relationship between predicted probabilities and observed frequencies. Variants are binned by predicted score, and the proportion of pathogenic variants in each bin is plotted against the bin’s mean predicted probability. Perfect calibration falls on the diagonal: a predicted 0.8 pathogenicity corresponds to an 80% observed pathogenic rate. Points below the diagonal indicate overconfidence (predictions exceed reality), while points above indicate underconfidence.</p>
<p>Most raw model outputs are poorly calibrated. Neural networks trained with cross-entropy loss tend toward overconfidence, predicting probabilities near 0 or 1 more often than warranted. Protein language model likelihood ratios produce unbounded scores requiring transformation before probability interpretation. The theoretical foundations of why deep networks and foundation models exhibit systematic miscalibration, along with formal definitions of calibration metrics including expected calibration error (ECE), are developed in <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-calibration" class="quarto-xref"><span>Section 24.2</span></a>. The specific challenges posed by foundation model miscalibration in clinical settings are examined in <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-fm-miscalibration" class="quarto-xref"><span>Section 24.2.3</span></a>.</p>
</section>
<section id="sec-ch18-calibration-methods" class="level3" data-number="18.5.2">
<h3 data-number="18.5.2" class="anchored" data-anchor-id="sec-ch18-calibration-methods"><span class="header-section-number">18.5.2</span> Calibration Methods for Variant Effect Prediction</h3>
<p>Post-hoc calibration transforms raw model outputs into probabilities that match observed pathogenicity frequencies. The technical details of these transformations, including temperature scaling, Platt scaling, and isotonic regression, are developed in <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-post-hoc-calibration" class="quarto-xref"><span>Section 24.3</span></a>. Here we focus on their application to variant effect prediction.</p>
<p>Calibration should use data representative of deployment conditions. Calibrating on ClinVar expert-reviewed variants produces reliable performance on similar variants but may not transfer to novel genes, rare populations, or variant classes underrepresented in ClinVar. A model calibrated on well-studied cancer genes may be systematically overconfident when applied to genes with fewer characterized variants. Stratified calibration by gene function, variant class, or population improves reliability at the cost of increased data requirements.</p>
<p>The systematic biases that arise from distribution shift between calibration and deployment present particular challenges for clinical genomics. Foundation models trained predominantly on European-ancestry data may exhibit differential calibration across populations, producing well-calibrated predictions for some patient groups and miscalibrated predictions for others (<a href="../part_3/p3-ch13-confounding.html" class="quarto-xref"><span>Chapter 13</span></a>). These disparities have direct implications for equitable care, as clinical decisions based on miscalibrated predictions will be systematically worse for patients from underrepresented backgrounds. The sources and consequences of such differential calibration are examined in <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-calibration" class="quarto-xref"><span>Section 24.2</span></a>.</p>
<div id="fig-calibration-clinical" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-calibration-clinical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/04-A-fig-calibration-clinical.svg" class="img-fluid figure-img"></p>
<figcaption>Raw model outputs require calibration</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/04-B-fig-calibration-clinical.svg" class="img-fluid figure-img"></p>
<figcaption>Calibration methods correct systematic bias</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/04-C-fig-calibration-clinical.svg" class="img-fluid figure-img"></p>
<figcaption>Threshold selection for clinical use</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/04-D-fig-calibration-clinical.svg" class="img-fluid figure-img"></p>
<figcaption>Prevalence affects score interpretation</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-calibration-clinical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18.4: Calibration for clinical variant interpretation. (A) Raw model scores are not calibrated probabilities—neural networks exhibit systematic overconfidence, clustering predictions near 0 and 1. (B) Calibration curves reveal and correct probability bias; post-calibration predictions track the diagonal, providing accurate probability estimates. (C) Threshold selection depends on clinical context: screening applications favor high sensitivity, diagnostic applications balance sensitivity and specificity, confirmation applications favor high specificity. (D) Clinical prevalence dramatically affects interpretation—the same score means different things in healthy populations versus rare disease clinics. Proper clinical deployment requires calibration and prevalence-adjusted interpretation.
</figcaption>
</figure>
</div>
</section>
<section id="sec-ch18-acmg-mapping" class="level3" data-number="18.5.3">
<h3 data-number="18.5.3" class="anchored" data-anchor-id="sec-ch18-acmg-mapping"><span class="header-section-number">18.5.3</span> Mapping to ACMG Categories</h3>
<p>The ACMG-AMP variant classification framework defines five categories: pathogenic, likely pathogenic, uncertain significance, likely benign, and benign <span class="citation" data-cites="richards_standards_2015">(<a href="../bib/references.html#ref-richards_standards_2015" role="doc-biblioref">Richards et al. 2015</a>)</span>. Computational evidence contributes to classification through specific criteria: PP3 (computational evidence supporting pathogenicity) and BP4 (computational evidence supporting benignity).</p>
<div class="callout callout-style-default callout-note callout-titled" title="ACMG-AMP Variant Classification Framework">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ACMG-AMP Variant Classification Framework
</div>
</div>
<div class="callout-body-container callout-body">
<p>The American College of Medical Genetics and Genomics (ACMG) and Association for Molecular Pathology (AMP) established a standardized framework for classifying sequence variants in Mendelian disease genes <span class="citation" data-cites="richards_standards_2015">(<a href="../bib/references.html#ref-richards_standards_2015" role="doc-biblioref">Richards et al. 2015</a>)</span>. Understanding this framework is essential for applying foundation model predictions in clinical settings.</p>
<p><strong>Classification categories:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Category</th>
<th>Abbreviation</th>
<th>Clinical interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pathogenic</td>
<td>P</td>
<td>Disease-causing; actionable</td>
</tr>
<tr class="even">
<td>Likely pathogenic</td>
<td>LP</td>
<td>&gt;90% probability pathogenic; actionable</td>
</tr>
<tr class="odd">
<td>Uncertain significance</td>
<td>VUS</td>
<td>Insufficient evidence; not actionable</td>
</tr>
<tr class="even">
<td>Likely benign</td>
<td>LB</td>
<td>&gt;90% probability benign</td>
</tr>
<tr class="odd">
<td>Benign</td>
<td>B</td>
<td>Not disease-causing</td>
</tr>
</tbody>
</table>
<p><strong>Evidence types and strengths:</strong></p>
<p>Evidence for pathogenicity includes: - <strong>PVS1</strong> (Very Strong): Null variant in gene where loss-of-function causes disease - <strong>PS1-PS4</strong> (Strong): Same amino acid change known pathogenic, functional studies, segregation in families, prevalence in affected vs.&nbsp;controls - <strong>PM1-PM6</strong> (Moderate): Functional domain, absent from controls, missense in gene with low benign variation, etc. - <strong>PP1-PP5</strong> (Supporting): Cosegregation, missense in gene with mostly missense pathogenic, <strong>computational evidence (PP3)</strong>, patient phenotype match, reputable source</p>
<p>Evidence for benignity includes: - <strong>BA1</strong> (Stand-alone): Allele frequency &gt;5% in population databases - <strong>BS1-BS4</strong> (Strong): Frequency higher than expected, functional studies, segregation against, observed in trans with pathogenic - <strong>BP1-BP7</strong> (Supporting): Missense in gene with truncating mechanism, silent with no splice impact, <strong>computational evidence (BP4)</strong>, etc.</p>
<p><strong>Combining evidence:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 44%">
<col style="width: 55%">
</colgroup>
<thead>
<tr class="header">
<th>Classification</th>
<th>Evidence required</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pathogenic</td>
<td>PVS1 + ≥1 PS; OR 2 PS; OR 1 PS + 3 PM; OR 1 PS + 2 PM + 2 PP; …</td>
</tr>
<tr class="even">
<td>Likely pathogenic</td>
<td>1 PVS1 + 1 PM; OR 1 PS + 1-2 PM; OR 1 PS + ≥2 PP; …</td>
</tr>
<tr class="odd">
<td>Likely benign</td>
<td>1 BS + 1 BP; OR ≥2 BP</td>
</tr>
<tr class="even">
<td>Benign</td>
<td>BA1; OR ≥2 BS</td>
</tr>
<tr class="odd">
<td>VUS</td>
<td>Criteria not met for other categories</td>
</tr>
</tbody>
</table>
<p><strong>Computational evidence (PP3/BP4):</strong></p>
<p>Foundation model scores contribute through PP3 (supporting pathogenicity) or BP4 (supporting benignity). These criteria provide supporting-level evidence. To achieve stronger evidence levels, tools must be calibrated to demonstrate odds ratios of pathogenicity meeting specific thresholds: &gt;2.08 for supporting, &gt;4.33 for moderate, &gt;18.7 for strong <span class="citation" data-cites="tavtigian_modeling_2018">(<a href="../bib/references.html#ref-tavtigian_modeling_2018" role="doc-biblioref">Tavtigian et al. 2018</a>)</span>. Recent calibration studies have established that several foundation model-based predictors can achieve moderate or strong evidence levels at appropriate thresholds <span class="citation" data-cites="pejaver_calibration_2022 bergquist_calibration_2025">(<a href="../bib/references.html#ref-pejaver_calibration_2022" role="doc-biblioref">Pejaver et al. 2022</a>; <a href="../bib/references.html#ref-bergquist_calibration_2025" role="doc-biblioref">Bergquist et al. 2025</a>)</span>.</p>
</div>
</div>
<p>Mapping continuous foundation model scores to these discrete criteria requires threshold selection. Conservative thresholds ensure high precision at the cost of low recall: only variants with very high (or very low) scores receive computational evidence designation. Lenient thresholds increase recall but admit more false positives, potentially inflating pathogenicity classifications. The choice reflects a fundamental trade-off between missing actionable variants and overclassifying benign variants as potentially harmful.</p>
<p>ClinGen sequence variant interpretation working groups have developed model-specific recommendations for computational predictors, specifying score thresholds that correspond to different evidence strengths. Tavtigian and colleagues proposed a Bayesian framework for calibrating computational evidence strength based on odds ratios of pathogenicity at different score thresholds <span class="citation" data-cites="tavtigian_modeling_2018">(<a href="../bib/references.html#ref-tavtigian_modeling_2018" role="doc-biblioref">Tavtigian et al. 2018</a>)</span>. Under this framework, thresholds must achieve specific odds ratios (greater than 2.08 for supporting evidence, greater than 4.33 for moderate evidence) to qualify for particular ACMG evidence levels. Pejaver et al.&nbsp;applied this framework to calibrate 13 classical missense predictors, establishing that four tools (<em>BayesDel</em>, <em>MutPred2</em>, <em>REVEL</em>, <em>VEST4</em>) could provide up to Strong evidence for pathogenicity <span class="citation" data-cites="pejaver_calibration_2022">(<a href="../bib/references.html#ref-pejaver_calibration_2022" role="doc-biblioref">Pejaver et al. 2022</a>)</span>. In 2025, ClinGen extended these calibrations to foundation model-based predictors, demonstrating that <em>AlphaMissense</em>, <em>ESM1b</em>, and <em>VARITY</em> all reach Strong evidence for pathogenicity and Moderate for benignity at appropriate score thresholds <span class="citation" data-cites="bergquist_calibration_2025">(<a href="../bib/references.html#ref-bergquist_calibration_2025" role="doc-biblioref">Bergquist et al. 2025</a>)</span>. Laboratories should select tools with established calibrations and document threshold choices in variant reports.</p>
</section>
<section id="sec-ch18-vus-challenge" class="level3" data-number="18.5.4">
<h3 data-number="18.5.4" class="anchored" data-anchor-id="sec-ch18-vus-challenge"><span class="header-section-number">18.5.4</span> The Challenge of Uncertain Significance</h3>
<p>The <strong>variant of uncertain significance (VUS)</strong> category deserves particular attention. Variants with intermediate foundation model scores genuinely reflect uncertainty: the models cannot confidently distinguish pathogenic from benign. This uncertainty may arise from limited training data for the gene or variant class, conflicting signals in the sequence context, or genuine biological ambiguity where the variant’s effect depends on factors the model cannot observe.</p>
<p>Forcing these variants into discrete categories by applying arbitrary cutoffs misrepresents the actual evidence. A variant scored at 0.55 is not “slightly pathogenic”; it is a variant for which the model has insufficient evidence to discriminate. Reporting calibrated probabilities alongside discrete classifications preserves information for downstream decision-making. Clinicians can then integrate computational evidence with functional studies, segregation data, and clinical presentation, appropriately weighting the computational contribution based on its expressed uncertainty.</p>
<p>The broader framework for understanding and quantifying uncertainty in foundation model predictions, including methods for distinguishing uncertainty arising from limited data (epistemic uncertainty) from uncertainty inherent in the prediction task (aleatoric uncertainty), is developed in <a href="../part_6/p6-ch24-uncertainty.html" class="quarto-xref"><span>Chapter 24</span></a>. Conformal prediction methods that provide finite-sample coverage guarantees for variant classification are examined in <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-conformal" class="quarto-xref"><span>Section 24.5</span></a>.</p>
</section>
</section>
<section id="sec-ch18-uncertainty" class="level2" data-number="18.6">
<h2 data-number="18.6" class="anchored" data-anchor-id="sec-ch18-uncertainty"><span class="header-section-number">18.6</span> Uncertainty Quantification</h2>
<p>Calibration addresses systematic bias in probability estimates; uncertainty quantification addresses the confidence of individual predictions. A well-calibrated model might correctly estimate that 70% of variants in some category are pathogenic, but for any individual variant, we want to know whether the model’s prediction is reliable or whether the variant falls outside the model’s competence.</p>
<section id="sec-ch18-uncertainty-sources" class="level3" data-number="18.6.1">
<h3 data-number="18.6.1" class="anchored" data-anchor-id="sec-ch18-uncertainty-sources"><span class="header-section-number">18.6.1</span> Sources of Uncertainty</h3>
<p><strong>Epistemic uncertainty</strong> reflects gaps in the model’s knowledge: regions of input space with sparse training data, variant types rarely observed during training, or proteins from understudied families. This uncertainty is reducible in principle by collecting more data and can be estimated by measuring model disagreement across training variations.</p>
<p><strong>Aleatoric uncertainty</strong> reflects inherent noise in the prediction target: variants whose pathogenicity genuinely varies across individuals or contexts, or cases where the same score corresponds to both pathogenic and benign variants for biological rather than modeling reasons. This uncertainty is irreducible by additional training and represents fundamental limits on predictability.</p>
<p>Distinguishing these uncertainty types matters for interpretation. High epistemic uncertainty suggests caution: the model has not seen similar variants and may be extrapolating unreliably. High aleatoric uncertainty suggests that the variant’s effect genuinely depends on factors not captured by sequence alone.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Knowledge Check: Epistemic vs. Aleatoric Uncertainty">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Knowledge Check: Epistemic vs.&nbsp;Aleatoric Uncertainty
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider two variants with identical <em>AlphaMissense</em> scores of 0.65:</p>
<p><strong>Variant A:</strong> A missense change in <em>BRCA1</em>, a gene with thousands of characterized variants in ClinVar and extensive deep mutational scanning data.</p>
<p><strong>Variant B:</strong> A missense change in a recently discovered orphan gene with no characterized variants and only 8 homologous sequences in databases.</p>
<ol type="1">
<li>Which variant likely has higher epistemic uncertainty? Why?</li>
<li>For which variant might the intermediate score more likely reflect aleatoric uncertainty (genuine biological ambiguity)?</li>
<li>How would you communicate the different confidence levels to a clinician?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Variant B has higher epistemic uncertainty because the model has limited training data for orphan genes with sparse evolutionary sampling. For Variant A in BRCA1, the intermediate score more likely reflects aleatoric uncertainty—genuine biological ambiguity about pathogenicity given extensive characterization data. Communication to clinicians should distinguish these: “For BRCA1, the intermediate score reflects uncertain biological effect; for the orphan gene, the score itself is uncertain due to limited data and should be interpreted cautiously.”</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-ch18-uncertainty-methods" class="level3" data-number="18.6.2">
<h3 data-number="18.6.2" class="anchored" data-anchor-id="sec-ch18-uncertainty-methods"><span class="header-section-number">18.6.2</span> Uncertainty Estimation Methods</h3>
<p><strong>Ensemble methods</strong> train multiple models on different data subsets or with different random initializations. Like asking multiple doctors for second opinions on a diagnosis, if all the doctors independently reach the same conclusion, you can be more confident in the answer; if they disagree substantially, that disagreement itself is informative—the case is genuinely ambiguous. Similarly, prediction variance across ensemble members estimates epistemic uncertainty. Large disagreement indicates that the prediction depends strongly on training specifics rather than robust learned patterns. Deep ensembles provide well-calibrated uncertainty estimates but multiply computational cost linearly with ensemble size.</p>
<p>Why does ensemble disagreement estimate uncertainty? The intuition is that if multiple models trained on slightly different data or with different random seeds all converge to similar predictions, the prediction is robust to training details and likely reflects genuine patterns in the data. Conversely, if predictions diverge substantially, each model has learned something idiosyncratic that does not generalize. For variant effect prediction, a variant where five ensemble members predict pathogenicity between 0.75 and 0.82 warrants more confidence than one where predictions range from 0.35 to 0.90. The ensemble is effectively asking: “Would I reach the same conclusion if I had seen slightly different training examples?” When the answer is no, that uncertainty should propagate to clinical interpretation.</p>
<p>Monte Carlo dropout approximates Bayesian inference by applying dropout at test time and averaging predictions across multiple stochastic forward passes. Variance across passes estimates uncertainty without training multiple models. This approach adds modest computational overhead and can be applied to any dropout-containing architecture.</p>
<p><strong>Conformal prediction</strong> provides distribution-free uncertainty quantification with coverage guarantees <span class="citation" data-cites="angelopoulos_conformal_2023">(<a href="../bib/references.html#ref-angelopoulos_conformal_2023" role="doc-biblioref">Angelopoulos and Bates 2023</a>)</span>. Given a calibration set (held-out labeled examples used to determine score thresholds), conformal methods construct prediction sets guaranteed to contain the true label with specified probability (e.g., 90%). For variant classification, this might produce sets like {pathogenic, uncertain} or {benign} depending on the variant and desired coverage. Larger prediction sets indicate greater uncertainty; single-element sets indicate confident predictions. <a href="../part_6/p6-ch24-uncertainty.html#sec-ch24-conformal" class="quarto-xref"><span>Section 24.5</span></a> examines conformal methods for genomic applications in detail.</p>
</section>
<section id="sec-ch18-ood-detection" class="level3" data-number="18.6.3">
<h3 data-number="18.6.3" class="anchored" data-anchor-id="sec-ch18-ood-detection"><span class="header-section-number">18.6.3</span> Out-of-Distribution Detection</h3>
<p>Beyond quantifying uncertainty for in-distribution predictions, responsible deployment requires detecting when inputs fall outside the model’s training distribution. A protein language model trained on natural proteins may produce confident but unreliable predictions for synthetic sequences or fragments. A regulatory model trained on common cell types may fail on rare developmental stages.</p>
<p>Likelihood-based detection uses the model’s own representations to identify unfamiliar inputs. Sequences with low embedding density (few similar sequences nearby in the model’s learned representation space, indicating the input is unusual compared to training data) or anomalous attention patterns may fall outside the training distribution regardless of predicted scores. Flagging these inputs for manual review prevents automated classification of cases the model cannot reliably assess.</p>
<p>Distance-based methods compare new inputs to training examples in representation space. Variants far from any training example in embedding space warrant skepticism even if the model produces confident predictions. Maintaining summary statistics of training representations enables efficient distance computation at deployment.</p>
<div id="fig-vep-uncertainty" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vep-uncertainty-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/05-A-fig-vep-uncertainty.svg" class="img-fluid figure-img"></p>
<figcaption>Aleatoric vs.&nbsp;epistemic uncertainty sources</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/05-B-fig-vep-uncertainty.svg" class="img-fluid figure-img"></p>
<figcaption>Ensemble disagreement quantifies uncertainty</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/05-C-fig-vep-uncertainty.svg" class="img-fluid figure-img"></p>
<figcaption>Distance-based out-of-distribution detection</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/05-D-fig-vep-uncertainty.svg" class="img-fluid figure-img"></p>
<figcaption>Selective prediction improves reliability</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vep-uncertainty-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18.5: Uncertainty quantification for variant effect prediction. (A) Aleatoric uncertainty (inherent data ambiguity) reflects context-dependent effects that cannot be reduced. Epistemic uncertainty (model limitations) can be reduced with more training data. (B) Ensemble disagreement provides empirical uncertainty estimates—variance across model runs indicates prediction reliability. (C) Distance from training distribution flags out-of-distribution variants requiring caution. (D) Selective prediction uses uncertainty to abstain on difficult cases, achieving higher accuracy by routing uncertain variants to expert review rather than providing unreliable predictions.
</figcaption>
</figure>
</div>
<p><a href="../part_6/p6-ch24-uncertainty.html" class="quarto-xref"><span>Chapter 24</span></a> develops uncertainty quantification methods in detail, including practical implementation guidance and evaluation metrics. For VEP applications, the key insight is that uncertainty estimates complement point predictions: high-confidence predictions can inform clinical decisions; low-confidence predictions should prompt additional evidence gathering rather than blind acceptance of model outputs.</p>
</section>
</section>
<section id="sec-ch18-fm-gains" class="level2" data-number="18.7">
<h2 data-number="18.7" class="anchored" data-anchor-id="sec-ch18-fm-gains"><span class="header-section-number">18.7</span> What Foundation Models Add</h2>
<p>Having surveyed current foundation model approaches, we can now directly address what they contribute beyond classical methods (<a href="../part_1/p1-ch04-vep-classical.html" class="quarto-xref"><span>Chapter 4</span></a>). The answer is nuanced: substantial improvements in some domains, modest gains in others, and persistent blind spots that new architectures have not yet resolved.</p>
<section id="sec-ch18-improved-discrimination" class="level3" data-number="18.7.1">
<h3 data-number="18.7.1" class="anchored" data-anchor-id="sec-ch18-improved-discrimination"><span class="header-section-number">18.7.1</span> Improved Discrimination</h3>
<p>On standard benchmarks, foundation model VEP methods consistently outperform classical predictors. <em>AlphaMissense</em> achieves auROC of 0.91 on held-out ClinVar missense variants compared to 0.85 for <em>CADD</em> <em>[Citation Needed]</em>. <em>SpliceAI</em> detects pathogenic splicing variants with sensitivity of 0.90 compared to 0.60 for <em>MaxEntScan</em> <em>[Citation Needed]</em>. <em>GPN-MSA</em> scores correlate more strongly with deep mutational scanning measurements than phyloP or <em>GERP</em> <em>[Citation Needed]</em>.</p>
<p>These improvements reflect richer representations. Classical methods aggregate independent features (conservation, amino acid properties, domain annotations); foundation models learn nonlinear interactions among positions and capture patterns too subtle for manual feature engineering. The gap is largest for variants where context matters: buried core missense variants where structural environment determines impact, splice variants where cryptic site activation depends on flanking sequence, regulatory variants where motif disruption interacts with chromatin context.</p>
</section>
<section id="sec-ch18-extended-coverage" class="level3" data-number="18.7.2">
<h3 data-number="18.7.2" class="anchored" data-anchor-id="sec-ch18-extended-coverage"><span class="header-section-number">18.7.2</span> Extended Coverage</h3>
<p>Classical methods often fail silently on understudied genes, rare variant classes, or poorly annotated regions. <em>SIFT</em> and <em>PolyPhen</em> require protein alignments; variants in singleton genes without homologs receive no prediction. <em>CADD</em> depends on annotation features; variants in regions lacking regulatory marks receive uninformative scores.</p>
<p>Foundation models degrade more gracefully. Protein language models score any amino acid sequence regardless of available homologs. DNA language models score any genomic position regardless of existing annotation. This extended coverage matters for clinical sequencing of rare diseases, where pathogenic variants often reside in less-studied genes precisely because their severe effects are incompatible with population frequency.</p>
</section>
<section id="sec-ch18-mechanistic-interpretability" class="level3" data-number="18.7.3">
<h3 data-number="18.7.3" class="anchored" data-anchor-id="sec-ch18-mechanistic-interpretability"><span class="header-section-number">18.7.3</span> Mechanistic Interpretability</h3>
<p><em>AlphaGenome</em> and similar multi-output models provide predictions about mechanism rather than bare pathogenicity scores. A variant flagged as deleterious might also show predicted effects on chromatin accessibility, contact frequency, and downstream gene expression. These mechanistic predictions enable hypothesis generation and targeted experimental validation (<a href="../part_6/p6-ch25-interpretability.html" class="quarto-xref"><span>Chapter 25</span></a>).</p>
<p>Classical methods offer limited mechanistic insight. <em>CADD</em> provides a single score without indicating whether it derives from conservation, protein impact, regulatory disruption, or other features. Decomposing the score into component contributions requires separate analysis. Foundation models that predict molecular phenotypes naturally provide this decomposition.</p>
</section>
<section id="sec-ch18-persistent-limitations" class="level3" data-number="18.7.4">
<h3 data-number="18.7.4" class="anchored" data-anchor-id="sec-ch18-persistent-limitations"><span class="header-section-number">18.7.4</span> Persistent Limitations</h3>
<p>Foundation models have not solved several fundamental challenges. Ancestry bias persists because training data remain skewed toward European populations; performance degrades for variants common in African or Asian populations but rare in training sets. The systematic analysis of ancestry-related confounding appears in <a href="../part_3/p3-ch13-confounding.html#sec-ch13-ancestry-confounding" class="quarto-xref"><span>Section 13.2.1</span></a>, with broader confounding detection methods in <a href="../part_3/p3-ch13-confounding.html#sec-ch13-detection" class="quarto-xref"><span>Section 13.8</span></a>. Calibration requires substantial labeled data that inherit existing biases. Rare variant classes (structural variants, complex indels, repeat expansions) lack sufficient training examples for reliable prediction.</p>
<p>The comparison to classical methods reveals diminishing returns on certain axes. For well-conserved active site variants in thoroughly studied proteins, <em>PolyPhen-2</em> already achieves near-optimal performance; <em>AlphaMissense</em> improves marginally. The largest foundation model gains appear for difficult cases where classical features are uninformative or misleading.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Key Insight: Where Foundation Models Help Most">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: Where Foundation Models Help Most
</div>
</div>
<div class="callout-body-container callout-body">
<p>Foundation models provide the largest improvements over classical methods in precisely the situations where clinical need is greatest:</p>
<ol type="1">
<li><strong>Novel genes:</strong> Orphan proteins lacking homologs where alignment-based methods fail</li>
<li><strong>Rare variants:</strong> Never-before-seen substitutions where population frequency provides no information</li>
<li><strong>Noncoding regions:</strong> Regulatory variants where classical annotation is sparse</li>
<li><strong>Context-dependent effects:</strong> Buried core variants, cryptic splice sites, motif-chromatin interactions</li>
</ol>
<p>For common variants in well-studied genes with extensive clinical annotation, the marginal improvement may be modest. But these are not the variants causing diagnostic uncertainty. The value of foundation models lies in extending reliable prediction to the long tail of rare variants in less-characterized genes, exactly where clinical interpretation struggles most.</p>
</div>
</div>
<div id="fig-vep-gains-gaps" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vep-gains-gaps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/06-A-fig-vep-gains-gaps.svg" class="img-fluid figure-img"></p>
<figcaption>Performance varies by protein family</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/06-B-fig-vep-gains-gaps.svg" class="img-fluid figure-img"></p>
<figcaption>Rare variants remain challenging</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/06-C-fig-vep-gains-gaps.svg" class="img-fluid figure-img"></p>
<figcaption>Clinical impact assessment</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/06-D-fig-vep-gains-gaps.svg" class="img-fluid figure-img"></p>
<figcaption>Remaining gaps require new approaches</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vep-gains-gaps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18.6: Foundation model VEP: gains and remaining gaps. (A) Performance varies by protein family—well-characterized families achieve high accuracy while poorly-studied families show degraded performance. (B) Rare variants are harder to predict, particularly for recently evolved or population-specific variants. (C) Clinical impact assessment: FM predictions could reclassify significant fractions of VUS, but require appropriate validation. (D) Remaining gaps include complex variants (multi-allelic, structural), modifier effects, and tissue-specific pathogenicity. Foundation models have advanced VEP substantially but do not eliminate the need for functional validation.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-ch18-clinical-integration" class="level2" data-number="18.8">
<h2 data-number="18.8" class="anchored" data-anchor-id="sec-ch18-clinical-integration"><span class="header-section-number">18.8</span> Clinical Integration Considerations</h2>
<p>Foundation model VEP tools require thoughtful integration into clinical workflows. Their benchmark performance does not automatically translate without attention to deployment context, validation requirements, and human factors.</p>
<section id="sec-ch18-lab-validation" class="level3" data-number="18.8.1">
<h3 data-number="18.8.1" class="anchored" data-anchor-id="sec-ch18-lab-validation"><span class="header-section-number">18.8.1</span> Laboratory Validation</h3>
<p>Before clinical use, laboratories should validate foundation model tools against local truth sets representing their patient population. Published benchmark performance on ClinVar may not generalize to a laboratory’s specific case mix. Validation should assess discrimination (can the tool distinguish pathogenic from benign?), calibration (do probability estimates match observed frequencies?), and utility (does incorporating the tool improve variant classification compared to existing workflows?).</p>
<p>Validation requires variants with known pathogenicity independent of the computational predictions being tested. Using ClinVar variants whose classifications already incorporated <em>CADD</em> scores to validate <em>CADD</em> creates circular reasoning, a form of label circularity examined in <a href="../part_3/p3-ch13-confounding.html#sec-ch13-label-circularity" class="quarto-xref"><span>Section 13.5</span></a>. Gold-standard variants from functional studies, segregation data, or expert review provide cleaner validation targets, with detailed evaluation methodology in <a href="../part_3/p3-ch12-evaluation.html" class="quarto-xref"><span>Chapter 12</span></a>.</p>
<div class="callout callout-style-default callout-warning callout-titled" title="Practical Guidance: Laboratory Validation Checklist">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical Guidance: Laboratory Validation Checklist
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before deploying a foundation model VEP tool clinically, ensure you have:</p>
<ul class="task-list">
<li><label><input type="checkbox">Identified an appropriate validation set independent of tool training data</label></li>
<li><label><input type="checkbox">Assessed discrimination metrics (auROC, auPRC) on your patient population</label></li>
<li><label><input type="checkbox">Generated calibration plots and calculated expected calibration error</label></li>
<li><label><input type="checkbox">Compared performance to your current workflow (utility analysis)</label></li>
<li><label><input type="checkbox">Established thresholds for PP3/BP4 evidence based on local calibration</label></li>
<li><label><input type="checkbox">Documented ancestry composition of validation set and any stratified analyses</label></li>
<li><label><input type="checkbox">Trained analysts on appropriate interpretation and known limitations</label></li>
<li><label><input type="checkbox">Established a process for monitoring ongoing performance and updating thresholds</label></li>
</ul>
<p>This validation should be repeated when model versions change or when significant shifts in your patient population occur.</p>
</div>
</div>
</section>
<section id="sec-ch18-workflow-integration" class="level3" data-number="18.8.2">
<h3 data-number="18.8.2" class="anchored" data-anchor-id="sec-ch18-workflow-integration"><span class="header-section-number">18.8.2</span> Workflow Integration</h3>
<p>Foundation model predictions represent one evidence type among many. ACMG guidelines specify how computational evidence combines with population frequency, functional data, segregation, and clinical phenotype. Computational evidence alone rarely suffices for pathogenic or benign classification; it supports or weakens classifications established by other evidence types.</p>
<p>Laboratory information systems require modification to display and store foundation model outputs alongside existing annotations. Analyst training ensures appropriate interpretation: understanding that high scores indicate deleteriousness without establishing causation, recognizing when scores fall outside validated ranges, and knowing when to request additional evidence for uncertain cases.</p>
</section>
<section id="sec-ch18-clinical-communication" class="level3" data-number="18.8.3">
<h3 data-number="18.8.3" class="anchored" data-anchor-id="sec-ch18-clinical-communication"><span class="header-section-number">18.8.3</span> Communication to Clinicians</h3>
<p>Variant reports communicated to ordering clinicians should present foundation model evidence appropriately. Reporting raw scores without context confuses non-specialist clinicians. Reporting discrete classifications without uncertainty may convey false confidence. Effective reporting might state: “Computational tools (<em>AlphaMissense</em>, <em>SpliceAI</em>) concordantly predict this variant is likely to affect protein function, supporting the PP3 criterion for pathogenicity classification.”</p>
<p>When foundation model predictions conflict with other evidence, reports should acknowledge the discrepancy rather than suppressing inconvenient results. A variant segregating with disease in a family but receiving a benign computational prediction warrants explicit discussion, not quiet exclusion of the computational evidence.</p>
</section>
</section>
<section id="sec-ch18-open-challenges" class="level2" data-number="18.9">
<h2 data-number="18.9" class="anchored" data-anchor-id="sec-ch18-open-challenges"><span class="header-section-number">18.9</span> Open Challenges</h2>
<p>Current foundation model approaches leave substantial problems unsolved. These open challenges define directions for future research and areas where clinical caution remains warranted.</p>
<section id="sec-ch18-complex-variants" class="level3" data-number="18.9.1">
<h3 data-number="18.9.1" class="anchored" data-anchor-id="sec-ch18-complex-variants"><span class="header-section-number">18.9.1</span> Complex Variant Types</h3>
<p>Most current models address single nucleotide variants and small indels. Structural variants (deletions, duplications, inversions spanning kilobases to megabases) remain largely outside foundation model capabilities. Copy number variation, repeat expansions, and complex rearrangements alter genome architecture in ways current sequence models cannot represent. Extending foundation model paradigms to these variant classes requires architectural innovations beyond current approaches.</p>
</section>
<section id="sec-ch18-long-read" class="level3" data-number="18.9.2">
<h3 data-number="18.9.2" class="anchored" data-anchor-id="sec-ch18-long-read"><span class="header-section-number">18.9.2</span> Long-Read Sequencing and Variant Effect Prediction</h3>
<p>The emergence of long-read sequencing technologies fundamentally changes the landscape of variant detection and interpretation. Pacific Biosciences (PacBio) high-fidelity (HiFi) reads and Oxford Nanopore Technologies (ONT) ultra-long reads routinely span tens of kilobases, far exceeding the 150-300 base pair fragments of short-read platforms <span class="citation" data-cites="logsdon_long-read_2020">(<a href="../bib/references.html#ref-logsdon_long-read_2020" role="doc-biblioref">Logsdon, Vollger, and Eichler 2020</a>)</span>. This extended read length enables detection of variant classes invisible to short-read analysis while creating both opportunities and challenges for foundation model-based interpretation.</p>
<p><strong>Structural variant detection</strong> benefits most dramatically from long-read sequencing. Short reads struggle to resolve breakpoints of large deletions, duplications, and inversions, often missing structural variants entirely or mischaracterizing their boundaries. Long reads spanning structural variant breakpoints enable precise localization and accurate genotyping. Tools like <em>pbsv</em>, <em>Sniffles2</em>, and <em>SVIM</em> detect structural variants with sensitivity and specificity far exceeding short-read methods <span class="citation" data-cites="smolka_detection_2024">(<a href="../bib/references.html#ref-smolka_detection_2024" role="doc-biblioref">Smolka et al. 2024</a>)</span>. The resulting catalogs reveal that each human genome harbors thousands of structural variants affecting millions of base pairs, a substantial source of genetic variation previously obscured by technological limitations.</p>
<p>Interpreting these structural variants presents challenges that current foundation models do not address. A deletion removing an entire exon has qualitatively different consequences than a single nucleotide substitution, yet protein language models score point mutations without mechanisms for evaluating larger-scale changes. Regulatory models like <em>Enformer</em> operate on fixed-length sequence windows and cannot naturally represent the genomic rearrangements that structural variants introduce. Extending foundation model approaches to structural variant interpretation requires new architectures that explicitly model genome organization rather than treating sequence as a linear string.</p>
<p><strong>Phasing and haplotype-aware analysis</strong> represent a second area where long-read data transforms variant interpretation. Human genomes are diploid, with variants distributed across two homologous chromosomes. The functional consequences of multiple variants depend critically on whether they reside on the same haplotype (<em>cis</em>) or opposite haplotypes (<em>trans</em>). Two loss-of-function variants in <em>cis</em> leave one functional copy, while the same variants in <em>trans</em> may completely abolish gene function (<a href="../part_1/p1-ch01-ngs.html#sec-ch01-phasing" class="quarto-xref"><span>Section 1.4</span></a>; <a href="../part_7/p7-ch29-rare-disease.html#sec-ch29-compound-het" class="quarto-xref"><span>Section 29.3.2</span></a>).</p>
<p>Short-read sequencing typically produces unphased genotypes: variants are detected without determining their chromosomal assignment. Statistical phasing using population reference panels infers likely haplotypes but introduces errors, particularly for rare variants where population frequencies provide limited information. Long reads spanning multiple variant sites provide direct physical phasing, resolving haplotype structure from the sequencing data itself. With HiFi reads averaging 15-20 kilobases, most nearby variants can be directly phased, while ultra-long ONT reads exceeding 100 kilobases can phase variants separated by substantial genomic distances.</p>
<p>Foundation models have not yet incorporated haplotype information systematically. Protein language models score individual variants without considering whether they occur together on the same protein copy. DNA language models process single reference sequences rather than diploid genotypes with phased variants. Developing haplotype-aware variant effect prediction remains an open challenge: models must learn how variant combinations interact, distinguishing compensatory mutations that restore function from compound effects that amplify disruption.</p>
<div id="fig-long-read-vep" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-long-read-vep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_4/ch18/07-fig-long-read-vep.svg" class="img-fluid figure-img"></p>
<figcaption>Long-read sequencing expands variant detection scope</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-long-read-vep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18.7: Long-read sequencing expands the scope of variant effect prediction. Short-read sequencing (top) detects primarily SNVs and small indels for which current FM-VEP approaches are well-suited. Long-read sequencing (bottom) reveals structural variants, repeat expansions, and complex haplotypes that current models cannot process. Realizing the clinical potential of long-read sequencing requires developing FM-VEP approaches for these new variant classes—a major open challenge.
</figcaption>
</figure>
</div>
<p><strong>Long-read-specific variant calling</strong> increasingly incorporates deep learning approaches. <em>DeepVariant</em> and <em>Clair3</em> use convolutional and recurrent architectures to call variants from pileup images, with versions trained specifically on long-read data achieving accuracy that approaches or exceeds short-read calling for SNVs and small indels <span class="citation" data-cites="zheng_symphonizing_2022">(<a href="../bib/references.html#ref-zheng_symphonizing_2022" role="doc-biblioref">Zheng et al. 2022</a>)</span>. <em>PEPPER-Margin-DeepVariant</em> pipelines combine multiple neural network components to handle the higher error rates and distinct error profiles of nanopore sequencing. These tools demonstrate that deep learning can extract accurate variant calls from long-read data despite its different characteristics.</p>
<p>The error profiles of long-read platforms create both challenges and opportunities for foundation model training. ONT sequencing exhibits systematic errors in homopolymer regions and certain sequence contexts that differ from short-read error patterns. PacBio HiFi reads achieve per-read accuracy exceeding 99.9% through circular consensus sequencing, approaching short-read quality while retaining long-read advantages. Foundation models trained on long-read data must learn these error profiles to distinguish true variants from sequencing artifacts.</p>
<p><strong>Training foundation models on long-read data</strong> remains largely unexplored. Current DNA language models train on reference genomes and short-read assemblies, rarely incorporating the raw signal or base-called sequences from long-read platforms. Models trained directly on long-read data might learn different patterns: the extended context could enable modeling of longer-range dependencies, while exposure to structural variants during training could improve representation of genome architecture.</p>
<p>Several technical challenges complicate long-read foundation model development. Training data volumes are smaller: long-read datasets remain orders of magnitude smaller than short-read repositories. The computational cost of processing longer sequences scales unfavorably for attention-based architectures, though state-space models like those underlying <em>Evo 2</em> (<a href="../part_2/p2-ch07-attention.html#sec-ch07-ssm" class="quarto-xref"><span>Section 7.7.2</span></a>) partially address this limitation. Representing structural variants requires architectural innovations beyond sequence modeling, potentially incorporating graph representations or hierarchical encodings of genome structure.</p>
<p>The integration of long-read variant detection with foundation model interpretation represents a frontier for the field. As long-read sequencing costs decline and data volumes grow, training foundation models that leverage the unique advantages of long reads (extended context, structural variant representation, direct phasing) becomes increasingly feasible. Models that combine the pattern-recognition capabilities of foundation models with the variant classes revealed by long-read sequencing could substantially expand the scope of computational variant interpretation.</p>
</section>
<section id="sec-ch18-combinatorial" class="level3" data-number="18.9.3">
<h3 data-number="18.9.3" class="anchored" data-anchor-id="sec-ch18-combinatorial"><span class="header-section-number">18.9.3</span> Combinatorial Effects</h3>
<p>Genomes contain multiple variants that may interact. Compound heterozygosity (two variants affecting both copies of a gene) creates pathogenic states from individually tolerable variants, a clinical scenario examined in <a href="../part_1/p1-ch01-ngs.html#sec-ch01-phasing-importance" class="quarto-xref"><span>Section 1.4.1</span></a> and <a href="../part_7/p7-ch29-rare-disease.html#sec-ch29-compound-het" class="quarto-xref"><span>Section 29.3.2</span></a>. Modifier variants in other genes modulate penetrance. Haplotype effects mean variants on the same chromosome have different consequences than variants on opposite chromosomes, with phasing methods to distinguish these scenarios detailed in <a href="../part_1/p1-ch01-ngs.html#sec-ch01-phasing" class="quarto-xref"><span>Section 1.4</span></a>. Current models score variants independently, ignoring these interactions that determine clinical presentation.</p>
</section>
<section id="sec-ch18-phenotype-specificity" class="level3" data-number="18.9.4">
<h3 data-number="18.9.4" class="anchored" data-anchor-id="sec-ch18-phenotype-specificity"><span class="header-section-number">18.9.4</span> Phenotype Specificity</h3>
<p>A variant pathogenic for one phenotype may be benign for another. <em>SCN5A</em> variants cause distinct cardiac arrhythmia syndromes depending on their specific functional effects <em>[Citation Needed]</em>. Foundation models trained on pathogenic/benign labels average across phenotypes, potentially obscuring clinically relevant specificity. Phenotype-specific training requires much larger datasets than currently available.</p>
</section>
<section id="sec-ch18-temporal-context" class="level3" data-number="18.9.5">
<h3 data-number="18.9.5" class="anchored" data-anchor-id="sec-ch18-temporal-context"><span class="header-section-number">18.9.5</span> Temporal and Environmental Context</h3>
<p>Variant effects often depend on age, environmental exposures, or physiological state. A variant pathogenic under metabolic stress may be tolerable at baseline. Foundation models capture sequence context but not the dynamic biological context determining phenotypic expression. Integrating longitudinal clinical data with sequence-level predictions remains an unsolved challenge.</p>
</section>
<section id="sec-ch18-equity" class="level3" data-number="18.9.6">
<h3 data-number="18.9.6" class="anchored" data-anchor-id="sec-ch18-equity"><span class="header-section-number">18.9.6</span> Equity and Access</h3>
<p>State-of-the-art foundation models require substantial computational resources for training and sometimes for inference. Laboratories in resource-limited settings may lack access to cutting-edge tools, creating a two-tiered system where well-funded institutions deploy sophisticated variant interpretation while others rely on simpler methods. Precomputed scores (like <em>AlphaMissense’s</em> proteome-wide release) partially address computational barriers, but equity concerns extend far beyond compute access.</p>
<p>Training data composition determines which patients foundation models serve well. ClinVar contains many more pathogenic variant classifications for European-ancestry individuals than for other populations <span class="citation" data-cites="landrum_clinvar_2018">(<a href="../bib/references.html#ref-landrum_clinvar_2018" role="doc-biblioref">Landrum et al. 2018</a>)</span>. Protein language models trained predominantly on sequences from well-studied organisms may capture evolutionary constraints less accurately for proteins divergent from training distributions. The consequence is systematic: variant interpretation performs best for patients who already benefit most from biomedical research, and worst for those historically excluded. A diagnostic laboratory serving a cosmopolitan population will encounter variants where foundation model predictions are less reliable precisely because those variants come from underrepresented ancestries.</p>
<p>Validation cohorts exhibit similar biases. When foundation models are evaluated on ClinVar or gnomAD-derived benchmarks, performance metrics reflect accuracy for the populations overrepresented in those resources. A model achieving 0.95 auROC on standard benchmarks may achieve substantially lower discrimination for African-ancestry variants simply because the benchmark itself undersamples that population. Equitable deployment requires ancestry-stratified evaluation that explicitly reports performance gaps, not aggregate metrics that obscure disparities (<a href="../part_3/p3-ch12-evaluation.html" class="quarto-xref"><span>Chapter 12</span></a>). The broader implications of these biases, and governance frameworks for addressing them, receive comprehensive treatment in <a href="../part_6/p6-ch27-regulatory.html#sec-ch27-regulatory" class="quarto-xref"><span>Section 27.1</span></a>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Stop and Think: Equity in Model Development">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think: Equity in Model Development
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a clinical genetics laboratory that serves a diverse patient population where 40% of patients have non-European ancestry. The laboratory is evaluating <em>AlphaMissense</em> for clinical use.</p>
<ol type="1">
<li>What specific validation analyses should the laboratory conduct before deployment?</li>
<li>If the model performs well overall (auROC = 0.92) but substantially worse for African-ancestry variants (auROC = 0.81), what are the ethical implications of deploying it?</li>
<li>How might the laboratory communicate differential performance to ordering clinicians?</li>
</ol>
<p>There are no simple answers to these questions, but responsible deployment requires explicitly grappling with them.</p>
</div>
</div>
</section>
</section>
<section id="sec-ch18-conclusion" class="level2" data-number="18.10">
<h2 data-number="18.10" class="anchored" data-anchor-id="sec-ch18-conclusion"><span class="header-section-number">18.10</span> Tools for Interpretation, Not Oracles</h2>
<p>Foundation models have transformed variant effect prediction from feature engineering to <strong>representation learning</strong>. Protein language models capture evolutionary constraint at resolution that multiple sequence alignments cannot match. DNA language models and regulatory models extend coverage to noncoding variants across the genome. Multi-omic architectures provide mechanistic predictions enabling hypothesis generation beyond bare deleteriousness scores. The best current methods substantially outperform classical approaches on established benchmarks, particularly for rare variants and novel genes where training data are sparse.</p>
<p>Yet benchmark performance does not automatically translate to clinical utility. Calibration requires careful attention: a model may discriminate pathogenic from benign variants while systematically overestimating or underestimating probabilities. Uncertainty quantification remains immature; models often produce confident predictions for inputs that fall outside their training distribution. Population bias persists despite foundation model advances; improvements over classical methods are smallest for ancestry groups underrepresented in training data. Complex variant types, combinatorial effects, and tissue-specific consequences remain beyond current capabilities.</p>
<p>Clinical deployment demands humility alongside enthusiasm. Foundation model VEP tools are aids to human interpretation, not autonomous classifiers. Their predictions inform rather than determine variant classification, complementing population frequency data, functional assay evidence, segregation analysis, and clinical judgment. Used appropriately, they accelerate diagnosis and reduce missed findings. Used as oracles, they create false confidence and may perpetuate existing inequities in genomic medicine. Clinical workflows (<a href="../part_7/p7-ch29-rare-disease.html" class="quarto-xref"><span>Chapter 29</span></a>, <a href="../part_7/p7-ch28-clinical-risk.html" class="quarto-xref"><span>Chapter 28</span></a>) integrate these predictions alongside uncertainty quantification (<a href="../part_6/p6-ch24-uncertainty.html" class="quarto-xref"><span>Chapter 24</span></a>) and interpretability methods that probe what foundation models have learned (<a href="../part_6/p6-ch25-interpretability.html" class="quarto-xref"><span>Chapter 25</span></a>). Variant effect prediction sits at the center of genomic medicine; foundation models have raised its ceiling while the work of achieving its potential continues.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Chapter Summary">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Summary
</div>
</div>
<div class="callout-body-container callout-body">
<div class="callout callout-style-default callout-tip callout-titled" title="Test Yourself">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Test Yourself
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before reviewing the summary, test your recall:</p>
<ol type="1">
<li><p>Explain the paradigm shift from classical feature-based VEP to foundation model-based VEP. How do foundation models perform zero-shot variant scoring without pathogenicity labels?</p></li>
<li><p>Compare protein-based VEP approaches (ESM-1v, EVE, AlphaMissense) with DNA-based approaches (SpliceAI, Enformer, GPN-MSA). For each approach, identify what variant types it handles best and what biological information it leverages.</p></li>
<li><p>What is model calibration and why does it matter for clinical variant interpretation? How do reliability diagrams help assess calibration quality?</p></li>
<li><p>Describe three strategies for combining evidence across multiple foundation models. What is the double-counting problem and how can it be avoided when applying ACMG criteria?</p></li>
<li><p>Identify three persistent challenges or limitations in foundation model-based VEP that require human judgment. For each, explain why current models struggle and what types of variants are most affected.</p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answers">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answers
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Paradigm shift from classical to foundation model VEP</strong>: Classical methods manually engineer features (conservation scores, amino acid properties, domain annotations) and train classifiers on labeled pathogenic/benign variants. Foundation models invert this: they learn representations from unlabeled sequences during pretraining (masked token prediction), discovering evolutionary constraints implicitly. Zero-shot scoring compares the likelihood of reference versus variant alleles given learned sequence context—variants that are evolutionarily unexpected (low likelihood) tend to be deleterious. This approach requires no pathogenicity labels because evolution has already conducted billions of experiments testing which variants are compatible with life.</p></li>
<li><p><strong>Protein vs.&nbsp;DNA approaches comparison</strong>: Protein approaches (<em>ESM-1v</em>, <em>EVE</em>, <em>AlphaMissense</em>) operate on amino acid sequences and excel at missense variants. <em>ESM-1v</em> uses zero-shot likelihood ratios from protein language models. <em>EVE</em> fits variational autoencoders to MSAs, capturing co-evolution. <em>AlphaMissense</em> combines sequence with AlphaFold2 structural features for state-of-the-art missense prediction. DNA approaches (<em>SpliceAI</em>, <em>Enformer</em>, <em>GPN-MSA</em>, <em>Evo 2</em>) work on nucleotide sequences and cover all variant types. <em>SpliceAI</em> specializes in splice variants using dilated convolutions. <em>Enformer</em> predicts regulatory impacts. <em>GPN-MSA</em> and <em>Evo 2</em> provide DNA language model scores genome-wide, including noncoding regions where protein models cannot operate.</p></li>
<li><p><strong>Calibration importance and reliability diagrams</strong>: Calibration ensures that predicted probabilities match observed frequencies—a score of 0.8 should mean 80% of variants with that score are truly pathogenic. Without calibration, scores are arbitrary and cannot guide clinical decisions. Reliability diagrams plot predicted probabilities (x-axis) against observed pathogenic proportions (y-axis). Perfect calibration falls on the diagonal. Points below indicate overconfidence (model predicts higher probabilities than reality); points above indicate underconfidence. Neural networks typically overpredict extreme probabilities and require post-hoc calibration (temperature scaling, isotonic regression) before clinical use.</p></li>
<li><p><strong>Combining evidence strategies and double-counting</strong>: Three strategies:</p>
<ol type="1">
<li><p>Modular routing—apply different models to different variant types (AlphaMissense for missense, SpliceAI for splice sites).</p></li>
<li><p>Score aggregation—combine predictions from multiple models using ensemble methods or Bayesian integration with careful weighting.</p></li>
<li><p>Tiered filtering—use fast models for initial screening, expensive models for prioritized variants.</p></li>
</ol>
<p>The double-counting problem arises when multiple predictors share information sources (e.g., <em>AlphaMissense</em> and <em>ESM-1v</em> both encode evolutionary constraint). Treating correlated predictions as independent evidence overweights shared signals. Solution: assess correlations, group predictors by information source, select one representative from each group for ACMG evidence, and document tool correlations in laboratory validation records.</p></li>
<li><p><strong>Three persistent challenges</strong>:</p>
<ol type="1">
<li><p><strong>Structural variants</strong> (deletions, duplications, inversions)—current sequence models cannot represent architectural rearrangements; they are trained on SNVs and small indels.</p></li>
<li><p><strong>Combinatorial/compound effects</strong>—models score variants independently, missing compound heterozygosity where two individually tolerable variants together cause disease, and haplotype effects where phasing determines pathogenicity.</p></li>
<li><p><strong>Population bias</strong>—training data overrepresent European ancestry; models perform worse for African and Asian populations where variants are undersampled in ClinVar/gnomAD, creating systematic disparities in prediction accuracy for underrepresented groups.</p></li>
</ol>
<p>These limitations require human judgment to integrate additional evidence (segregation, functional assays, ancestry-appropriate interpretation).</p></li>
</ol>
</div>
</div>
</div>
</div>
</div>
<p><strong>Core concepts covered:</strong></p>
<ul>
<li><p><strong>Paradigm shift:</strong> Foundation models learn representations from unlabeled sequences, enabling variant scoring without pathogenicity labels. Evolution has already encoded functional constraints; models learn to detect when variants violate these patterns.</p></li>
<li><p><strong>Protein-based methods:</strong> Zero-shot scoring with protein language models (<em>ESM-1v</em>) compares amino acid likelihoods. Alignment-based models (<em>EVE</em>, <em>popEVE</em>) explicitly capture evolutionary constraints from MSAs. <em>AlphaMissense</em> combines sequence and structural information for state-of-the-art missense prediction.</p></li>
<li><p><strong>DNA-based methods:</strong> <em>SpliceAI</em> predicts splicing changes using dilated convolutions over 10kb context. <em>Enformer</em> and <em>Sei</em> predict regulatory effects. <em>GPN-MSA</em> and <em>Evo 2</em> provide DNA language model scoring for all variant types.</p></li>
<li><p><strong>Integration strategies:</strong> Different models address different variant types. Combining evidence requires avoiding double-counting from correlated predictors. Practical workflows tier models by computational cost.</p></li>
<li><p><strong>Calibration:</strong> Raw model outputs require calibration before clinical use. Reliability diagrams assess calibration quality. ACMG criteria (PP3/BP4) map continuous scores to evidence levels through calibrated thresholds.</p></li>
<li><p><strong>Uncertainty:</strong> Epistemic uncertainty (model knowledge gaps) differs from aleatoric uncertainty (inherent unpredictability). Ensemble methods, conformal prediction, and out-of-distribution detection provide complementary approaches.</p></li>
<li><p><strong>Persistent challenges:</strong> Structural variants, combinatorial effects, phenotype specificity, and population bias remain unsolved. Foundation models are tools for interpretation, not oracles.</p></li>
</ul>
<p><strong>Key connections:</strong></p>
<ul>
<li>Chapter 4 provides the classical VEP baseline that foundation models improve upon</li>
<li>Chapter 15 develops the protein language model architectures underlying <em>ESM-1v</em> and <em>AlphaMissense</em></li>
<li>Chapter 16 covers the regulatory models (<em>Enformer</em>, <em>Sei</em>) used for noncoding VEP</li>
<li>Chapter 23 presents the full technical treatment of calibration and uncertainty quantification</li>
<li>Chapters 27-28 show how VEP tools integrate into clinical workflows</li>
</ul>
<p><strong>Looking ahead:</strong> Having established how foundation models predict variant effects, <a href="../part_5/p5-ch19-rna.html" class="quarto-xref"><span>Chapter 19</span></a> extends these concepts to RNA-level predictions, while <a href="../part_6/p6-ch24-uncertainty.html" class="quarto-xref"><span>Chapter 24</span></a> provides the complete framework for responsible uncertainty quantification in clinical deployment.</p>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-angelopoulos_conformal_2023" class="csl-entry" role="listitem">
Angelopoulos, Anastasios N., and Stephen Bates. 2023. <span>“Conformal <span>Prediction</span>: <span>A</span> <span>Gentle</span> <span>Introduction</span>.”</span> <em>Foundations and Trends® in Machine Learning</em> 16 (4): 494–591. <a href="https://doi.org/10.1561/2200000101">https://doi.org/10.1561/2200000101</a>.
</div>
<div id="ref-avsec_enformer_2021" class="csl-entry" role="listitem">
Avsec, Žiga, Vikram Agarwal, Daniel Visentin, Joseph R. Ledsam, Agnieszka Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, and David R. Kelley. 2021. <span>“Effective Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.”</span> <em>Nature Methods</em> 18 (10): 1196–1203. <a href="https://doi.org/10.1038/s41592-021-01252-x">https://doi.org/10.1038/s41592-021-01252-x</a>.
</div>
<div id="ref-avsec_alphagenome_2025" class="csl-entry" role="listitem">
Avsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. <span>“<span>AlphaGenome</span>: <span>AI</span> for Better Understanding the Genome.”</span>
</div>
<div id="ref-benegas_gpn-msa_2024" class="csl-entry" role="listitem">
Benegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2024. <span>“<span>GPN</span>-<span>MSA</span>: An Alignment-Based <span>DNA</span> Language Model for Genome-Wide Variant Effect Prediction.”</span> <em>bioRxiv</em>, April, 2023.10.10.561776. <a href="https://doi.org/10.1101/2023.10.10.561776">https://doi.org/10.1101/2023.10.10.561776</a>.
</div>
<div id="ref-bergquist_calibration_2025" class="csl-entry" role="listitem">
Bergquist, Timothy, Sarah L. Stenton, Emily A. W. Nadeau, Alicia B. Byrne, Marc S. Greenblatt, Steven M. Harrison, Sean V. Tavtigian, et al. 2025. <span>“Calibration of Additional Computational Tools Expands <span>ClinGen</span> Recommendation Options for Variant Classification with <span>PP3</span>/<span>BP4</span> Criteria.”</span> <em>Genetics in Medicine</em> 27 (6): 101402. <a href="https://doi.org/10.1016/j.gim.2025.101402">https://doi.org/10.1016/j.gim.2025.101402</a>.
</div>
<div id="ref-brixi_evo_2025" class="csl-entry" role="listitem">
Brixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. <span>“[<span>Evo</span> 2] <span>Genome</span> Modeling and Design Across All Domains of Life with <span>Evo</span> 2.”</span> bioRxiv. <a href="https://doi.org/10.1101/2025.02.18.638918">https://doi.org/10.1101/2025.02.18.638918</a>.
</div>
<div id="ref-chen_deepsea_2022" class="csl-entry" role="listitem">
Chen, Kathleen M., Aaron K. Wong, Olga G. Troyanskaya, and Jian Zhou. 2022. <span>“[<span>DeepSEA</span> <span>Sei</span>] <span>A</span> Sequence-Based Global Map of Regulatory Activity for Deciphering Human Genetics.”</span> <em>Nature Genetics</em> 54 (7): 940–49. <a href="https://doi.org/10.1038/s41588-022-01102-2">https://doi.org/10.1038/s41588-022-01102-2</a>.
</div>
<div id="ref-cheng_alphamissense_2023" class="csl-entry" role="listitem">
Cheng, Jun, Guido Novati, Joshua Pan, Clare Bycroft, Akvilė Žemgulytė, Taylor Applebaum, Alexander Pritzel, et al. 2023. <span>“[<span>AlphaMissense</span>] <span>Accurate</span> Proteome-Wide Missense Variant Effect Prediction with <span>AlphaMissense</span>.”</span> <em>Science</em> 381 (6664): eadg7492. <a href="https://doi.org/10.1126/science.adg7492">https://doi.org/10.1126/science.adg7492</a>.
</div>
<div id="ref-frazer_eve_2021" class="csl-entry" role="listitem">
Frazer, Jonathan, Pascal Notin, Mafalda Dias, Aidan Gomez, Joseph K. Min, Kelly Brock, Yarin Gal, and Debora S. Marks. 2021. <span>“[<span>EVE</span>] <span>Disease</span> Variant Prediction with Deep Generative Models of Evolutionary Data.”</span> <em>Nature</em> 599 (7883): 91–95. <a href="https://doi.org/10.1038/s41586-021-04043-8">https://doi.org/10.1038/s41586-021-04043-8</a>.
</div>
<div id="ref-ioannidis_revel_2016" class="csl-entry" role="listitem">
Ioannidis, Nilah M., Joseph H. Rothstein, Vikas Pejaver, Sumit Middha, Shannon K. McDonnell, Saurabh Baheti, Anthony Musolf, et al. 2016. <span>“<span>REVEL</span>: <span>An</span> <span>Ensemble</span> <span>Method</span> for <span>Predicting</span> the <span>Pathogenicity</span> of <span>Rare</span> <span>Missense</span> <span>Variants</span>.”</span> <em>The American Journal of Human Genetics</em> 99 (4): 877–85. <a href="https://doi.org/10.1016/j.ajhg.2016.08.016">https://doi.org/10.1016/j.ajhg.2016.08.016</a>.
</div>
<div id="ref-jaganathan_spliceai_2019" class="csl-entry" role="listitem">
Jaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbandi, David Knowles, Yang I. Li, Jack A. Kosmicki, et al. 2019. <span>“[<span>SpliceAI</span>] <span>Predicting</span> <span>Splicing</span> from <span>Primary</span> <span>Sequence</span> with <span>Deep</span> <span>Learning</span>.”</span> <em>Cell</em> 176 (3): 535–548.e24. <a href="https://doi.org/10.1016/j.cell.2018.12.015">https://doi.org/10.1016/j.cell.2018.12.015</a>.
</div>
<div id="ref-jaganathan_predicting_2019" class="csl-entry" role="listitem">
Jaganathan, Kishore, Sofia Kyriazopoulou Panagiotopoulou, Jeremy F. McRae, Siavash Fazel Darbber, Helen V. Firth, Neil Banerjee, Richard Pointon, et al. 2019. <span>“Predicting <span>Splicing</span> from <span>Primary</span> <span>Sequence</span> with <span>Deep</span> <span>Learning</span>.”</span> <em>Cell</em> 176 (3): 535–548.e24. <a href="https://doi.org/10.1016/j.cell.2018.12.015">https://doi.org/10.1016/j.cell.2018.12.015</a>.
</div>
<div id="ref-landrum_clinvar_2018" class="csl-entry" role="listitem">
Landrum, Melissa J, Jennifer M Lee, Mark Benson, Garth R Brown, Chen Chao, Shanmuga Chitipiralla, Baoshan Gu, et al. 2018. <span>“<span>ClinVar</span>: Improving Access to Variant Interpretations and Supporting Evidence.”</span> <em>Nucleic Acids Research</em> 46 (D1): D1062–67. <a href="https://doi.org/10.1093/nar/gkx1153">https://doi.org/10.1093/nar/gkx1153</a>.
</div>
<div id="ref-logsdon_long-read_2020" class="csl-entry" role="listitem">
Logsdon, Glennis A., Mitchell R. Vollger, and Evan E. Eichler. 2020. <span>“Long-Read Human Genome Sequencing and Its Applications.”</span> <em>Nature Reviews Genetics</em> 21 (10): 597–614. <a href="https://doi.org/10.1038/s41576-020-0236-x">https://doi.org/10.1038/s41576-020-0236-x</a>.
</div>
<div id="ref-meier_esm-1v_2021" class="csl-entry" role="listitem">
Meier, Joshua, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu, and Alexander Rives. 2021. <span>“[<span>ESM</span>-1v] <span>Language</span> Models Enable Zero-Shot Prediction of the Effects of Mutations on Protein Function.”</span> bioRxiv. <a href="https://doi.org/10.1101/2021.07.09.450648">https://doi.org/10.1101/2021.07.09.450648</a>.
</div>
<div id="ref-orenbuch_popeve_2025" class="csl-entry" role="listitem">
Orenbuch, Rose, Courtney A. Shearer, Aaron W. Kollasch, Aviv D. Spinner, Thomas Hopf, Lood van Niekerk, Dinko Franceschi, Mafalda Dias, Jonathan Frazer, and Debora S. Marks. 2025. <span>“[<span class="nocase">popEVE</span>] <span>Proteome</span>-Wide Model for Human Disease Genetics.”</span> <em>Nature Genetics</em>, November, 1–10. <a href="https://doi.org/10.1038/s41588-025-02400-1">https://doi.org/10.1038/s41588-025-02400-1</a>.
</div>
<div id="ref-pejaver_calibration_2022" class="csl-entry" role="listitem">
Pejaver, Vikas, Alicia B. Byrne, Bing-Jian Feng, Kymberleigh A. Pagel, Sean D. Mooney, Rachel Karchin, Anne O’Donnell-Luria, et al. 2022. <span>“Calibration of Computational Tools for Missense Variant Pathogenicity Classification and <span>ClinGen</span> Recommendations for <span>PP3</span>/<span>BP4</span> Criteria.”</span> <em>American Journal of Human Genetics</em> 109 (12): 2163–77. <a href="https://doi.org/10.1016/j.ajhg.2022.10.013">https://doi.org/10.1016/j.ajhg.2022.10.013</a>.
</div>
<div id="ref-richards_standards_2015" class="csl-entry" role="listitem">
Richards, Sue, Nazneen Aziz, Sherri Bale, David Bick, Soma Das, Julie Gastier-Foster, Wayne W. Grody, et al. 2015. <span>“Standards and Guidelines for the Interpretation of Sequence Variants: A Joint Consensus Recommendation of the <span>American</span> <span>College</span> of <span>Medical</span> <span>Genetics</span> and <span>Genomics</span> and the <span>Association</span> for <span>Molecular</span> <span>Pathology</span>.”</span> <em>Genetics in Medicine</em> 17 (5): 405–24. <a href="https://doi.org/10.1038/gim.2015.30">https://doi.org/10.1038/gim.2015.30</a>.
</div>
<div id="ref-smolka_detection_2024" class="csl-entry" role="listitem">
Smolka, Moritz, Luis F. Paulin, Christopher M. Grochowski, Dominic W. Horner, Medhat Mahmoud, Sairam Behera, Ester Kalef-Ezra, et al. 2024. <span>“Detection of Mosaic and Population-Level Structural Variants with <span>Sniffles2</span>.”</span> <em>Nature Biotechnology</em> 42 (10): 1571–80. <a href="https://doi.org/10.1038/s41587-023-02024-y">https://doi.org/10.1038/s41587-023-02024-y</a>.
</div>
<div id="ref-tavtigian_modeling_2018" class="csl-entry" role="listitem">
Tavtigian, Sean V., Marc S. Greenblatt, Steven M. Harrison, Robert L. Nussbaum, Snehit A. Prabhu, Kenneth M. Boucher, and Leslie G. Biesecker. 2018. <span>“Modeling the <span>ACMG</span>/<span>AMP</span> Variant Classification Guidelines as a <span>Bayesian</span> Classification Framework.”</span> <em>Genetics in Medicine</em> 20 (9): 1054–60. <a href="https://doi.org/10.1038/gim.2017.210">https://doi.org/10.1038/gim.2017.210</a>.
</div>
<div id="ref-zheng_symphonizing_2022" class="csl-entry" role="listitem">
Zheng, Zhenxian, Shumin Li, Junhao Su, Amy Wing-Sze Leung, Tak-Wah Lam, and Ruibang Luo. 2022. <span>“Symphonizing Pileup and Full-Alignment for Deep Learning-Based Long-Read Variant Calling.”</span> <em>Nature Computational Science</em> 2 (12): 797–803. <a href="https://doi.org/10.1038/s43588-022-00387-x">https://doi.org/10.1038/s43588-022-00387-x</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../part_4/p4-ch17-regulatory.html" class="pagination-link" aria-label="Regulatory Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Regulatory Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../part_5/p5--cellular-context.html" class="pagination-link" aria-label="Part V: Cellular Context">
        <span class="nav-page-text">Part V: Cellular Context</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025-2026, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>