<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Sequence Representation &amp; Tokens – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./p3-ch09-plm.html" rel="next">
<link href="./p2-ch07-splice.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-dc143be7b5ab757de7144a4a454fa469.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-37fc66690c56f8eb85cc6d9cce9ca9f7.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-dc143be7b5ab757de7144a4a454fa469.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p3-ch08-tokens.html">Part III: Transformers Models</a></li><li class="breadcrumb-item"><a href="./p3-ch08-tokens.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Data &amp; Pre-DL Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sequencing: From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Genomic Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch03-pgs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS &amp; Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch04-cadd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deleteriousness Scores</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: CNN Seq-to-Function Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch05-reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regulatory Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch06-transc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Transcriptional Effects</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch07-splice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Splicing Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Transformers Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch08-tokens.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch09-plm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch10-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Genomic Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch11-hybrid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Part IV: GFMs &amp; Multi-omics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch12-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Genomic FMs: Principles &amp; Practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch13-vep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch14-omics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Multi-omics &amp; Systems Context</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Part V: Reliability &amp; Interpretation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch15-eval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Model Evaluation &amp; Benchmarks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch16-confound.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch17-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Part VI: Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch18-clinical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch19-variants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Pathogenic Variant Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch20-drugs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Drug Discovery &amp; Biotech</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer for Genomics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-b-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Additional Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-c-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#from-sequence-to-model-the-representation-problem" id="toc-from-sequence-to-model-the-representation-problem" class="nav-link active" data-scroll-target="#from-sequence-to-model-the-representation-problem"><span class="header-section-number">8.1</span> From Sequence to Model: The Representation Problem</a></li>
  <li><a href="#one-hot-encoding-the-cnn-foundation" id="toc-one-hot-encoding-the-cnn-foundation" class="nav-link" data-scroll-target="#one-hot-encoding-the-cnn-foundation"><span class="header-section-number">8.2</span> One-Hot Encoding: The CNN Foundation</a></li>
  <li><a href="#k-mer-tokenization-the-dnabert-approach" id="toc-k-mer-tokenization-the-dnabert-approach" class="nav-link" data-scroll-target="#k-mer-tokenization-the-dnabert-approach"><span class="header-section-number">8.3</span> K-mer Tokenization: The DNABERT Approach</a></li>
  <li><a href="#byte-pair-encoding-learning-the-vocabulary" id="toc-byte-pair-encoding-learning-the-vocabulary" class="nav-link" data-scroll-target="#byte-pair-encoding-learning-the-vocabulary"><span class="header-section-number">8.4</span> Byte Pair Encoding: Learning the Vocabulary</a></li>
  <li><a href="#single-nucleotide-tokenization-the-hyenadna-approach" id="toc-single-nucleotide-tokenization-the-hyenadna-approach" class="nav-link" data-scroll-target="#single-nucleotide-tokenization-the-hyenadna-approach"><span class="header-section-number">8.5</span> Single-Nucleotide Tokenization: The HyenaDNA Approach</a></li>
  <li><a href="#biologically-informed-tokenization" id="toc-biologically-informed-tokenization" class="nav-link" data-scroll-target="#biologically-informed-tokenization"><span class="header-section-number">8.6</span> Biologically-Informed Tokenization</a></li>
  <li><a href="#the-context-length-evolution" id="toc-the-context-length-evolution" class="nav-link" data-scroll-target="#the-context-length-evolution"><span class="header-section-number">8.7</span> The Context Length Evolution</a></li>
  <li><a href="#trade-offs-and-practical-considerations" id="toc-trade-offs-and-practical-considerations" class="nav-link" data-scroll-target="#trade-offs-and-practical-considerations"><span class="header-section-number">8.8</span> Trade-offs and Practical Considerations</a></li>
  <li><a href="#the-emerging-consensus" id="toc-the-emerging-consensus" class="nav-link" data-scroll-target="#the-emerging-consensus"><span class="header-section-number">8.9</span> The Emerging Consensus</a></li>
  <li><a href="#implications-for-subsequent-chapters" id="toc-implications-for-subsequent-chapters" class="nav-link" data-scroll-target="#implications-for-subsequent-chapters"><span class="header-section-number">8.10</span> Implications for Subsequent Chapters</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p3-ch08-tokens.html">Part III: Transformers Models</a></li><li class="breadcrumb-item"><a href="./p3-ch08-tokens.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-token" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="content-visible callout callout-style-default callout-warning callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>TODO:</strong></p>
<ul>
<li>Verify tradeoffs and general concensus discussion is sufficient</li>
<li>…</li>
</ul>
</div>
</div>
<section id="from-sequence-to-model-the-representation-problem" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="from-sequence-to-model-the-representation-problem"><span class="header-section-number">8.1</span> From Sequence to Model: The Representation Problem</h2>
<p>Every genomic deep learning model must answer a fundamental question before learning can begin: how should DNA sequence be represented as numerical input? This question might seem purely technical, a preprocessing detail to be settled and forgotten. Yet the choice of representation profoundly shapes what a model can learn, how efficiently it trains, and what biological phenomena it can capture. The previous chapters employed one-hot encoding without much discussion, treating it as the obvious default for CNN-based architectures like DeepSEA (<a href="p2-ch05-reg.html" class="quarto-xref"><span>Chapter 5</span></a>) and SpliceAI (<a href="p2-ch07-splice.html" class="quarto-xref"><span>Chapter 7</span></a>). This approach worked remarkably well for those models, but the emergence of transformer-based language models introduced new considerations around tokenization, vocabulary design, and the fundamental trade-offs between sequence compression and resolution.</p>
<p>The challenge can be understood through an analogy to natural language processing. When training a language model on English text, researchers must decide how to segment the continuous stream of characters into discrete tokens. One could treat each character as a token, preserving maximum resolution but creating very long sequences. Alternatively, one could use words as tokens, compressing the sequence but potentially losing information about word structure. Or one could learn a vocabulary of subword units that balances these concerns. Each choice affects what patterns the model can discover and how efficiently it can process long documents.</p>
<p>DNA presents similar choices but with important differences. The genome has only four letters rather than dozens, no natural word boundaries, and biological structure that operates at multiple scales simultaneously. A transcription factor binding site might span 6-12 nucleotides, but the regulatory grammar linking multiple binding sites can extend over hundreds of base pairs. Coding sequences follow a strict three-nucleotide codon structure, while noncoding regions have no such constraint. Any representation scheme must navigate these biological realities while remaining computationally tractable.</p>
<p>This chapter examines the evolution of sequence representation strategies in genomic deep learning. We trace the progression from one-hot encoding through k-mer tokenization to modern approaches including Byte Pair Encoding, single-nucleotide tokens, and biologically-informed tokenization schemes. Understanding these choices clarifies design decisions in models throughout Parts III and IV, and illuminates why seemingly minor representation choices can dramatically affect model capabilities.</p>
</section>
<section id="one-hot-encoding-the-cnn-foundation" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="one-hot-encoding-the-cnn-foundation"><span class="header-section-number">8.2</span> One-Hot Encoding: The CNN Foundation</h2>
<p>One-hot encoding represents the simplest possible approach to sequence representation: each nucleotide becomes a sparse binary vector with a single active element indicating its identity. Adenine is encoded as [1, 0, 0, 0], cytosine as [0, 1, 0, 0], guanine as [0, 0, 1, 0], and thymine as [0, 0, 0, 1]. A sequence of length <span class="math inline">\(L\)</span> thus becomes a matrix of dimensions <span class="math inline">\(4 \times L\)</span>, interpretable as four channels analogous to the RGB channels of an image plus one additional channel.</p>
<p>This representation dominated the CNN era of genomic deep learning for good reason. One-hot encoding is lossless, preserving every nucleotide explicitly without any information compression. It maintains single-nucleotide resolution, enabling detection of effects from individual SNPs, which is critical for variant interpretation. The representation exhibits translation equivariance, meaning that convolutional filters learn position-invariant motifs that can be recognized anywhere in the sequence. And it requires no preprocessing, vocabulary construction, or tokenizer training, making implementation straightforward.</p>
<p>DeepSEA, ExPecto, and SpliceAI all employed one-hot encoding without modification. The convolutional layers in these models learned to detect sequence patterns directly from the binary representation, with first-layer filters discovering motifs corresponding to transcription factor binding sites and deeper layers capturing combinations and spatial arrangements. The representation worked because CNNs process sequences through local operations, with each convolutional filter examining only a small window of positions at a time. The sparse, orthogonal nature of one-hot vectors posed no obstacle to this local processing.</p>
<p>Yet for transformer architectures, one-hot encoding presents significant challenges. Transformers compute attention between all pairs of positions in a sequence, with computational cost scaling as <span class="math inline">\(O(L^2)\)</span> where <span class="math inline">\(L\)</span> is the sequence length. A 10 kb sequence requires 10,000 tokens, meaning 100 million pairwise attention computations per layer. This quickly becomes prohibitive for the long sequences that genomic applications require. Furthermore, transformers typically learn dense embeddings for each token, but with only four possible nucleotides, there is little opportunity for the model to discover rich representations through the embedding layer. The sparse one-hot vectors provide minimal information for the embedding to transform. Most critically, practical transformer context windows of 512 to 4,096 tokens translate to only 512 to 4,096 base pairs when using one-hot encoding, a tiny fraction of genes or regulatory regions and far less than the context that proved valuable for models like Enformer and SpliceAI.</p>
<p>These limitations motivated the search for alternative representations that could compress genomic sequences into fewer tokens while preserving the information needed for biological prediction.</p>
</section>
<section id="k-mer-tokenization-the-dnabert-approach" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="k-mer-tokenization-the-dnabert-approach"><span class="header-section-number">8.3</span> K-mer Tokenization: The DNABERT Approach</h2>
<p>K-mer tokenization treats overlapping subsequences of length <span class="math inline">\(k\)</span> as tokens, drawing an analogy between k-mers and words in natural language. Just as sentences are composed of words that carry meaning through their sequence and combination, genomic sequences might be understood as composed of k-mer “words” that encode biological function through their arrangement. DNABERT (2021) pioneered this approach for genomic transformers, using 6-mers as tokens and training a BERT-style masked language model on human reference sequences <span class="citation" data-cites="ji_dnabert_2021">(<a href="references.html#ref-ji_dnabert_2021" role="doc-biblioref">Ji et al. 2021</a>)</span>.</p>
<p>The k-mer vocabulary has a fixed size of <span class="math inline">\(4^k\)</span> possible tokens. For 6-mers, this yields 4,096 distinct tokens, comparable to the vocabulary sizes used in some natural language models. Each token represents six consecutive nucleotides, creating a direct correspondence between subsequence and token identity. The tokenization proceeds by sliding a window across the sequence and recording each k-mer encountered.</p>
<p>DNABERT used overlapping k-mers, meaning that for a sequence like ACGTACGT, the 6-mer tokens would share five nucleotides with their neighbors. The sequence position advances by one nucleotide at a time, generating one token per position (minus the k-1 positions at the end where a complete k-mer cannot be formed). This overlapping design preserves positional information and ensures that every nucleotide contributes to multiple tokens, potentially providing redundancy that helps the model learn robust representations.</p>
<p>The DNABERT approach provided valuable proof of concept. It demonstrated that self-supervised pretraining on raw DNA sequences could improve performance over training from scratch, that learned embeddings could capture biologically meaningful regularities even when trained only on the reference genome, and that BERT-style architectures could be reused across multiple downstream tasks. DNABERT achieved state-of-the-art performance on prediction of promoters, splice sites, and transcription factor binding sites after fine-tuning with relatively small amounts of task-specific labeled data.</p>
<p>However, subsequent analysis revealed fundamental limitations of k-mer tokenization that stemmed from the overlapping design. DNABERT-2 (2024) articulated these problems clearly <span class="citation" data-cites="zhou_dnabert-2_2024">(<a href="references.html#ref-zhou_dnabert-2_2024" role="doc-biblioref">Zhou et al. 2024</a>)</span>. First, overlapping k-mers provide no sequence compression. The number of tokens equals the number of nucleotides (minus a small constant), so context window limitations persist unchanged. A 10 kb sequence still requires approximately 10,000 tokens, and the quadratic attention complexity remains prohibitive for long sequences.</p>
<p>Second, overlapping tokenization creates ambiguity in how sequence positions map to tokens. A single nucleotide contributes to <span class="math inline">\(k\)</span> different tokens, complicating interpretation of which token is responsible for any given prediction. This ambiguity becomes particularly problematic for variant effect interpretation, where one wants to understand how changing a specific nucleotide alters model predictions. The effect of a single nucleotide substitution propagates through <span class="math inline">\(k\)</span> different tokens in ways that can be difficult to disentangle.</p>
<p>Third, the overlapping design introduces sample inefficiency. The model must learn that overlapping tokens share nucleotides, a relationship that is obvious from the tokenization scheme but must be discovered through training. This redundancy consumes model capacity that could otherwise be devoted to learning more complex biological patterns.</p>
<p>Fourth, the fixed <span class="math inline">\(4^k\)</span> vocabulary does not adapt to corpus statistics. Frequent and rare k-mers receive equal representation capacity in the embedding table, even though their importance for prediction may differ substantially. Common motifs that appear throughout the genome receive no more parameters than rare sequences that might represent sequencing errors or unique regulatory elements.</p>
<p>These limitations motivated exploration of alternative tokenization strategies that could achieve genuine sequence compression while preserving the information needed for biological prediction.</p>
</section>
<section id="byte-pair-encoding-learning-the-vocabulary" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="byte-pair-encoding-learning-the-vocabulary"><span class="header-section-number">8.4</span> Byte Pair Encoding: Learning the Vocabulary</h2>
<p>Byte Pair Encoding offers a fundamentally different approach to tokenization. Rather than defining tokens through a fixed rule (every k consecutive nucleotides), BPE constructs a vocabulary by learning which subsequences appear frequently in the training corpus. The algorithm, originally developed for data compression, iteratively merges the most frequent adjacent token pairs until reaching a desired vocabulary size.</p>
<p>The BPE algorithm begins by initializing the vocabulary with single nucleotides: {A, C, G, T}. It then scans the training corpus to count all adjacent token pairs and identifies the most frequent pair. This pair is merged into a new token, added to the vocabulary, and all instances in the corpus are replaced with the new token. The process repeats, counting pairs again (now including the newly created token) and merging the next most frequent pair. Through many iterations, BPE builds a vocabulary of variable-length tokens that capture frequently occurring sequence patterns.</p>
<p>The key insight is that BPE produces genuine sequence compression. Unlike overlapping k-mers where each nucleotide generates its own token, BPE creates non-overlapping tokens that can span multiple nucleotides. A 10 kb sequence might compress to 2,000 or 3,000 tokens depending on its repetitive structure, enabling transformers to process much longer sequences within the same context window.</p>
<p>DNABERT-2 replaced 6-mer tokenization with BPE and demonstrated dramatic improvements <span class="citation" data-cites="zhou_dnabert-2_2024">(<a href="references.html#ref-zhou_dnabert-2_2024" role="doc-biblioref">Zhou et al. 2024</a>)</span>. The new model achieved comparable performance to state-of-the-art approaches while using 21 times fewer parameters and requiring approximately 92 times less GPU time in pretraining. The efficiency gains stem directly from non-overlapping tokenization: actual sequence compression enables processing longer sequences with the same computational budget, and eliminating the redundancy of overlapping tokens allows the model to focus capacity on learning biological patterns rather than token relationships.</p>
<p>The BPE vocabulary learns corpus statistics through its construction process. Repetitive elements that appear frequently throughout the genome, such as Alu sequences or common regulatory motifs, receive dedicated tokens that span many nucleotides. These long tokens enable efficient representation of repetitive regions while preserving single-nucleotide resolution for unique sequences. Rare sequences that BPE never encountered during vocabulary construction are represented as concatenations of shorter subunits, maintaining the ability to encode any sequence while allocating more representation capacity to common patterns.</p>
<p>GROVER (Genome Rules Obtained Via Extracted Representations) extended this approach by training BPE specifically on the human genome and selecting vocabulary using a custom next-k-mer prediction task <span class="citation" data-cites="sanabria_grover_2024">(<a href="references.html#ref-sanabria_grover_2024" role="doc-biblioref">Sanabria et al. 2024</a>)</span>. Analysis of the resulting token embeddings revealed that the learned vocabulary encodes biologically meaningful structure. Common tokens cluster separately from rare ones in embedding space. GC-rich tokens segregate from AT-rich tokens, reflecting the different properties of these sequence compositions. Token length correlates with specific embedding dimensions, allowing the model to represent both the content and extent of each token. Some tokens appear primarily in repetitive regions while others distribute broadly across the genome, and this localization pattern is captured in the learned representations.</p>
<p>Yet BPE introduces its own complications. The variable-length tokens mean that variant positions fall at different locations relative to token boundaries depending on the local sequence context. A SNP might fall in the middle of a long token in one context but at a token boundary in another, potentially affecting how the model represents and processes the variant. This context-dependence can complicate variant effect interpretation, as the same nucleotide change may alter different numbers of tokens depending on surrounding sequence.</p>
</section>
<section id="single-nucleotide-tokenization-the-hyenadna-approach" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="single-nucleotide-tokenization-the-hyenadna-approach"><span class="header-section-number">8.5</span> Single-Nucleotide Tokenization: The HyenaDNA Approach</h2>
<p>While k-mer and BPE tokenization compress sequences to enable longer context windows, they sacrifice single-nucleotide resolution in doing so. This trade-off becomes problematic for variant effect prediction, where the precise position and identity of mutations is paramount. A single nucleotide polymorphism can completely alter protein function through mechanisms ranging from amino acid substitution to splice site disruption to regulatory element ablation. Multi-nucleotide tokens obscure exactly where variants fall and how they relate to the boundaries of biological features.</p>
<p>HyenaDNA (2023) took the opposite approach, using single-nucleotide tokens with no compression whatsoever <span class="citation" data-cites="nguyen_hyenadna_2023">(<a href="references.html#ref-nguyen_hyenadna_2023" role="doc-biblioref">Nguyen et al. 2023</a>)</span>. Each nucleotide (A, C, G, T) is a separate token, maintaining the maximum possible resolution. Every nucleotide is independently represented in the token sequence, SNP effects can be isolated to specific token positions without ambiguity, and there are no tokenization artifacts that depend on surrounding sequence context.</p>
<p>The challenge with single-nucleotide tokens is sequence length. A 1 Mb region requires 1 million tokens, far beyond the capacity of any standard transformer. The quadratic attention complexity would require a trillion pairwise computations per layer, rendering the approach computationally infeasible with conventional architectures.</p>
<p>HyenaDNA addressed this challenge through a fundamental architectural innovation rather than a tokenization compromise. The Hyena architecture replaces the attention mechanism with implicit convolutions that scale sub-quadratically with sequence length. Where attention computes explicit pairwise interactions between all positions, Hyena uses long convolutions parameterized by a small neural network, achieving similar representational power with <span class="math inline">\(O(L \log L)\)</span> complexity rather than <span class="math inline">\(O(L^2)\)</span>. This enables processing of sequences hundreds of times longer than attention-based transformers within the same computational budget.</p>
<p>The result was a 500-fold increase in context length over dense attention models while maintaining single-nucleotide resolution. HyenaDNA could process 1 Mb sequences where DNABERT was limited to approximately 500 bp and the Nucleotide Transformer to approximately 6 kb. On the Nucleotide Transformer benchmarks, HyenaDNA reached state-of-the-art performance on 12 of 18 datasets with orders of magnitude fewer parameters and less pretraining data. On GenomicBenchmarks, it surpassed prior state-of-the-art on 7 of 8 datasets by an average of 10 accuracy points.</p>
<p>Perhaps most notably, HyenaDNA demonstrated the first use of in-context learning in genomics. The model could perform tasks based on examples provided in the context window without any fine-tuning, simply by conditioning on demonstration sequences. This capability, familiar from large language models, had not previously been shown for genomic sequences and suggests that very long context combined with high resolution enables qualitatively new forms of biological reasoning.</p>
</section>
<section id="biologically-informed-tokenization" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="biologically-informed-tokenization"><span class="header-section-number">8.6</span> Biologically-Informed Tokenization</h2>
<p>Standard tokenization schemes treat DNA as a homogeneous string of characters, ignoring the biological reality that different genomic regions serve fundamentally different functions and follow different structural rules. Coding sequences obey a strict codon structure where every three nucleotides encode an amino acid, while noncoding regions have no such constraint. Treating these regions identically wastes an opportunity to build biological knowledge directly into the representation.</p>
<p>Life-Code (2025) proposed codon-aware tokenization that respects the central dogma of molecular biology <span class="citation" data-cites="liu_life-code_2025">(<a href="references.html#ref-liu_life-code_2025" role="doc-biblioref">Liu et al. 2025</a>)</span>. The approach uses different tokenization strategies for different genomic regions based on their biological function. Coding regions are tokenized by codons, with each three-nucleotide unit encoding an amino acid becoming a single token. This aligns the token boundaries with the fundamental unit of protein translation, enabling the model to learn directly about amino acid sequences and protein structure. Noncoding regions, lacking codon structure, are tokenized by learned patterns that capture regulatory motifs and other functional elements.</p>
<p>This biologically-informed design enables Life-Code to learn protein structure through knowledge distillation from protein language models, capture interactions between coding and noncoding regions within a unified framework, and achieve state-of-the-art results across tasks involving DNA, RNA, and protein. The approach demonstrates that tokenization need not be uniform across the genome, and that encoding biological knowledge in the representation itself can improve model capabilities.</p>
<p>BioToken (2025) extends tokenization even further beyond sequence content to include explicit genomic structural annotations <span class="citation" data-cites="medvedev_biotoken_2025">(<a href="references.html#ref-medvedev_biotoken_2025" role="doc-biblioref">Medvedev et al. 2025</a>)</span>. Rather than treating variants as implicit changes in the sequence string, BioToken creates tokens that explicitly represent SNPs, insertions, and deletions. Known regulatory elements receive dedicated tokens encoding their presence and type. Gene structure, chromatin state, and other functional annotations are integrated directly into the token representation.</p>
<p>By incorporating biological inductive biases directly into tokenization, BioToken’s associated model (BioFM) achieves competitive or superior performance to specialized models like Enformer and SpliceAI with significantly fewer parameters, approximately 265 million compared to the billions in some contemporary models. This efficiency suggests that appropriate representation can substitute for model scale, at least partially, by making the learning problem easier through informed structure.</p>
</section>
<section id="the-context-length-evolution" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="the-context-length-evolution"><span class="header-section-number">8.7</span> The Context Length Evolution</h2>
<p>Examining the history of genomic deep learning reveals a consistent trend toward longer sequence context, reflecting growing appreciation for the importance of distal regulatory interactions.</p>
<p>The earliest CNN models from 2015 to 2017, including DeepSEA and DeepBind, operated on sequences of approximately 1 kb, sufficient to capture local motifs and their immediate context. The next generation of models from 2018 to 2020, including ExPecto and SpliceAI, expanded to 10-40 kb windows, enabling capture of promoter-proximal regulatory elements and the extended context needed for accurate splice site prediction.</p>
<p>The transformer era beginning in 2021 brought divergent approaches. DNABERT with its overlapping k-mers was limited to approximately 512 bp of effective context, while Enformer combined CNN preprocessing with attention to achieve 200 kb contexts. The Nucleotide Transformer (2022-2023) pushed transformer-based models to 6 kb using k-mer tokenization. Then HyenaDNA and Caduceus (2023-2024) demonstrated that sub-quadratic architectures could reach 1 Mb while maintaining single-nucleotide resolution through character-level tokenization. Most recently, Evo 2 (2025) has achieved similar million-base-pair contexts using single-nucleotide tokens with BPE-style learned embeddings.</p>
<p>This progression reflects biological reality. Enhancers can regulate genes from hundreds of kilobases away. TAD boundaries and loop anchors create long-range dependencies in chromatin organization. Understanding genome function requires integrating information across these distances, and representation schemes must enable architectures capable of capturing such interactions.</p>
</section>
<section id="trade-offs-and-practical-considerations" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="trade-offs-and-practical-considerations"><span class="header-section-number">8.8</span> Trade-offs and Practical Considerations</h2>
<p>The choice between tokenization strategies involves multiple competing considerations that depend on the intended application.</p>
<p>Compression and resolution exist in fundamental tension. Higher compression enables longer context windows within fixed computational budgets, but loses precision for identifying exactly where variants fall and how they relate to biological features. One-hot encoding and single-nucleotide tokenization provide no compression but maintain full resolution. Non-overlapping k-mers achieve approximately k-fold compression at the cost of k-nucleotide resolution. BPE provides variable compression depending on sequence repetitiveness, with corresponding variable resolution. For variant effect prediction, where single nucleotide changes can have dramatic phenotypic consequences, resolution is paramount and the computational costs of long single-nucleotide sequences are often justified.</p>
<p>Vocabulary size affects both model capacity and efficiency. Larger vocabularies require bigger embedding tables but may capture more complex patterns directly. Smaller vocabularies are parameter-efficient but require the model to learn compositional structure through multiple layers. The vocabulary size of one-hot encoding (4 tokens plus special tokens) minimizes embedding parameters but maximizes the compositional learning burden. K-mer vocabularies scale exponentially with k, reaching 4,096 for 6-mers. BPE vocabularies are tunable, typically ranging from 4,096 to 32,000 tokens for genomic applications. Codon-aware approaches use approximately 64 codons plus additional tokens for noncoding regions.</p>
<p>Computational efficiency depends on both tokenization and architecture. For standard attention with <span class="math inline">\(O(L^2)\)</span> complexity, any compression directly reduces cost: non-overlapping k-mers reduce attention cost by a factor of <span class="math inline">\(k^2\)</span>, and BPE with average compression <span class="math inline">\(c\)</span> reduces cost by <span class="math inline">\(c^2\)</span>. But sub-quadratic architectures like Hyena change this calculus, making single-nucleotide tokenization computationally feasible at long contexts and eliminating the need to trade resolution for efficiency.</p>
<p>For variant effect prediction specifically, tokenization choice has direct implications. Single-nucleotide tokens (as in HyenaDNA) enable clean comparison of reference and alternate alleles at the same token position with no ambiguity about effect localization. K-mer tokens complicate matters because a single SNP changes <span class="math inline">\(k\)</span> overlapping tokens, requiring aggregation across affected tokens and introducing potential boundary effects. BPE tokens create context-dependent effects where the same variant may fall at different positions relative to token boundaries depending on surrounding sequence, and where re-tokenization may be needed to properly represent the alternate allele.</p>
</section>
<section id="the-emerging-consensus" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="the-emerging-consensus"><span class="header-section-number">8.9</span> The Emerging Consensus</h2>
<p>Recent developments in the field suggest convergence toward several principles, though the optimal approach continues to evolve.</p>
<p>First, single-nucleotide resolution has become the preferred choice for applications requiring precise variant interpretation. The development of sub-quadratic architectures like Hyena, Mamba, and state space models has eliminated the computational barriers that previously forced researchers to accept resolution trade-offs. When long context and high resolution can both be achieved, there is little reason to sacrifice resolution through compression.</p>
<p>Second, learned embeddings rather than fixed representations have become standard. Even single-nucleotide tokenization now typically involves trainable embeddings that transform the four nucleotide identities into dense vectors. This allows the model to discover meaningful representations of nucleotide properties rather than treating all positions equivalently.</p>
<p>Third, biologically-informed augmentation has emerged as a promising direction for incorporating domain knowledge. Encoding codons in coding regions, incorporating functional annotations, or using species-specific vocabularies can provide useful inductive biases that improve learning efficiency and model interpretability.</p>
<p>Fourth, hybrid approaches that combine multiple representation strategies show promise for different genomic contexts. A model might use codon-level tokenization within genes while employing single-nucleotide tokens in regulatory regions, adapting the representation to the structure of each region.</p>
<p>The choice ultimately depends on the task at hand. Variant effect prediction demands high resolution and benefits most from single-nucleotide approaches. Species classification or repeat annotation may benefit from compression that enables comparison across longer regions. Expression prediction requires sufficient context to capture distal enhancers while maintaining resolution to identify causal variants. Understanding these trade-offs is essential for selecting or designing appropriate representations for specific applications.</p>
</section>
<section id="implications-for-subsequent-chapters" class="level2" data-number="8.10">
<h2 data-number="8.10" class="anchored" data-anchor-id="implications-for-subsequent-chapters"><span class="header-section-number">8.10</span> Implications for Subsequent Chapters</h2>
<p>The tokenization choices examined in this chapter set the stage for the genomic language models covered in <a href="p3-ch10-glm.html" class="quarto-xref"><span>Chapter 10</span></a>. Understanding why models like the Nucleotide Transformer use 6-mers <span class="citation" data-cites="dalla-torre_nucleotide_2023">(<a href="references.html#ref-dalla-torre_nucleotide_2023" role="doc-biblioref">Dalla-Torre et al. 2023</a>)</span>, why DNABERT-2 switched to BPE, and why HyenaDNA’s single-nucleotide approach enabled unprecedented context lengths clarifies the design space these models navigate. The hybrid architectures of <a href="p3-ch11-hybrid.html" class="quarto-xref"><span>Chapter 11</span></a>, including Enformer and Borzoi, largely retained one-hot encoding for its precision in variant effect prediction, while the foundation models of <a href="p4-ch12-principles.html" class="quarto-xref"><span>Chapter 12</span></a> explore how sub-quadratic architectures enable single-nucleotide tokenization at truly genomic scale.</p>
<p>The representation problem remains an active area of research. As models grow larger and contexts extend further, new tokenization strategies may emerge that better balance compression, resolution, and biological structure. The field has moved from treating tokenization as a fixed preprocessing step to recognizing it as a fundamental design decision that shapes what models can learn and how they can be applied.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-dalla-torre_nucleotide_2023" class="csl-entry" role="listitem">
Dalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2023. <span>“Nucleotide <span>Transformer</span>: Building and Evaluating Robust Foundation Models for Human Genomics.”</span> <em>Nature Methods</em> 22 (2): 287–97. <a href="https://doi.org/10.1038/s41592-024-02523-z">https://doi.org/10.1038/s41592-024-02523-z</a>.
</div>
<div id="ref-ji_dnabert_2021" class="csl-entry" role="listitem">
Ji, Yanrong, Zhihan Zhou, Han Liu, and Ramana V Davuluri. 2021. <span>“<span>DNABERT</span>: Pre-Trained <span>Bidirectional</span> <span>Encoder</span> <span>Representations</span> from <span>Transformers</span> Model for <span>DNA</span>-Language in Genome.”</span> <em>Bioinformatics</em> 37 (15): 2112–20. <a href="https://doi.org/10.1093/bioinformatics/btab083">https://doi.org/10.1093/bioinformatics/btab083</a>.
</div>
<div id="ref-liu_life-code_2025" class="csl-entry" role="listitem">
Liu, Zicheng, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, and Stan Z. Li. 2025. <span>“Life-<span>Code</span>: <span>Central</span> <span>Dogma</span> <span>Modeling</span> with <span>Multi</span>-<span>Omics</span> <span>Sequence</span> <span>Unification</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2502.07299">https://doi.org/10.48550/arXiv.2502.07299</a>.
</div>
<div id="ref-medvedev_biotoken_2025" class="csl-entry" role="listitem">
Medvedev, Aleksandr, Karthik Viswanathan, Praveenkumar Kanithi, Kirill Vishniakov, Prateek Munjal, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, and Shadab Khan. 2025. <span>“<span>BioToken</span> and <span>BioFM</span> – <span>Biologically</span>-<span>Informed</span> <span>Tokenization</span> <span>Enables</span> <span>Accurate</span> and <span>Efficient</span> <span>Genomic</span> <span>Foundation</span> <span>Models</span>.”</span> bioRxiv. <a href="https://doi.org/10.1101/2025.03.27.645711">https://doi.org/10.1101/2025.03.27.645711</a>.
</div>
<div id="ref-nguyen_hyenadna_2023" class="csl-entry" role="listitem">
Nguyen, Eric, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, et al. 2023. <span>“<span>HyenaDNA</span>: <span>Long</span>-<span>Range</span> <span>Genomic</span> <span>Sequence</span> <span>Modeling</span> at <span>Single</span> <span>Nucleotide</span> <span>Resolution</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2306.15794">https://doi.org/10.48550/arXiv.2306.15794</a>.
</div>
<div id="ref-sanabria_grover_2024" class="csl-entry" role="listitem">
Sanabria, Melissa, Jonas Hirsch, Pierre M. Joubert, and Anna R. Poetsch. 2024. <span>“[<span>GROVER</span>] <span>DNA</span> Language Model <span>GROVER</span> Learns Sequence Context in the Human Genome.”</span> <em>Nature Machine Intelligence</em> 6 (8): 911–23. <a href="https://doi.org/10.1038/s42256-024-00872-0">https://doi.org/10.1038/s42256-024-00872-0</a>.
</div>
<div id="ref-zhou_dnabert-2_2024" class="csl-entry" role="listitem">
Zhou, Zhihan, Yanrong Ji, Weijian Li, Pratik Dutta, Ramana Davuluri, and Han Liu. 2024. <span>“<span>DNABERT</span>-2: <span>Efficient</span> <span>Foundation</span> <span>Model</span> and <span>Benchmark</span> <span>For</span> <span>Multi</span>-<span>Species</span> <span>Genome</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2306.15006">https://doi.org/10.48550/arXiv.2306.15006</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./p2-ch07-splice.html" class="pagination-link" aria-label="Splicing Prediction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Splicing Prediction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./p3-ch09-plm.html" class="pagination-link" aria-label="Protein Language Models">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>