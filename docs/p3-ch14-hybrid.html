<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>14&nbsp; Long-range Hybrid Models – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./p4-ch15-sc-epi.html" rel="next">
<link href="./p3-ch13-plm.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-d1e9b63c6b6094879b9f94a7628e3370.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p3--architectures.html">Part II: Deep Learning Architectures</a></li><li class="breadcrumb-item"><a href="./p3-ch14-hybrid.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sequencing: From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Genomic Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch03-pgs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS &amp; Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch04-cadd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deleteriousness Scores</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p2--principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Core Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch05-tokens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Sequence Representation &amp; Tokens</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch06-transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Transformer Architecture for Genomics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch07-foundation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Genomic Foundation Models: Concepts &amp; Taxonomy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch08-pretrain.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Objectives &amp; Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning &amp; Deployment</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p3--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Deep Learning Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch10-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">CNN Sequence-to-Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch11-dna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">DNA and Genomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch12-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RNA &amp; Transcript-Level Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch13-plm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch14-hybrid.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">p4–multi-modal_multi-scale.qmd</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch15-sc-epi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Single-Cell &amp; Epigenomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch16-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Graphs, Networks, and Biology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch17-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Multi-Omics &amp; Systems Biology</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p5--eval-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Evaluation and Reliability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch18-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Benchmarks for Genomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch19-eval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Evaluation of Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch20-vep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch21-confound.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch22-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Interpretability &amp; Mechanisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p6--translation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI — Translation and Application</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch23-clinical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch24-variants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Pathogenic Variant Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch25-drugs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Drug Discovery &amp; Biotech</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch26-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Sequence Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch27-future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Future Work &amp; Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-b-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Model Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-c-model-list.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Referenced Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-d-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Additional Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-e-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#why-expression-needs-long-range-models" id="toc-why-expression-needs-long-range-models" class="nav-link active" data-scroll-target="#why-expression-needs-long-range-models"><span class="header-section-number">14.1</span> Why Expression Needs Long-Range Models</a></li>
  <li><a href="#problem-setting-sequence-to-expression-at-scale" id="toc-problem-setting-sequence-to-expression-at-scale" class="nav-link" data-scroll-target="#problem-setting-sequence-to-expression-at-scale"><span class="header-section-number">14.2</span> Problem Setting: Sequence-to-Expression at Scale</a>
  <ul class="collapse">
  <li><a href="#inputs-and-outputs" id="toc-inputs-and-outputs" class="nav-link" data-scroll-target="#inputs-and-outputs"><span class="header-section-number">14.2.1</span> Inputs and Outputs</a></li>
  <li><a href="#training-objective" id="toc-training-objective" class="nav-link" data-scroll-target="#training-objective"><span class="header-section-number">14.2.2</span> Training Objective</a></li>
  </ul></li>
  <li><a href="#enformer-cnn-plus-attention-for-200-kb-context" id="toc-enformer-cnn-plus-attention-for-200-kb-context" class="nav-link" data-scroll-target="#enformer-cnn-plus-attention-for-200-kb-context"><span class="header-section-number">14.3</span> Enformer: CNN Plus Attention for 200 kb Context</a>
  <ul class="collapse">
  <li><a href="#architectural-overview" id="toc-architectural-overview" class="nav-link" data-scroll-target="#architectural-overview"><span class="header-section-number">14.3.1</span> Architectural Overview</a></li>
  <li><a href="#training-data-and-cross-species-learning" id="toc-training-data-and-cross-species-learning" class="nav-link" data-scroll-target="#training-data-and-cross-species-learning"><span class="header-section-number">14.3.2</span> Training Data and Cross-Species Learning</a></li>
  <li><a href="#variant-effect-prediction" id="toc-variant-effect-prediction" class="nav-link" data-scroll-target="#variant-effect-prediction"><span class="header-section-number">14.3.3</span> Variant Effect Prediction</a></li>
  <li><a href="#validation-against-gtex-eqtls" id="toc-validation-against-gtex-eqtls" class="nav-link" data-scroll-target="#validation-against-gtex-eqtls"><span class="header-section-number">14.3.4</span> Validation Against GTEx eQTLs</a></li>
  <li><a href="#interpretation-and-mechanistic-insight" id="toc-interpretation-and-mechanistic-insight" class="nav-link" data-scroll-target="#interpretation-and-mechanistic-insight"><span class="header-section-number">14.3.5</span> Interpretation and Mechanistic Insight</a></li>
  </ul></li>
  <li><a href="#borzoi-transcriptome-centric-hybrid-modeling" id="toc-borzoi-transcriptome-centric-hybrid-modeling" class="nav-link" data-scroll-target="#borzoi-transcriptome-centric-hybrid-modeling"><span class="header-section-number">14.4</span> Borzoi: Transcriptome-Centric Hybrid Modeling</a>
  <ul class="collapse">
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation"><span class="header-section-number">14.4.1</span> Motivation</a></li>
  <li><a href="#architecture" id="toc-architecture" class="nav-link" data-scroll-target="#architecture"><span class="header-section-number">14.4.2</span> Architecture</a></li>
  <li><a href="#from-chromatin-signals-to-rna-readouts" id="toc-from-chromatin-signals-to-rna-readouts" class="nav-link" data-scroll-target="#from-chromatin-signals-to-rna-readouts"><span class="header-section-number">14.4.3</span> From Chromatin Signals to RNA Readouts</a></li>
  </ul></li>
  <li><a href="#alphagenome-unified-megabase-scale-regulatory-modeling" id="toc-alphagenome-unified-megabase-scale-regulatory-modeling" class="nav-link" data-scroll-target="#alphagenome-unified-megabase-scale-regulatory-modeling"><span class="header-section-number">14.5</span> AlphaGenome: Unified Megabase-Scale Regulatory Modeling</a>
  <ul class="collapse">
  <li><a href="#motivation-from-specialized-models-to-unified-prediction" id="toc-motivation-from-specialized-models-to-unified-prediction" class="nav-link" data-scroll-target="#motivation-from-specialized-models-to-unified-prediction"><span class="header-section-number">14.5.1</span> Motivation: From Specialized Models to Unified Prediction</a></li>
  <li><a href="#architecture-1" id="toc-architecture-1" class="nav-link" data-scroll-target="#architecture-1"><span class="header-section-number">14.5.2</span> Architecture</a></li>
  <li><a href="#access-and-practical-use" id="toc-access-and-practical-use" class="nav-link" data-scroll-target="#access-and-practical-use"><span class="header-section-number">14.5.3</span> Access and Practical Use</a></li>
  <li><a href="#positioning-in-the-landscape" id="toc-positioning-in-the-landscape" class="nav-link" data-scroll-target="#positioning-in-the-landscape"><span class="header-section-number">14.5.4</span> Positioning in the Landscape</a></li>
  </ul></li>
  <li><a href="#alternative-architectures-hierarchical-attention" id="toc-alternative-architectures-hierarchical-attention" class="nav-link" data-scroll-target="#alternative-architectures-hierarchical-attention"><span class="header-section-number">14.6</span> Alternative Architectures: Hierarchical Attention</a>
  <ul class="collapse">
  <li><a href="#genomic-interpreter-and-1d-swin-transformers" id="toc-genomic-interpreter-and-1d-swin-transformers" class="nav-link" data-scroll-target="#genomic-interpreter-and-1d-swin-transformers"><span class="header-section-number">14.6.1</span> Genomic Interpreter and 1D-Swin Transformers</a></li>
  <li><a href="#computational-trade-offs" id="toc-computational-trade-offs" class="nav-link" data-scroll-target="#computational-trade-offs"><span class="header-section-number">14.6.2</span> Computational Trade-offs</a></li>
  </ul></li>
  <li><a href="#what-hybrid-models-changed" id="toc-what-hybrid-models-changed" class="nav-link" data-scroll-target="#what-hybrid-models-changed"><span class="header-section-number">14.7</span> What Hybrid Models Changed</a>
  <ul class="collapse">
  <li><a href="#explicit-long-range-modeling" id="toc-explicit-long-range-modeling" class="nav-link" data-scroll-target="#explicit-long-range-modeling"><span class="header-section-number">14.7.1</span> Explicit Long-Range Modeling</a></li>
  <li><a href="#unified-multi-task-learning-across-modalities" id="toc-unified-multi-task-learning-across-modalities" class="nav-link" data-scroll-target="#unified-multi-task-learning-across-modalities"><span class="header-section-number">14.7.2</span> Unified Multi-Task Learning Across Modalities</a></li>
  <li><a href="#improved-variant-effect-prediction-for-expression" id="toc-improved-variant-effect-prediction-for-expression" class="nav-link" data-scroll-target="#improved-variant-effect-prediction-for-expression"><span class="header-section-number">14.7.3</span> Improved Variant Effect Prediction for Expression</a></li>
  </ul></li>
  <li><a href="#limitations-and-failure-modes" id="toc-limitations-and-failure-modes" class="nav-link" data-scroll-target="#limitations-and-failure-modes"><span class="header-section-number">14.8</span> Limitations and Failure Modes</a>
  <ul class="collapse">
  <li><a href="#data-and-label-limitations" id="toc-data-and-label-limitations" class="nav-link" data-scroll-target="#data-and-label-limitations"><span class="header-section-number">14.8.1</span> Data and Label Limitations</a></li>
  <li><a href="#sequence-context-and-generalization" id="toc-sequence-context-and-generalization" class="nav-link" data-scroll-target="#sequence-context-and-generalization"><span class="header-section-number">14.8.2</span> Sequence Context and Generalization</a></li>
  <li><a href="#interpretability-and-trust" id="toc-interpretability-and-trust" class="nav-link" data-scroll-target="#interpretability-and-trust"><span class="header-section-number">14.8.3</span> Interpretability and Trust</a></li>
  </ul></li>
  <li><a href="#role-in-the-genomic-foundation-model-landscape" id="toc-role-in-the-genomic-foundation-model-landscape" class="nav-link" data-scroll-target="#role-in-the-genomic-foundation-model-landscape"><span class="header-section-number">14.9</span> Role in the Genomic Foundation Model Landscape</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">14.10</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p3--architectures.html">Part II: Deep Learning Architectures</a></li><li class="breadcrumb-item"><a href="./p3-ch14-hybrid.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-hybrid" class="quarto-section-identifier"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Long-range Hybrid Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Hybrid convolution–transformer architectures such as Enformer and Borzoi were developed to tackle one of the hardest supervised problems in regulatory genomics: predicting gene expression and other functional readouts directly from long stretches of DNA sequence. By combining the locality and efficiency of convolutions with the expressiveness of attention, these models extend the effective receptive field from a few kilobases to hundreds of kilobases or more, while still training end-to-end on large functional genomics compendia.</p>
<p>In this chapter, we focus on long-range hybrid models for expression and related tasks. We start with the motivation for long-range context, formalize the problem setting, and then discuss three representative models:</p>
<ul>
<li><strong>Enformer</strong> <span class="citation" data-cites="avsec_enformer_2021">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Ž. Avsec et al. 2021</a>)</span>, which predicts chromatin and CAGE profiles from 200 kb windows using a CNN front-end and transformer trunk.</li>
<li><strong>Borzoi</strong> <span class="citation" data-cites="linder_borzoi_2025">(<a href="references.html#ref-linder_borzoi_2025" role="doc-biblioref">Linder et al. 2025</a>)</span>, which extends an Enformer-style backbone to predict base-level RNA-seq coverage and related transcriptomic readouts.</li>
<li><strong>AlphaGenome</strong> <span class="citation" data-cites="avsec_alphagenome_2025">(<a href="references.html#ref-avsec_alphagenome_2025" role="doc-biblioref">Z. Avsec, Latysheva, and Cheng 2025</a>)</span>, which pushes context to roughly a megabase and unifies multiple regulatory and transcriptional modalities.</li>
</ul>
<p>We then briefly survey alternative long-range architectures such as hierarchical and windowed attention (Genomic Interpreter) <span class="citation" data-cites="li_genomic_2023">(<a href="references.html#ref-li_genomic_2023" role="doc-biblioref">Li et al. 2023</a>)</span>, discuss what these models changed relative to earlier CNN-only architectures, and highlight their limitations and role within the broader genomic foundation model landscape.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (overview)</strong><br>
Place a small schematic here showing the progression DeepSEA → Basenji2 → Enformer → Borzoi → AlphaGenome with increasing context length and richer outputs.</p>
</div>
</div>
<section id="why-expression-needs-long-range-models" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="why-expression-needs-long-range-models"><span class="header-section-number">14.1</span> Why Expression Needs Long-Range Models</h2>
<p>Early sequence-based models like DeepSEA <span class="citation" data-cites="zhou_deepsea_2015">(<a href="references.html#ref-zhou_deepsea_2015" role="doc-biblioref">Zhou and Troyanskaya 2015</a>)</span> and Expecto <span class="citation" data-cites="zhou_expecto_2018">(<a href="references.html#ref-zhou_expecto_2018" role="doc-biblioref">Zhou et al. 2018</a>)</span> demonstrated that local chromatin features and gene expression can be predicted <em>ab initio</em> from relatively short windows of DNA around promoters and candidate regulatory elements. These models showed that motif content, nucleosome positioning signals, and short-range sequence context carry substantial information about chromatin accessibility, histone marks, and transcriptional activity.</p>
<p>However, gene regulation in higher eukaryotes is a long-range, three-dimensional phenomenon. Enhancers and silencers can act over hundreds of kilobases or more, often skipping over nearby genes to regulate more distant targets. Chromatin looping and topologically associating domains (TADs) bring promoters into physical proximity with distal regulatory elements. Many disease-associated variants discovered by GWAS sit far from gene bodies and promoters, but still influence gene expression via such long-range interactions.</p>
<p>Short-context models inevitably treat distal sequence as noise. They can capture promoter-proximal elements, but may miss key enhancers, silencers, and insulators that fall outside their receptive field. As a result, they can misattribute regulatory effects or underestimate the impact of variants that act through distal elements.</p>
<p>As functional genomics datasets grew through ENCODE, Roadmap, FANTOM, and GTEx, and sequencing costs dropped, the field accumulated enough data to train models with substantially longer context. At the same time, improvements in hardware and optimization made deeper and wider convolutional architectures feasible. Basenji2 <span class="citation" data-cites="kelley_basenji_2018">(<a href="references.html#ref-kelley_basenji_2018" role="doc-biblioref">Kelley et al. 2018</a>)</span> extended context to tens of kilobases by aggressive pooling, but purely convolutional networks still struggle to propagate information across hundreds of kilobases without very deep stacks.</p>
<p>Hybrid architectures like Enformer and Borzoi emerged as a compromise: use convolutions to condense local sequence into a manageable sequence of latent tokens, then apply attention to propagate information across 100–200 kb. By predicting many signals at once, including chromatin marks, transcription initiation, and RNA coverage, these models can learn a rich representation of regulatory sequence that is particularly useful for variant effect prediction.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (biological motivation)</strong><br>
Figure illustrating promoter–enhancer interactions: a gene with several distal enhancers and silencers spanning ~200 kb, with cartoon 3D chromatin loops and annotated GWAS variants.</p>
</div>
</div>
</section>
<section id="problem-setting-sequence-to-expression-at-scale" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="problem-setting-sequence-to-expression-at-scale"><span class="header-section-number">14.2</span> Problem Setting: Sequence-to-Expression at Scale</h2>
<p>The models in this chapter tackle a demanding version of the classic sequence-to-label problem. Instead of predicting a single scalar from a short sequence, they map a long DNA window to thousands of positional, multi-task outputs.</p>
<section id="inputs-and-outputs" class="level3" data-number="14.2.1">
<h3 data-number="14.2.1" class="anchored" data-anchor-id="inputs-and-outputs"><span class="header-section-number">14.2.1</span> Inputs and Outputs</h3>
<p>The input is a <strong>one-hot encoded DNA sequence</strong>, typically spanning 100–200 kb for Enformer and Borzoi, and up to ~1 Mb for AlphaGenome. Most implementations use four channels for nucleotides A, C, G, and T, with ambiguous “N” positions either masked or handled by learned embeddings. A fixed reference genome (e.g., GRCh38) provides the sequence; variants are introduced during inference using in silico mutagenesis or by directly encoding alternative alleles.</p>
<p>To make attention computationally tractable, hybrid models use a <strong>convolutional front-end</strong> that progressively downsamples the sequence. For example, Enformer starts at single-base resolution, applies several convolutional and pooling layers, and ends with a latent sequence of a few thousand tokens representing the 200 kb window.</p>
<p>The <strong>outputs</strong> are multi-task, multi-position tracks:</p>
<ul>
<li>For Enformer: per-base predictions of chromatin accessibility, histone modifications, and CAGE signal across many cell types and assays.</li>
<li>For Borzoi: base-level RNA-seq coverage and other transcriptomic signals (e.g., PRO-seq, nascent transcription) across cell types.</li>
<li>For AlphaGenome: a broader set of outputs spanning chromatin, gene expression, splicing, and 3D contacts.</li>
</ul>
<p>Outputs are typically arranged as a tensor with axes for <strong>position</strong>, <strong>task/assay</strong>, and <strong>cell type or condition</strong>. Different readouts may be predicted at different resolutions (e.g., downsampled 128 bp bins for chromatin, finer bins around promoters and splice sites).</p>
</section>
<section id="training-objective" class="level3" data-number="14.2.2">
<h3 data-number="14.2.2" class="anchored" data-anchor-id="training-objective"><span class="header-section-number">14.2.2</span> Training Objective</h3>
<p>The training objective is usually a <strong>count-based likelihood</strong> or loss computed per track and per position. Common choices include:</p>
<ul>
<li><strong>Poisson or negative binomial log-likelihood</strong> for sequencing counts, sometimes with log-link transformations and offsets for library size.</li>
<li><strong>Mean squared error (MSE)</strong> or Pearson correlation objectives when predicting normalized, continuous signals (e.g., log-transformed coverage).</li>
<li><strong>Classification losses</strong> (e.g., binary cross-entropy) for presence/absence or peak/no-peak tasks.</li>
</ul>
<p>Because models predict thousands of outputs simultaneously, losses are aggregated across positions, tasks, and cell types. Many implementations use <strong>per-track weighting</strong> to prevent abundant assays or cell types from dominating the gradient. Some models explicitly down-weight noisy tracks or use curriculum strategies to stabilize training.</p>
<p>From a foundation model perspective, these hybrid architectures can be viewed as <strong>supervised multi-task pretraining</strong>: the model learns a shared representation of regulatory sequence by jointly optimizing against many functional genomics readouts. This representation can then be probed directly for variant effect prediction, interpreted using attribution methods, or adapted to downstream prediction tasks.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (problem formulation)</strong><br>
Figure showing: 200 kb DNA window → convolutional downsampling → transformer tokens → multi-task output heads producing a stack of tracks (chromatin, CAGE, RNA-seq) across cell types.</p>
</div>
</div>
</section>
</section>
<section id="enformer-cnn-plus-attention-for-200-kb-context" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="enformer-cnn-plus-attention-for-200-kb-context"><span class="header-section-number">14.3</span> Enformer: CNN Plus Attention for 200 kb Context</h2>
<p>Enformer <span class="citation" data-cites="avsec_enformer_2021">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Ž. Avsec et al. 2021</a>)</span> is a landmark model that directly predicts chromatin and CAGE profiles from 200 kb windows of DNA. It demonstrates that long-range context and cross-species training substantially improve prediction of gene expression and regulatory activity, and it introduces a widely adopted template for hybrid genomic architectures.</p>
<section id="architectural-overview" class="level3" data-number="14.3.1">
<h3 data-number="14.3.1" class="anchored" data-anchor-id="architectural-overview"><span class="header-section-number">14.3.1</span> Architectural Overview</h3>
<p>Conceptually, Enformer consists of three stages:</p>
<ol type="1">
<li><p><strong>Convolutional stem</strong><br>
A stack of one-dimensional convolutions with residual connections and pooling progressively transforms base-level one-hot sequence into a shorter sequence of latent representations. This stem detects local motifs and short-range patterns, applies dilated convolutions to expand the receptive field, and uses pooling to reduce sequence length while increasing channel dimensionality.</p></li>
<li><p><strong>Transformer trunk</strong><br>
The downsampled latent sequence (on the order of 1–2k positions) is fed into a stack of multi-head self-attention blocks. These blocks use positional encodings to retain information about relative position within the 200 kb window, allow each position to attend to any other, enabling modeling of long-range dependencies across the window, and include feed-forward layers and normalization to stabilize training.</p></li>
<li><p><strong>Multi-task output heads</strong><br>
After the transformer trunk, Enformer applies task-specific linear and convolutional layers to predict coverage tracks for many assays and cell types. Different heads share the same backbone but specialize in different modalities (e.g., DNase, histone marks, CAGE).</p></li>
</ol>
<p>This design balances <strong>local pattern recognition</strong> (handled by convolutions) and <strong>global interaction modeling</strong> (handled by attention), while keeping the attention cost manageable by operating on a downsampled sequence.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (architecture)</strong><br>
Figure: Enformer architecture schematic — one-hot DNA → convolutional blocks (with pooling) → transformer blocks → multi-task regression heads producing chromatin and CAGE tracks.</p>
</div>
</div>
<p>Enformer differs from its predecessor Basenji2 <span class="citation" data-cites="kelley_basenji_2018">(<a href="references.html#ref-kelley_basenji_2018" role="doc-biblioref">Kelley et al. 2018</a>)</span> in several key respects. It extends the input window to 200 kb and uses attention instead of relying solely on very deep dilated convolutions to carry long-range information. It unifies many assays and cell types in a single model, rather than training separate models per modality. It explicitly targets gene expression and promoter-level activity, not just local chromatin accessibility. These changes allow Enformer to capture the influence of distal elements on promoters that may be separated by tens or hundreds of kilobases.</p>
</section>
<section id="training-data-and-cross-species-learning" class="level3" data-number="14.3.2">
<h3 data-number="14.3.2" class="anchored" data-anchor-id="training-data-and-cross-species-learning"><span class="header-section-number">14.3.2</span> Training Data and Cross-Species Learning</h3>
<p>Enformer is trained on a large collection of human and mouse regulatory data, including chromatin accessibility (e.g., DNase, ATAC), histone modifications and other marks (ChIP-seq), CAGE or related measures of transcription initiation, and other functional readouts where sufficient coverage is available.</p>
<p>Mouse data from analogous assays enables <strong>cross-species learning</strong>: by training a single model on both human and mouse genomes, Enformer learns regulatory motifs and patterns that are conserved across mammals. This reduces overfitting to species-specific idiosyncrasies and improves generalization.</p>
<p>Two key design choices shape the training regime. First, genome-wide sampling ensures the model is trained on many windows across the genome, not just promoter-proximal regions, ensuring exposure to diverse regulatory contexts. Second, multi-task learning means all assays, cell types, and output positions contribute to the loss, which encourages the backbone to learn features useful across modalities. Cross-species and multi-task training together push Enformer toward learning <strong>biologically meaningful regulatory syntax</strong> that generalizes beyond any single dataset.</p>
</section>
<section id="variant-effect-prediction" class="level3" data-number="14.3.3">
<h3 data-number="14.3.3" class="anchored" data-anchor-id="variant-effect-prediction"><span class="header-section-number">14.3.3</span> Variant Effect Prediction</h3>
<p>Like DeepSEA and Basenji2 before it, Enformer can be used for <em>in silico</em> variant effect prediction. The standard approach is to select a genomic locus and extract a 200 kb window around it, encode the reference allele and compute Enformer’s predicted output tracks, encode an alternative allele (or multiple variants) and recompute predictions, and compute differences between reference and alternative predictions for each track and cell type.</p>
<p>This workflow yields per-variant effect estimates on chromatin and CAGE signals across many cell types. Changes can be summarized at the level of gene expression (by aggregating CAGE or chromatin signal around promoters and transcription start sites), regulatory features (by examining specific histone marks or accessibility tracks), and cell-type specificity (by comparing changes across cell types and conditions).</p>
<p>Because Enformer provides <strong>position-resolved, multi-task outputs</strong>, it supports rich analyses of how a variant may alter regulatory landscapes, not just a single scalar expression measure.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (variant effects)</strong><br>
Figure: Heatmap of predicted log-fold change in expression across tissues for a set of variants in a gene’s promoter, with example highlighted showing a motif-disrupting variant.</p>
</div>
</div>
</section>
<section id="validation-against-gtex-eqtls" class="level3" data-number="14.3.4">
<h3 data-number="14.3.4" class="anchored" data-anchor-id="validation-against-gtex-eqtls"><span class="header-section-number">14.3.4</span> Validation Against GTEx eQTLs</h3>
<p>A crucial question is whether Enformer’s variant predictions align with observed expression quantitative trait loci (eQTLs), such as those cataloged in GTEx. In the original work <span class="citation" data-cites="avsec_enformer_2021">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Ž. Avsec et al. 2021</a>)</span>, Enformer’s predictions were systematically compared to GTEx eQTLs. Variants with large predicted effects on promoter CAGE often coincided with significant eQTLs. Enformer captured <strong>long-range regulation</strong>: variants located tens of kilobases away from a gene’s transcription start site still showed predictive power for expression changes when they lay in predicted enhancers.</p>
<p>While not perfect, these analyses showed that <strong>purely sequence-based predictions</strong> from Enformer can recover a substantial fraction of eQTL signal, especially for variants in regulatory regions with strong chromatin and CAGE signals.</p>
</section>
<section id="interpretation-and-mechanistic-insight" class="level3" data-number="14.3.5">
<h3 data-number="14.3.5" class="anchored" data-anchor-id="interpretation-and-mechanistic-insight"><span class="header-section-number">14.3.5</span> Interpretation and Mechanistic Insight</h3>
<p>Despite its size, Enformer is amenable to several interpretation strategies: gradient-based attribution (e.g., saliency maps, integrated gradients) to highlight sequence positions and motifs that contribute most to predicted outputs, in silico saturation mutagenesis systematically testing all possible substitutions in a region to map functional motifs, and attention visualization examining which positions attend to promoters in the transformer layers, providing hints about promoter–enhancer interactions.</p>
<p>These tools have been used to map candidate long-range regulatory interactions, generate hypotheses about motif function, and prioritize variants for experimental follow-up. However, as discussed in Chapter <a href="p5-ch20-vep.html" class="quarto-xref"><span>Chapter 20</span></a>, attribution is not foolproof; it must be interpreted carefully and combined with external evidence.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (attention / attribution)</strong><br>
Figure: Side-by-side attributions showing (1) gradient-based importance scores around a promoter, and (2) attention weights connecting distal enhancers to that promoter.</p>
</div>
</div>
</section>
</section>
<section id="borzoi-transcriptome-centric-hybrid-modeling" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="borzoi-transcriptome-centric-hybrid-modeling"><span class="header-section-number">14.4</span> Borzoi: Transcriptome-Centric Hybrid Modeling</h2>
<p>Enformer is primarily trained on chromatin and transcription initiation signals (CAGE). Borzoi <span class="citation" data-cites="linder_borzoi_2025">(<a href="references.html#ref-linder_borzoi_2025" role="doc-biblioref">Linder et al. 2025</a>)</span> extends this paradigm to <strong>full RNA-seq coverage</strong>, capturing splicing, alternative isoforms, and polyadenylation patterns in a unified framework. Instead of focusing on promoter activity, Borzoi treats the entire <strong>transcript lifecycle</strong> as a modeling target.</p>
<section id="motivation" class="level3" data-number="14.4.1">
<h3 data-number="14.4.1" class="anchored" data-anchor-id="motivation"><span class="header-section-number">14.4.1</span> Motivation</h3>
<p>RNA-seq carries richer information than a single expression value per gene: exon–intron structure and splice junction usage, alternative transcription start sites and promoter choice, alternative polyadenylation and 3′ UTR usage, and allele-specific expression in heterozygous individuals.</p>
<p>These features encode not only transcriptional regulation but also aspects of RNA processing, stability, localization, and translation efficiency. A model that predicts base-level RNA-seq coverage across the genome can therefore inform diverse downstream analyses, from variant effect prediction on splicing to interpretation of 3′ UTR variants that modulate mRNA stability.</p>
</section>
<section id="architecture" class="level3" data-number="14.4.2">
<h3 data-number="14.4.2" class="anchored" data-anchor-id="architecture"><span class="header-section-number">14.4.2</span> Architecture</h3>
<p>Borzoi builds on an Enformer-style backbone with modifications tailored to RNA readouts. A convolutional stem and transformer trunk similar in spirit to Enformer provide long-range context (hundreds of kilobases). The output heads predict stranded RNA-seq coverage across the window and additional transcriptomic signals such as PRO-seq, CAGE, and other assays when available. The model places special emphasis on splice junctions (acceptor and donor sites), promoter regions with alternative TSS usage, and 3′ ends where polyadenylation and cleavage occur.</p>
<p>Multi-task learning across these signals encourages the backbone to encode regulatory information from chromatin through transcription initiation to processing and degradation.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (Borzoi architecture + outputs)</strong><br>
Figure: Comparison diagram — Enformer outputs chromatin + CAGE, Borzoi outputs RNA-seq coverage with highlighted exon–intron structure and alternative 3′ UTR usage on an example gene.</p>
</div>
</div>
</section>
<section id="from-chromatin-signals-to-rna-readouts" class="level3" data-number="14.4.3">
<h3 data-number="14.4.3" class="anchored" data-anchor-id="from-chromatin-signals-to-rna-readouts"><span class="header-section-number">14.4.3</span> From Chromatin Signals to RNA Readouts</h3>
<p>By predicting RNA-seq coverage instead of just promoter-proximal activity, Borzoi supports several analyses not easily addressed by chromatin-only models.</p>
<p><strong>Splicing variant effects</strong> can be evaluated by comparing predicted coverage at exons and junctions under reference and alternative alleles. Large changes in junction usage suggest splicing disruption, complementing specialized models like SpliceAI.</p>
<p><strong>Alternative promoter and TSS usage</strong> becomes visible through coverage predictions. Promoter-proximal variants may alter initiation at alternative TSSs. Borzoi’s coverage predictions reveal shifts in the relative usage of upstream versus downstream promoters.</p>
<p><strong>Alternative polyadenylation and 3′ UTR regulation</strong> can be assessed by measuring shifts in predicted coverage around alternative polyA sites. Variants in 3′ UTRs and downstream regulatory regions may affect mRNA stability and microRNA targeting.</p>
<p>Variant effect prediction follows similar steps as with Enformer (in silico mutagenesis or allelic substitution), but the <strong>outputs now span the entire gene body and flanks</strong>, enabling a unified view of how sequence changes affect transcription, splicing, and polyadenylation simultaneously.</p>
<p>From a foundation model perspective, Borzoi moves closer to modeling a <strong>full transcriptome readout</strong> from sequence. It provides a rich, supervised training signal for representations that encode both regulatory and post-transcriptional features.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (RNA coverage example)</strong><br>
Figure: Real vs predicted RNA-seq coverage across a gene with an alternative exon and alternative 3′ UTR. Show how a splice-site variant alters predicted exon inclusion.</p>
</div>
</div>
</section>
</section>
<section id="alphagenome-unified-megabase-scale-regulatory-modeling" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="alphagenome-unified-megabase-scale-regulatory-modeling"><span class="header-section-number">14.5</span> AlphaGenome: Unified Megabase-Scale Regulatory Modeling</h2>
<p>AlphaGenome <span class="citation" data-cites="avsec_alphagenome_2025">(<a href="references.html#ref-avsec_alphagenome_2025" role="doc-biblioref">Z. Avsec, Latysheva, and Cheng 2025</a>)</span> pushes the hybrid modeling paradigm further by expanding context to roughly a megabase and unifying multiple regulatory, transcriptional, and structural readouts in a single model. Instead of focusing on specific modalities like chromatin or RNA, AlphaGenome aims to serve as a <strong>general-purpose regulatory model</strong> of the human genome.</p>
<section id="motivation-from-specialized-models-to-unified-prediction" class="level3" data-number="14.5.1">
<h3 data-number="14.5.1" class="anchored" data-anchor-id="motivation-from-specialized-models-to-unified-prediction"><span class="header-section-number">14.5.1</span> Motivation: From Specialized Models to Unified Prediction</h3>
<p>Enformer and Borzoi demonstrate that long-range, multi-task models can predict chromatin and transcriptional features, respectively. However, variant interpretation and mechanistic understanding often require integrating multiple modalities: chromatin accessibility and histone marks (regulatory potential), promoter activity and gene expression (transcription), splicing outcomes (isoform composition), and three-dimensional contacts (which distal elements can act on which genes).</p>
<p>Running separate models for each modality complicates interpretation and can introduce inconsistencies. AlphaGenome’s goal is to <strong>unify these tasks</strong> within a single architecture, so that the backbone representation is informed by data across modalities, variant effect predictions are coherent across chromatin, expression, splicing, and 3D structure, and one can query the model for many types of effects without juggling multiple systems.</p>
</section>
<section id="architecture-1" class="level3" data-number="14.5.2">
<h3 data-number="14.5.2" class="anchored" data-anchor-id="architecture-1"><span class="header-section-number">14.5.2</span> Architecture</h3>
<p>At a high level, AlphaGenome follows the hybrid template but at larger scale. The input window spans roughly 1 Mb of DNA sequence, encoded at single-base resolution and then downsampled by a convolutional stem into a sequence of latent tokens. The convolutional stem, similar in spirit to DeepSEA/Basenji lineages, uses stacked convolutions with pooling and nonlinearities to extract local motifs and patterns while reducing sequence length.</p>
<p>A deep stack of self-attention layers (the transformer trunk) operates on the condensed sequence, enabling modeling of interactions across the full megabase window. Positional encodings and architectural choices are tuned to handle the longer context without prohibitive memory use.</p>
<p>Separate output heads predict chromatin signals (accessibility, histone marks), transcriptional readouts (including gene-level expression and promoter activity), splicing-related features (e.g., exon inclusion, splice junction usage), and structural features such as Hi-C or Micro-C contact maps.</p>
<p>The model is trained in a multi-task manner, leveraging large compendia of human functional genomics data. Compared to Enformer and Borzoi, AlphaGenome emphasizes <strong>human data and multi-modal integration</strong>, rather than cross-species training.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (AlphaGenome schematic)</strong><br>
Figure: 1 Mb DNA window with icons for outputs: chromatin tracks, expression values per gene, splicing metrics per exon, and a 2D contact map, all predicted from a shared backbone.</p>
</div>
</div>
</section>
<section id="access-and-practical-use" class="level3" data-number="14.5.3">
<h3 data-number="14.5.3" class="anchored" data-anchor-id="access-and-practical-use"><span class="header-section-number">14.5.3</span> Access and Practical Use</h3>
<p>At the time of writing, AlphaGenome is primarily available through an <strong>API interface</strong>, rather than as an openly downloadable model. This has several practical consequences. Users can <strong>score large sets of variants</strong> without running training or heavy inference infrastructure locally. The API abstracts away model complexity but limits <strong>fine-grained customization</strong> (e.g., domain-specific fine-tuning). Data privacy and regulatory requirements may restrict which genomic datasets can be sent to a cloud-hosted API, especially in clinical contexts.</p>
<p>In practice, AlphaGenome can be used to score candidate regulatory variants identified from GWAS or sequencing studies, generate multi-modal hypotheses about how a variant acts (e.g., altered chromatin plus splicing disruption), and provide large-scale annotations for variant effect prioritization pipelines, complementing specialized models and statistical fine-mapping.</p>
</section>
<section id="positioning-in-the-landscape" class="level3" data-number="14.5.4">
<h3 data-number="14.5.4" class="anchored" data-anchor-id="positioning-in-the-landscape"><span class="header-section-number">14.5.4</span> Positioning in the Landscape</h3>
<p>AlphaGenome sits at the intersection of long-range hybrid architectures and <strong>multi-modal genomic foundation models</strong>. Compared to Enformer and Borzoi, it extends context from 200 kb to ~1 Mb, broadens outputs from chromatin/RNA to include splicing and 3D structure, and emphasizes a unified, human-centric regulatory model.</p>
<p>Relative to emerging cross-species sequence models such as Evo 2 <span class="citation" data-cites="brixi_evo_2025">(<a href="references.html#ref-brixi_evo_2025" role="doc-biblioref">Brixi et al. 2025</a>)</span>, AlphaGenome is more <strong>task-specific and supervised</strong>, using labeled functional genomics datasets. Evo 2 focuses on <strong>self-supervised pretraining</strong> across diverse genomes, potentially providing more general sequence representations but less direct mechanistic interpretability.</p>
<p>Relative to self-supervised DNA language models and efficient long-context architectures (Hyena, Mamba; see <a href="p2-ch07-foundation.html" class="quarto-xref"><span>Chapter 7</span></a>), AlphaGenome can be seen as a <strong>bridge</strong> between specialized supervised models and broad foundation models, offering rich, multi-modal supervision within a long-range hybrid backbone.</p>
<p>From a practical standpoint, AlphaGenome’s API and multi-modal outputs make it an attractive candidate for <strong>variant interpretation pipelines</strong>, particularly where a single system that integrates chromatin, expression, splicing, and contacts is desirable.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (positioning figure)</strong><br>
Table or figure comparing Enformer, Borzoi, and AlphaGenome on axes: context length, modalities predicted, training regime, access (open model vs API).</p>
</div>
</div>
</section>
</section>
<section id="alternative-architectures-hierarchical-attention" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="alternative-architectures-hierarchical-attention"><span class="header-section-number">14.6</span> Alternative Architectures: Hierarchical Attention</h2>
<p>While Enformer, Borzoi, and AlphaGenome use standard self-attention over a condensed sequence, long-range modeling can also be approached through <strong>hierarchical or windowed attention mechanisms</strong> that reduce computational cost and impose additional inductive biases.</p>
<section id="genomic-interpreter-and-1d-swin-transformers" class="level3" data-number="14.6.1">
<h3 data-number="14.6.1" class="anchored" data-anchor-id="genomic-interpreter-and-1d-swin-transformers"><span class="header-section-number">14.6.1</span> Genomic Interpreter and 1D-Swin Transformers</h3>
<p>Genomic Interpreter <span class="citation" data-cites="li_genomic_2023">(<a href="references.html#ref-li_genomic_2023" role="doc-biblioref">Li et al. 2023</a>)</span> adapts the shifted window (Swin) transformer paradigm to one-dimensional genomic sequences. The core idea is to partition the downsampled sequence into <strong>local windows</strong>, apply self-attention <strong>within each window</strong> (which is cheaper than full-sequence attention), use <strong>shifted windows</strong> in alternating layers so that information can propagate across window boundaries over depth, and merge representations hierarchically, allowing the model to build progressively more global features.</p>
<p>The 1D-Swin block operates in two alternating phases. First, standard windowed attention where each position attends only to positions within its local window. Second, shifted-window attention where windows are shifted relative to the original partition so that tokens at window boundaries can attend to neighbors in adjacent windows.</p>
<p>By stacking these layers, Genomic Interpreter achieves <strong>effective long-range dependency modeling</strong> while limiting the quadratic cost of attention to smaller windows. This yields better <strong>scaling to longer input sequences</strong> than full self-attention at the same resolution and an inductive bias toward <strong>local-to-global aggregation</strong>, which may align with hierarchical aspects of regulatory architecture (e.g., motifs to enhancers to domains).</p>
<p>Genomic Interpreter has been evaluated on long-range chromatin and expression prediction tasks, often matching or surpassing Enformer-style baselines at similar compute budgets, especially when pushing context lengths beyond a few hundred kilobases.</p>
</section>
<section id="computational-trade-offs" class="level3" data-number="14.6.2">
<h3 data-number="14.6.2" class="anchored" data-anchor-id="computational-trade-offs"><span class="header-section-number">14.6.2</span> Computational Trade-offs</h3>
<p>The choice between full attention and hierarchical/windowed attention involves several trade-offs.</p>
<p><strong>Full attention (Enformer-style)</strong> offers flexibility and expressiveness (any position can attend to any other in a single layer) but has quadratic cost in sequence length, becoming expensive at longer context or higher resolution.</p>
<p><strong>Hierarchical/windowed attention (Genomic Interpreter, 1D-Swin)</strong> scales better with sequence length and can handle longer inputs at similar compute budgets. However, some long-range interactions require multiple layers to propagate, and the inductive bias may or may not match specific regulatory architectures.</p>
<p><strong>Alternative efficient mechanisms</strong> (e.g., Hyena, state-space models, Mamba; see <a href="p2-ch07-foundation.html" class="quarto-xref"><span>Chapter 7</span></a>) replace attention entirely with architectures that have <strong>sub-quadratic or linear</strong> scaling and strong long-range memory. These are still being actively explored and benchmarked on genomic tasks; integration with multi-task hybrid setups is an open area.</p>
<p>In practice, hybrid models are likely to incorporate a mix of these ideas: convolutional stems for motif-scale features, efficient long-range mechanisms for context propagation, and multi-task heads for rich outputs. The frontier is moving from “Can we model 200 kb?” to “Can we model megabase-scale or chromosomal segments with biologically meaningful inductive biases?”</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (architectural comparison)</strong><br>
Figure: Side-by-side schematic comparing full self-attention vs windowed/shifted attention vs a generic efficient long-range mechanism, with curves showing theoretical compute vs context length.</p>
</div>
</div>
</section>
</section>
<section id="what-hybrid-models-changed" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="what-hybrid-models-changed"><span class="header-section-number">14.7</span> What Hybrid Models Changed</h2>
<p>Hybrid CNN–transformer sequence models like Enformer and Borzoi introduced several conceptual advances over earlier architectures.</p>
<section id="explicit-long-range-modeling" class="level3" data-number="14.7.1">
<h3 data-number="14.7.1" class="anchored" data-anchor-id="explicit-long-range-modeling"><span class="header-section-number">14.7.1</span> Explicit Long-Range Modeling</h3>
<p>By combining convolutional downsampling with attention over latent tokens, hybrid models explicitly model <strong>long-range interactions</strong> within windows of 100–200 kb or more. This enables better representation of enhancer–promoter and enhancer–enhancer interactions, modeling of promoter competition and insulator effects within regulatory neighborhoods, and capture of regulatory context spanning multiple genes and non-coding regions.</p>
<p>Earlier CNN-only models such as DeepSEA and Basenji2 could expand their receptive fields through deeper stacks and dilated convolutions, but the path length between distal positions remained long. Attention shortens this path, making it easier to learn dependencies between distant positions given enough data and capacity.</p>
</section>
<section id="unified-multi-task-learning-across-modalities" class="level3" data-number="14.7.2">
<h3 data-number="14.7.2" class="anchored" data-anchor-id="unified-multi-task-learning-across-modalities"><span class="header-section-number">14.7.2</span> Unified Multi-Task Learning Across Modalities</h3>
<p>Hybrid models jointly predict multiple modalities (chromatin, transcription initiation, RNA coverage, and more) from a shared backbone. This multi-task setup encourages the model to learn representations that are <strong>consistent across modalities</strong> (e.g., open chromatin plus active histone marks plus high transcription), allows <strong>implicit modeling of relationships</strong> between assays (e.g., chromatin changes that precede expression changes), and provides a form of <strong>regularization</strong>, as the model must simultaneously fit many related outputs.</p>
<p>From a foundation model perspective, this is a supervised analog of multi-modal pretraining: a single model learns from heterogeneous signals, which can then be probed or adapted for downstream tasks.</p>
</section>
<section id="improved-variant-effect-prediction-for-expression" class="level3" data-number="14.7.3">
<h3 data-number="14.7.3" class="anchored" data-anchor-id="improved-variant-effect-prediction-for-expression"><span class="header-section-number">14.7.3</span> Improved Variant Effect Prediction for Expression</h3>
<p>Compared to earlier CNN-only models like DeepSEA, Beluga, and Expecto, hybrid models substantially improve variant effect prediction for expression-related outcomes. Longer context allows them to capture the effects of <strong>distal regulatory variants</strong> that would be invisible to short-window models. Multi-modal outputs provide richer evidence for how a variant acts (via chromatin, promoter activity, splicing, or polyadenylation) rather than a single scalar change. Cross-species and multi-task training help filter out noise and emphasize <strong>conserved regulatory mechanisms</strong>.</p>
<p>Borzoi further extends this by connecting sequence changes to the <strong>full RNA life cycle</strong>, offering predictions about splicing, isoform ratios, and 3′ UTR usage. This is particularly valuable for interpreting variants in non-coding regions that regulate isoform-specific expression rather than total gene expression.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (before vs after)</strong><br>
Figure: Conceptual diagram comparing “pre-hybrid” vs “hybrid” landscapes for variant effect prediction: short-range scalar outputs vs long-range, multi-modal outputs informing expression, splicing, and chromatin.</p>
</div>
</div>
</section>
</section>
<section id="limitations-and-failure-modes" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="limitations-and-failure-modes"><span class="header-section-number">14.8</span> Limitations and Failure Modes</h2>
<p>Despite their power, hybrid long-range models are not omniscient and introduce new challenges alongside their capabilities.</p>
<section id="data-and-label-limitations" class="level3" data-number="14.8.1">
<h3 data-number="14.8.1" class="anchored" data-anchor-id="data-and-label-limitations"><span class="header-section-number">14.8.1</span> Data and Label Limitations</h3>
<p>Training data still imposes strong constraints. Functional genomics assays are <strong>biased toward certain cell types and conditions</strong>, often over-representing well-studied tissues and cancer lines. Many loci, particularly in <strong>non-European ancestries</strong>, are underrepresented or absent from training data. Assays are noisy, with batch effects, sequencing artifacts, and experimental variability.</p>
<p>As a result, models may <strong>underperform in underrepresented cell types or ancestries</strong>, and their predictions should be treated with caution in those settings. Rare regulatory phenomena, such as cell-state-specific enhancers or context-dependent chromatin changes, may be only partially captured. Predictions can reflect <strong>technical artifacts</strong> in training data, not just biology (a theme revisited in the chapters on evaluation, <a href="p5-ch19-eval.html" class="quarto-xref"><span>Chapter 19</span></a>, and confounders, <a href="p5-ch21-confound.html" class="quarto-xref"><span>Chapter 21</span></a>).</p>
</section>
<section id="sequence-context-and-generalization" class="level3" data-number="14.8.2">
<h3 data-number="14.8.2" class="anchored" data-anchor-id="sequence-context-and-generalization"><span class="header-section-number">14.8.2</span> Sequence Context and Generalization</h3>
<p>Enformer, Borzoi, and AlphaGenome are trained on fixed window sizes around annotated loci or genome-wide tiles. This introduces several limitations. Even a 1 Mb window (finite context) does not capture whole-chromosome or trans-chromosomal interactions, which can matter for some regulatory events. Models implicitly assume that the relevant information for a readout lies within the chosen window (assumption of local causality). Structural variants, long-range rearrangements, or trans-regulatory effects that fall outside the window are not modeled. Training windows are typically sampled from a reference genome (reference-centric view); complex haplotypes and structural variation are underrepresented.</p>
<p>These constraints mean that predictions are most trustworthy for <strong>cis-acting variants</strong> whose effects are captured within the window and training distribution. Out-of-distribution scenarios (novel structural variants, unusual haplotypes, or highly divergent backgrounds) require special care and, ideally, experimental validation.</p>
</section>
<section id="interpretability-and-trust" class="level3" data-number="14.8.3">
<h3 data-number="14.8.3" class="anchored" data-anchor-id="interpretability-and-trust"><span class="header-section-number">14.8.3</span> Interpretability and Trust</h3>
<p>Although attribution and interpretation methods exist and have yielded biologically plausible insights, several caveats remain. Attribution maps can be <strong>sensitive to model architecture and noise</strong>, and may highlight correlated but non-causal sequence features. Attention weights are not guaranteed to be faithful explanations of the model’s reasoning. Multi-modal outputs increase the <strong>complexity of interpretation</strong>, as one must reconcile changes across many tracks.</p>
<p>As discussed in the chapters on evaluation (<a href="p5-ch19-eval.html" class="quarto-xref"><span>Chapter 19</span></a>) and confounders (<a href="p5-ch21-confound.html" class="quarto-xref"><span>Chapter 21</span></a>), hybrid models must be evaluated not only on predictive performance but also on their <strong>robustness, calibration, and susceptibility to dataset biases</strong>. Interpretability tools should be treated as hypothesis-generating, not as definitive proofs of mechanism.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (failure modes)</strong><br>
Figure: Cartoon panel showing several failure modes — missing data for some cell types, misinterpreted attribution maps, structural variant outside model context, ancestry mismatch.</p>
</div>
</div>
</section>
</section>
<section id="role-in-the-genomic-foundation-model-landscape" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="role-in-the-genomic-foundation-model-landscape"><span class="header-section-number">14.9</span> Role in the Genomic Foundation Model Landscape</h2>
<p>Hybrid architectures like Enformer, Borzoi, and AlphaGenome occupy an interesting niche in the broader genomic foundation model landscape. They are <strong>high-capacity models trained on large, heterogeneous datasets</strong>, much like foundation models in NLP and vision. However, they are <strong>strongly supervised</strong> by specific assays and tasks, rather than being pre-trained purely self-supervised on raw DNA.</p>
<p>In practice, hybrid models serve multiple roles:</p>
<ul>
<li>As <strong>task models</strong>: directly predicting chromatin, expression, RNA coverage, and variant effects from sequence.</li>
<li>As <strong>feature extractors</strong>: their internal representations can be used as embeddings for downstream models, fine-tuned for specific tasks or cell types.</li>
<li>As <strong>benchmarks and baselines</strong>: they set a high bar for supervised performance on regulatory tasks, against which newer architectures (state-space models, Hyena, Mamba, and large self-supervised DNA language models) must be compared (<a href="p2-ch07-foundation.html" class="quarto-xref"><span>Chapter 7</span></a>).</li>
</ul>
<p>As the field moves toward large, multi-modal genomic foundation models, hybrid long-range architectures are likely to remain important as <strong>specialized, mechanistically grounded models</strong> for variant effect prediction, provide <strong>training curricula and evaluation tasks</strong> for more general sequence models, and influence the design of future architectures that blend <strong>supervised multi-task learning</strong> with <strong>self-supervised pretraining</strong> on large-scale genomic data.</p>
<p>In other words, hybrid models sit between early CNN-based predictors and fully general genomic foundation models, providing both a stepping stone and a practical tool for current applications.</p>
<div class="content-visible callout callout-style-default callout-note callout-titled" data-when-profile="draft">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>VISUAL SUGGESTION (ecosystem diagram)</strong><br>
Figure: Ecosystem diagram placing hybrid models alongside self-supervised DNA language models, multi-modal GFMs, and downstream clinical models, with arrows showing how representations and predictions flow between them.</p>
</div>
</div>
</section>
<section id="summary" class="level2" data-number="14.10">
<h2 data-number="14.10" class="anchored" data-anchor-id="summary"><span class="header-section-number">14.10</span> Summary</h2>
<p>This chapter examined hybrid CNN–transformer architectures designed for long-range genomic prediction, focusing on Enformer, Borzoi, and AlphaGenome as representative examples.</p>
<p>Enformer combines a convolutional stem with transformer blocks to predict chromatin and CAGE profiles from 200 kb windows, enabling explicit modeling of long-range regulatory interactions and improving variant effect prediction for expression <span class="citation" data-cites="avsec_enformer_2021">(<a href="references.html#ref-avsec_enformer_2021" role="doc-biblioref">Ž. Avsec et al. 2021</a>)</span>. Borzoi extends this paradigm to RNA-seq coverage and related transcriptomic signals, providing a unified view of how sequence variation affects transcription, splicing, and polyadenylation <span class="citation" data-cites="linder_borzoi_2025">(<a href="references.html#ref-linder_borzoi_2025" role="doc-biblioref">Linder et al. 2025</a>)</span>. AlphaGenome pushes context to megabase scale and unifies multiple modalities (chromatin, expression, splicing, and 3D contacts) within a single hybrid model, currently accessible primarily via API <span class="citation" data-cites="avsec_alphagenome_2025">(<a href="references.html#ref-avsec_alphagenome_2025" role="doc-biblioref">Z. Avsec, Latysheva, and Cheng 2025</a>)</span>. Hierarchical and efficient attention architectures such as Genomic Interpreter’s 1D-Swin transformer offer alternative ways to scale long-range modeling while controlling compute <span class="citation" data-cites="li_genomic_2023">(<a href="references.html#ref-li_genomic_2023" role="doc-biblioref">Li et al. 2023</a>)</span>.</p>
<p>The key lessons from this chapter are that long-range context substantially improves our ability to predict expression and regulatory activity from sequence alone, multi-task and multi-modal supervision helps models learn representations that connect chromatin, transcription, and RNA processing, hybrid models are powerful tools for variant effect prediction but remain limited by data biases, finite context, and interpretability challenges, and in the broader genomic foundation model ecosystem, hybrid long-range architectures act as both state-of-the-art task models and stepping stones toward more general, multi-modal genomic foundation models.</p>
<p>In <a href="p2-ch07-foundation.html" class="quarto-xref"><span>Chapter 7</span></a>, we step back to consider what makes a model a “genomic foundation model” and how hybrid architectures, self-supervised sequence models, and efficient long-context mechanisms fit together in this rapidly evolving space.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-avsec_enformer_2021" class="csl-entry" role="listitem">
Avsec, Žiga, Vikram Agarwal, D. Visentin, J. Ledsam, A. Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, J. Jumper, Pushmeet Kohli, and David R. Kelley. 2021. <span>“[<span>Enformer</span>] <span>Effective</span> Gene Expression Prediction from Sequence by Integrating Long-Range Interactions.”</span> <em>Nature Methods</em> 18 (October): 1196–1203. <a href="https://doi.org/10.1038/s41592-021-01252-x">https://doi.org/10.1038/s41592-021-01252-x</a>.
</div>
<div id="ref-avsec_alphagenome_2025" class="csl-entry" role="listitem">
Avsec, Ziga, Natasha Latysheva, and Jun Cheng. 2025. <span>“<span>AlphaGenome</span>: <span>AI</span> for Better Understanding the Genome.”</span> <em>Google DeepMind</em>. <a href="https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/">https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/</a>.
</div>
<div id="ref-brixi_evo_2025" class="csl-entry" role="listitem">
Brixi, Garyk, Matthew G. Durrant, Jerome Ku, Michael Poli, Greg Brockman, Daniel Chang, Gabriel A. Gonzalez, et al. 2025. <span>“[<span>Evo</span> 2] <span>Genome</span> Modeling and Design Across All Domains of Life with <span>Evo</span> 2.”</span> bioRxiv. <a href="https://doi.org/10.1101/2025.02.18.638918">https://doi.org/10.1101/2025.02.18.638918</a>.
</div>
<div id="ref-kelley_basenji_2018" class="csl-entry" role="listitem">
Kelley, David R., Yakir A. Reshef, Maxwell Bileschi, David Belanger, Cory Y. McLean, and Jasper Snoek. 2018. <span>“[<span>Basenji2</span>] <span>Sequential</span> Regulatory Activity Prediction Across Chromosomes with Convolutional Neural Networks.”</span> <em>Genome Research</em> 28 (5): 739–50. <a href="https://doi.org/10.1101/gr.227819.117">https://doi.org/10.1101/gr.227819.117</a>.
</div>
<div id="ref-li_genomic_2023" class="csl-entry" role="listitem">
Li, Zehui, Akashaditya Das, William A. V. Beardall, Yiren Zhao, and Guy-Bart Stan. 2023. <span>“Genomic <span>Interpreter</span>: <span>A</span> <span>Hierarchical</span> <span>Genomic</span> <span>Deep</span> <span>Neural</span> <span>Network</span> with <span>1D</span> <span>Shifted</span> <span>Window</span> <span>Transformer</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2306.05143">https://doi.org/10.48550/arXiv.2306.05143</a>.
</div>
<div id="ref-linder_borzoi_2025" class="csl-entry" role="listitem">
Linder, Johannes, Divyanshi Srivastava, Han Yuan, Vikram Agarwal, and David R. Kelley. 2025. <span>“[<span>Borzoi</span>] <span>Predicting</span> <span>RNA</span>-Seq Coverage from <span>DNA</span> Sequence as a Unifying Model of Gene Regulation.”</span> <em>Nature Genetics</em> 57 (4): 949–61. <a href="https://doi.org/10.1038/s41588-024-02053-6">https://doi.org/10.1038/s41588-024-02053-6</a>.
</div>
<div id="ref-zhou_expecto_2018" class="csl-entry" role="listitem">
Zhou, Jian, Chandra L. Theesfeld, Kevin Yao, Kathleen M. Chen, Aaron K. Wong, and Olga G. Troyanskaya. 2018. <span>“[<span>Expecto</span>] <span>Deep</span> Learning Sequence-Based Ab Initio Prediction of Variant Effects on Expression and Disease Risk.”</span> <em>Nature Genetics</em> 50 (8): 1171–79. <a href="https://doi.org/10.1038/s41588-018-0160-6">https://doi.org/10.1038/s41588-018-0160-6</a>.
</div>
<div id="ref-zhou_deepsea_2015" class="csl-entry" role="listitem">
Zhou, Jian, and Olga G. Troyanskaya. 2015. <span>“[<span>DeepSEA</span>] <span>Predicting</span> Effects of Noncoding Variants with Deep Learning–Based Sequence Model.”</span> <em>Nature Methods</em> 12 (10): 931–34. <a href="https://doi.org/10.1038/nmeth.3547">https://doi.org/10.1038/nmeth.3547</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./p3-ch13-plm.html" class="pagination-link" aria-label="Protein Language Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./p4-ch15-sc-epi.html" class="pagination-link" aria-label="Single-Cell &amp; Epigenomic Models">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Single-Cell &amp; Epigenomic Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>