<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>24&nbsp; Uncertainty Quantification – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../part_6/p6-ch25-interpretability.html" rel="next">
<link href="../part_6/p6--responsible-deployment.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_6/p6--responsible-deployment.html">Part VI: Responsible Deployment</a></li><li class="breadcrumb-item"><a href="../part_6/p6-ch24-uncertainty.html"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_1/p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Data Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch03-gwas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS and Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/p1-ch04-vep-classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classical Variant Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_2/p2--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch05-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Tokens and Embeddings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch06-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Convolutional Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/p2-ch07-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transformers and Attention</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_3/p3--learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Learning &amp; Evaluation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch08-pretraining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning Foundations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch10-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Adaptation Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch11-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmark Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch12-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Evaluation Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/p3-ch13-confounding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Confounding and Data Leakage</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_4/p4--fm-families.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Foundation Model Families</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch14-fm-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Foundation Model Paradigm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch15-dna-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">DNA Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch16-protein-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch17-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Regulatory Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/p4-ch18-vep-fm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Variant Effect Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_5/p5--cellular-context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Cellular Context</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch19-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">RNA Structure and Function</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch20-single-cell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Single-Cell Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch21-3d-genome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">3D Genome Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch22-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Graph and Network Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/p5-ch23-multi-omics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_6/p6--responsible-deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI: Responsible Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch24-uncertainty.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch25-interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch26-causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Causality</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_6/p6-ch27-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regulatory and Governance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_7/p7--applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VII: Applications &amp; Frontiers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch28-clinical-risk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch29-rare-disease.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Rare Disease Diagnosis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch30-drug-discovery.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Drug Discovery</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch31-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Sequence Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_7/p7-ch32-frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Frontiers and Synthesis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bib/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-b-compute.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Deployment and Compute</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-c-data-curation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Data Curation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-d-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Model Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-e-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/app-f-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-ch24-types" id="toc-sec-ch24-types" class="nav-link active" data-scroll-target="#sec-ch24-types"><span class="header-section-number">24.1</span> Types of Uncertainty in Genomic Prediction</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-why-uncertainty" id="toc-sec-ch24-why-uncertainty" class="nav-link" data-scroll-target="#sec-ch24-why-uncertainty"><span class="header-section-number">24.1.1</span> Why Uncertainty Matters</a></li>
  <li><a href="#sec-ch24-epistemic" id="toc-sec-ch24-epistemic" class="nav-link" data-scroll-target="#sec-ch24-epistemic"><span class="header-section-number">24.1.2</span> Epistemic Uncertainty</a></li>
  <li><a href="#sec-ch24-aleatoric" id="toc-sec-ch24-aleatoric" class="nav-link" data-scroll-target="#sec-ch24-aleatoric"><span class="header-section-number">24.1.3</span> Aleatoric Uncertainty</a></li>
  <li><a href="#sec-ch24-decomposition" id="toc-sec-ch24-decomposition" class="nav-link" data-scroll-target="#sec-ch24-decomposition"><span class="header-section-number">24.1.4</span> Decomposing Total Uncertainty</a></li>
  </ul></li>
  <li><a href="#sec-ch24-calibration" id="toc-sec-ch24-calibration" class="nav-link" data-scroll-target="#sec-ch24-calibration"><span class="header-section-number">24.2</span> Calibration and Confidence Interpretation</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-calibration-problem" id="toc-sec-ch24-calibration-problem" class="nav-link" data-scroll-target="#sec-ch24-calibration-problem"><span class="header-section-number">24.2.1</span> The Calibration Problem</a></li>
  <li><a href="#sec-ch24-measuring-calibration" id="toc-sec-ch24-measuring-calibration" class="nav-link" data-scroll-target="#sec-ch24-measuring-calibration"><span class="header-section-number">24.2.2</span> Measuring Calibration</a></li>
  <li><a href="#sec-ch24-fm-miscalibration" id="toc-sec-ch24-fm-miscalibration" class="nav-link" data-scroll-target="#sec-ch24-fm-miscalibration"><span class="header-section-number">24.2.3</span> Why Foundation Models Are Often Miscalibrated</a></li>
  <li><a href="#sec-ch24-subgroup-calibration" id="toc-sec-ch24-subgroup-calibration" class="nav-link" data-scroll-target="#sec-ch24-subgroup-calibration"><span class="header-section-number">24.2.4</span> Calibration Across Subgroups</a></li>
  </ul></li>
  <li><a href="#sec-ch24-post-hoc-calibration" id="toc-sec-ch24-post-hoc-calibration" class="nav-link" data-scroll-target="#sec-ch24-post-hoc-calibration"><span class="header-section-number">24.3</span> Post-Hoc Calibration Methods</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-temperature-scaling" id="toc-sec-ch24-temperature-scaling" class="nav-link" data-scroll-target="#sec-ch24-temperature-scaling"><span class="header-section-number">24.3.1</span> Temperature Scaling</a></li>
  <li><a href="#sec-ch24-platt-scaling" id="toc-sec-ch24-platt-scaling" class="nav-link" data-scroll-target="#sec-ch24-platt-scaling"><span class="header-section-number">24.3.2</span> Platt Scaling</a></li>
  <li><a href="#sec-ch24-isotonic-regression" id="toc-sec-ch24-isotonic-regression" class="nav-link" data-scroll-target="#sec-ch24-isotonic-regression"><span class="header-section-number">24.3.3</span> Isotonic Regression</a></li>
  <li><a href="#sec-ch24-calibrating-fm" id="toc-sec-ch24-calibrating-fm" class="nav-link" data-scroll-target="#sec-ch24-calibrating-fm"><span class="header-section-number">24.3.4</span> Calibrating Foundation Model Outputs</a></li>
  </ul></li>
  <li><a href="#sec-ch24-uq-methods" id="toc-sec-ch24-uq-methods" class="nav-link" data-scroll-target="#sec-ch24-uq-methods"><span class="header-section-number">24.4</span> Uncertainty Quantification Methods for Foundation Models</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-deep-ensembles" id="toc-sec-ch24-deep-ensembles" class="nav-link" data-scroll-target="#sec-ch24-deep-ensembles"><span class="header-section-number">24.4.1</span> Deep Ensembles</a></li>
  <li><a href="#sec-ch24-mc-dropout" id="toc-sec-ch24-mc-dropout" class="nav-link" data-scroll-target="#sec-ch24-mc-dropout"><span class="header-section-number">24.4.2</span> Monte Carlo Dropout</a></li>
  <li><a href="#sec-ch24-heteroscedastic" id="toc-sec-ch24-heteroscedastic" class="nav-link" data-scroll-target="#sec-ch24-heteroscedastic"><span class="header-section-number">24.4.3</span> Heteroscedastic Models</a></li>
  <li><a href="#sec-ch24-evidential" id="toc-sec-ch24-evidential" class="nav-link" data-scroll-target="#sec-ch24-evidential"><span class="header-section-number">24.4.4</span> Evidential Deep Learning</a></li>
  <li><a href="#sec-ch24-selecting-uq" id="toc-sec-ch24-selecting-uq" class="nav-link" data-scroll-target="#sec-ch24-selecting-uq"><span class="header-section-number">24.4.5</span> Selecting Uncertainty Quantification Methods</a></li>
  </ul></li>
  <li><a href="#sec-ch24-conformal" id="toc-sec-ch24-conformal" class="nav-link" data-scroll-target="#sec-ch24-conformal"><span class="header-section-number">24.5</span> Conformal Prediction: Distribution-Free Guarantees</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-split-conformal" id="toc-sec-ch24-split-conformal" class="nav-link" data-scroll-target="#sec-ch24-split-conformal"><span class="header-section-number">24.5.1</span> Split Conformal Prediction</a></li>
  <li><a href="#sec-ch24-conformal-variant" id="toc-sec-ch24-conformal-variant" class="nav-link" data-scroll-target="#sec-ch24-conformal-variant"><span class="header-section-number">24.5.2</span> Conformal Prediction for Variant Classification</a></li>
  <li><a href="#sec-ch24-conformal-limitations" id="toc-sec-ch24-conformal-limitations" class="nav-link" data-scroll-target="#sec-ch24-conformal-limitations"><span class="header-section-number">24.5.3</span> Limitations and Practical Considerations</a></li>
  <li><a href="#sec-ch24-conformal-clinical" id="toc-sec-ch24-conformal-clinical" class="nav-link" data-scroll-target="#sec-ch24-conformal-clinical"><span class="header-section-number">24.5.4</span> Integration with Clinical Workflows</a></li>
  </ul></li>
  <li><a href="#sec-ch24-ood-detection" id="toc-sec-ch24-ood-detection" class="nav-link" data-scroll-target="#sec-ch24-ood-detection"><span class="header-section-number">24.6</span> Out-of-Distribution Detection</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-ood-problem" id="toc-sec-ch24-ood-problem" class="nav-link" data-scroll-target="#sec-ch24-ood-problem"><span class="header-section-number">24.6.1</span> Out-of-Distribution Problem</a></li>
  <li><a href="#sec-ch24-likelihood-ood" id="toc-sec-ch24-likelihood-ood" class="nav-link" data-scroll-target="#sec-ch24-likelihood-ood"><span class="header-section-number">24.6.2</span> Likelihood-Based Detection and Its Failures</a></li>
  <li><a href="#sec-ch24-embedding-ood" id="toc-sec-ch24-embedding-ood" class="nav-link" data-scroll-target="#sec-ch24-embedding-ood"><span class="header-section-number">24.6.3</span> Embedding-Based Detection</a></li>
  <li><a href="#sec-ch24-practical-ood" id="toc-sec-ch24-practical-ood" class="nav-link" data-scroll-target="#sec-ch24-practical-ood"><span class="header-section-number">24.6.4</span> Practical OOD Detection for Genomic Applications</a></li>
  </ul></li>
  <li><a href="#sec-ch24-selective-prediction" id="toc-sec-ch24-selective-prediction" class="nav-link" data-scroll-target="#sec-ch24-selective-prediction"><span class="header-section-number">24.7</span> Selective Prediction and Abstention</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-when-abstain" id="toc-sec-ch24-when-abstain" class="nav-link" data-scroll-target="#sec-ch24-when-abstain"><span class="header-section-number">24.7.1</span> When to Abstain</a></li>
  <li><a href="#sec-ch24-selective-methods" id="toc-sec-ch24-selective-methods" class="nav-link" data-scroll-target="#sec-ch24-selective-methods"><span class="header-section-number">24.7.2</span> Selective Prediction Methods</a></li>
  <li><a href="#sec-ch24-selective-eval" id="toc-sec-ch24-selective-eval" class="nav-link" data-scroll-target="#sec-ch24-selective-eval"><span class="header-section-number">24.7.3</span> Evaluating Selective Prediction</a></li>
  </ul></li>
  <li><a href="#sec-ch24-genomic-uq" id="toc-sec-ch24-genomic-uq" class="nav-link" data-scroll-target="#sec-ch24-genomic-uq"><span class="header-section-number">24.8</span> Uncertainty for Specific Genomic Tasks</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-vep-uncertainty" id="toc-sec-ch24-vep-uncertainty" class="nav-link" data-scroll-target="#sec-ch24-vep-uncertainty"><span class="header-section-number">24.8.1</span> Variant Effect Prediction Uncertainty</a></li>
  <li><a href="#sec-ch24-regulatory-uncertainty" id="toc-sec-ch24-regulatory-uncertainty" class="nav-link" data-scroll-target="#sec-ch24-regulatory-uncertainty"><span class="header-section-number">24.8.2</span> Regulatory Variant Uncertainty</a></li>
  <li><a href="#sec-ch24-population-uncertainty" id="toc-sec-ch24-population-uncertainty" class="nav-link" data-scroll-target="#sec-ch24-population-uncertainty"><span class="header-section-number">24.8.3</span> Uncertainty Across Populations</a></li>
  </ul></li>
  <li><a href="#sec-ch24-communication" id="toc-sec-ch24-communication" class="nav-link" data-scroll-target="#sec-ch24-communication"><span class="header-section-number">24.9</span> Communicating Uncertainty to End Users</a>
  <ul class="collapse">
  <li><a href="#sec-ch24-communication-challenge" id="toc-sec-ch24-communication-challenge" class="nav-link" data-scroll-target="#sec-ch24-communication-challenge"><span class="header-section-number">24.9.1</span> Communication Challenge</a></li>
  <li><a href="#sec-ch24-categorical-reporting" id="toc-sec-ch24-categorical-reporting" class="nav-link" data-scroll-target="#sec-ch24-categorical-reporting"><span class="header-section-number">24.9.2</span> Categorical Reporting</a></li>
  <li><a href="#sec-ch24-visual-communication" id="toc-sec-ch24-visual-communication" class="nav-link" data-scroll-target="#sec-ch24-visual-communication"><span class="header-section-number">24.9.3</span> Visual Communication</a></li>
  <li><a href="#sec-ch24-decision-framing" id="toc-sec-ch24-decision-framing" class="nav-link" data-scroll-target="#sec-ch24-decision-framing"><span class="header-section-number">24.9.4</span> Decision-Theoretic Framing</a></li>
  </ul></li>
  <li><a href="#sec-ch24-conclusion" id="toc-sec-ch24-conclusion" class="nav-link" data-scroll-target="#sec-ch24-conclusion"><span class="header-section-number">24.10</span> Necessary but Insufficient</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../part_6/p6--responsible-deployment.html">Part VI: Responsible Deployment</a></li><li class="breadcrumb-item"><a href="../part_6/p6-ch24-uncertainty.html"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ch24-uncertainty" class="quarto-section-identifier"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>A pathogenicity score of 0.73 means nothing unless we know what 0.73 means.</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Prerequisites:</strong> This chapter builds on concepts from earlier chapters including model calibration basics (<a href="../part_3/p3-ch12-evaluation.html" class="quarto-xref"><span>Chapter 12</span></a>), pretraining objectives (<a href="../part_3/p3-ch08-pretraining.html" class="quarto-xref"><span>Chapter 8</span></a>), and variant effect prediction (<a href="../part_4/p4-ch18-vep-fm.html" class="quarto-xref"><span>Chapter 18</span></a>). Familiarity with basic probability and statistics (means, variances, distributions) is assumed.</p>
<p><strong>Learning Objectives:</strong> After completing this chapter, you will be able to:</p>
<ol type="1">
<li>Distinguish between epistemic and aleatoric uncertainty, and explain why this distinction matters for clinical decision-making</li>
<li>Assess model calibration using reliability diagrams and expected calibration error (ECE)</li>
<li>Apply post-hoc calibration methods (temperature scaling, Platt scaling, isotonic regression) to foundation model outputs</li>
<li>Evaluate uncertainty quantification methods including deep ensembles, MC dropout, and heteroscedastic models</li>
<li>Implement conformal prediction to obtain distribution-free coverage guarantees</li>
<li>Design out-of-distribution detection pipelines for genomic sequences</li>
<li>Communicate uncertainty appropriately to different stakeholders (clinicians, researchers, patients)</li>
</ol>
<p><strong>Estimated Reading Time:</strong> 45-60 minutes</p>
</div>
</div>
<p>This is not a philosophical riddle. If the model is well-calibrated, approximately 73% of variants receiving this score are truly pathogenic, and a clinician can weigh this probability against the costs of further testing. If the model is miscalibrated, the true pathogenicity rate among variants scored at 0.73 could be 40% or 95%, and the nominal probability provides no reliable basis for decision-making. The distinction is not between accurate and inaccurate models but between models that know what they know and models that do not. A miscalibrated model with high average accuracy can be more dangerous than a calibrated model with lower accuracy, because the miscalibrated model provides false confidence that leads to systematically wrong decisions.</p>
<p>Foundation models produce continuous scores, but clinical decisions require categorical actions: test or do not test, treat or do not treat, report to the family or continue monitoring. This translation from probability to action only works when probabilities are trustworthy. A model that systematically overstates confidence will trigger unnecessary interventions. A model that understates confidence will miss actionable findings. A model that reports high confidence on inputs it has never seen before fails at a fundamental level regardless of its average performance on familiar data. Uncertainty quantification provides the tools to assess when model predictions deserve trust.</p>
<section id="sec-ch24-types" class="level2" data-number="24.1">
<h2 data-number="24.1" class="anchored" data-anchor-id="sec-ch24-types"><span class="header-section-number">24.1</span> Types of Uncertainty in Genomic Prediction</h2>
<p>Uncertainty in genomic prediction arises from two fundamentally different sources that demand different responses. One source reflects limitations in what the model has learned from available data; this uncertainty can, in principle, be reduced by gathering more examples or improving model architecture. The other source reflects genuine randomness in the biological system itself, where identical genotypes produce variable phenotypes through stochastic developmental processes, environmental interactions, or incomplete penetrance. Distinguishing between these sources determines whether additional data collection would help or whether we must accept irreducible limits on predictive confidence.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Deep Dive: Epistemic vs. Aleatoric Uncertainty">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Deep Dive: Epistemic vs.&nbsp;Aleatoric Uncertainty
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>For biology readers:</strong> Two fundamentally different types of uncertainty require different responses:</p>
<p><strong>Epistemic uncertainty</strong> (“knowledge uncertainty”) — what the model doesn’t know:</p>
<ul>
<li>Arises from limited training data or model limitations</li>
<li><em>Can be reduced</em> by collecting more data or improving the model</li>
<li>Example: A variant in an understudied gene has high epistemic uncertainty because few similar variants were in training data</li>
<li>Detected by: ensemble disagreement, out-of-distribution detection</li>
</ul>
<p><strong>Aleatoric uncertainty</strong> (“data uncertainty”) — inherent randomness:</p>
<ul>
<li>Arises from genuine biological variability or measurement noise</li>
<li><em>Cannot be reduced</em> even with infinite data</li>
<li>Example: Incomplete penetrance in <em>BRCA1</em> — the same variant causes cancer in some carriers but not others due to modifier genes and environment</li>
<li>Detected by: heteroscedastic models, known biology</li>
</ul>
<p><strong>Why the distinction matters clinically:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 27%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Uncertainty Type</th>
<th>Response</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>High epistemic</td>
<td>Defer, investigate</td>
<td>Order additional testing, expert consult</td>
</tr>
<tr class="even">
<td>High aleatoric</td>
<td>Accept, communicate</td>
<td>Explain inherent limits to patient</td>
</tr>
<tr class="odd">
<td>High both</td>
<td>Maximum caution</td>
<td>Conservative management</td>
</tr>
</tbody>
</table>
<p>A model that conflates these types cannot guide appropriate action: it cannot tell you whether more data would help or whether you must accept the uncertainty as irreducible.</p>
</div>
</div>
<section id="sec-ch24-why-uncertainty" class="level3" data-number="24.1.1">
<h3 data-number="24.1.1" class="anchored" data-anchor-id="sec-ch24-why-uncertainty"><span class="header-section-number">24.1.1</span> Why Uncertainty Matters</h3>
<p>Clinical genetics operates under fundamental uncertainty. When a laboratory reports a <strong>variant of uncertain significance (VUS)</strong>, they acknowledge that current evidence cannot confidently classify the variant as pathogenic or benign. ClinVar contains approximately two million VUS compared to roughly 250,000 variants classified as pathogenic <span class="citation" data-cites="landrum_clinvar_2018">(<a href="../bib/references.html#ref-landrum_clinvar_2018" role="doc-biblioref">Landrum et al. 2018</a>)</span>, reflecting the reality that most genetic variation remains incompletely understood. Foundation models inherit and sometimes amplify this uncertainty: they may produce confident-seeming scores for variants where the underlying biology remains genuinely unknown. The challenges of VUS classification and current interpretation frameworks are examined in detail in <a href="../part_7/p7-ch29-rare-disease.html" class="quarto-xref"><span>Chapter 29</span></a>.</p>
<p>The consequences of ignoring uncertainty extend beyond statistical abstraction. An overconfident pathogenic prediction may trigger unnecessary interventions, from prophylactic surgeries to reproductive decisions that alter family planning. An overconfident benign prediction may provide false reassurance, delaying diagnosis while a treatable condition progresses. In both cases, the harm stems not from prediction error per se but from the mismatch between stated confidence and actual reliability. A model that accurately conveys its uncertainty enables appropriate clinical reasoning even when the prediction itself is imperfect.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: Calibration vs.&nbsp;Accuracy
</div>
</div>
<div class="callout-body-container callout-body">
<p>A model can be highly accurate on average yet dangerously miscalibrated. If a model achieves 90% accuracy but assigns 95% confidence to all predictions, clinicians will trust predictions that deserve skepticism. Conversely, a model with 80% accuracy that honestly reports its uncertainty enables better decisions than the overconfident 90% model. <strong>The goal is not just to be right, but to know when you’re right.</strong></p>
</div>
</div>
<p>Decision theory formalizes this intuition. The expected value of a clinical action depends on the probability of each outcome weighted by its utility. When a model reports 0.73 probability of pathogenicity, downstream decision-making implicitly assumes this probability is accurate. If the true probability is 0.50, actions optimized for 0.73 will systematically err. Uncertainty quantification ensures that the probabilities entering clinical decisions reflect genuine knowledge rather than artifacts of model architecture or training procedure.</p>
</section>
<section id="sec-ch24-epistemic" class="level3" data-number="24.1.2">
<h3 data-number="24.1.2" class="anchored" data-anchor-id="sec-ch24-epistemic"><span class="header-section-number">24.1.2</span> Epistemic Uncertainty</h3>
<p>A model trained exclusively on European-ancestry data encounters its first genome from an individual of African ancestry. The model’s predictions may be statistically valid within the distribution it has seen, yet unreliable for this new input due to limited exposure to ancestry-specific patterns of variation, <strong>linkage disequilibrium</strong>, and regulatory architecture. This uncertainty about what the model has learned, as distinct from noise inherent in the prediction task itself, constitutes <strong>epistemic uncertainty</strong>.</p>
<div id="fig-uncertainty-types" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-uncertainty-types-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/01-A-fig-uncertainty-types.svg" class="img-fluid figure-img"></p>
<figcaption>Aleatoric: irreducible stochastic variability</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/01-B-fig-uncertainty-types.svg" class="img-fluid figure-img"></p>
<figcaption>Epistemic: reducible knowledge-based uncertainty</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-uncertainty-types-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24.1: Two types of uncertainty. (A) Aleatoric uncertainty: irreducible stochasticity from biological variability or measurement noise—cannot be eliminated with more data. (B) Epistemic uncertainty: reducible uncertainty from limited knowledge—decreases as training data grow. Distinguishing these is critical: high epistemic uncertainty should trigger caution, while aleatoric uncertainty sets fundamental prediction limits.
</figcaption>
</figure>
</div>
<p>Epistemic uncertainty arises from limitations in training data that could, in principle, be reduced by gathering more examples. In genomic foundation models, epistemic uncertainty concentrates in predictable regions of biological space. Proteins from poorly characterized families, where training data contained few homologs, exhibit high epistemic uncertainty because the model has limited basis for inference. This manifests concretely in protein benchmarks: <em>ProteinGym</em> performance varies substantially across protein families (<a href="../part_3/p3-ch11-benchmarks.html#sec-ch11-proteingym" class="quarto-xref"><span>Section 11.1.3</span></a>). Genes with few characterized variants in ClinVar or gnomAD provide sparse supervision, leaving the model uncertain about which sequence features distinguish pathogenic from benign variation (see <a href="../part_1/p1-ch02-data.html#sec-ch02-clinvar" class="quarto-xref"><span>Section 2.8.1</span></a> and <a href="../part_1/p1-ch02-data.html#sec-ch02-gnomad" class="quarto-xref"><span>Section 2.2.3</span></a> for data resource details). Rare variant classes, such as in-frame deletions in specific protein domains, appear infrequently in training data and consequently generate uncertain predictions. Populations under-represented in biobanks contribute fewer training examples, creating systematic epistemic uncertainty for individuals from these backgrounds, a challenge examined in <a href="../part_1/p1-ch03-gwas.html#sec-ch03-portability" class="quarto-xref"><span>Section 3.7</span></a> and with confounding implications discussed in <a href="../part_3/p3-ch13-confounding.html#sec-ch13-ancestry-confounding" class="quarto-xref"><span>Section 13.2.1</span></a>.</p>
<p>Mathematically, epistemic uncertainty reflects uncertainty over model parameters or learned representations. A Bayesian perspective treats the trained model as one sample from a posterior distribution over possible models consistent with the training data. Different plausible models may disagree on predictions for inputs far from training examples while agreeing on well-represented inputs. This disagreement manifests as high variance in predictions across model variants, sensitivity to random initialization, or instability under small perturbations to training data.</p>
<p>Foundation models exhibit epistemic uncertainty through several observable signatures. Embeddings for unfamiliar sequences cluster in sparse regions of representation space, distant from the dense clusters formed by well-represented sequence families. Ensemble members trained with different random seeds produce divergent predictions for novel inputs while converging for familiar ones. Fine-tuning on the same downstream task with different random seeds yields inconsistent results for edge cases. These signatures provide practical diagnostics for identifying when epistemic uncertainty is high.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before reading the next section, consider: If you have a variant in a gene with only 5 known pathogenic variants in ClinVar (versus thousands for a well-studied gene like <em>BRCA1</em>), what type of uncertainty dominates your prediction? Would collecting more data help? What kind of data would be most valuable?</p>
</div>
</div>
</section>
<section id="sec-ch24-aleatoric" class="level3" data-number="24.1.3">
<h3 data-number="24.1.3" class="anchored" data-anchor-id="sec-ch24-aleatoric"><span class="header-section-number">24.1.3</span> Aleatoric Uncertainty</h3>
<p>Some variants are genuinely ambiguous regardless of how much data we collect. The same pathogenic variant in <em>BRCA1</em> causes breast cancer in one carrier but not another due to modifier genes, hormonal exposures, or stochastic developmental processes. Incomplete penetrance, the phenomenon where disease-associated variants do not always produce disease, creates irreducible uncertainty that no amount of training data can eliminate. This inherent randomness in the mapping from genotype to phenotype constitutes <strong>aleatoric uncertainty</strong>.</p>
<p>Aleatoric uncertainty reflects noise or stochasticity intrinsic to the prediction problem rather than limitations of the model. Variable expressivity means that even when a variant causes disease, the severity and specific manifestations vary across individuals. Measurement noise in functional assays introduces uncertainty into the labels used for training: <strong>deep mutational scanning</strong> experiments typically exhibit 10 to 20 percent technical variation between replicates <span class="citation" data-cites="fowler_deep_2014 rubin_statistical_2017">(<a href="../bib/references.html#ref-fowler_deep_2014" role="doc-biblioref">Fowler and Fields 2014</a>; <a href="../bib/references.html#ref-rubin_statistical_2017" role="doc-biblioref">Rubin et al. 2017</a>)</span>, creating a floor below which prediction error cannot decrease regardless of model sophistication (see <a href="../part_1/p1-ch02-data.html#sec-ch02-dms" class="quarto-xref"><span>Section 2.4.4</span></a> for a discussion of DMS data characteristics). Stochastic gene expression means that two genetically identical cells may express a gene at different levels due to random fluctuations in transcription and translation. These sources of randomness set fundamental limits on predictive accuracy.</p>
<p>Aleatoric uncertainty often varies with the input, a property termed heteroscedasticity. Coding variants in essential genes may have relatively low aleatoric uncertainty because strong selection pressure produces consistent phenotypic effects. Regulatory variants exhibit higher aleatoric uncertainty because their effects depend on cellular context, developmental timing, and interactions with other genetic and environmental factors. A model that captures this heteroscedasticity can provide more informative uncertainty estimates by conveying that some predictions are inherently more reliable than others.</p>
<p>The following table summarizes the key distinctions between epistemic and aleatoric uncertainty:</p>
<div id="tbl-uncertainty-types" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-uncertainty-types-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;24.1: Comparison of epistemic and aleatoric uncertainty in genomic prediction.
</figcaption>
<div aria-describedby="tbl-uncertainty-types-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 40%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Property</th>
<th>Epistemic Uncertainty</th>
<th>Aleatoric Uncertainty</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Source</strong></td>
<td>Limited training data, model knowledge gaps</td>
<td>Inherent noise in biological system</td>
</tr>
<tr class="even">
<td><strong>Reducibility</strong></td>
<td>Can be reduced with more data</td>
<td>Irreducible, fundamental limit</td>
</tr>
<tr class="odd">
<td><strong>Example causes</strong></td>
<td>Under-represented populations, rare genes, novel folds</td>
<td>Incomplete penetrance, measurement noise, stochastic expression</td>
</tr>
<tr class="even">
<td><strong>Detection method</strong></td>
<td>Ensemble disagreement, embedding distance</td>
<td>Heteroscedastic model predictions</td>
</tr>
<tr class="odd">
<td><strong>Response</strong></td>
<td>Collect more data, seek expert review</td>
<td>Accept limits, communicate uncertainty</td>
</tr>
<tr class="even">
<td><strong>Clinical implication</strong></td>
<td>Defer decision, request additional evidence</td>
<td>Proceed with acknowledged uncertainty</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-ch24-decomposition" class="level3" data-number="24.1.4">
<h3 data-number="24.1.4" class="anchored" data-anchor-id="sec-ch24-decomposition"><span class="header-section-number">24.1.4</span> Decomposing Total Uncertainty</h3>
<p>Total predictive uncertainty combines epistemic and aleatoric components, and distinguishing between them has practical implications for decision-making. High epistemic uncertainty suggests that gathering more data, either through additional training examples or further investigation of the specific case, could reduce uncertainty and improve the prediction. High aleatoric uncertainty indicates that the prediction is as good as it can get given inherent noise in the problem; additional data will not help because the underlying biology is stochastic.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Difficulty Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>The following mathematical framework for uncertainty decomposition requires comfort with variance and conditional probability. If these concepts are unfamiliar, focus on the intuition: ensemble disagreement measures epistemic uncertainty, while within-model variance measures aleatoric uncertainty. The key insight is that total uncertainty can be partitioned into “uncertainty we can reduce” and “uncertainty we cannot.”</p>
</div>
</div>
<p>The law of total variance provides a mathematical framework for decomposition. Total variance in predictions equals the sum of variance due to model uncertainty (epistemic) and variance inherent in the data-generating process (aleatoric). In practice, ensemble methods approximate epistemic uncertainty through disagreement between members: if five independently trained models produce predictions of 0.65, 0.68, 0.70, 0.72, and 0.75, the spread reflects epistemic uncertainty, while the residual variance within each model’s predictions reflects aleatoric uncertainty. Heteroscedastic neural networks, which output both a predicted mean and a predicted variance, can estimate aleatoric uncertainty by learning input-dependent noise levels.</p>
<p>These decompositions depend on modeling assumptions and provide approximations rather than exact separations. Ensemble disagreement may underestimate epistemic uncertainty if all members share similar biases from common training data. Heteroscedastic models may confound aleatoric and epistemic uncertainty if the training data is too sparse to reliably estimate noise levels. Despite these limitations, approximate decomposition provides actionable information: variants flagged for high epistemic uncertainty warrant additional data collection or expert review, while variants with high aleatoric uncertainty may require acceptance of irreducible limits on predictive confidence.</p>
</section>
</section>
<section id="sec-ch24-calibration" class="level2" data-number="24.2">
<h2 data-number="24.2" class="anchored" data-anchor-id="sec-ch24-calibration"><span class="header-section-number">24.2</span> Calibration and Confidence Interpretation</h2>
<p><strong>Calibration</strong> determines whether model outputs can be interpreted as probabilities. A score of 0.85 from a pathogenicity predictor should mean that 85% of variants receiving similar scores are truly pathogenic; only then can clinicians rationally weight computational evidence against other diagnostic criteria. This chapter provides the comprehensive treatment of calibration theory and methods. Readers encountering calibration in applied contexts, whether variant effect prediction (<a href="../part_4/p4-ch18-vep-fm.html#sec-ch18-calibration" class="quarto-xref"><span>Section 18.5</span></a>) or evaluation methodology (<a href="../part_3/p3-ch12-evaluation.html" class="quarto-xref"><span>Chapter 12</span></a>), are referred here for the formal foundations and complete methodological catalog.</p>
<div id="fig-calibration-diagrams" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-calibration-diagrams-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/02-A-fig-calibration-diagrams.svg" class="img-fluid figure-img"></p>
<figcaption>Perfect calibration: predictions match observed frequencies</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/02-B-fig-calibration-diagrams.svg" class="img-fluid figure-img"></p>
<figcaption>Overconfident: predictions exceed reality</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/02-C-fig-calibration-diagrams.svg" class="img-fluid figure-img"></p>
<figcaption>Underconfident: predictions underestimate true probabilities</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/02-D-fig-calibration-diagrams.svg" class="img-fluid figure-img"></p>
<figcaption>Calibration metrics: ECE and MCE quantify miscalibration</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-calibration-diagrams-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24.2: Model calibration assessment. (A) Perfect calibration: predicted probabilities match observed frequencies on the diagonal. (B) Overconfident model: predictions systematically exceed reality—dangerous for clinical use. (C) Underconfident model: predictions underestimate true probabilities—reduces utility. (D) Calibration metrics: Expected Calibration Error (ECE) averages across bins; Maximum Calibration Error (MCE) captures worst-case performance.
</figcaption>
</figure>
</div>
<section id="sec-ch24-calibration-problem" class="level3" data-number="24.2.1">
<h3 data-number="24.2.1" class="anchored" data-anchor-id="sec-ch24-calibration-problem"><span class="header-section-number">24.2.1</span> The Calibration Problem</h3>
<p><em>AlphaMissense</em> outputs a continuous score between 0 and 1 for each possible missense variant in the human proteome. When it reports 0.85 for a particular variant, what does this number mean? If the model is calibrated, collecting all variants scored near 0.85 and checking their true clinical status should reveal that approximately 85% are pathogenic. Perfect calibration means that predicted probabilities match observed frequencies across the entire range of model outputs: among variants scored at 0.30, roughly 30% should be pathogenic; among variants scored at 0.95, roughly 95% should be pathogenic. This alignment between stated confidence and empirical accuracy is calibration, and most foundation models fail to achieve it.</p>
<p>Think of calibration like weather forecasts. When your weather app says “70% chance of rain,” you expect that across many days with 70% forecasts, it actually rains about 70% of the time. If it only rains 40% of those days, the app is overconfident and you cannot trust its numbers to plan your week. Similarly, a pathogenicity predictor claiming 85% confidence should be right 85% of the time at that confidence level—otherwise, clinicians cannot rationally weigh its predictions against other evidence.</p>
<p>Formally, a model <span class="math inline">\(f\)</span> mapping inputs <span class="math inline">\(X\)</span> to probability estimates <span class="math inline">\(p = f(X)\)</span> is calibrated if <span class="math inline">\(P(Y = 1 \mid f(X) = p) = p\)</span> for all <span class="math inline">\(p\)</span> in the interval from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span>. The calibration condition requires that the model’s stated confidence equals the true probability of the positive class conditional on that stated confidence. Miscalibration occurs when this equality fails: overconfident models produce predicted probabilities that exceed true frequencies (a variant scored at <span class="math inline">\(0.85\)</span> is pathogenic only <span class="math inline">\(60\%\)</span> of the time), while underconfident models produce predicted probabilities below true frequencies.</p>
<p>Modern deep neural networks are systematically miscalibrated despite achieving high accuracy. Guo and colleagues demonstrated that contemporary architectures exhibit worse calibration than older, less accurate models <span class="citation" data-cites="guo_calibration_2017">(<a href="../bib/references.html#ref-guo_calibration_2017" role="doc-biblioref">Guo et al. 2017</a>)</span>. The phenomenon arises because standard training objectives like cross-entropy loss optimize for discrimination (separating positive from negative examples) rather than calibration (matching predicted probabilities to frequencies). Over-parameterized models with capacity exceeding what the data requires can achieve near-perfect training loss while producing overconfident predictions on held-out data. The softmax temperature in transformer architectures affects the sharpness of probability distributions, and default settings often produce excessively peaked outputs.</p>
<p>Calibration and discrimination are distinct properties. A model can achieve perfect <strong>area under the receiver operating characteristic curve (auROC)</strong>, correctly ranking all positive examples above all negative examples, while being arbitrarily miscalibrated. If a classifier assigns probability 0.99 to all positive examples and 0.98 to all negative examples, it ranks perfectly but provides useless probability estimates. Conversely, a calibrated model that assigns 0.51 to positives and 0.49 to negatives would be calibrated but nearly useless for discrimination. Clinical applications typically require both: accurate ranking to identify high-risk variants and accurate probabilities to inform decision-making.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Knowledge Check
</div>
</div>
<div class="callout-body-container callout-body">
<p>A variant effect predictor achieves auROC of 0.95 on a held-out test set. A colleague concludes that “the model’s probability estimates are reliable.” What is wrong with this reasoning? What additional assessment would you recommend?</p>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>auROC measures discrimination (how well the model ranks pathogenic variants above benign ones) but says nothing about calibration (whether predicted probabilities match observed frequencies). A model can achieve perfect auROC while being arbitrarily miscalibrated—for example, by assigning 0.99 to all pathogenic variants and 0.98 to all benign variants. You should assess calibration using reliability diagrams and ECE, stratified by relevant subgroups like ancestry and variant type.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-ch24-measuring-calibration" class="level3" data-number="24.2.2">
<h3 data-number="24.2.2" class="anchored" data-anchor-id="sec-ch24-measuring-calibration"><span class="header-section-number">24.2.2</span> Measuring Calibration</h3>
<p><strong>Reliability diagrams</strong> provide visual assessment of calibration by plotting predicted probabilities against observed frequencies. Construction involves binning predictions into intervals (commonly ten bins spanning 0 to 0.1, 0.1 to 0.2, and so forth), computing the mean predicted probability within each bin, computing the fraction of positive examples within each bin, and plotting these two quantities against each other. A perfectly calibrated model produces points along the diagonal where predicted probability equals observed frequency. Systematic deviations reveal calibration patterns: points below the diagonal indicate overconfidence (predictions exceed reality), points above indicate underconfidence, and S-shaped curves suggest nonlinear miscalibration requiring more flexible correction.</p>
<p><strong>Expected calibration error (ECE)</strong> provides a scalar summary of calibration quality. ECE computes the weighted average absolute difference between predicted probabilities and observed frequencies across bins:</p>
<p><span id="eq-24-01"><span class="math display">\[
\text{ECE} = \sum_{m=1}^{M} \frac{|B_m|}{n} \left| \text{acc}(B_m) - \text{conf}(B_m) \right|
\tag{24.1}\]</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(M\)</span> is the number of bins (typically 10-15)</li>
<li><span class="math inline">\(B_m\)</span> denotes the set of examples in bin <span class="math inline">\(m\)</span>, <span class="math inline">\(|B_m|\)</span> is the number of examples in that bin, <span class="math inline">\(n\)</span> is the total number of examples, <span class="math inline">\(\text{acc}(B_m)\)</span> is the accuracy (fraction of positives) in bin <span class="math inline">\(m\)</span>, and <span class="math inline">\(\text{conf}(B_m)\)</span> is the mean predicted probability in bin <span class="math inline">\(m\)</span>. Lower ECE indicates better calibration, with zero representing perfect calibration. ECE depends on binning strategy; equal-width bins may place most examples in a few bins for models with concentrated predictions, while equal-mass bins ensure each bin contains the same number of examples but may span wide probability ranges.</li>
</ul>
<p><strong>Maximum calibration error (MCE)</strong> captures worst-case miscalibration by reporting the largest absolute gap between predicted and observed frequencies across all bins. MCE is appropriate when any severe miscalibration is unacceptable, as in high-stakes clinical applications where even rare catastrophic errors carry significant consequences.</p>
<p><strong>Brier score</strong> decomposes into components measuring calibration and discrimination (refinement), providing a single proper scoring rule that rewards both properties. The Brier score equals the mean squared difference between predicted probabilities and binary outcomes, and its decomposition reveals whether poor scores stem from miscalibration, poor discrimination, or both.</p>
<p>The following table summarizes these calibration metrics and their appropriate use cases:</p>
<div id="tbl-calibration-metrics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-calibration-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;24.2: Calibration metrics for genomic foundation models. ECE and MCE depend on binning choices; report the binning strategy alongside metric values.
</figcaption>
<div aria-describedby="tbl-calibration-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 36%">
<col style="width: 12%">
<col style="width: 20%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Formula/Description</th>
<th>Range</th>
<th>Best Value</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Reliability diagram</strong></td>
<td>Visual: predicted vs.&nbsp;observed frequency</td>
<td>N/A</td>
<td>Points on diagonal</td>
<td>Initial assessment, pattern identification</td>
</tr>
<tr class="even">
<td><strong>ECE</strong></td>
<td>Weighted average</td>
<td>predicted - observed</td>
<td></td>
<td>[0, 1]</td>
</tr>
<tr class="odd">
<td><strong>MCE</strong></td>
<td>Maximum</td>
<td>predicted - observed</td>
<td>across bins</td>
<td>[0, 1]</td>
</tr>
<tr class="even">
<td><strong>Brier score</strong></td>
<td>Mean squared error of probabilities</td>
<td>[0, 1]</td>
<td>0</td>
<td>Combined calibration + discrimination</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-ch24-fm-miscalibration" class="level3" data-number="24.2.3">
<h3 data-number="24.2.3" class="anchored" data-anchor-id="sec-ch24-fm-miscalibration"><span class="header-section-number">24.2.3</span> Why Foundation Models Are Often Miscalibrated</h3>
<p>Foundation models face calibration challenges beyond those affecting standard neural networks. Pretraining objectives like masked language modeling optimize for predicting held-out tokens, not for producing calibrated probability distributions over downstream tasks (see <a href="../part_3/p3-ch08-pretraining.html" class="quarto-xref"><span>Chapter 8</span></a> for a detailed discussion of pretraining objectives). The representations learned during pretraining may encode useful information about sequence biology while providing no guarantee that fine-tuned classifiers will be well-calibrated.</p>
<p>Distribution shift between pretraining and evaluation compounds miscalibration. A protein language model pretrained on UniRef sequences encounters a fine-tuning task using ClinVar variants. The pretraining distribution emphasizes common proteins with many homologs, while clinical variants concentrate in disease-associated genes with different sequence characteristics. Models may be well-calibrated on held-out pretraining data while miscalibrated on clinically relevant evaluation sets. The broader challenges of distribution shift are examined in <a href="../part_3/p3-ch10-adaptation.html#sec-ch10-domain-shift" class="quarto-xref"><span>Section 10.5</span></a>.</p>
<p>Label noise in training data propagates to calibration errors. ClinVar annotations reflect the state of knowledge at submission time and may contain errors, particularly for older entries or variants from less-studied genes. Deep mutational scanning experiments provide functional labels but with measurement noise that varies across assays. Models trained on noisy labels may learn the noise distribution, producing predictions that match training labels but not underlying truth.</p>
<p>Zero-shot approaches present particular calibration challenges. <em>ESM-1v</em> log-likelihood ratios measure how surprising a mutation is to the language model, but these ratios are not probabilities and have no inherent calibration. Converting log-likelihood ratios to pathogenicity probabilities requires explicit calibration against external labels, and the resulting calibration depends on the reference dataset used for this conversion. The protein language model family and its variant effect scoring capabilities are discussed in <a href="../part_4/p4-ch16-protein-lm.html#sec-ch16-variant-effects" class="quarto-xref"><span>Section 16.6</span></a>.</p>
</section>
<section id="sec-ch24-subgroup-calibration" class="level3" data-number="24.2.4">
<h3 data-number="24.2.4" class="anchored" data-anchor-id="sec-ch24-subgroup-calibration"><span class="header-section-number">24.2.4</span> Calibration Across Subgroups</h3>
<p>Aggregate calibration metrics can mask severe miscalibration in clinically important subgroups. A model might achieve low ECE overall while being dramatically overconfident for variants in African-ancestry individuals and underconfident for European-ancestry individuals, with opposite errors canceling in aggregate statistics. Subgroup-stratified calibration assessment is essential for any model intended for diverse populations.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: Hidden Calibration Disparities
</div>
</div>
<div class="callout-body-container callout-body">
<p>Aggregate calibration metrics (ECE, Brier score) can appear excellent while masking severe disparities across subgroups. A model that is overconfident for one population and underconfident for another may achieve near-zero aggregate ECE if errors cancel. <strong>Always compute calibration metrics stratified by ancestry, gene family, and variant class.</strong> This is not just a technical concern; it directly impacts health equity.</p>
</div>
</div>
<p>Ancestry-stratified calibration reveals systematic patterns in current foundation models. Training data for protein language models and variant effect predictors derive predominantly from European-ancestry cohorts, creating differential epistemic uncertainty across populations. Calibration curves stratified by ancestry often show that models are better calibrated for populations well-represented in training data and overconfident or underconfident for underrepresented populations. This differential calibration has direct fairness implications: clinical decisions based on miscalibrated predictions will be systematically worse for patients from underrepresented backgrounds. The broader challenges of fairness and health equity are addressed in <a href="../part_1/p1-ch03-gwas.html#sec-ch03-fairness" class="quarto-xref"><span>Section 3.7.2</span></a> and <a href="p6-ch27-regulatory.html#sec-ch27-regulatory" class="quarto-xref"><span>Section 27.1</span></a>.</p>
<p>Calibration may also vary by variant class, gene constraint level, protein family, or disease category. Missense variants in highly constrained genes may show different calibration patterns than those in tolerant genes. Variants in well-studied protein families with abundant training examples may be better calibrated than variants in orphan proteins. Stratified reliability diagrams across these categories reveal whether a single calibration correction suffices or whether subgroup-specific approaches are necessary.</p>
</section>
</section>
<section id="sec-ch24-post-hoc-calibration" class="level2" data-number="24.3">
<h2 data-number="24.3" class="anchored" data-anchor-id="sec-ch24-post-hoc-calibration"><span class="header-section-number">24.3</span> Post-Hoc Calibration Methods</h2>
<div id="fig-calibration-methods" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-calibration-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/03-A-fig-calibration-methods.svg" class="img-fluid figure-img"></p>
<figcaption>Temperature scaling: single parameter, preserves ranking</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/03-B-fig-calibration-methods.svg" class="img-fluid figure-img"></p>
<figcaption>Platt scaling: handles asymmetric miscalibration</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/03-C-fig-calibration-methods.svg" class="img-fluid figure-img"></p>
<figcaption>Isotonic regression: flexible non-parametric fit</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-calibration-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24.3: Post-hoc calibration methods. (A) Temperature scaling: divides logits by learned temperature T before softmax—simple, preserves ranking, widely effective. (B) Platt scaling: fits logistic regression on model scores—handles asymmetric miscalibration with two parameters. (C) Isotonic regression: non-parametric monotonic fit—most flexible but requires more calibration data and risks overfitting.
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before learning about calibration methods, consider: If a model consistently assigns probabilities that are too high (overconfident), what mathematical operation might correct this? What if the overconfidence varies depending on the predicted probability level?</p>
</div>
</div>
<section id="sec-ch24-temperature-scaling" class="level3" data-number="24.3.1">
<h3 data-number="24.3.1" class="anchored" data-anchor-id="sec-ch24-temperature-scaling"><span class="header-section-number">24.3.1</span> Temperature Scaling</h3>
<p>The simplest calibration fix is often the most effective. <strong>Temperature scaling</strong> applies a single learned parameter to adjust model confidence, dramatically improving calibration with minimal computational overhead and no change to model predictions’ ranking.</p>
<p>The method modifies the softmax function by dividing logits by a temperature parameter <em>T</em> before applying softmax. The intuition is straightforward: overconfident models produce logits that are too large in magnitude, causing softmax probabilities to concentrate near 0 or 1 rather than reflecting true uncertainty. Dividing by <em>T</em> &gt; 1 shrinks these logits toward zero, which “softens” the probability distribution and reduces spurious confidence:</p>
<p><span id="eq-24-02"><span class="math display">\[
\hat{p}_i = \frac{\exp(z_i / T)}{\sum_{j=1}^{K} \exp(z_j / T)}
\tag{24.2}\]</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(z_i\)</span> are the logits (pre-softmax outputs) for class <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(K\)</span> is the number of classes</li>
<li><span class="math inline">\(T &gt; 0\)</span> is the temperature parameter:
<ul>
<li><span class="math inline">\(T = 1\)</span>: original softmax (no calibration)</li>
<li><span class="math inline">\(T &gt; 1\)</span>: softer distribution (reduces overconfidence)</li>
<li><span class="math inline">\(T &lt; 1\)</span>: sharper distribution (increases confidence)</li>
</ul></li>
<li><span class="math inline">\(\hat{p}_i\)</span> are the calibrated probabilities</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Worked Example: Temperature Scaling">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Worked Example: Temperature Scaling
</div>
</div>
<div class="callout-body-container callout-body">
<p>A variant effect prediction model produces logits for a missense variant:</p>
<p><strong>Before calibration (T = 1.0):</strong> - Logits: <span class="math inline">\(z = [2.5, -1.2]\)</span> for [pathogenic, benign] - Softmax: <span class="math inline">\(p = [\frac{e^{2.5}}{e^{2.5} + e^{-1.2}}, \frac{e^{-1.2}}{e^{2.5} + e^{-1.2}}] = [0.976, 0.024]\)</span> - The model claims 97.6% confidence in pathogenicity</p>
<p><strong>After calibration (T = 2.0, learned from calibration set):</strong> - Scaled logits: <span class="math inline">\(z/T = [1.25, -0.6]\)</span> - Softmax: <span class="math inline">\(p = [\frac{e^{1.25}}{e^{1.25} + e^{-0.6}}, \frac{e^{-0.6}}{e^{1.25} + e^{-0.6}}] = [0.86, 0.14]\)</span> - Now the model reports 86% confidence—still favoring pathogenic, but acknowledging greater uncertainty</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Temperature</th>
<th>P(pathogenic)</th>
<th>P(benign)</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>T = 1.0 (uncalibrated)</td>
<td>0.976</td>
<td>0.024</td>
<td>Overconfident</td>
</tr>
<tr class="even">
<td>T = 2.0 (calibrated)</td>
<td>0.86</td>
<td>0.14</td>
<td>Realistic uncertainty</td>
</tr>
<tr class="odd">
<td>T = 4.0 (over-softened)</td>
<td>0.71</td>
<td>0.29</td>
<td>Underconfident</td>
</tr>
</tbody>
</table>
<p>Note that the ranking is preserved: pathogenic remains more likely than benign. Only the magnitude of confidence changes.</p>
</div>
</div>
<p>When <em>T</em> &gt; 1, the distribution becomes softer (more uniform), reducing overconfidence. When <em>T</em> &lt; 1, the distribution becomes sharper, increasing confidence. The optimal temperature is learned by minimizing negative log-likelihood on a held-out calibration set, typically yielding <em>T</em> between 1.5 and 3 for overconfident deep networks.</p>
<p>Temperature scaling preserves the model’s ranking because dividing all logits by the same constant does not change their relative ordering. A variant ranked as more likely pathogenic than another remains more likely after temperature scaling; only the magnitudes of probability estimates change. This preservation of discrimination while improving calibration makes temperature scaling particularly attractive: calibration improves without sacrificing the model’s hard-won ability to distinguish pathogenic from benign variants.</p>
<p>The method’s simplicity (one parameter) is both strength and limitation. A single global temperature cannot fix heterogeneous miscalibration where the model is overconfident in some regions of input space and underconfident in others. When reliability diagrams show complex nonlinear patterns, more flexible calibration methods are necessary.</p>
</section>
<section id="sec-ch24-platt-scaling" class="level3" data-number="24.3.2">
<h3 data-number="24.3.2" class="anchored" data-anchor-id="sec-ch24-platt-scaling"><span class="header-section-number">24.3.2</span> Platt Scaling</h3>
<p><strong>Platt scaling</strong> fits a logistic regression model on the original model’s outputs, learning both a slope and intercept to transform scores into calibrated probabilities. For binary classification:</p>
<p><span id="eq-24-03"><span class="math display">\[
\hat{p}(x) = \sigma(a \cdot f(x) + b) = \frac{1}{1 + \exp(-(a \cdot f(x) + b))}
\tag{24.3}\]</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(f(x) \in [0, 1]\)</span> is the original model’s predicted probability for input <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\(\sigma(\cdot)\)</span> is the sigmoid function</li>
<li><span class="math inline">\(a, b \in \mathbb{R}\)</span> are learned parameters: <span class="math inline">\(a\)</span> controls sharpness, <span class="math inline">\(b\)</span> controls the decision threshold</li>
<li>Parameters are fit by maximizing log-likelihood on a held-out calibration set The two parameters provide more flexibility than temperature scaling’s single parameter, allowing correction of both the sharpness and the location of the probability distribution.</li>
</ul>
<p>Platt scaling is appropriate when miscalibration involves systematic bias (predictions consistently too high or too low) in addition to over- or underconfidence. The method assumes that a monotonic logistic transformation suffices to correct miscalibration, which may not hold for models with complex, non-monotonic calibration curves.</p>
</section>
<section id="sec-ch24-isotonic-regression" class="level3" data-number="24.3.3">
<h3 data-number="24.3.3" class="anchored" data-anchor-id="sec-ch24-isotonic-regression"><span class="header-section-number">24.3.3</span> Isotonic Regression</h3>
<p><strong>Isotonic regression</strong> provides a non-parametric approach that fits a monotonically increasing function mapping raw scores to calibrated probabilities. Unlike temperature or Platt scaling, isotonic regression makes no assumptions about the functional form of miscalibration, allowing it to correct arbitrary monotonic patterns.</p>
<p>The method works by pooling adjacent bins whose empirical frequencies violate monotonicity, then assigning each bin its pooled frequency. The resulting calibration function is a step function that increases with the original score. This flexibility comes at a cost: with limited calibration data, isotonic regression may overfit to noise in the calibration set, and the step-function output can appear discontinuous. Additionally, isotonic regression provides no uncertainty estimate on the calibration itself; we learn a point estimate of the calibration function without knowing how reliable that estimate is.</p>
<p>The following table provides guidance for selecting among post-hoc calibration methods:</p>
<div id="tbl-calibration-selection" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-calibration-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;24.3: Selection guide for post-hoc calibration methods. Start with temperature scaling; move to more complex methods only when reliability diagrams show patterns that simpler methods cannot address.
</figcaption>
<div aria-describedby="tbl-calibration-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 17%">
<col style="width: 14%">
<col style="width: 19%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Parameters</th>
<th>Best For</th>
<th>Limitations</th>
<th>Calibration Data Needed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Temperature scaling</strong></td>
<td>1</td>
<td>Uniform overconfidence, when ranking must be preserved</td>
<td>Cannot fix heterogeneous or nonlinear miscalibration</td>
<td>~1,000 examples</td>
</tr>
<tr class="even">
<td><strong>Platt scaling</strong></td>
<td>2</td>
<td>Bias + overconfidence, binary classification</td>
<td>Assumes logistic correction is sufficient</td>
<td>~1,000 examples</td>
</tr>
<tr class="odd">
<td><strong>Isotonic regression</strong></td>
<td>Many</td>
<td>Complex, nonlinear calibration curves</td>
<td>Overfits with limited data, discontinuous output</td>
<td>~5,000+ examples</td>
</tr>
<tr class="even">
<td><strong>Subgroup-specific</strong></td>
<td>Varies</td>
<td>Known calibration disparities across groups</td>
<td>Requires labeled data per subgroup</td>
<td>~1,000 per group</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-ch24-calibrating-fm" class="level3" data-number="24.3.4">
<h3 data-number="24.3.4" class="anchored" data-anchor-id="sec-ch24-calibrating-fm"><span class="header-section-number">24.3.4</span> Calibrating Foundation Model Outputs</h3>
<p>Genomic foundation models present specific calibration considerations beyond standard classification settings. The choice of calibration approach depends on whether the model produces logits, log-likelihood ratios, or continuous regression outputs, and on whether calibration targets are available for the deployment distribution.</p>
<p>For zero-shot variant effect scores like <em>ESM-1v</em> log-likelihood ratios, raw outputs have no inherent probabilistic interpretation. Calibration requires mapping these continuous scores to pathogenicity probabilities using external labels, typically from ClinVar or population frequency data. This mapping should occur on held-out genes or variants not used for any model development, and the resulting calibration reflects the specific label set used; calibration against ClinVar pathogenic/benign labels may not transfer to other clinical contexts. The principles of proper held-out evaluation are discussed in <a href="../part_3/p3-ch12-evaluation.html" class="quarto-xref"><span>Chapter 12</span></a>.</p>
<p>Multi-output models that predict across many tasks (multiple cell types, tissues, or assays) may require separate calibration for each output. A regulatory model predicting expression across 200 cell types is unlikely to be uniformly calibrated across all outputs; cell types with more training data may show better calibration than rare cell types.</p>
<p>Temporal stability of calibration deserves consideration. As ClinVar annotations evolve with new evidence, the ground truth against which models were calibrated changes. A model calibrated against 2020 ClinVar labels may become miscalibrated relative to 2025 labels as variant classifications are updated. Periodic recalibration against current labels helps maintain clinical relevance.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical Guidance: Calibration Workflow
</div>
</div>
<div class="callout-body-container callout-body">
<p>When deploying a foundation model for clinical variant interpretation:</p>
<ol type="1">
<li><strong>Assess baseline calibration</strong> using reliability diagrams and ECE on held-out data representative of deployment</li>
<li><strong>Stratify by subgroup</strong> (ancestry, gene family, variant class) to identify hidden disparities</li>
<li><strong>Start simple</strong>: Apply temperature scaling; check if the calibration curve approaches the diagonal</li>
<li><strong>Escalate if needed</strong>: If temperature scaling leaves nonlinear patterns, try Platt scaling or isotonic regression</li>
<li><strong>Validate on deployment distribution</strong>: Calibration learned on one distribution may not transfer</li>
<li><strong>Monitor and recalibrate</strong>: Track calibration over time as ground truth labels evolve</li>
</ol>
</div>
</div>
</section>
</section>
<section id="sec-ch24-uq-methods" class="level2" data-number="24.4">
<h2 data-number="24.4" class="anchored" data-anchor-id="sec-ch24-uq-methods"><span class="header-section-number">24.4</span> Uncertainty Quantification Methods for Foundation Models</h2>
<p>Calibration ensures that stated probabilities match observed frequencies, but even well-calibrated models provide only point estimates. When a model reports 0.70 pathogenicity probability, is that uncertainty reducible with more data, or does it reflect genuine ambiguity in the biological signal? Distinguishing these sources of uncertainty enables more appropriate clinical responses: epistemic uncertainty (arising from limited data) suggests the prediction might change with additional evidence, while aleatoric uncertainty (inherent to the problem) indicates that even perfect models would remain uncertain.</p>
<div id="fig-uq-methods" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-uq-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/04-fig-uq-methods.svg" class="img-fluid figure-img"></p>
<figcaption>Uncertainty quantification methods overview</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-uq-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24.4: Uncertainty quantification methods for deep learning. Ensembles train multiple models and use prediction variance; MC Dropout uses stochastic forward passes through a single model; Bayesian neural networks maintain distributions over weights; evidential deep learning predicts distribution parameters directly. Each involves tradeoffs between computational cost, theoretical grounding, and calibration quality.
</figcaption>
</figure>
</div>
<section id="sec-ch24-deep-ensembles" class="level3" data-number="24.4.1">
<h3 data-number="24.4.1" class="anchored" data-anchor-id="sec-ch24-deep-ensembles"><span class="header-section-number">24.4.1</span> Deep Ensembles</h3>
<p>If one model expresses uncertainty about a prediction, querying multiple models reveals whether that uncertainty reflects genuine ambiguity in the data or an artifact of a particular training run. When five independently trained models agree on a prediction, confidence is warranted; when they disagree, the disagreement itself signals uncertainty. Ensemble disagreement provides one of the most reliable uncertainty estimates available in deep learning, at the cost of training and maintaining multiple models.</p>
<p><strong>Deep ensembles</strong> train <em>M</em> models (typically 5 to 10) with different random initializations, data orderings, or minor architectural variations. At inference time, all members produce predictions, and uncertainty is estimated from the variance or entropy of the ensemble distribution. For classification, epistemic uncertainty appears as disagreement in predicted class probabilities across members. For regression, epistemic uncertainty appears as variance in predicted values.</p>
<p>Why do ensembles work for uncertainty estimation? The key insight is that ensemble disagreement reveals where the data underdetermines the model. The theoretical basis for ensemble uncertainty estimation rests on the observation that disagreement between models reflects regions of input space where the training data provides insufficient constraint. Where training examples are dense, gradient descent from different initializations converges to similar solutions, producing agreement. Where training examples are sparse or conflicting, different initializations find different local optima, producing disagreement. This interpretation connects ensembles to Bayesian model averaging, where predictions are averaged over the posterior distribution of model parameters.</p>
<p>For foundation models with billions of parameters, training full ensembles becomes prohibitively expensive. Training five copies of <em>ESM-2</em> requires approximately five times the compute of a single model, potentially millions of dollars in cloud computing costs. Several practical alternatives reduce this burden. Last-layer ensembles freeze the pretrained backbone and train only an ensemble of prediction heads, reducing cost by orders of magnitude while still capturing uncertainty from the fine-tuning process. Snapshot ensembles save model checkpoints at various points during optimization and use these snapshots as ensemble members, requiring only single-model training time. Multi-seed fine-tuning trains the same architecture from multiple random seeds on the fine-tuning task, which is far cheaper than multi-seed pretraining. The broader considerations of fine-tuning and adaptation strategies are discussed in <a href="../part_3/p3-ch09-transfer.html" class="quarto-xref"><span>Chapter 9</span></a>.</p>
</section>
<section id="sec-ch24-mc-dropout" class="level3" data-number="24.4.2">
<h3 data-number="24.4.2" class="anchored" data-anchor-id="sec-ch24-mc-dropout"><span class="header-section-number">24.4.2</span> Monte Carlo Dropout</h3>
<p><strong>Monte Carlo (MC) dropout</strong> provides uncertainty estimates from a single trained model by treating dropout regularization as approximate Bayesian inference. During standard training with dropout, random subsets of neurons are zeroed at each forward pass. MC dropout keeps dropout active at test time and performs multiple stochastic forward passes, treating the variation across passes as a measure of model uncertainty.</p>
<p>Gal and Ghahramani showed that this procedure approximates variational inference over the model’s weights <span class="citation" data-cites="gal_dropout_2016">(<a href="../bib/references.html#ref-gal_dropout_2016" role="doc-biblioref">Gal and Ghahramani 2016</a>)</span>. Each forward pass with dropout samples a different subnetwork, and the distribution of predictions across samples approximates the predictive distribution under a particular prior over weights. High variance across MC samples indicates epistemic uncertainty about the model’s parameters for that input.</p>
<p>Why does dropout approximate Bayesian inference? During training, dropout randomly masks neurons to prevent co-adaptation—forcing the network to learn redundant representations. Treating this masking as sampling from a distribution over subnetworks connects to Bayesian inference: each sampled subnetwork is like a draw from a posterior over model architectures. When many subnetworks agree on a prediction, the input lies in a region well-constrained by training data; when subnetworks disagree, the input lies in a region where different architectural variants have learned different solutions—exactly the signature of epistemic uncertainty.</p>
<p>MC dropout offers the significant advantage of requiring only a single trained model, avoiding the computational overhead of ensembles. Implementation is straightforward: enable dropout during inference and average predictions over 10 to 50 stochastic forward passes. The variance or entropy of these predictions serves as the uncertainty estimate.</p>
<p>Limitations temper the method’s appeal. Modern transformer architectures often do not use dropout in their standard configurations, or use dropout only in specific locations (attention dropout, residual dropout) where the approximation may be less accurate. The quality of uncertainty estimates depends on the dropout rate and architecture, with higher dropout rates providing better uncertainty estimates but potentially degrading mean predictions. Empirical comparisons often find that MC dropout underestimates uncertainty relative to deep ensembles, particularly in low-data regimes where epistemic uncertainty should be high.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stop and Think
</div>
</div>
<div class="callout-body-container callout-body">
<p>You need to deploy a variant effect predictor with uncertainty quantification, but you have a limited compute budget. Full ensembles of the foundation model are too expensive. What alternatives could you consider, and what trade-offs would each involve? Think about this before reading the heteroscedastic models section.</p>
</div>
</div>
</section>
<section id="sec-ch24-heteroscedastic" class="level3" data-number="24.4.3">
<h3 data-number="24.4.3" class="anchored" data-anchor-id="sec-ch24-heteroscedastic"><span class="header-section-number">24.4.3</span> Heteroscedastic Models</h3>
<p>Standard regression models predict a single output value, implicitly assuming constant noise variance across all inputs. <strong>Heteroscedastic models</strong> instead predict both a mean and a variance for each input, capturing the intuition that prediction uncertainty varies depending on the input. For genomic applications, this approach naturally handles the observation that some prediction tasks are inherently noisier than others: coding variant effects may be more predictable than regulatory variant effects, constrained genes more predictable than tolerant genes.</p>
<p>Architecture modifications are minimal. Instead of outputting a single value, the model outputs two values interpreted as the mean <span class="math inline">\(\mu(x)\)</span> and variance <span class="math inline">\(\sigma^2(x)\)</span> of a Gaussian distribution over outputs. Training uses negative log-likelihood loss under this Gaussian, which penalizes both prediction errors and miscalibrated variance estimates:</p>
<p><span id="eq-24-04"><span class="math display">\[
\mathcal{L}(x, y) = \frac{(y - \mu(x))^2}{2\sigma^2(x)} + \frac{1}{2}\log \sigma^2(x)
\tag{24.4}\]</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(y\)</span> is the ground truth value for input <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\(\mu(x)\)</span> is the model’s predicted mean (one network output)</li>
<li><span class="math inline">\(\sigma^2(x) = \exp(s(x))\)</span> is the predicted variance (second network output, exponentiated to ensure positivity)</li>
<li>The first term penalizes prediction errors, weighted by inverse variance</li>
<li>The second term prevents trivially predicting infinite variance</li>
</ul>
<p>Why does this loss function take this particular form? It derives from the negative log-likelihood of a Gaussian distribution: if the model predicts that the output follows a Gaussian with mean <span class="math inline">\(\mu(x)\)</span> and variance <span class="math inline">\(\sigma^2(x)\)</span>, then the probability of observing the true value <span class="math inline">\(y\)</span> is higher when <span class="math inline">\(y\)</span> is close to <span class="math inline">\(\mu\)</span> and when variance is well-matched to actual prediction error. The first term penalizes prediction errors, weighted by inverse variance so that high-variance predictions are penalized less for the same absolute error—this is mathematically necessary because a Gaussian with larger variance assigns non-negligible probability to a wider range of values. The second term prevents the model from simply predicting infinite variance to avoid all penalties; without it, the optimal strategy would be to always predict <span class="math inline">\(\sigma^2 \to \infty\)</span>, making any prediction equally likely. The balance between these terms forces the model to predict variance that actually matches the empirical noise level. The result is a model that learns to predict larger variance for inputs where training labels are noisy or inconsistent, capturing aleatoric uncertainty in an input-dependent manner.</p>
<p>Heteroscedastic models capture aleatoric uncertainty but not epistemic uncertainty. The predicted variance reflects noise inherent in the labels, not uncertainty about model parameters. Combining heteroscedastic outputs with ensemble methods provides estimates of both uncertainty types: ensemble disagreement captures epistemic uncertainty while the predicted variance captures aleatoric uncertainty.</p>
</section>
<section id="sec-ch24-evidential" class="level3" data-number="24.4.4">
<h3 data-number="24.4.4" class="anchored" data-anchor-id="sec-ch24-evidential"><span class="header-section-number">24.4.4</span> Evidential Deep Learning</h3>
<p><strong>Evidential deep learning</strong> places a prior distribution over the class probabilities themselves rather than directly predicting probabilities. For classification, the model outputs parameters of a Dirichlet distribution, which serves as a prior over the simplex of class probabilities. The concentration parameters of this Dirichlet encode both the predicted class probabilities (via their relative magnitudes) and the model’s uncertainty (via their absolute magnitudes).</p>
<p>Low total concentration indicates high uncertainty: the model is unsure which class is correct. High total concentration with one dominant class indicates confident prediction. This framework provides a principled way to separate epistemic uncertainty (low concentration) from confident predictions (high concentration), all from a single forward pass without ensembling or MC sampling.</p>
<p>Critics have noted that evidential deep learning can produce unreliable uncertainty estimates when the distributional assumptions are violated or when training data is limited <em>[Citation Needed]</em>. Practical experience suggests that ensembles and MC dropout often provide more robust uncertainty estimates, though evidential methods continue to be refined.</p>
</section>
<section id="sec-ch24-selecting-uq" class="level3" data-number="24.4.5">
<h3 data-number="24.4.5" class="anchored" data-anchor-id="sec-ch24-selecting-uq"><span class="header-section-number">24.4.5</span> Selecting Uncertainty Quantification Methods</h3>
<p>The choice among uncertainty quantification methods depends on computational constraints, the types of uncertainty relevant to the application, and the foundation model architecture.</p>
<p>For applications where distinguishing epistemic from aleatoric uncertainty matters, combining ensemble methods with heteroscedastic predictions provides both. Ensemble disagreement identifies variants where more training data might reduce uncertainty, while high predicted variance identifies variants where uncertainty is inherent to the prediction task.</p>
<p>For foundation model applications where full ensembles are impractical, last-layer ensembles offer the best trade-off between computational cost and uncertainty quality. The pretrained representations capture most of the model’s knowledge, and ensembling only the prediction heads captures uncertainty arising from the fine-tuning task.</p>
<p>For real-time applications requiring single forward passes, evidential deep learning or heteroscedastic models provide uncertainty estimates without inference-time overhead. These methods capture aleatoric uncertainty effectively but may underestimate epistemic uncertainty for out-of-distribution inputs.</p>
<p>The following table summarizes uncertainty quantification methods and their trade-offs:</p>
<div id="tbl-uq-methods" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-uq-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;24.4: Comparison of uncertainty quantification methods for genomic foundation models. M = number of ensemble members (typically 5-10); N = number of MC samples (typically 10-50).
</figcaption>
<div aria-describedby="tbl-uq-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 16%">
<col style="width: 17%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Epistemic</th>
<th>Aleatoric</th>
<th>Training Cost</th>
<th>Inference Cost</th>
<th>Foundation Model Compatibility</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Deep ensembles</strong></td>
<td>Excellent</td>
<td>Via heteroscedastic variant</td>
<td>M× base</td>
<td>M× base</td>
<td>Expensive for large models</td>
</tr>
<tr class="even">
<td><strong>Last-layer ensembles</strong></td>
<td>Good</td>
<td>Via heteroscedastic heads</td>
<td>1× backbone + M× heads</td>
<td>M× heads (cheap)</td>
<td>Practical for any foundation model</td>
</tr>
<tr class="odd">
<td><strong>MC dropout</strong></td>
<td>Moderate</td>
<td>Via heteroscedastic variant</td>
<td>1×</td>
<td>N× forward passes</td>
<td>Requires dropout in architecture</td>
</tr>
<tr class="even">
<td><strong>Heteroscedastic</strong></td>
<td>None</td>
<td>Excellent</td>
<td>1×</td>
<td>1×</td>
<td>Easy to add to any model</td>
</tr>
<tr class="odd">
<td><strong>Evidential</strong></td>
<td>Moderate</td>
<td>Moderate</td>
<td>1×</td>
<td>1×</td>
<td>Requires architectural changes</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="sec-ch24-conformal" class="level2" data-number="24.5">
<h2 data-number="24.5" class="anchored" data-anchor-id="sec-ch24-conformal"><span class="header-section-number">24.5</span> Conformal Prediction: Distribution-Free Guarantees</h2>
<p>Most uncertainty quantification methods make assumptions about model behavior or data distributions that may not hold in practice. Temperature scaling assumes miscalibration follows a particular functional form. Ensembles assume that disagreement reflects epistemic uncertainty rather than artifacts of training. Bayesian methods assume specific priors over model parameters. When these assumptions fail, uncertainty estimates may be unreliable precisely when reliability matters most.</p>
<p>Consider how a cautious doctor might communicate diagnostic uncertainty. Rather than saying “I am 73% confident this is condition A,” they might say “Based on your symptoms and test results, I can confidently rule out conditions C, D, and E, but I cannot yet distinguish between A and B—we need more information.” This approach sidesteps the difficulty of assigning precise probabilities by instead specifying which possibilities remain plausible. The size of this “plausible set” communicates uncertainty: a single remaining possibility indicates high confidence, while many remaining possibilities indicate low confidence.</p>
<p><strong>Conformal prediction</strong> formalizes this intuition and offers something stronger: finite-sample coverage guarantees that hold under minimal assumptions. Instead of outputting a point prediction, conformal methods produce a prediction set guaranteed to contain the true label with probability at least <span class="math inline">\(1 - \alpha\)</span>, where <span class="math inline">\(\alpha\)</span> is a user-specified error rate. If we request <span class="math inline">\(90\%\)</span> coverage (<span class="math inline">\(\alpha = 0.10\)</span>), the prediction set will contain the true label at least <span class="math inline">\(90\%\)</span> of the time, regardless of the model’s accuracy or calibration. This guarantee requires only that calibration and test examples are exchangeable (a condition weaker than independent and identically distributed), making conformal prediction robust to model misspecification.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight: Prediction Sets Convey Uncertainty Without Probabilities
</div>
</div>
<div class="callout-body-container callout-body">
<p>Conformal prediction sidesteps the need for well-calibrated probabilities. Instead of asking “what is the probability this variant is pathogenic?”, it answers “which classifications can we confidently rule out?” A prediction set of {Pathogenic} means high confidence. A set of {Pathogenic, VUS, Benign} means low confidence. <strong>The size of the set is the uncertainty estimate</strong>, and the coverage guarantee holds regardless of model calibration.</p>
</div>
</div>
<div id="fig-conformal-prediction" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-conformal-prediction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/05-fig-conformal-prediction.svg" class="img-fluid figure-img"></p>
<figcaption>Conformal prediction provides coverage-guaranteed prediction sets</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-conformal-prediction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24.5: Conformal prediction for coverage-guaranteed uncertainty. The procedure uses a calibration set to establish a score threshold such that prediction sets cover the true label with probability at least 1−α. Unlike point predictions, conformal sets communicate uncertainty through their size: well-characterized variants receive small sets, while rare variants receive larger sets that honestly reflect limited knowledge.
</figcaption>
</figure>
</div>
<section id="sec-ch24-split-conformal" class="level3" data-number="24.5.1">
<h3 data-number="24.5.1" class="anchored" data-anchor-id="sec-ch24-split-conformal"><span class="header-section-number">24.5.1</span> Split Conformal Prediction</h3>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Difficulty Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>This section introduces the mathematical framework for conformal prediction, including quantile computations and non-conformity scores. The key intuition is simpler than the formalism: use a held-out calibration set to learn what scores are “normal,” then flag test predictions as uncertain if they look unusual relative to calibration. Focus on the algorithm steps if the probability theory is unfamiliar.</p>
</div>
</div>
<p>The most practical conformal method, <strong>split conformal prediction</strong>, begins by partitioning labeled data into training and calibration subsets. After training the model exclusively on the training portion, non-conformity scores are computed for each calibration example, where higher scores indicate poorer agreement between prediction and true label. The threshold <span class="math inline">\(q\)</span> is then set at the <span class="math inline">\((1-\alpha)(1+1/n)\)</span> quantile of these calibration scores. At test time, the prediction set includes all labels whose non-conformity score falls below this threshold.</p>
<p>Non-conformity scores measure how “strange” a candidate label is given the model’s output. For classification, a common choice is <span class="math inline">\(1 - \hat{p}_y\)</span>, where <span class="math inline">\(\hat{p}_y\)</span> is the predicted probability of the true class. High predicted probability means low non-conformity (the label conforms to the model’s expectations); low predicted probability means high non-conformity. For regression, absolute residuals <span class="math inline">\(|y - \hat{y}|\)</span> serve as non-conformity scores.</p>
<p>The construction ensures coverage because calibration scores are exchangeable with test scores under the exchangeability assumption. The quantile threshold is set so that a random calibration score exceeds the threshold with probability at most <span class="math inline">\(\alpha\)</span>; by exchangeability, the same holds for test scores. This elegant argument yields exact coverage guarantees without requiring the model to be accurate or well-calibrated.</p>
<p>The coverage guarantee is finite-sample: it holds exactly for any sample size, not just asymptotically. For clinical genomics applications where individual predictions carry significant consequences, this finite-sample property provides assurance that cannot be obtained from asymptotic calibration arguments.</p>
</section>
<section id="sec-ch24-conformal-variant" class="level3" data-number="24.5.2">
<h3 data-number="24.5.2" class="anchored" data-anchor-id="sec-ch24-conformal-variant"><span class="header-section-number">24.5.2</span> Conformal Prediction for Variant Classification</h3>
<p>Variant effect prediction, examined in detail in <a href="../part_4/p4-ch18-vep-fm.html" class="quarto-xref"><span>Chapter 18</span></a>, concentrates the challenges of uncertainty quantification. Instead of reporting a single pathogenicity score, a conformalized variant classifier outputs a prediction set from the possibilities: {pathogenic}, {benign}, {pathogenic, benign}, or the empty set. The set is guaranteed to contain the true label at the specified coverage rate.</p>
<p>Set size conveys uncertainty without requiring probability interpretation. A singleton prediction set indicates high confidence: the model has enough information to narrow to a single class. A set containing multiple classes indicates uncertainty: the model cannot confidently distinguish between possibilities. The empty set indicates extreme uncertainty where even the most permissive threshold cannot be satisfied.</p>
<p>The trade-off between coverage and informativeness shapes practical deployment. At 99% coverage, prediction sets will frequently include multiple classes, providing reliable but uninformative predictions. At 80% coverage, prediction sets will more often be singletons, providing informative but less reliable predictions. Stakeholders must choose coverage levels that match their tolerance for error versus the cost of uninformative predictions.</p>
</section>
<section id="sec-ch24-conformal-limitations" class="level3" data-number="24.5.3">
<h3 data-number="24.5.3" class="anchored" data-anchor-id="sec-ch24-conformal-limitations"><span class="header-section-number">24.5.3</span> Limitations and Practical Considerations</h3>
<p>Conformal prediction provides marginal coverage guarantees: averaged over all inputs, 90% of prediction sets will contain the true label. This does not guarantee conditional coverage for any particular subgroup. A model might achieve 90% coverage overall while providing only 70% coverage for rare variant classes or underrepresented populations. Subgroup-stratified coverage assessment reveals these disparities, though achieving conditional coverage guarantees requires stronger assumptions or larger calibration datasets.</p>
<p>The exchangeability assumption can fail in practice. If the calibration set derives from one population and the test set from another, coverage guarantees may not hold. Temporal shifts (calibration on historical data, testing on future data) similarly violate exchangeability. Methods for conformal prediction under distribution shift exist but require additional assumptions about the nature of the shift.</p>
<p>Prediction set size trades off against informativeness. Larger sets provide more reliable coverage but less useful predictions. A model that produces {pathogenic, benign} for every variant achieves perfect coverage but provides no discrimination. Careful model development to improve underlying accuracy reduces average set size while maintaining coverage guarantees.</p>
</section>
<section id="sec-ch24-conformal-clinical" class="level3" data-number="24.5.4">
<h3 data-number="24.5.4" class="anchored" data-anchor-id="sec-ch24-conformal-clinical"><span class="header-section-number">24.5.4</span> Integration with Clinical Workflows</h3>
<p>Conformal prediction sets integrate naturally with existing variant classification frameworks. The ACMG-AMP guidelines already accommodate uncertainty through categories like “variant of uncertain significance.” Conformal sets provide a principled basis for this categorization: variants receiving singleton sets ({pathogenic} or {benign}) have strong computational evidence, while variants receiving larger sets have uncertain computational evidence. The ACMG-AMP framework and its integration with computational evidence are discussed in <a href="../part_7/p7-ch29-rare-disease.html" class="quarto-xref"><span>Chapter 29</span></a>.</p>
<p>The coverage guarantee provides a quantitative basis for laboratory policies. A laboratory might decide that computational evidence should achieve 95% coverage before contributing to variant classification, using conformal methods to verify this threshold is met. The guarantee holds regardless of which specific variants are encountered, providing assurance that the policy will perform as intended across the laboratory’s case mix.</p>
<p>Conformal methods also enable selective prediction, where the model abstains rather than producing uncertain predictions. By setting coverage requirements appropriately, laboratories can identify variants where computational methods provide reliable evidence and variants where human review is essential. This selective approach focuses expert attention where it is most needed while allowing automated processing of straightforward cases.</p>
</section>
</section>
<section id="sec-ch24-ood-detection" class="level2" data-number="24.6">
<h2 data-number="24.6" class="anchored" data-anchor-id="sec-ch24-ood-detection"><span class="header-section-number">24.6</span> Out-of-Distribution Detection</h2>
<div id="fig-ood-detection" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ood-detection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/06-A-fig-ood-detection.svg" class="img-fluid figure-img"></p>
<figcaption>The OOD problem: models extrapolate confidently into unreliable regions</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/06-B-fig-ood-detection.svg" class="img-fluid figure-img"></p>
<figcaption>Detection methods: from softmax thresholds to embedding approaches</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/06-C-fig-ood-detection.svg" class="img-fluid figure-img"></p>
<figcaption>Genomic OOD scenarios requiring detection before clinical use</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ood-detection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24.6: Out-of-distribution detection for safe deployment. (A) The OOD problem: models extrapolate confidently into regions where predictions are unreliable. (B) Detection methods: from simple softmax thresholds to sophisticated embedding-space approaches. (C) Genomic OOD scenarios: novel genes, underrepresented populations, unusual variant types, mismatched tissues, and technical batch effects—all require detection before clinical use.
</figcaption>
</figure>
</div>
<section id="sec-ch24-ood-problem" class="level3" data-number="24.6.1">
<h3 data-number="24.6.1" class="anchored" data-anchor-id="sec-ch24-ood-problem"><span class="header-section-number">24.6.1</span> Out-of-Distribution Problem</h3>
<p>A DNA language model trained on mammalian genomes encounters a novel archaeal sequence. The model’s embedding places this sequence in an unfamiliar region of representation space, far from the clusters formed by training examples. Yet the model still produces a prediction, potentially with high confidence, because standard neural networks are not designed to recognize when inputs lie outside their training distribution. Detecting <strong>out-of-distribution (OOD)</strong> inputs is essential for safe deployment of foundation models in settings where novel sequences are inevitable.</p>
<p>OOD detection identifies inputs that differ meaningfully from training data, allowing systems to flag uncertain predictions before they cause harm. Novel pathogens may share little sequence similarity with characterized viruses in training data. Synthetic proteins designed for therapeutic purposes may occupy regions of sequence space unsampled by evolution. Variants in poorly characterized genes may lack the contextual information that models rely on for accurate prediction. In each case, recognizing that the input is unusual enables appropriate caution.</p>
<p>The confidence problem compounds OOD challenges. Neural networks often produce high-confidence predictions on OOD inputs because nothing in standard training penalizes confidence on unfamiliar examples. A classifier trained to distinguish pathogenic from benign variants may confidently predict “pathogenic” for a completely random sequence, not because it has evidence for pathogenicity but because it lacks the capacity to say “I do not know.” This failure mode makes OOD detection essential rather than optional.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Knowledge Check
</div>
</div>
<div class="callout-body-container callout-body">
<p>A protein language model is deployed to score variants in a newly discovered gene with no homologs in UniRef. The model returns high-confidence pathogenicity predictions. What concerns should you have? What additional information would help you assess whether to trust these predictions?</p>
<div class="callout callout-style-default callout-note callout-titled" title="Check Your Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check Your Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This gene is out-of-distribution relative to the model’s training data—high epistemic uncertainty is expected. The confident predictions are a red flag: the model may be extrapolating unreliably beyond its training experience. You should check embedding distance to training examples, ensemble disagreement if available, and whether the model’s confidence is calibrated for truly novel protein families. Experimental validation through functional assays would be essential before acting on these predictions.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-ch24-likelihood-ood" class="level3" data-number="24.6.2">
<h3 data-number="24.6.2" class="anchored" data-anchor-id="sec-ch24-likelihood-ood"><span class="header-section-number">24.6.2</span> Likelihood-Based Detection and Its Failures</h3>
<p>The intuitive approach to OOD detection uses model likelihood: inputs the model finds improbable should be flagged as OOD. Language models assign likelihoods to sequences; surely OOD sequences should receive low likelihood?</p>
<p>This intuition fails for deep generative models. Complex models can assign high likelihood to OOD data for reasons unrelated to semantic similarity to training examples. In high-dimensional spaces, typical sets (regions where most probability mass concentrates) do not coincide with high-density regions. A sequence might land in a high-density region of the model’s distribution while being semantically distant from any training example.</p>
<p>Empirically, language models assign high likelihood to repetitive sequences, sequences with unusual but consistent patterns, and sequences from different domains that happen to share statistical properties with training data <em>[Citation Needed]</em>. For genomic models, this means likelihood alone cannot reliably distinguish novel biological sequences from sequences within the training distribution.</p>
</section>
<section id="sec-ch24-embedding-ood" class="level3" data-number="24.6.3">
<h3 data-number="24.6.3" class="anchored" data-anchor-id="sec-ch24-embedding-ood"><span class="header-section-number">24.6.3</span> Embedding-Based Detection</h3>
<p>Learned representations provide more reliable OOD detection than raw likelihood. The key insight is that embeddings encode semantic structure: similar sequences cluster together in embedding space, and OOD sequences land in sparse regions distant from training clusters.</p>
<p><strong>Mahalanobis distance</strong> measures how far a test embedding lies from training data, accounting for the covariance structure of the embedding space. For each class, compute the mean embedding and covariance matrix from training examples. For a test input, compute its distance to each class centroid in units of standard deviations, accounting for correlations between embedding dimensions. Large Mahalanobis distance indicates OOD inputs.</p>
<p>Why Mahalanobis rather than simple Euclidean distance? Euclidean distance treats all embedding dimensions equally, but learned representations often have highly correlated dimensions and vary substantially in scale. A test point that appears close in Euclidean terms might actually be unusual because it deviates along a low-variance direction where training examples are tightly clustered. Mahalanobis distance normalizes by the covariance structure, detecting such deviations by asking “how many standard deviations away is this point along each principal axis of variation?”</p>
<p>Nearest-neighbor methods provide a non-parametric alternative. For a test embedding, find the <span class="math inline">\(k\)</span> nearest neighbors among training embeddings and compute the average distance. Large average distance to neighbors indicates the test input lies in a sparse region of embedding space, suggesting it is OOD. This approach makes no distributional assumptions and scales well with modern approximate nearest-neighbor algorithms.</p>
<p>For genomic foundation models, embedding-based OOD detection enables practical deployment safeguards. <em>ESM</em> embeddings place novel protein folds in regions distant from characterized folds, allowing detection of sequences outside the model’s training experience. <em>DNABERT</em> embeddings reveal unusual sequence composition or repeat structures that may confound predictions. Flagging these cases for expert review prevents confident but unreliable predictions from reaching clinical decisions. The properties of DNA and protein language model embeddings are discussed in <a href="../part_4/p4-ch15-dna-lm.html" class="quarto-xref"><span>Chapter 15</span></a> and <a href="../part_4/p4-ch16-protein-lm.html" class="quarto-xref"><span>Chapter 16</span></a>.</p>
</section>
<section id="sec-ch24-practical-ood" class="level3" data-number="24.6.4">
<h3 data-number="24.6.4" class="anchored" data-anchor-id="sec-ch24-practical-ood"><span class="header-section-number">24.6.4</span> Practical OOD Detection for Genomic Applications</h3>
<p>Defining what counts as OOD requires domain knowledge. Novel species or clades may share evolutionary history with training examples yet differ enough to warrant caution. Extreme GC content can indicate contamination, unusual biology, or simply under-represented genomic regions. Engineered sequences (designed proteins, synthetic regulatory elements) intentionally explore regions of sequence space not represented in natural sequences.</p>
<p>Combining multiple OOD signals improves reliability. Embedding distance, likelihood, and prediction confidence each capture different aspects of distributional difference. An input flagged by multiple methods is more reliably OOD than one flagged by a single method. Threshold selection involves trade-offs between false positives (flagging in-distribution examples unnecessarily) and false negatives (missing true OOD examples).</p>
<p>The operational response to OOD detection depends on the application. For variant interpretation, OOD inputs might trigger automatic flagging for expert review rather than automated classification. For high-throughput screening, OOD inputs might receive tentative predictions with explicit uncertainty warnings. For safety-critical applications, OOD inputs might trigger rejection with a request for additional information.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical Guidance: OOD Detection Pipeline
</div>
</div>
<div class="callout-body-container callout-body">
<p>For deploying foundation models with OOD safeguards:</p>
<ol type="1">
<li><strong>Store training embeddings</strong> or a compressed representation (centroids, covariance) during model development</li>
<li><strong>Compute embedding distance</strong> for each test input using Mahalanobis or k-NN distance</li>
<li><strong>Set threshold</strong> based on desired false positive rate on a held-out validation set</li>
<li><strong>Flag OOD inputs</strong> for human review rather than automated processing</li>
<li><strong>Log and monitor</strong> OOD rates over time; increasing rates may signal distribution shift</li>
<li><strong>Combine signals</strong> (embedding distance, ensemble disagreement, confidence) for robust detection</li>
</ol>
</div>
</div>
</section>
</section>
<section id="sec-ch24-selective-prediction" class="level2" data-number="24.7">
<h2 data-number="24.7" class="anchored" data-anchor-id="sec-ch24-selective-prediction"><span class="header-section-number">24.7</span> Selective Prediction and Abstention</h2>
<div id="fig-selective-prediction" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-selective-prediction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figs/part_6/ch24/07-fig-selective-prediction.svg" class="img-fluid figure-img"></p>
<figcaption>Selective prediction enables tiered clinical workflows</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-selective-prediction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24.7: Selective prediction for clinical deployment. Rather than forcing predictions on all cases, models abstain when uncertainty exceeds a threshold, routing uncertain cases to human review. The coverage-accuracy tradeoff determines what fraction of cases are automated: higher accuracy requires accepting fewer cases. This enables tiered clinical workflows where confident predictions proceed automatically while uncertain cases receive expert attention.
</figcaption>
</figure>
</div>
<section id="sec-ch24-when-abstain" class="level3" data-number="24.7.1">
<h3 data-number="24.7.1" class="anchored" data-anchor-id="sec-ch24-when-abstain"><span class="header-section-number">24.7.1</span> When to Abstain</h3>
<p>A variant effect predictor achieving 95% accuracy overall provides more clinical value if it can identify which predictions are reliable. <strong>Selective prediction</strong> allows models to abstain on difficult cases, concentrating predictions on inputs where confidence is warranted. The trade-off between coverage (fraction of inputs receiving predictions) and accuracy (correctness among predictions made) defines the selective prediction problem.</p>
<p>The coverage-accuracy trade-off reflects a fundamental tension. At 100% coverage, the model predicts on all inputs and achieves its baseline accuracy. As coverage decreases (more abstention), accuracy among predictions made typically increases because the model abstains on its most uncertain cases. The shape of this trade-off curve characterizes the model’s ability to identify reliable predictions.</p>
<p>Abstention is appropriate when the cost of errors exceeds the cost of deferral. In clinical variant interpretation, a confident but incorrect pathogenic prediction may trigger unnecessary medical intervention, while abstention merely defers the decision to expert review. If expert review is available and affordable relative to error costs, abstaining on uncertain cases improves overall decision quality. Conversely, in high-throughput screening where expert review is infeasible, abstention may provide little benefit because all predictions eventually require automated handling.</p>
</section>
<section id="sec-ch24-selective-methods" class="level3" data-number="24.7.2">
<h3 data-number="24.7.2" class="anchored" data-anchor-id="sec-ch24-selective-methods"><span class="header-section-number">24.7.2</span> Selective Prediction Methods</h3>
<p>Confidence-based selection abstains when the model’s maximum predicted probability falls below a threshold. For a classifier producing probabilities over classes, if max_c *p̂_c* &lt; τ, the model abstains. This simple approach works well when model confidence correlates with correctness, but fails when models are confidently wrong.</p>
<p>Ensemble-based selection abstains when ensemble members disagree beyond a threshold. High disagreement indicates epistemic uncertainty about the correct prediction, warranting abstention even if individual members express confidence. This approach captures uncertainty that confidence-based selection misses when models are overconfident.</p>
<p>Conformal selection abstains when prediction sets exceed a size threshold. If the conformal prediction set contains more than one class, the model lacks confidence to make a unique prediction. This approach connects selective prediction to the coverage guarantees of conformal methods: the model makes predictions with guaranteed coverage on the non-abstained cases.</p>
<p>Learned selection trains a separate model to predict whether the primary model will be correct on each input. This “rejection model” learns to identify failure modes that simple confidence thresholds miss, potentially achieving better coverage-accuracy trade-offs than heuristic methods.</p>
</section>
<section id="sec-ch24-selective-eval" class="level3" data-number="24.7.3">
<h3 data-number="24.7.3" class="anchored" data-anchor-id="sec-ch24-selective-eval"><span class="header-section-number">24.7.3</span> Evaluating Selective Prediction</h3>
<p><strong>Risk-coverage curves</strong> plot accuracy (or its complement, risk) as a function of coverage, revealing how performance improves as the model becomes more selective. The area under the risk-coverage curve summarizes overall selective prediction quality. Models with better uncertainty estimates produce steeper curves, achieving high accuracy at lower coverage.</p>
<p>Selective accuracy at fixed coverage specifies a coverage level (e.g., 80%) and reports accuracy among predictions made at that coverage. This metric directly answers practical questions: “If we let the model predict on its 80% most confident cases, how accurate will it be?”</p>
<p>Comparison across methods requires matched coverage levels. A method that achieves 99% accuracy at 50% coverage and 95% accuracy at 90% coverage may be preferable to a method achieving 97% accuracy at both levels, depending on operational requirements. Reporting full risk-coverage curves enables stakeholders to select operating points appropriate to their cost structures.</p>
</section>
</section>
<section id="sec-ch24-genomic-uq" class="level2" data-number="24.8">
<h2 data-number="24.8" class="anchored" data-anchor-id="sec-ch24-genomic-uq"><span class="header-section-number">24.8</span> Uncertainty for Specific Genomic Tasks</h2>
<p>The general principles of uncertainty quantification apply differently across genomic prediction tasks. Variant effect prediction, regulatory variant interpretation, and cross-population generalization each present distinct challenges for calibration, coverage, and out-of-distribution detection. The sources of uncertainty vary: coding variants benefit from stronger evolutionary constraint and clearer functional readouts, while regulatory variants operate through context-dependent mechanisms that introduce irreducible noise. Population-specific uncertainty reflects training data composition and has direct implications for equitable clinical deployment.</p>
<section id="sec-ch24-vep-uncertainty" class="level3" data-number="24.8.1">
<h3 data-number="24.8.1" class="anchored" data-anchor-id="sec-ch24-vep-uncertainty"><span class="header-section-number">24.8.1</span> Variant Effect Prediction Uncertainty</h3>
<p>Variant effect prediction concentrates the challenges of uncertainty quantification. Epistemic uncertainty arises from poorly characterized genes, novel protein folds, and under-represented populations in training data. Aleatoric uncertainty stems from incomplete penetrance, variable expressivity, and noise in functional assay labels. Both types of uncertainty must be estimated and communicated for variant predictions to inform clinical decisions appropriately. The technical details of variant effect prediction models are covered in <a href="../part_4/p4-ch18-vep-fm.html" class="quarto-xref"><span>Chapter 18</span></a>.</p>
<p>Calibration challenges for VEP include the evolving nature of ground truth labels. ClinVar annotations change as new evidence emerges; variants classified as VUS may be reclassified as pathogenic or benign, and even confident classifications occasionally reverse. A model calibrated against a historical version of ClinVar may appear miscalibrated against current annotations, not because the model changed but because the labels did. Periodic recalibration against current databases maintains alignment between model outputs and contemporary clinical understanding.</p>
<p>Population-specific calibration addresses the reality that training data predominantly derive from European-ancestry cohorts. For patients from other ancestral backgrounds, both epistemic uncertainty (fewer training examples) and calibration (different baseline pathogenicity rates, different patterns of variation) may differ from the aggregate. Stratified reliability diagrams by ancestry reveal these differences; ancestry-conditional calibration may be necessary for equitable performance across populations. The governance and policy dimensions of ensuring equitable uncertainty communication are addressed in <a href="p6-ch27-regulatory.html#sec-ch27-regulatory" class="quarto-xref"><span>Section 27.1</span></a>.</p>
</section>
<section id="sec-ch24-regulatory-uncertainty" class="level3" data-number="24.8.2">
<h3 data-number="24.8.2" class="anchored" data-anchor-id="sec-ch24-regulatory-uncertainty"><span class="header-section-number">24.8.2</span> Regulatory Variant Uncertainty</h3>
<p>Regulatory variants present distinct uncertainty challenges. Unlike coding variants where effects can be localized to specific amino acid changes, regulatory variants act through complex mechanisms involving transcription factor binding, chromatin accessibility, and three-dimensional genome organization. This mechanistic complexity translates to higher aleatoric uncertainty: even perfectly characterized regulatory variants may have context-dependent effects that vary across cell types, developmental stages, and genetic backgrounds. A variant that disrupts a transcription factor binding site may have dramatic effects in tissues where that factor is active and negligible effects elsewhere, yet the model must predict across all contexts simultaneously. The architecture and capabilities of regulatory prediction models are discussed in <a href="../part_4/p4-ch17-regulatory.html" class="quarto-xref"><span>Chapter 17</span></a>.</p>
<p>The context-dependence of regulatory effects creates a calibration challenge distinct from coding variants. A model may be well-calibrated for predicting expression changes in cell types abundant in training data (lymphoblastoid cell lines, common cancer lines) while poorly calibrated for clinically relevant primary tissues rarely profiled at scale. Stratified calibration assessment across tissue types reveals these disparities, but the sparsity of ground truth labels for many tissues limits the precision of tissue-specific calibration estimates.</p>
<p>Expression prediction models like <em>Enformer</em> and <em>Borzoi</em> provide uncertainty estimates for predicted expression changes through several approaches. Ensemble methods quantify disagreement across model variants trained with different random seeds. Heteroscedastic architectures predict tissue-specific confidence alongside tissue-specific expression, learning that predictions for well-characterized tissues deserve higher confidence than those for rarely profiled contexts. These uncertainties propagate to downstream interpretations: a variant predicted to alter expression with high uncertainty warrants different treatment than one with narrow confidence bounds, and the tissue-specificity of uncertainty may itself be informative about which experimental follow-up would most reduce ambiguity.</p>
</section>
<section id="sec-ch24-population-uncertainty" class="level3" data-number="24.8.3">
<h3 data-number="24.8.3" class="anchored" data-anchor-id="sec-ch24-population-uncertainty"><span class="header-section-number">24.8.3</span> Uncertainty Across Populations</h3>
<p>Differential uncertainty across populations has direct implications for health equity. Models trained predominantly on European-ancestry data exhibit higher epistemic uncertainty for other populations, manifesting in several observable ways: larger prediction sets from conformal methods, higher abstention rates from selective prediction, greater ensemble disagreement, and less reliable confidence estimates from calibration. These differences arise from multiple sources. Linkage disequilibrium patterns differ across populations, meaning that variant correlations learned from European data may not transfer. Population-specific variants absent from training data generate pure epistemic uncertainty. Even shared variants may have different effect sizes across populations due to gene-environment interactions or epistatic backgrounds that vary by ancestry.</p>
<p>Quantifying population-specific uncertainty requires appropriate calibration and evaluation datasets. A model calibrated exclusively on European-ancestry ClinVar submissions may appear well-calibrated on aggregate metrics while being systematically miscalibrated for other populations. The scarcity of diverse calibration data creates a challenging circularity: we cannot assess population-specific calibration without diverse labeled datasets, yet diverse labeled datasets are precisely what current genomic databases lack. Initiatives like the All of Us Research Program and population-specific biobanks (Uganda Genome Resource, Taiwan Biobank, BioBank Japan) are beginning to address this gap, enabling population-stratified uncertainty assessment that was previously impossible. The broader context of biobank resources and their composition is discussed in <a href="../part_1/p1-ch02-data.html#sec-ch02-biobanks" class="quarto-xref"><span>Section 2.3</span></a>.</p>
<p>Transparent reporting of population-stratified uncertainty metrics enables informed decisions about model deployment. If a model abstains on 30% of variants in one population but only 10% in another, users can make informed choices about supplementary analyses for the higher-abstention population. Clinical laboratories might establish ancestry-specific thresholds for automated reporting versus expert review. Research applications might weight predictions by ancestry-specific confidence when aggregating across diverse cohorts. Ignoring these differences risks providing lower-quality predictions to already under-served populations while presenting a false appearance of uniform reliability, compounding existing disparities in genomic medicine.</p>
</section>
</section>
<section id="sec-ch24-communication" class="level2" data-number="24.9">
<h2 data-number="24.9" class="anchored" data-anchor-id="sec-ch24-communication"><span class="header-section-number">24.9</span> Communicating Uncertainty to End Users</h2>
<p>Statistical uncertainty estimates serve clinical decisions only when they reach end users in interpretable form. The translation from model outputs to actionable information involves choices about categorical versus continuous reporting, numerical versus visual presentation, and whether to frame results as probabilities or as expected outcomes under alternative decisions. Different stakeholders require different presentations: clinicians need actionable categories, researchers need distributional information, and patients need accessible risk communication.</p>
<section id="sec-ch24-communication-challenge" class="level3" data-number="24.9.1">
<h3 data-number="24.9.1" class="anchored" data-anchor-id="sec-ch24-communication-challenge"><span class="header-section-number">24.9.1</span> Communication Challenge</h3>
<p>A pathogenicity score of 0.73 ± 0.15 may be statistically accurate but nearly useless to a clinician deciding whether to order confirmatory testing. The gap between statistical uncertainty and decision-relevant communication presents a persistent challenge for genomic AI deployment. Different users reason differently about probability and risk; effective communication requires understanding these differences.</p>
<p>Cognitive biases complicate probability interpretation. Humans tend toward overconfidence in point estimates, treating 0.73 as more certain than warranted. Prediction intervals are frequently misunderstood: a 90% <strong>confidence interval</strong> does not mean the true value has a 90% chance of being in that specific interval (a Bayesian interpretation) but rather that 90% of such intervals would contain the true value (a frequentist interpretation). Base rate neglect leads users to interpret variant-level pathogenicity predictions without accounting for prior probability based on clinical presentation, family history, and phenotypic specificity.</p>
<p>Different stakeholders have different needs. Clinicians require actionable categories that map to clinical decision points, not continuous scores requiring interpretation. Researchers may prefer full probability distributions enabling flexible downstream analysis. Patients and families need understandable risk communication that supports informed decision-making without inducing inappropriate anxiety or false reassurance.</p>
</section>
<section id="sec-ch24-categorical-reporting" class="level3" data-number="24.9.2">
<h3 data-number="24.9.2" class="anchored" data-anchor-id="sec-ch24-categorical-reporting"><span class="header-section-number">24.9.2</span> Categorical Reporting</h3>
<p>Clinical genetics has established categorical frameworks for variant interpretation. The ACMG-AMP guidelines define five categories: pathogenic, likely pathogenic, variant of uncertain significance, likely benign, and benign. The complete ACMG-AMP framework, including how computational evidence integrates with other evidence types, is examined in <a href="../part_7/p7-ch29-rare-disease.html#sec-ch29-acmg-amp" class="quarto-xref"><span>Section 29.2</span></a>. Mapping continuous model outputs to these categories requires threshold selection that balances sensitivity and specificity at clinically meaningful operating points, with guidance on calibrating model outputs to ACMG evidence strength provided in <a href="../part_4/p4-ch18-vep-fm.html#sec-ch18-acmg-mapping" class="quarto-xref"><span>Section 18.5.3</span></a>.</p>
<p>Uncertainty within categories can be conveyed through confidence qualifiers or numerical confidence scores attached to categorical calls. A “likely pathogenic” call with 95% confidence differs meaningfully from one with 60% confidence, even though both receive the same categorical label. Two-dimensional reporting combining category and confidence enables more nuanced interpretation without abandoning the categorical framework that clinicians expect.</p>
<p>Threshold selection involves value judgments beyond pure statistics. The consequences of false positive and false negative pathogenic calls differ by clinical context. For a severe, treatable condition, false negatives carry higher cost, warranting lower thresholds for pathogenic classification. For untreatable conditions where pathogenic classification affects reproductive decisions, the calculus differs. Uncertainty quantification enables informed threshold selection by revealing the trade-offs at different operating points.</p>
</section>
<section id="sec-ch24-visual-communication" class="level3" data-number="24.9.3">
<h3 data-number="24.9.3" class="anchored" data-anchor-id="sec-ch24-visual-communication"><span class="header-section-number">24.9.3</span> Visual Communication</h3>
<p>Probability bars and confidence intervals provide visual representation of uncertainty, though their interpretation depends on user familiarity with statistical graphics. Icon arrays, which represent probabilities as proportions of colored icons in a grid (e.g., 73 red icons and 27 blue icons out of 100), improve comprehension for users without statistical training. The visual representation of proportion is more intuitive than numerical probability for many audiences.</p>
<p>Risk ladders place the prediction in context by showing where it falls relative to other risks of varying magnitude. A variant with 0.73 probability of pathogenicity can be placed alongside risks from other genetic conditions, environmental exposures, or common medical procedures, enabling intuitive comparison.</p>
<p>Interactive visualizations allow users to explore uncertainty in detail, examining how predictions change under different assumptions or how uncertainty varies across related variants. These approaches suit sophisticated users engaged in research or detailed clinical analysis but may overwhelm users seeking simple answers.</p>
</section>
<section id="sec-ch24-decision-framing" class="level3" data-number="24.9.4">
<h3 data-number="24.9.4" class="anchored" data-anchor-id="sec-ch24-decision-framing"><span class="header-section-number">24.9.4</span> Decision-Theoretic Framing</h3>
<p>Rather than communicating probability alone, decision-theoretic framing presents expected outcomes under different actions. Instead of “this variant has 73% probability of being pathogenic,” the report might state “if we assume this variant is pathogenic and proceed with surveillance, the expected outcomes are X; if we assume it is benign and decline surveillance, the expected outcomes are Y.”</p>
<p>This framing integrates uncertainty with action, helping users understand how uncertainty affects what they should do rather than treating probability as an end in itself. The approach requires modeling clinical outcomes, which introduces additional assumptions, but makes explicit the decision-relevant implications of uncertainty rather than leaving users to integrate probability with consequences on their own.</p>
</section>
</section>
<section id="sec-ch24-conclusion" class="level2" data-number="24.10">
<h2 data-number="24.10" class="anchored" data-anchor-id="sec-ch24-conclusion"><span class="header-section-number">24.10</span> Necessary but Insufficient</h2>
<p>Uncertainty quantification transforms foundation model outputs from opaque scores into components of rational decision processes. A well-calibrated pathogenicity prediction that honestly communicates its limitations enables appropriate clinical reasoning: high confidence warrants action, low confidence warrants additional testing or expert review. An overconfident score that claims false precision causes harm through both false positives (unnecessary interventions) and false negatives (missed diagnoses). Temperature scaling, conformal prediction, and out-of-distribution detection together provide the technical foundation for trustworthy genomic AI.</p>
<p>The path from uncertainty quantification to clinical impact requires integrating these methods into operational workflows. Selective prediction enables triage between automated handling and expert review based on model confidence. Conformal prediction sets provide coverage guarantees that support risk-aware decision-making. Out-of-distribution detection prevents confident predictions on inputs that fall outside the training distribution, a particularly important capability given the confounding issues examined in <a href="../part_3/p3-ch13-confounding.html" class="quarto-xref"><span>Chapter 13</span></a>. Calibration ensures that numerical probabilities mean what they claim to mean. Together, these tools enable foundation models to participate in clinical decisions without overstating their reliability. Clinical risk prediction frameworks (<a href="../part_7/p7-ch28-clinical-risk.html" class="quarto-xref"><span>Chapter 28</span></a>) develop these tools further for deployment contexts, while rare disease workflows (<a href="../part_7/p7-ch29-rare-disease.html" class="quarto-xref"><span>Chapter 29</span></a>) apply them to diagnostic interpretation.</p>
<p>Yet uncertainty quantification alone is insufficient. A perfectly calibrated black box remains a black box. The clinician who receives an uncertain prediction wants to understand why the model is uncertain: Is it because the variant falls in a poorly characterized gene? Because the model has never encountered this protein fold? Because the underlying biology is genuinely ambiguous? Interpretability, examined in <a href="p6-ch25-interpretability.html" class="quarto-xref"><span>Chapter 25</span></a>, complements uncertainty by revealing the basis for predictions and their associated confidence. Attribution methods (<a href="p6-ch25-interpretability.html#sec-ch25-attribution" class="quarto-xref"><span>Section 25.1</span></a>) identify which input features drive predictions; probing classifiers (<a href="p6-ch25-interpretability.html#sec-ch25-probing" class="quarto-xref"><span>Section 25.4</span></a>) reveal what information representations encode. The conjunction of calibrated uncertainty and mechanistic understanding approaches what trustworthy clinical AI requires. Neither alone suffices; together they provide the foundation for models that clinicians can reason with rather than merely defer to.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Test Yourself">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Test Yourself
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before reviewing the summary, test your recall:</p>
<ol type="1">
<li>What is the difference between epistemic and aleatoric uncertainty, and why does this distinction matter for clinical decision-making?</li>
<li>What is model calibration, and why can a highly accurate model still be dangerously miscalibrated?</li>
<li>Explain how temperature scaling improves calibration. What does it preserve and what does it change?</li>
<li>How do deep ensembles quantify epistemic uncertainty, and what makes them the “gold standard” among uncertainty quantification methods?</li>
<li>What coverage guarantee does conformal prediction provide, and why does marginal coverage differ from conditional coverage?</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter Summary
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Epistemic vs.&nbsp;aleatoric uncertainty</strong>: Epistemic uncertainty arises from limited training data and can be reduced with more examples; aleatoric uncertainty reflects inherent biological noise and is irreducible</li>
<li><strong>Calibration</strong>: A model is calibrated when its predicted probabilities match observed frequencies; most foundation models are miscalibrated and require post-hoc correction</li>
<li><strong>Post-hoc calibration methods</strong>: Temperature scaling (simple, preserves ranking), Platt scaling (handles bias), and isotonic regression (flexible, requires more data)</li>
<li><strong>Uncertainty quantification methods</strong>: Deep ensembles (gold standard), MC dropout (single model), heteroscedastic models (aleatoric), last-layer ensembles (practical for foundation models)</li>
<li><strong>Conformal prediction</strong>: Distribution-free coverage guarantees; prediction set size conveys uncertainty; marginal not conditional coverage</li>
<li><strong>OOD detection</strong>: Embedding-based methods more reliable than likelihood; flag unusual inputs for expert review</li>
<li><strong>Selective prediction</strong>: Abstain on uncertain cases to improve accuracy on retained predictions</li>
</ul>
<p><strong>Clinical Implications:</strong></p>
<ul>
<li>Calibration must be assessed within subgroups (ancestry, gene family) to avoid hidden disparities</li>
<li>Population-specific uncertainty has direct health equity implications</li>
<li>Uncertainty communication should match stakeholder needs (categorical for clinicians, distributional for researchers)</li>
<li>Uncertainty quantification is necessary but insufficient; interpretability complements it</li>
</ul>
<p><strong>Connections to Other Chapters:</strong></p>
<ul>
<li>Builds on evaluation principles (<a href="../part_3/p3-ch12-evaluation.html" class="quarto-xref"><span>Chapter 12</span></a>) and pretraining objectives (<a href="../part_3/p3-ch08-pretraining.html" class="quarto-xref"><span>Chapter 8</span></a>)</li>
<li>Precedes interpretability (<a href="p6-ch25-interpretability.html" class="quarto-xref"><span>Chapter 25</span></a>) which explains why models are uncertain</li>
<li>Applies to clinical risk prediction (<a href="../part_7/p7-ch28-clinical-risk.html" class="quarto-xref"><span>Chapter 28</span></a>) and rare disease diagnosis (<a href="../part_7/p7-ch29-rare-disease.html" class="quarto-xref"><span>Chapter 29</span></a>)</li>
<li>Intersects with fairness concerns (<a href="../part_1/p1-ch03-gwas.html#sec-ch03-fairness" class="quarto-xref"><span>Section 3.7.2</span></a>, <a href="p6-ch27-regulatory.html#sec-ch27-regulatory" class="quarto-xref"><span>Section 27.1</span></a>)</li>
</ul>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-fowler_deep_2014" class="csl-entry" role="listitem">
Fowler, Douglas M., and Stanley Fields. 2014. <span>“Deep Mutational Scanning: A New Style of Protein Science.”</span> <em>Nature Methods</em> 11 (8): 801–7. <a href="https://doi.org/10.1038/nmeth.3027">https://doi.org/10.1038/nmeth.3027</a>.
</div>
<div id="ref-gal_dropout_2016" class="csl-entry" role="listitem">
Gal, Yarin, and Zoubin Ghahramani. 2016. <span>“Dropout as a <span>Bayesian</span> <span>Approximation</span>: <span>Representing</span> <span>Model</span> <span>Uncertainty</span> in <span>Deep</span> <span>Learning</span>.”</span> In <em>Proceedings of <span>The</span> 33rd <span>International</span> <span>Conference</span> on <span>Machine</span> <span>Learning</span></em>, 1050–59. PMLR.
</div>
<div id="ref-guo_calibration_2017" class="csl-entry" role="listitem">
Guo, Chuan, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. 2017. <span>“On <span>Calibration</span> of <span>Modern</span> <span>Neural</span> <span>Networks</span>.”</span> In <em>Proceedings of the 34th <span>International</span> <span>Conference</span> on <span>Machine</span> <span>Learning</span></em>, 1321–30. PMLR.
</div>
<div id="ref-landrum_clinvar_2018" class="csl-entry" role="listitem">
Landrum, Melissa J, Jennifer M Lee, Mark Benson, Garth R Brown, Chen Chao, Shanmuga Chitipiralla, Baoshan Gu, et al. 2018. <span>“<span>ClinVar</span>: Improving Access to Variant Interpretations and Supporting Evidence.”</span> <em>Nucleic Acids Research</em> 46 (D1): D1062–67. <a href="https://doi.org/10.1093/nar/gkx1153">https://doi.org/10.1093/nar/gkx1153</a>.
</div>
<div id="ref-rubin_statistical_2017" class="csl-entry" role="listitem">
Rubin, Alan F., Hannah Gelman, Nathan Lucas, Sandra M. Bajjalieh, Anthony T. Papenfuss, Terence P. Speed, and Douglas M. Fowler. 2017. <span>“A Statistical Framework for Analyzing Deep Mutational Scanning Data.”</span> <em>Genome Biology</em> 18 (1): 150. <a href="https://doi.org/10.1186/s13059-017-1272-5">https://doi.org/10.1186/s13059-017-1272-5</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../part_6/p6--responsible-deployment.html" class="pagination-link" aria-label="Part VI: Responsible Deployment">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Part VI: Responsible Deployment</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../part_6/p6-ch25-interpretability.html" class="pagination-link" aria-label="Interpretability">
        <span class="nav-page-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Interpretability</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025-2026, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>