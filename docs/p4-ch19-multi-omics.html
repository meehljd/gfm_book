<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>19&nbsp; Multi-Omics Integration – Genomic Foundation Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./p5--eval-interp.html" rel="next">
<link href="./p4-ch18-networks.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-d1e9b63c6b6094879b9f94a7628e3370.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-a1553387a0f784068632030e9fbb8a3c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p4--multi-scale.html">Part IV: Multi-Scale Modeling</a></li><li class="breadcrumb-item"><a href="./p4-ch19-multi-omics.html"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Genomic Foundation Models</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p1--foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch01-ngs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sequencing: From Reads to Variants</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch02-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Genomic Data Landscape</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch03-gwas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GWAS and Polygenic Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p1-ch04-vep-classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classical Variant Effect Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p2--principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Core Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch05-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Sequence Representation and Tokenization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch06-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Convolutional Models for Genomic Sequence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch07-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Attention and Transformers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch08-pretraining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pretraining Objectives and Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p2-ch09-transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transfer Learning and Adaptation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p3--architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Deep Learning Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch10-fm-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">The Foundation Model Paradigm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch11-dna-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">DNA Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch12-protein-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Protein Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch13-regulatory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Long-Context Regulatory Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p3-ch14-vep-fm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Variant Effect Prediction with Foundation Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p4--multi-scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Multi-Scale Modeling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch15-rna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">RNA Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch16-single-cell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Single-Cell and Epigenomic Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch17-3d-genome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">3D Genome and Spatial Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch18-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Gap Analysis: Chapter 18 Networks and Graph-Based Reasoning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p4-ch19-multi-omics.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p5--eval-interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Evaluation and Reliability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch20-benchmarks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Benchmarks for Genomic AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch21-eval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Evaluation Methodology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch22-confounding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Confounders in Model Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch23-uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Uncertainty Quantification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p5-ch24-interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Interpretability and Mechanism</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./p6--translation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI — Translation and Application</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch25-clinical-risk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Clinical Risk Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch26-rare-disease.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Rare Disease and Variant Interpretation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch27-drug-discovery.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Drug Discovery and Target Identification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch28-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Sequence Design and Engineering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./p6-ch29-future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Regulatory, Ethical, and Future Considerations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-a-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-b-compute.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Model Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-c-data-curation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Training Data Curation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-d-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Referenced Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-e-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Additional Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-f-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-limits-of-single-modality-models" id="toc-the-limits-of-single-modality-models" class="nav-link active" data-scroll-target="#the-limits-of-single-modality-models"><span class="header-section-number">19.1</span> The Limits of Single-Modality Models</a></li>
  <li><a href="#integration-strategies-and-their-tradeoffs" id="toc-integration-strategies-and-their-tradeoffs" class="nav-link" data-scroll-target="#integration-strategies-and-their-tradeoffs"><span class="header-section-number">19.2</span> Integration Strategies and Their Tradeoffs</a>
  <ul class="collapse">
  <li><a href="#early-fusion" id="toc-early-fusion" class="nav-link" data-scroll-target="#early-fusion"><span class="header-section-number">19.2.1</span> Early Fusion</a></li>
  <li><a href="#late-fusion" id="toc-late-fusion" class="nav-link" data-scroll-target="#late-fusion"><span class="header-section-number">19.2.2</span> Late Fusion</a></li>
  <li><a href="#intermediate-fusion" id="toc-intermediate-fusion" class="nav-link" data-scroll-target="#intermediate-fusion"><span class="header-section-number">19.2.3</span> Intermediate Fusion</a></li>
  </ul></li>
  <li><a href="#multi-omics-foundation-models" id="toc-multi-omics-foundation-models" class="nav-link" data-scroll-target="#multi-omics-foundation-models"><span class="header-section-number">19.3</span> Multi-Omics Foundation Models</a>
  <ul class="collapse">
  <li><a href="#factor-based-integration" id="toc-factor-based-integration" class="nav-link" data-scroll-target="#factor-based-integration"><span class="header-section-number">19.3.1</span> Factor-Based Integration</a></li>
  <li><a href="#deep-generative-multi-omics-models" id="toc-deep-generative-multi-omics-models" class="nav-link" data-scroll-target="#deep-generative-multi-omics-models"><span class="header-section-number">19.3.2</span> Deep Generative Multi-Omics Models</a></li>
  <li><a href="#contrastive-multi-modal-learning" id="toc-contrastive-multi-modal-learning" class="nav-link" data-scroll-target="#contrastive-multi-modal-learning"><span class="header-section-number">19.3.3</span> Contrastive Multi-Modal Learning</a></li>
  </ul></li>
  <li><a href="#clinical-integration-ehr-imaging-and-molecular-data" id="toc-clinical-integration-ehr-imaging-and-molecular-data" class="nav-link" data-scroll-target="#clinical-integration-ehr-imaging-and-molecular-data"><span class="header-section-number">19.4</span> Clinical Integration: EHR, Imaging, and Molecular Data</a>
  <ul class="collapse">
  <li><a href="#electronic-health-records-as-a-modality" id="toc-electronic-health-records-as-a-modality" class="nav-link" data-scroll-target="#electronic-health-records-as-a-modality"><span class="header-section-number">19.4.1</span> Electronic Health Records as a Modality</a></li>
  <li><a href="#imaging-integration" id="toc-imaging-integration" class="nav-link" data-scroll-target="#imaging-integration"><span class="header-section-number">19.4.2</span> Imaging Integration</a></li>
  <li><a href="#multi-modal-clinical-prediction-models" id="toc-multi-modal-clinical-prediction-models" class="nav-link" data-scroll-target="#multi-modal-clinical-prediction-models"><span class="header-section-number">19.4.3</span> Multi-Modal Clinical Prediction Models</a></li>
  </ul></li>
  <li><a href="#the-systems-view-from-variant-to-phenotype" id="toc-the-systems-view-from-variant-to-phenotype" class="nav-link" data-scroll-target="#the-systems-view-from-variant-to-phenotype"><span class="header-section-number">19.5</span> The Systems View: From Variant to Phenotype</a>
  <ul class="collapse">
  <li><a href="#the-information-cascade" id="toc-the-information-cascade" class="nav-link" data-scroll-target="#the-information-cascade"><span class="header-section-number">19.5.1</span> The Information Cascade</a></li>
  <li><a href="#bottleneck-modalities" id="toc-bottleneck-modalities" class="nav-link" data-scroll-target="#bottleneck-modalities"><span class="header-section-number">19.5.2</span> Bottleneck Modalities</a></li>
  <li><a href="#causal-vs.-correlational-integration" id="toc-causal-vs.-correlational-integration" class="nav-link" data-scroll-target="#causal-vs.-correlational-integration"><span class="header-section-number">19.5.3</span> Causal vs.&nbsp;Correlational Integration</a></li>
  </ul></li>
  <li><a href="#handling-missing-modalities" id="toc-handling-missing-modalities" class="nav-link" data-scroll-target="#handling-missing-modalities"><span class="header-section-number">19.6</span> Handling Missing Modalities</a>
  <ul class="collapse">
  <li><a href="#training-with-incomplete-data" id="toc-training-with-incomplete-data" class="nav-link" data-scroll-target="#training-with-incomplete-data"><span class="header-section-number">19.6.1</span> Training with Incomplete Data</a></li>
  <li><a href="#cross-modal-imputation" id="toc-cross-modal-imputation" class="nav-link" data-scroll-target="#cross-modal-imputation"><span class="header-section-number">19.6.2</span> Cross-Modal Imputation</a></li>
  <li><a href="#zero-shot-cross-modal-transfer" id="toc-zero-shot-cross-modal-transfer" class="nav-link" data-scroll-target="#zero-shot-cross-modal-transfer"><span class="header-section-number">19.6.3</span> Zero-Shot Cross-Modal Transfer</a></li>
  </ul></li>
  <li><a href="#practical-challenges" id="toc-practical-challenges" class="nav-link" data-scroll-target="#practical-challenges"><span class="header-section-number">19.7</span> Practical Challenges</a>
  <ul class="collapse">
  <li><a href="#batch-effects-across-modalities" id="toc-batch-effects-across-modalities" class="nav-link" data-scroll-target="#batch-effects-across-modalities"><span class="header-section-number">19.7.1</span> Batch Effects Across Modalities</a></li>
  <li><a href="#sample-size-and-power" id="toc-sample-size-and-power" class="nav-link" data-scroll-target="#sample-size-and-power"><span class="header-section-number">19.7.2</span> Sample Size and Power</a></li>
  <li><a href="#interpretability-across-modalities" id="toc-interpretability-across-modalities" class="nav-link" data-scroll-target="#interpretability-across-modalities"><span class="header-section-number">19.7.3</span> Interpretability Across Modalities</a></li>
  <li><a href="#evaluation-complexity" id="toc-evaluation-complexity" class="nav-link" data-scroll-target="#evaluation-complexity"><span class="header-section-number">19.7.4</span> Evaluation Complexity</a></li>
  </ul></li>
  <li><a href="#from-integration-to-prediction" id="toc-from-integration-to-prediction" class="nav-link" data-scroll-target="#from-integration-to-prediction"><span class="header-section-number">19.8</span> From Integration to Prediction</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./p4--multi-scale.html">Part IV: Multi-Scale Modeling</a></li><li class="breadcrumb-item"><a href="./p4-ch19-multi-omics.html"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-multi-omics" class="quarto-section-identifier"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Multi-Omics Integration</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>A patient presents with symptoms suggesting an autoimmune condition, but standard genetic testing reveals no pathogenic variants in known disease genes. Transcriptomic profiling shows aberrant expression of inflammatory pathways, methylation analysis indicates hypomethylation at immune regulatory loci, and proteomic data reveals elevated cytokine levels. No single data type provides a diagnosis, yet the pattern across modalities points unmistakably toward systemic lupus erythematosus. This scenario, increasingly common in research hospitals with multi-omics capabilities, illustrates both the promise and the challenge: each molecular layer captures part of the biological story, but the complete narrative emerges only through integration. The central tension of multi-omics modeling is that combining data types should improve prediction, yet naive combination often degrades performance through noise amplification, batch effects, and the curse of dimensionality.</p>
<p>This chapter examines strategies for integrating multiple data types into unified representations. We compare early, intermediate, and late fusion approaches and their tradeoffs for different applications. We survey multi-omics foundation models that learn joint representations across genomics, transcriptomics, proteomics, and other modalities. We extend to clinical integration, where electronic health records, imaging, and molecular data must be combined for patient-level prediction. We develop a systems biology perspective that traces the information cascade from genetic variants through molecular intermediates to clinical phenotypes. Throughout, we address the practical challenges of missing modalities, batch effects, and the gap between multi-omics potential and deployment reality.</p>
<section id="the-limits-of-single-modality-models" class="level2" data-number="19.1">
<h2 data-number="19.1" class="anchored" data-anchor-id="the-limits-of-single-modality-models"><span class="header-section-number">19.1</span> The Limits of Single-Modality Models</h2>
<p>Each molecular layer tells an incomplete story. DNA sequence is static; it encodes potential but not state. A variant’s presence says nothing about whether the gene is expressed, whether the protein is active, or whether the pathway is perturbed. Transcriptomic data captures expression state but misses post-transcriptional regulation, protein modifications, and metabolic flux. Proteomic measurements reveal protein abundance but not necessarily activity or localization. Methylation profiles indicate epigenetic state but require expression data to understand functional consequences.</p>
<p>The incompleteness becomes concrete when modeling complex traits. Genome-wide association studies explain perhaps 10-20% of heritability for most common diseases through identified variants. Adding expression quantitative trait loci (eQTLs) improves fine-mapping by suggesting which variants affect gene expression, but many causal mechanisms operate through splicing, translation, or post-translational modification rather than expression level. Single-cell RNA sequencing reveals cellular heterogeneity invisible to bulk measurements, but the same cell cannot simultaneously undergo RNA-seq and ATAC-seq, forcing computational integration across modalities measured in different cells.</p>
<p>Consider the challenge of predicting drug response. Germline variants in drug-metabolizing enzymes explain some inter-individual variation, but tumor-specific somatic mutations, expression programs, and microenvironment all influence therapeutic efficacy. A genomics-only model sees the inherited component; a transcriptomics-only model sees the current expression state; neither captures the full picture. Multi-omics integration promises to bridge these gaps by learning representations that span molecular layers.</p>
<p>The foundation models examined in preceding chapters address each layer individually: sequence models predict regulatory effects from DNA (<span class="quarto-unresolved-ref">?sec-regulatory-models</span>), expression models capture transcriptional programs (<span class="quarto-unresolved-ref">?sec-transcriptomics</span>), and protein language models predict structure and function from amino acid sequence (<a href="p3-ch12-protein-lm.html" class="quarto-xref"><span>Chapter 12</span></a>). Multi-omics integration asks how these modality-specific representations can be combined into unified patient or cell representations.</p>
<p>The promise comes with caveats. Adding modalities increases the number of parameters that must be estimated, potentially worsening overfitting when sample sizes are limited. Different modalities have different noise characteristics, batch structures, and missingness patterns. The same patient’s measurements across platforms may not align perfectly due to sample handling, timing, or technical variation. Naive concatenation of features often performs worse than single-modality models because the signal-to-noise ratio degrades when noisy features outnumber informative ones.</p>
<p>These challenges motivate careful consideration of integration strategy. The question is not whether to integrate, but how.</p>
</section>
<section id="integration-strategies-and-their-tradeoffs" class="level2" data-number="19.2">
<h2 data-number="19.2" class="anchored" data-anchor-id="integration-strategies-and-their-tradeoffs"><span class="header-section-number">19.2</span> Integration Strategies and Their Tradeoffs</h2>
<p>Three broad strategies have emerged for combining multi-omics data, each with distinct strengths and limitations.</p>
<section id="early-fusion" class="level3" data-number="19.2.1">
<h3 data-number="19.2.1" class="anchored" data-anchor-id="early-fusion"><span class="header-section-number">19.2.1</span> Early Fusion</h3>
<p>Early fusion concatenates features from multiple modalities before any modeling, creating a single high-dimensional input vector that contains genomic variants, expression values, methylation levels, and any other available measurements. A classifier or regressor then learns directly from this concatenated representation.</p>
<p>The appeal of early fusion lies in its simplicity and flexibility. Any downstream model architecture can operate on concatenated features, from linear regression to deep neural networks. The model can learn arbitrary interactions between features from different modalities, since all information is present in the input. Implementation requires only normalization and alignment of features across samples.</p>
<p>The limitations become apparent at scale. Dimensionality explodes when combining genome-wide variants (millions of features), gene expression (tens of thousands of genes), methylation (hundreds of thousands of CpG sites), and protein abundance (thousands of proteins). Most samples have far fewer observations than features, creating severe overfitting risk. Regularization helps but cannot fully compensate when the ratio of features to samples exceeds practical bounds.</p>
<p>Missing data creates additional complications. If any modality is missing for a sample, early fusion requires either excluding that sample (reducing effective sample size) or imputing the missing modality (introducing noise and potential bias). Since multi-omics studies often have incomplete overlap between modalities, with some patients having genomics and transcriptomics but not proteomics, early fusion frequently operates on substantially reduced cohorts.</p>
<p>Scale differences between modalities pose another challenge. Expression values span orders of magnitude; methylation beta values range from zero to one; variant encodings are typically binary. Without careful normalization, modalities with larger variance can dominate the learned representation regardless of biological relevance. Batch effects within each modality add further complexity, since batch correction must precede concatenation but may interact with cross-modal relationships.</p>
<p>Despite these limitations, early fusion remains appropriate when sample sizes are large relative to feature counts, when all modalities are available for all samples, and when the downstream task is well-defined enough to guide feature selection. Biobank-scale studies with thousands of participants and focused feature sets can succeed with early fusion approaches.</p>
</section>
<section id="late-fusion" class="level3" data-number="19.2.2">
<h3 data-number="19.2.2" class="anchored" data-anchor-id="late-fusion"><span class="header-section-number">19.2.2</span> Late Fusion</h3>
<p>Late fusion trains separate models for each modality and combines their predictions at the output level. A genomics model produces a risk score; a transcriptomics model produces another risk score; an ensemble method or meta-learner combines these modality-specific predictions into a final output.</p>
<p>This approach handles missing modalities gracefully. If a patient lacks proteomic data, the proteomics model simply does not contribute to the ensemble. Sample sizes for each modality-specific model can differ, since training requires only samples with that modality rather than complete multi-omics profiles. Each modality can use whatever architecture works best for its data type: deep networks for imaging, gradient boosting for tabular omics, convolutional architectures for sequence.</p>
<p>Late fusion cannot capture cross-modal interactions at the feature level. If a variant’s effect on disease depends on expression level of a regulatory gene, neither the genomics model nor the transcriptomics model alone can detect this interaction. The ensemble sees only the modality-specific predictions, not the underlying features. This limitation is fundamental: late fusion assumes that each modality provides independent signal that can be additively combined.</p>
<p>The assumption of independence often fails in biological systems. Gene expression depends on genetic variants through eQTLs. Protein levels depend on both transcription and post-transcriptional regulation. Methylation states influence and are influenced by transcription. The molecular layers are not independent information sources but coupled components of a dynamic system. Late fusion ignores this coupling.</p>
<p>Calibration presents a practical challenge. For ensemble predictions to be meaningful, the modality-specific models must produce well-calibrated probability estimates. If the genomics model is overconfident and the transcriptomics model is underconfident, naive averaging produces biased predictions. Calibration techniques help but add complexity to the modeling pipeline.</p>
<p>Late fusion works well when modalities genuinely provide independent signals, when sample sizes for each modality differ substantially, or when interpretability requires understanding each modality’s contribution separately. Clinical deployment often favors late fusion because it gracefully handles the reality that not all patients will have all measurements.</p>
</section>
<section id="intermediate-fusion" class="level3" data-number="19.2.3">
<h3 data-number="19.2.3" class="anchored" data-anchor-id="intermediate-fusion"><span class="header-section-number">19.2.3</span> Intermediate Fusion</h3>
<p>Intermediate fusion learns modality-specific encoders that map each data type into a shared latent space, then operates on the aligned representations for downstream tasks. This approach combines the flexibility of early fusion with the robustness of late fusion.</p>
<p>Each modality has its own encoder architecture tailored to its characteristics. A variational autoencoder might encode single-cell expression data, handling sparsity and dropout noise. A convolutional network might process methylation profiles along chromosomal coordinates. A graph neural network might encode protein interaction data. These diverse architectures share nothing except their output dimensionality: all encoders produce embeddings in a common latent space.</p>
<p>Alignment between modalities is encouraged through multiple mechanisms. Reconstruction losses require each encoder’s latent representation to support decoding back to the original features, ensuring that the embeddings retain modality-specific information. Contrastive terms pull together representations of the same biological entity across modalities: the expression embedding for a cell should be similar to the ATAC-seq embedding for the same cell. Graph constraints enforce consistency with known biological relationships: genes connected in interaction networks should have similar embeddings.</p>
<p>The shared latent space enables cross-modal reasoning. A classifier operating on the shared space can learn interactions between genomic and transcriptomic features, since both are present in the same representation. Transfer becomes possible: a model trained on expression data can be applied to samples with only ATAC-seq by encoding through the ATAC-seq encoder into the shared space.</p>
<p>Missing modalities no longer require imputation or exclusion. If a sample lacks proteomics, only the available encoders fire, producing a partial representation in the shared space. The downstream model operates on whatever representation is available, degrading gracefully as modalities are missing rather than failing entirely.</p>
<p>GLUE, introduced in <a href="p4-ch16-single-cell.html" class="quarto-xref"><span>Chapter 16</span></a> for single-cell multi-omics integration, exemplifies this approach. Separate variational autoencoders encode RNA-seq and ATAC-seq data into a shared cell embedding space. A feature graph links ATAC-seq peaks to genes based on genomic proximity and transcription factor binding, providing biological constraints on the alignment. The result enables integration of measurements from different cells, not just different modalities in the same cell.</p>
<p>Intermediate fusion dominates modern multi-omics deep learning because it balances flexibility with robustness. The modality-specific encoders can be pretrained on large single-modality datasets, then fine-tuned for alignment. New modalities can be added by training new encoders without retraining existing components. The shared space provides a natural target for interpretation and visualization.</p>
<p>The approach is not without limitations. The quality of alignment depends heavily on the training objective and the availability of paired samples where multiple modalities are measured in the same biological entity. Without sufficient anchoring, the shared space may fail to capture true biological correspondence. Hyperparameter choices for balancing reconstruction against alignment losses require careful tuning.</p>
</section>
</section>
<section id="multi-omics-foundation-models" class="level2" data-number="19.3">
<h2 data-number="19.3" class="anchored" data-anchor-id="multi-omics-foundation-models"><span class="header-section-number">19.3</span> Multi-Omics Foundation Models</h2>
<p>The foundation model paradigm, introduced in <a href="p3-ch10-fm-principles.html" class="quarto-xref"><span>Chapter 10</span></a>, extends naturally to multi-omics settings. Rather than training task-specific models that integrate modalities for a single downstream application, multi-omics foundation models learn general-purpose representations that transfer across tasks.</p>
<section id="factor-based-integration" class="level3" data-number="19.3.1">
<h3 data-number="19.3.1" class="anchored" data-anchor-id="factor-based-integration"><span class="header-section-number">19.3.1</span> Factor-Based Integration</h3>
<p>Multi-Omics Factor Analysis (MOFA and its successor MOFA+) provides a probabilistic framework for learning shared and modality-specific factors from multi-omics data. The approach assumes that observed measurements across modalities can be explained by a small number of latent factors, some shared across modalities and others specific to individual data types.</p>
<p>MOFA+ extends this framework to handle multiple sample groups (such as different tissues or conditions), non-Gaussian likelihoods appropriate for count data, and scalable inference for large datasets. The factors learned by MOFA+ capture sources of variation that span modalities, enabling biological interpretation: a factor that loads heavily on inflammatory genes in expression data and on hypomethylation at immune loci in methylation data suggests coordinated epigenetic-transcriptional regulation of inflammation.</p>
<p>While MOFA+ is not a deep learning method in the strict sense, its factor-based decomposition provides a foundation for understanding what multi-omics integration should capture. The shared factors correspond to biological processes that manifest across molecular layers; the modality-specific factors capture technical variation or layer-specific biology.</p>
</section>
<section id="deep-generative-multi-omics-models" class="level3" data-number="19.3.2">
<h3 data-number="19.3.2" class="anchored" data-anchor-id="deep-generative-multi-omics-models"><span class="header-section-number">19.3.2</span> Deep Generative Multi-Omics Models</h3>
<p>totalVI (Total Variational Inference) integrates protein abundance from CITE-seq with gene expression in single-cell data through a hierarchical Bayesian model. The approach learns a joint latent space that captures cell state while properly modeling the distinct noise characteristics of RNA and protein measurements. Protein abundance follows a negative binomial distribution with technical factors including background binding; RNA counts follow a zero-inflated negative binomial accounting for dropout.</p>
<p>The generative model structure enables imputation of missing modalities. Given RNA expression alone, totalVI can predict expected protein abundance by sampling from the learned joint distribution. This imputation is not mere correlation-based prediction but reflects the full posterior distribution over protein levels given expression.</p>
<p>MultiVI extends this framework to integrate gene expression with chromatin accessibility. The model learns to align measurements from different cells, enabling construction of unified cell atlases from studies that measured different modalities. The alignment relies on the biological assumption that gene expression and chromatin state reflect the same underlying cell state, even when measured in different cells.</p>
<p>These Bayesian deep generative models exemplify intermediate fusion with principled uncertainty quantification. The posterior distributions over latent variables capture not just point estimates but confidence in the learned representations. This property becomes important for clinical applications where prediction uncertainty must inform decision-making.</p>
</section>
<section id="contrastive-multi-modal-learning" class="level3" data-number="19.3.3">
<h3 data-number="19.3.3" class="anchored" data-anchor-id="contrastive-multi-modal-learning"><span class="header-section-number">19.3.3</span> Contrastive Multi-Modal Learning</h3>
<p>Contrastive learning provides another path to multi-omics integration. The CLIP model for vision-language demonstrated that contrastive objectives can align embeddings from fundamentally different data types (images and text) into a shared space. Similar approaches apply to biological modalities.</p>
<p>The contrastive objective is straightforward: embeddings of the same biological entity across modalities should be similar, while embeddings of different entities should be dissimilar. A cell’s expression embedding should be close to its methylation embedding and far from other cells’ methylation embeddings. A patient’s genomic embedding should be close to their transcriptomic embedding across the cohort.</p>
<p>This objective requires paired samples for training: the same cells or patients measured across modalities. Anchor pairs define the positive examples; negative examples come from non-matching pairs within a batch. The encoders learn to produce embeddings where cross-modal correspondence emerges from training dynamics rather than explicit feature engineering.</p>
<p>Contrastive approaches scale well and can incorporate foundation model encoders pretrained on single modalities. An expression encoder pretrained on millions of cells via masked gene prediction can be fine-tuned with contrastive objectives to align with an ATAC-seq encoder. The pretraining provides rich initial representations; the contrastive fine-tuning establishes cross-modal correspondence.</p>
</section>
</section>
<section id="clinical-integration-ehr-imaging-and-molecular-data" class="level2" data-number="19.4">
<h2 data-number="19.4" class="anchored" data-anchor-id="clinical-integration-ehr-imaging-and-molecular-data"><span class="header-section-number">19.4</span> Clinical Integration: EHR, Imaging, and Molecular Data</h2>
<p>The ultimate goal of multi-omics modeling for many applications is patient-level prediction: disease risk, treatment response, prognosis. Achieving this goal requires integrating molecular measurements with clinical data that directly captures patient state and outcomes.</p>
<section id="electronic-health-records-as-a-modality" class="level3" data-number="19.4.1">
<h3 data-number="19.4.1" class="anchored" data-anchor-id="electronic-health-records-as-a-modality"><span class="header-section-number">19.4.1</span> Electronic Health Records as a Modality</h3>
<p>Electronic health records contain decades of longitudinal observations for millions of patients: diagnoses, procedures, medications, laboratory values, vital signs, clinical notes. This wealth of phenotypic information complements molecular data by capturing disease manifestation rather than molecular mechanism.</p>
<p>Integrating EHR with genomics poses distinct challenges. The data types differ fundamentally: structured codes, continuous lab values, free-text notes, and time-stamped events versus static or slowly-changing molecular measurements. Temporal structure matters: the sequence of diagnoses and treatments contains prognostic information that static snapshots miss. Missingness is informative: the absence of a laboratory test may indicate that a clinician deemed it unnecessary, which itself conveys information about patient state.</p>
<p>Foundation models for EHR data learn representations from the longitudinal event sequences. These models, often based on transformer architectures that process sequences of medical codes, capture temporal dependencies and co-occurrence patterns in clinical trajectories. The resulting patient embeddings encode disease state and prognosis in a form amenable to integration with molecular data.</p>
<p>Combining EHR embeddings with genomic features requires handling the different temporal scales. Genetic variants are constant throughout life; EHR observations accumulate over years. The integration must determine which clinical observations are relevant to a given molecular measurement, accounting for the time between sample collection and clinical events.</p>
</section>
<section id="imaging-integration" class="level3" data-number="19.4.2">
<h3 data-number="19.4.2" class="anchored" data-anchor-id="imaging-integration"><span class="header-section-number">19.4.2</span> Imaging Integration</h3>
<p>Medical imaging provides spatial information that molecular assays lack. A CT scan reveals tumor location, size, and heterogeneity; histopathology slides show cellular morphology and tissue architecture; MRI captures organ structure and function. These spatial data complement molecular measurements that aggregate over dissected tissue regions.</p>
<p>Radiogenomics links imaging features to genetic and molecular characteristics. Glioblastoma tumors with specific imaging signatures have distinct methylation patterns and expression programs. Radiomic features extracted from CT scans correlate with mutational burden and immune infiltration in lung cancer. These associations enable prediction of molecular state from non-invasive imaging, potentially guiding treatment decisions when biopsy is impractical.</p>
<p>Foundation models for medical imaging, pretrained on millions of scans through self-supervised objectives, provide rich representations for downstream tasks. Integrating these imaging embeddings with molecular data follows the intermediate fusion paradigm: modality-specific encoders produce representations in a shared latent space where multi-modal classifiers operate.</p>
<p>The integration must account for correspondence between imaging regions and molecular samples. A tumor may be molecularly heterogeneous, with different subclones in different spatial locations. A biopsy samples one location; imaging captures the entire lesion. Alignment requires either spatial registration of biopsy location to imaging coordinates or acceptance that the correspondence is imperfect.</p>
</section>
<section id="multi-modal-clinical-prediction-models" class="level3" data-number="19.4.3">
<h3 data-number="19.4.3" class="anchored" data-anchor-id="multi-modal-clinical-prediction-models"><span class="header-section-number">19.4.3</span> Multi-Modal Clinical Prediction Models</h3>
<p>Combining EHR, imaging, and molecular data for clinical prediction follows the intermediate fusion pattern. Each data type has a specialized encoder: a transformer for longitudinal EHR events, a vision encoder for imaging, domain-specific encoders for expression, methylation, and other molecular modalities. All encoders produce embeddings in a common patient representation space.</p>
<p>The training objective typically combines modality-specific reconstruction losses with alignment terms that encourage consistency across data types. A patient’s EHR embedding should be predictive of their molecular state; their imaging embedding should be consistent with their clinical trajectory. Downstream classifiers for outcomes like survival, treatment response, or disease progression operate on the combined representation.</p>
<p>Missing modalities are common in clinical settings. Not all patients have genomic data; imaging may be unavailable for some conditions; the depth of EHR history varies by healthcare system and patient engagement. Multi-modal clinical models must handle this missingness gracefully, producing useful predictions from whatever data are available while leveraging cross-modal information when present.</p>
<p>The clinical deployment path for such models requires validation on external cohorts, prospective evaluation, and regulatory clearance. These practical considerations, addressed in <a href="p6-ch25-clinical-risk.html" class="quarto-xref"><span>Chapter 25</span></a>, shape model development from the outset. A model that performs well on a research cohort but requires modalities unavailable in clinical workflows provides little value.</p>
</section>
</section>
<section id="the-systems-view-from-variant-to-phenotype" class="level2" data-number="19.5">
<h2 data-number="19.5" class="anchored" data-anchor-id="the-systems-view-from-variant-to-phenotype"><span class="header-section-number">19.5</span> The Systems View: From Variant to Phenotype</h2>
<p>Multi-omics integration gains conceptual clarity from a systems biology perspective that traces information flow from genetic variation through molecular intermediates to clinical phenotypes. This cascade view organizes the molecular layers into a causal hierarchy and identifies where integration should occur.</p>
<section id="the-information-cascade" class="level3" data-number="19.5.1">
<h3 data-number="19.5.1" class="anchored" data-anchor-id="the-information-cascade"><span class="header-section-number">19.5.1</span> The Information Cascade</h3>
<p>Genetic variants are the starting point: heritable differences in DNA sequence that perturb downstream molecular processes. Some variants directly alter protein structure through missense or nonsense mutations. Others affect regulation: promoter variants change expression level, splice site variants alter transcript isoforms, enhancer variants modulate tissue-specific expression.</p>
<p>These primary effects propagate through molecular layers. Expression changes alter the cellular protein complement. Protein level changes affect enzyme activity, signaling cascades, and transcriptional feedback. Metabolic flux shifts in response to enzyme availability. Cell behavior changes as the integrated molecular state crosses thresholds for proliferation, differentiation, or death.</p>
<p>Tissue-level phenotypes emerge from cellular behavior aggregated across the organ. Tumor growth reflects altered cell proliferation; fibrosis reflects aberrant extracellular matrix deposition; inflammation reflects immune cell recruitment and activation. These tissue phenotypes manifest as clinical symptoms, laboratory abnormalities, and imaging findings.</p>
<p>The cascade view suggests where different modalities provide information. Genomics captures the inherited potential and somatic alterations. Transcriptomics and epigenomics capture the current regulatory state. Proteomics and metabolomics capture the functional molecular complement. Clinical data captures the phenotypic consequences.</p>
</section>
<section id="bottleneck-modalities" class="level3" data-number="19.5.2">
<h3 data-number="19.5.2" class="anchored" data-anchor-id="bottleneck-modalities"><span class="header-section-number">19.5.2</span> Bottleneck Modalities</h3>
<p>Not all modalities are equally informative for all questions. The concept of bottleneck modalities identifies which molecular layers most directly mediate the relationship between genetic variation and phenotype.</p>
<p>For many coding variants, protein structure is the bottleneck. A missense variant’s effect on disease depends primarily on how it alters protein function, which depends on how the amino acid substitution affects folding, stability, and activity. Expression level matters less than structural consequence. Protein language models that predict structural effects from sequence directly address this bottleneck.</p>
<p>For regulatory variants, expression is closer to the bottleneck. An enhancer variant affects disease through its effect on target gene expression, which affects downstream processes. Chromatin accessibility and transcription factor binding are intermediate steps; expression level is the more proximal readout. Models that predict expression effects from sequence address this bottleneck.</p>
<p>For some phenotypes, the bottleneck may lie downstream of molecular measurements entirely. Behavioral traits depend on neural circuit function that emerges from complex cellular and network dynamics. Metabolic traits depend on flux through interconnected pathways that may not be apparent from enzyme abundance alone. These cases suggest that molecular measurements provide incomplete information regardless of integration sophistication.</p>
</section>
<section id="causal-vs.-correlational-integration" class="level3" data-number="19.5.3">
<h3 data-number="19.5.3" class="anchored" data-anchor-id="causal-vs.-correlational-integration"><span class="header-section-number">19.5.3</span> Causal vs.&nbsp;Correlational Integration</h3>
<p>Multi-omics data are pervasively correlated. Genes in the same pathway have correlated expression. Methylation and expression are anti-correlated at many promoters. Clinical variables cluster by disease category. These correlations can improve prediction even without causal understanding.</p>
<p>Causal integration seeks to identify the mechanistic relationships between molecular layers. If a variant causes reduced expression, which causes protein deficiency, which causes metabolic dysfunction, this causal chain suggests intervention targets: expression restoration or enzyme supplementation might address the downstream effects. Correlational integration might achieve the same predictive performance without identifying this chain, since all layers correlate with the phenotype.</p>
<p>Distinguishing causal from correlational relationships requires experimental perturbation or careful causal inference from observational data. Mendelian randomization uses genetic variants as instruments to infer causal effects of expression on outcomes. CRISPR screens directly perturb gene function and measure consequences. Multi-omics integration methods increasingly incorporate causal assumptions or validation against perturbation data.</p>
<p>The distinction matters for interpretation and intervention. A predictive model based on correlations may fail when the data distribution shifts or when interventions alter the causal structure. A causally informed model captures mechanism that persists across contexts.</p>
</section>
</section>
<section id="handling-missing-modalities" class="level2" data-number="19.6">
<h2 data-number="19.6" class="anchored" data-anchor-id="handling-missing-modalities"><span class="header-section-number">19.6</span> Handling Missing Modalities</h2>
<p>Real-world multi-omics data are incomplete. Different studies measure different modalities. Within studies, technical failures, sample limitations, and cost constraints create missing data. Clinical deployment must handle patients with incomplete molecular profiles. Robust multi-omics methods must address missingness directly.</p>
<section id="training-with-incomplete-data" class="level3" data-number="19.6.1">
<h3 data-number="19.6.1" class="anchored" data-anchor-id="training-with-incomplete-data"><span class="header-section-number">19.6.1</span> Training with Incomplete Data</h3>
<p>Intermediate fusion architectures handle missing modalities naturally during inference: only the available encoders contribute to the shared representation. Training is more complex because alignment terms require paired measurements across modalities.</p>
<p>One approach trains on the subset of samples with complete data, then applies the trained encoders to samples with partial data during inference. This wastes information from the samples with incomplete profiles and may learn representations that fail to generalize to the missing-modality setting.</p>
<p>A better approach incorporates missingness into training. Modality dropout randomly masks modalities during training, forcing the model to learn representations robust to missing inputs. The reconstruction and alignment losses are computed only for available modalities, so samples with partial data can still contribute to training.</p>
<p>Curriculum learning strategies may first train with complete data to establish alignment, then gradually increase modality dropout to improve robustness. The balance between alignment quality (which benefits from complete data) and robustness (which requires training on partial data) requires empirical tuning.</p>
</section>
<section id="cross-modal-imputation" class="level3" data-number="19.6.2">
<h3 data-number="19.6.2" class="anchored" data-anchor-id="cross-modal-imputation"><span class="header-section-number">19.6.2</span> Cross-Modal Imputation</h3>
<p>Intermediate fusion enables principled imputation of missing modalities. Given a sample’s available modalities encoded into the shared latent space, decoders for missing modalities can predict expected values. If a patient has expression data but not methylation, the expression encoder produces a latent embedding, and the methylation decoder generates predicted methylation values from that embedding.</p>
<p>The imputation quality depends on how well the shared space captures the biological factors underlying both modalities. If expression and methylation reflect the same cell state, the imputation may be accurate. If they capture distinct aspects of biology, imputation will smooth over true variation.</p>
<p>Uncertainty in imputation matters for downstream use. Point estimates of missing values provide no indication of confidence. Generative models that produce distributions over missing values enable propagation of uncertainty through downstream analyses. A risk prediction that depends heavily on imputed values should have wider confidence intervals than one based entirely on measured data.</p>
</section>
<section id="zero-shot-cross-modal-transfer" class="level3" data-number="19.6.3">
<h3 data-number="19.6.3" class="anchored" data-anchor-id="zero-shot-cross-modal-transfer"><span class="header-section-number">19.6.3</span> Zero-Shot Cross-Modal Transfer</h3>
<p>The most ambitious application of multi-omics integration is zero-shot prediction across modalities: using a model trained on one set of modalities to make predictions for samples measured with entirely different modalities.</p>
<p>This transfer relies on the shared latent space capturing biological state independently of measurement modality. If the space truly represents cell state, then a classifier trained on expression-derived embeddings should work on ATAC-seq-derived embeddings, since both encoders map to the same biological meaning. The alignment training enables this transfer by ensuring that the same biological entity maps to the same latent location regardless of which modality was measured.</p>
<p>Zero-shot transfer is rarely perfect. The modalities may capture somewhat different aspects of biology, and the alignment may be imprecise. But partial transfer can still be valuable: a model achieving 80% of supervised performance without any labeled examples in the new modality saves substantial annotation effort.</p>
</section>
</section>
<section id="practical-challenges" class="level2" data-number="19.7">
<h2 data-number="19.7" class="anchored" data-anchor-id="practical-challenges"><span class="header-section-number">19.7</span> Practical Challenges</h2>
<section id="batch-effects-across-modalities" class="level3" data-number="19.7.1">
<h3 data-number="19.7.1" class="anchored" data-anchor-id="batch-effects-across-modalities"><span class="header-section-number">19.7.1</span> Batch Effects Across Modalities</h3>
<p>Batch effects, systematic technical variation between experimental batches, are endemic in high-throughput biology. Multi-omics integration faces compounded batch effects: each modality may have its own batch structure, batches may be correlated or anti-correlated across modalities, and batch correction methods designed for single modalities may not extend to multi-modal settings.</p>
<p>Consider a study where expression data were generated at three sequencing centers and proteomics data were generated at two mass spectrometry facilities. The batch effects in each modality are independent. Samples from expression batch 1 are spread across proteomics batches. Correcting expression batch effects does not address proteomics batch effects, and vice versa.</p>
<p>Integration must either correct batch effects within each modality before combining (risking removal of real biology that correlates with batch) or incorporate batch as a covariate in the integrated model (requiring that batch structure be known and modeled correctly). Domain adaptation techniques treat batches as domains and learn representations invariant to domain while retaining biological signal.</p>
</section>
<section id="sample-size-and-power" class="level3" data-number="19.7.2">
<h3 data-number="19.7.2" class="anchored" data-anchor-id="sample-size-and-power"><span class="header-section-number">19.7.2</span> Sample Size and Power</h3>
<p>Multi-omics studies typically have smaller sample sizes than single-modality studies due to cost constraints. Each additional modality increases per-sample cost, trading breadth for depth. This tradeoff has implications for statistical power and model complexity.</p>
<p>The effective sample size for multi-omics integration may be smaller than for any single modality. If 1000 patients have expression data and 800 have methylation data but only 600 have both, intermediate fusion sees 600 fully informative samples. Late fusion can use all 1000 expression samples and all 800 methylation samples, avoiding the intersection penalty.</p>
<p>Power analyses for multi-omics studies must account for the specific integration strategy and the expected missingness pattern. A study designed for early fusion needs larger sample sizes (relative to feature count) than one designed for late fusion. Grant applications and study planning should explicitly consider how integration choices affect required sample sizes.</p>
</section>
<section id="interpretability-across-modalities" class="level3" data-number="19.7.3">
<h3 data-number="19.7.3" class="anchored" data-anchor-id="interpretability-across-modalities"><span class="header-section-number">19.7.3</span> Interpretability Across Modalities</h3>
<p>Multi-omics models compound the interpretability challenges inherent in deep learning. When a model predicts disease risk from integrated genomic, transcriptomic, and proteomic features, clinicians need to understand which modalities and which features drive the prediction. A black-box risk score, however accurate, provides little guidance for understanding mechanism or identifying intervention targets.</p>
<p>Attribution methods that work for single-modality models do not automatically extend to multi-modal settings. Gradient-based attribution can identify important features within each modality, but comparing importance across modalities requires careful normalization. A genomic variant and an expression value operate on different scales with different effect size distributions; raw attribution scores are not directly comparable.</p>
<p>The intermediate fusion architecture offers some interpretability advantages. The shared latent space can be visualized to understand how samples cluster and which modalities contribute to separation. Attention weights in cross-modal transformers indicate which features from each modality the model considers when making predictions. Modality ablation studies quantify each data type’s contribution to overall performance.</p>
<p>Biological interpretability requires connecting learned representations to known biology. Do the latent dimensions correspond to pathways, cell types, or disease processes? Are cross-modal attention patterns consistent with known regulatory relationships? These questions demand validation against external biological knowledge, not just introspection of model parameters. The interpretability methods developed in <a href="p5-ch24-interpretability.html" class="quarto-xref"><span>Chapter 24</span></a> provide starting points, but multi-modal settings require extensions that account for the distinct semantics and scales of each data type.</p>
</section>
<section id="evaluation-complexity" class="level3" data-number="19.7.4">
<h3 data-number="19.7.4" class="anchored" data-anchor-id="evaluation-complexity"><span class="header-section-number">19.7.4</span> Evaluation Complexity</h3>
<p>Evaluating multi-omics models is more complex than evaluating single-modality models. Multiple dimensions of performance matter: prediction accuracy, calibration, cross-modality transfer, robustness to missing modalities, biological plausibility of learned representations, and clinical utility.</p>
<p>A model might achieve high prediction accuracy by memorizing batch effects or leveraging shortcuts in the data. Evaluation should include cross-batch and cross-cohort validation to assess generalization. Ablation studies that remove each modality quantify the contribution of each data type and identify whether the model genuinely integrates information or relies predominantly on one modality.</p>
<p>Biological validation through comparison to known biology provides another evaluation axis. Do the learned factors correspond to known pathways? Are attention patterns consistent with regulatory relationships? Do imputed values match held-out measurements? These checks assess whether the model captures biological signal rather than technical artifacts. The evaluation frameworks for multi-modal models, including strategies for ablation studies, calibration assessment, and cross-cohort validation, are developed systematically in <span class="quarto-unresolved-ref">?sec-evaluation</span>.</p>
<p>Clinical evaluation, addressed in <a href="p6-ch25-clinical-risk.html" class="quarto-xref"><span>Chapter 25</span></a>, requires prospective validation in real deployment settings. A model that improves prediction in research cohorts may not improve clinical decisions if the predictions do not change management or if the required modalities are unavailable in clinical workflows.</p>
</section>
</section>
<section id="from-integration-to-prediction" class="level2" data-number="19.8">
<h2 data-number="19.8" class="anchored" data-anchor-id="from-integration-to-prediction"><span class="header-section-number">19.8</span> From Integration to Prediction</h2>
<p>Multi-omics integration is not an end in itself but a means to improved prediction, understanding, and intervention. The integration strategies and foundation models surveyed here provide representations; downstream models convert representations to actionable outputs.</p>
<p>Risk prediction combines multi-omic embeddings with clinical variables for individualized prognosis. Treatment response models predict which patients will benefit from specific therapies based on their integrated molecular profiles. These capabilities extend beyond individual patient care to drug discovery, where multi-omics integration informs target identification, patient stratification for clinical trials, and prediction of drug response across populations (<a href="p6-ch27-drug-discovery.html" class="quarto-xref"><span>Chapter 27</span></a>). Biomarker discovery identifies features that discriminate conditions or predict outcomes, potentially revealing new biology or therapeutic targets.</p>
<p>The systems view shapes how these predictions should be interpreted. A risk prediction based on multi-omics features inherits explanatory power from the causal structure relating molecular layers to phenotypes. Understanding which modalities drive predictions, and how they relate to underlying biology, supports clinical reasoning and identifies potential interventions.</p>
<p>The path from research models to clinical deployment, examined in <a href="p6-ch25-clinical-risk.html" class="quarto-xref"><span>Chapter 25</span></a> and <a href="p6-ch26-rare-disease.html" class="quarto-xref"><span>Chapter 26</span></a>, requires addressing the practical challenges discussed here: batch effects, missing modalities, sample size limitations, and evaluation complexity. Multi-omics integration offers richer patient characterization than any single modality, but realizing this promise requires careful attention to the realities of clinical data and deployment constraints.</p>
<p>As the field advances toward whole-patient foundation models that jointly encode genomics, transcriptomics, proteomics, imaging, and clinical data, the integration principles established here provide the foundation. The tradeoffs between fusion strategies, the importance of shared latent spaces, the challenge of missing modalities, and the systems biology perspective on information flow will remain relevant as the scale and scope of integration expand.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./p4-ch18-networks.html" class="pagination-link" aria-label="Gap Analysis: Chapter 18 Networks and Graph-Based Reasoning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Gap Analysis: Chapter 18 Networks and Graph-Based Reasoning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./p5--eval-interp.html" class="pagination-link" aria-label="Part V: Evaluation and Reliability">
        <span class="nav-page-text">Part V: Evaluation and Reliability</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, Josh Meehl</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>