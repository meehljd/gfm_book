::: {.callout-warning .content-visible when-profile="draft"}
**TODO:**

- Add visual: Flowchart of WGS/WES pipeline highlighting variant prioritization stage
- Add visual: Contrastive diagram showing proxy-neutral vs proxy-deleterious distributions
- Add visual: Table/panel of feature groups with example features and sources
- Add visual: PHRED scale transformation with annotated thresholds
- Add visual: CADD v1.7 schematic showing classical and deep learning features
- Add visual: Multi-panel benchmarking figure (ROC curves, allele frequency correlation, circularity cartoon)
- Add visual: Timeline placing CADD alongside deep learning models

- FORMAT: Add bullets, numbers where appropriate to show clear structure.
:::


# Deleteriousness Scores {#sec-cadd}

## The Variant Prioritization Challenge

A typical human genome contains approximately four to five million genetic variants relative to the reference assembly, encompassing single-nucleotide variants and short insertions and deletions. The vast majority of these are functionally neutral, representing the accumulated diversity of human evolution and population history. For any individual with a suspected genetic condition, the central interpretive challenge is to identify the handful of variants that plausibly contribute to disease from this enormous background of benign variation. This challenge of variant prioritization stands at the heart of clinical genomics: given a long list of candidate variants from exome or genome sequencing, which ones deserve experimental follow-up or clinical attention?

The data resources surveyed in @sec-data provide multiple complementary views of variant function, each with distinct strengths and limitations. Population frequency databases such as gnomAD reveal which variants survive in large cohorts of ostensibly healthy individuals, offering a powerful filter for identifying rare, potentially deleterious alleles [@gnomAD]. Functional genomics consortia including ENCODE and the Roadmap Epigenomics Project indicate which genomic regions show evidence of biochemical activity across diverse cell types and developmental contexts. Clinical databases such as ClinVar and HGMD collect expert-curated variant classifications drawn from case reports and diagnostic laboratories, providing ground truth labels for known pathogenic and benign variants.

Each of these sources is partial in important ways. Population databases are dominated by common variants, which are mostly tolerated by virtue of their high frequency. Rare and de novo variants, which are often most relevant for Mendelian disease, have sparse or no direct labels. Functional genomics data is inherently noisy and often context-specific: a region active in liver hepatocytes may be quiescent in neurons, and vice versa. Clinical databases are sparse and heavily biased toward well-studied genes and variant types, leaving vast swaths of the genome without reliable clinical annotations. The annotation density varies dramatically across the genome, with protein-coding exons densely labeled relative to deep intronic and intergenic sequences. Non-coding regions remain especially under-annotated despite harboring the majority of disease-associated variants identified by genome-wide association studies.

Before deep learning, variant effect predictors typically tackled this problem by focusing on one narrow signal. Conservation-based methods such as phyloP and GERP score each position according to its evolutionary constraint across multi-species alignments, under the logic that positions conserved over hundreds of millions of years are likely functionally important [@siepel_phastcons_2005; @davydov_gerp_2010]. Protein-level tools such as SIFT and PolyPhen predict the impact of amino acid substitutions based on sequence homology, physicochemical properties, and structural features [@ng_sift_2003; @adzhubei_polyphen_2010]. Positional annotations capture simple features like distance to splice sites or proximity to known regulatory elements. Each of these approaches captures a real biological signal, but each is also incomplete: conservation scores miss recently evolved functional elements, protein-level tools are blind to non-coding variants, and positional annotations lack the resolution to distinguish causal variants from linked neutral neighbors. Moreover, these early tools were limited in scope (primarily addressing missense single-nucleotide variants), built around relatively small feature sets, and trained on relatively modest numbers of labeled variants.

Combined Annotation-Dependent Depletion (CADD) represented a fundamental shift in this landscape [@kircher_general_2014; @rentzsch_cadd_2019]. Rather than relying on a single predictive signal, CADD defined a general framework for genome-wide variant prioritization that integrates dozens of heterogeneous annotations and uses evolutionary depletion as a proxy training label. The key insight was to avoid training directly on small sets of known pathogenic versus benign variants, which are scarce and biased toward certain genes and variant types. Instead, CADD contrasts variants that have survived purifying selection in the human lineage with matched simulated variants that could have occurred but did not. This evolutionary proxy strategy yields an enormous training set, enables genome-wide coverage, and produces scores that generalize across coding and non-coding regions alike.

This chapter focuses on the CADD framework because it establishes design patterns that recur throughout the deep learning models covered in subsequent chapters: proxy labels derived from evolutionary signals, large-scale training on millions of examples, integration of diverse features into unified scores, and genome-wide precomputation for downstream reuse.


## The Evolutionary Proxy Training Strategy

CADD's most important conceptual contribution was to reframe variant effect prediction as a large-scale machine learning problem with labels derived from evolutionary signal rather than clinical curation. A major obstacle to training a supervised variant effect predictor is the lack of gold-standard labels at scale. The scarcity and bias of known pathogenic variants has long limited supervised approaches to variant interpretation. ClinVar and similar databases contain tens of thousands of labeled variants, but these are concentrated in a small fraction of genes, skewed toward certain variant types (nonsense, frameshift, canonical splice site), and subject to ascertainment bias from clinical referral patterns. Truly benign variants are hard to certify, and truly pathogenic variants are rare and often context dependent. Training directly on such labels tends to produce models that perform well on variants similar to the training set but generalize poorly to the broader genome.

Rather than relying solely on curated clinical labels, CADD uses evolution as a weak supervisory signal, constructing two proxy classes of variants [@kircher_general_2014; @rentzsch_cadd_2019]. The proxy-neutral class consists of variants that have been tolerated by purifying selection, while the proxy-deleterious class represents hypothetical mutations that could arise but are not observed. This design converts the question "How pathogenic is this variant?" into a closely related question: "Does this variant resemble mutations that are depleted by selection?"

### Proxy-Neutral Variants

The proxy-neutral class is built from variants that appear to have survived long-term purifying selection. CADD draws these from sequence differences that arose on the human lineage since the split from chimpanzees and became fixed or nearly fixed in modern humans [@kircher_general_2014; @rentzsch_cadd_2019]. These derived human alleles are present at very high frequency in human populations, yet absent from the inferred human-chimp ancestral sequence. Because they have persisted over millions of years of evolution, most are presumed to be neutral or only weakly deleterious. They are distributed broadly across coding and non-coding regions, capturing a wide range of functional contexts.

This is not a perfect proxy for benign variants. Some observed alleles are genuinely pathogenic, particularly those with incomplete penetrance, late onset, or context-dependent effects. Variants under weak negative selection may persist at low to moderate frequencies for thousands of generations before eventual elimination. Population-specific bottlenecks and founder effects can elevate the frequency of otherwise deleterious alleles in particular groups. Despite these caveats, the proxy-neutral class is, on average, substantially enriched for tolerated alleles relative to a random sample of possible mutations. The key statistical insight is that systematic enrichment, even if imperfect at the individual variant level, provides a useful training signal when aggregated across millions of examples.

### Proxy-Deleterious Variants

The proxy-deleterious class is constructed by simulating mutations across the genome according to realistic mutational processes rather than through direct observation [@kircher_general_2014; @rentzsch_cadd_2019]. The simulation matches local sequence context, typically using trinucleotide frequencies to capture the strong dependence of mutation rates on the identity of flanking bases. CpG dinucleotides, for example, have elevated mutation rates due to spontaneous deamination of methylated cytosines, and the simulation accounts for this by generating more CpG transitions in the proxy-deleterious set. Regional variation in mutation rates, driven by factors including replication timing, chromatin state, and local sequence composition, is similarly incorporated by scaling mutation counts within genomic windows. The simulator also adjusts for local substitution frequencies and indel length distributions inferred from the proxy-neutral set.

The logic underlying this construction is subtle but powerful. Simulated variants represent changes that could plausibly occur under human mutational processes but are generally not observed at high frequency in population databases. Many of these simulated variants would in fact be neutral if they were to arise; the simulation makes no attempt to identify truly deleterious mutations at the individual level. However, the proxy-deleterious class as a whole is enriched for alleles that are disfavored by selection, because the set of possible mutations includes many that disrupt conserved elements, alter protein function, or perturb regulatory sequences. By contrasting this set with the proxy-neutral class, CADD learns to recognize the annotation signatures that distinguish variants under purifying selection from those that have been tolerated.

### Training Objective

With proxy-neutral and proxy-deleterious classes in hand, CADD trains a binary classifier to distinguish between them [@kircher_general_2014; @rentzsch_cadd_2019]. The input to this classifier is a feature vector describing each variant, encompassing the diverse annotations surveyed in the following section: gene model features, conservation scores, epigenetic signals, protein-level predictions, and more. The label is simply whether the variant was simulated (proxy-deleterious) or observed (proxy-neutral). The objective is straightforward: learn a decision function that separates these two classes as well as possible, assigning higher values to simulated variants and reflecting their predicted deleteriousness.

Early CADD versions employed linear support vector machines trained on approximately 30 million simulated versus observed variants with 63 annotation features plus selected interaction terms [@rentzsch_cadd_2019]. This relatively simple architecture was sufficient to capture the main structure of the problem, in part because the features themselves encode substantial biological knowledge. Later versions, including CADD v1.7, employ logistic regression-style models with expanded feature sets, retaining the same fundamental paradigm of contrasting simulated and observed variants while accommodating richer annotations [@schubach_cadd_2024].

This evolutionary depletion framework is conceptually related to contrastive learning: the model learns a representation of variants that maximally distinguishes those that evolution has accepted from those it has not. Unlike modern self-supervised contrastive objectives, CADD uses a fixed set of hand-engineered features and a linear classifier, and the labels are derived from evolutionary simulations rather than augmentations of the same underlying data. The training set is extremely large, enabling complex decision boundaries and robust generalization. The resulting scores are precomputed genome-wide and reused for diverse downstream tasks, from rare disease gene discovery to variant filtration pipelines to evaluation baselines for newer models. In this sense, CADD can be understood as an early example of pretraining on a large-scale proxy task followed by transfer to clinical applications, a pattern that defines modern foundation models.


## Integration of Diverse Annotations

CADD's second conceptual pillar is the integration of many weak, noisy annotations into a single composite score. Where earlier variant effect predictors typically relied on one or a few signals, CADD combines more than 60 features in its original incarnation and substantially more in version 1.7 [@kircher_general_2014; @rentzsch_cadd_2019; @schubach_cadd_2024]. This integrative approach recognizes that no single annotation captures the full complexity of variant function. Conservation scores miss recently evolved functional elements. Protein-level predictions are uninformative for non-coding variants. Regulatory annotations are noisy and incomplete. By learning optimal weights for combining these diverse signals, CADD achieves performance that exceeds any individual component.

Because @sec-data already surveys the underlying data resources in detail, this section focuses on the categories of features and how they function within the CADD framework. For specifics on individual databases such as ENCODE, Roadmap, gnomAD, and ClinVar, readers should consult the earlier chapter.

### Gene Model Annotations

Gene model annotations describe the local transcript and coding context of each variant. The most fundamental is the predicted sequence consequence: whether a variant is synonymous, missense, nonsense, frameshift, splice-site disrupting, or located in untranslated or intronic regions. These consequence categories capture qualitatively different modes of disruption, from silent changes that preserve protein sequence to truncating mutations that eliminate large portions of the gene product.

Beyond simple consequence, CADD incorporates positional features such as distance to exon-intron boundaries and proximity to canonical splice sites. Variants near splice junctions have elevated potential to disrupt splicing even if they do not directly alter the canonical GT-AG dinucleotides. Distance to the start and stop codons provides additional context, as does the position within the reading frame for coding variants.

Gene-level attributes further enrich the annotation set. Constraint metrics derived from population data, such as the probability of loss-of-function intolerance (pLI) and the loss-of-function observed/expected upper bound fraction (LOEUF), quantify how tolerant each gene is to damaging variation [@gnomAD]. Variants in highly constrained genes receive elevated deleteriousness scores, reflecting the empirical observation that such genes are enriched for disease associations. Known disease gene status from OMIM and similar resources provides complementary information about genes with established pathogenic roles.

For amino acid-changing variants, CADD includes protein-level features beyond simple consequence. Predicted impact on coding sequence from tools such as SIFT and PolyPhen-2 provides established assessments of whether substitutions are likely damaging [@ng_sift_2003; @adzhubei_polyphen_2010]. Amino acid physicochemical properties, including size, charge, hydrophobicity, and polarity, inform predictions about whether a substitution is conservative or radical. Grantham distances quantify the biochemical dissimilarity between amino acid pairs, while secondary structure and domain annotations from databases like Pfam provide structural context.

These gene model features allow CADD to make biologically meaningful distinctions. A synonymous variant in a tolerant gene with high LOEUF receives a very different score than a truncating variant in a highly constrained developmental regulator. The model learns these distinctions from the differential representation of variant types across the proxy-neutral and proxy-deleterious training classes.

### Conservation and Constraint

Evolutionary conservation provides some of the strongest signals for variant deleteriousness, particularly in non-coding regions where direct functional labels are scarce. CADD incorporates multiple conservation metrics computed from multi-species alignments spanning mammals, vertebrates, and more distant taxa.

Base-level conservation scores such as GERP (Genomic Evolutionary Rate Profiling) and phyloP quantify the deviation of observed substitution rates from neutral expectation [@davydov_gerp_2010; @siepel_phastcons_2005]. Positions with strong negative GERP scores show substitution rates far below neutral, indicating purifying selection has maintained these bases across tens or hundreds of millions of years of evolution. PhastCons provides a complementary view by identifying conserved elements, contiguous regions with elevated conservation that likely correspond to functional units. PhyloP scores individual positions without the smoothing implicit in element-based approaches, capturing both conservation (slow evolution) and acceleration (fast evolution) relative to neutral models.

Regional measures of constraint complement base-level scores. These capture broader patterns of evolutionary pressure that may not be evident at single positions but emerge when considering larger windows. Measures of regional intolerance to variation derived from population datasets, such as gene- or exon-level constraint from gnomAD, add further context [@gnomAD]. Mutation rate estimates, derived from substitution patterns in presumably neutral regions such as ancestral repeats, allow the model to distinguish true constraint from low mutation rate.

Conservation features are particularly valuable for non-coding variant interpretation, where biochemical annotations are often incomplete or absent. A deeply conserved non-coding position is likely functional even if no enhancer or promoter annotation overlaps it. Conversely, lack of conservation provides evidence (though not proof) that a position is tolerant to variation.

### Epigenetic and Regulatory Activity

CADD incorporates regulatory annotations derived from functional genomics assays to capture the chromatin and regulatory context of each variant. These features draw primarily from large-scale consortium efforts including ENCODE and the Roadmap Epigenomics Project, which have profiled chromatin accessibility, histone modifications, and transcription factor binding across hundreds of cell types and tissues.

DNase I hypersensitivity and ATAC-seq peaks identify regions of open chromatin, marking active regulatory elements including promoters, enhancers, and insulators. ChIP-seq signals for histone modifications provide additional context: H3K4me3 marks active promoters, H3K27ac marks active enhancers, H3K36me3 spans transcribed gene bodies, and H3K27me3 marks polycomb-repressed regions. Transcription factor ChIP-seq directly identifies binding sites for specific regulators, though coverage varies considerably across factors and cell types.

Chromatin state segmentations integrate multiple histone marks and accessibility signals into discrete functional categories. These segmentations, produced by algorithms such as ChromHMM, assign each genomic position to states like "active promoter," "strong enhancer," "weak enhancer," "transcribed region," or "heterochromatin." By including these aggregate states alongside raw signals, CADD can capture combinatorial patterns that distinguish functional regulatory elements from background.

These epigenomic features help prioritize non-coding variants that disrupt active regulatory regions. A variant falling within an active enhancer marked by H3K27ac and DNase hypersensitivity in a relevant tissue receives elevated deleteriousness scores, even if its conservation is modest. The tissue specificity of regulatory annotations presents both opportunity and challenge: a variant may be highly consequential in one cellular context while neutral in another, and CADD's genome-wide scores necessarily average across this heterogeneity.

### Additional Features

Beyond the major annotation categories, CADD incorporates features capturing local sequence context and genomic architecture. GC content and CpG dinucleotide density affect mutation rates, chromatin structure, and gene regulation. Segmental duplications and low-complexity regions flag positions where mapping uncertainty may confound variant calls or where duplicated sequences complicate interpretation. Distance to transcription start sites, polyadenylation signals, telomeres, and centromeres provides coarse chromosomal and genic context. Regional recombination rates and other genomic descriptors round out the feature set.

Not every individual annotation is informative in isolation. Many features are noisy, incomplete, or redundant with one another. The power of CADD lies in learning how to weight and combine these heterogeneous signals, up-weighting annotations that distinguish proxy-deleterious from proxy-neutral variants and down-weighting those that do not. This learned integration is more powerful than any manually specified combination rule and adapts automatically as new features are added in subsequent versions.

From the perspective of this book, these features exemplify classic feature engineering: human experts select and pre-compute biologically meaningful quantities, which are then passed to a general-purpose machine learning algorithm. The transition to deep learning, explored in subsequent chapters, shifts much of this burden from manual feature design to learned representations, though as we will see with CADD v1.7, the two approaches can be productively combined.


## Model Architecture and Scoring

### Machine Learning Framework

CADD's classifier operates on a high-dimensional feature vector assembled for each variant. The input representation concatenates all annotations described in the previous section: gene model features, conservation scores, epigenomic signals, sequence context, and protein-level predictions where applicable. For a typical variant, this yields a vector of several dozen to over a hundred features, depending on the CADD version and whether the variant falls in coding or non-coding sequence.

The original CADD model uses a linear support vector machine trained to discriminate proxy-neutral and proxy-deleterious variants based on the annotation vector [@kircher_general_2014; @rentzsch_cadd_2019]. The choice of a linear model was deliberate and reflects pragmatic considerations. With tens of millions of training examples and dozens of features, a linear SVM is computationally tractable while still capturing the main structure of the classification problem. Many features are correlated, and a linear model with appropriate regularization can nonetheless capture a useful decision boundary. The linearity also provides some interpretability, as feature weights indicate which annotations most strongly distinguish the proxy classes.

In CADD v1.7, the framework transitions to a logistic regression-style model with an expanded annotation set exceeding 100 features [@schubach_cadd_2024]. The fundamental paradigm remains unchanged: contrast simulated and observed variants using a discriminative classifier. The logistic formulation provides well-calibrated probability estimates that facilitate downstream score transformations, while the expanded feature set incorporates new annotations including protein language model scores and regulatory CNN predictions discussed in the following section.

Conceptually, the classifier learns a scoring function such that large positive values indicate variants whose annotation profiles resemble the proxy-deleterious class, while large negative values indicate profiles resembling the proxy-neutral class. Variants with intermediate scores occupy an ambiguous middle ground where the annotation evidence does not clearly favor either class. The raw output of this classifier is often referred to as the C-score or raw CADD score.

### PHRED-Scaled Scores

Raw CADD scores are not directly interpretable as probabilities or biological effect sizes. The scale depends on model architecture, feature normalization, and training set composition, all of which vary across CADD versions. To provide a more intuitive and stable scoring system, CADD defines PHRED-like scaled scores based on the rank of each variant among all possible single-nucleotide substitutions in the reference genome [@rentzsch_cadd_2019; @schubach_cadd_2024].

The PHRED scaling follows the same logarithmic convention used in sequencing quality scores. A scaled score of 10 indicates that a variant falls in the top 10% of predicted deleteriousness among all possible substitutions. A score of 20 indicates the top 1%, and a score of 30 indicates the top 0.1%. More generally, a scaled score of n corresponds to the top 10^(-n/10) fraction of the deleteriousness distribution. This transformation compresses the raw scores into a 1-99 range that reflects percentile rank rather than absolute effect size.

This rank-based transformation has several practical consequences. First, it provides a simple interpretation: users can immediately understand that a variant with scaled score 20 is predicted to be more deleterious than 99% of possible substitutions. Second, it ensures comparability across CADD versions. Because the scaled score is defined relative to the full distribution of possible variants, a score of 20 always means "top 1%" even as the underlying model, features, and raw score distributions change between releases. Third, it facilitates direct comparison of scores between variants in different regions. Fourth, it sacrifices resolution in the bulk of the distribution. Most variants are predicted to be relatively benign, and these cluster in the low-score range where differences are difficult to interpret. The scaling concentrates dynamic range in the high-score tail where clinical interpretation typically focuses.

In rare disease pipelines, CADD scaled scores are commonly used as filters to enrich for potentially pathogenic variants before detailed interpretation. Typical thresholds range from 15 (top 3%) to 20 (top 1%) or higher, depending on the stringency required and the downstream analysis workflow. Variants with CADD scores of 20 or above are often considered moderately high deleteriousness candidates, while scores at or above 30 are frequently interpreted as strongly enriched for functional impact. These filters are not intended as definitive pathogenicity calls but rather as prioritization tools that reduce the variant burden to a manageable number for expert review. The thresholds remain heuristic and context-dependent; downstream interpretation should incorporate phenotype, segregation, and other lines of evidence.


## CADD v1.7: Integration of Deep Learning Predictions

CADD v1.7 demonstrates how the original annotation-integration framework naturally accommodates deep learning outputs and modern sequence models [@schubach_cadd_2024]. Rather than replacing CADD's architecture with an end-to-end neural network, the developers adopted a pragmatic strategy: treat deep learning predictions as additional features within the existing integrative framework. This approach preserves CADD's interpretable structure while benefiting from the representational power of large pretrained models. Broadly, CADD v1.7 adds three major categories of features: protein language model scores for coding variants, sequence-based CNN regulatory predictions for non-coding variants, and extended conservation scores from the Zoonomia consortium.

### Protein Language Model Features

For protein-coding variants, CADD v1.7 integrates variant effect scores from protein language models, particularly ESM-1v [@meier_esm-1v_2021; @schubach_cadd_2024]. These models represent a paradigm shift in protein sequence analysis. Trained self-supervised on hundreds of millions of protein sequences using masked language modeling objectives, PLMs learn contextual embeddings that capture the evolutionary constraints and functional requirements shaping protein sequences. The resulting representations encode information about secondary structure, domain boundaries, binding interfaces, and catalytic sites without explicit supervision on any of these properties.

ESM-1v provides per-variant scores by comparing the log-likelihood of the reference and alternate amino acids at each position. Positions where the model confidently predicts the reference residue and assigns low probability to the alternate receive large effect scores, indicating the substitution violates learned sequence constraints. A large drop in likelihood suggests that the mutant is less compatible with the evolutionary sequence distribution learned by the model and is therefore more likely to be functionally disruptive. These scores correlate strongly with experimental measurements of variant effects from deep mutational scanning assays, demonstrating that PLMs capture genuine functional information [@notin_proteingym_2023].

By embedding ESM-1v-derived features into its annotation set, CADD v1.7 effectively delegates part of the representation learning to a large foundational protein model, then uses its own classifier to recalibrate and integrate these signals with other annotations. This division of labor plays to each model's strengths: the PLM learns rich sequence representations from massive protein databases, while CADD's integrative framework combines these representations with genomic context, conservation, and regulatory features that protein-only models cannot access. The result is access to rich protein context, including implicit structure, dynamics, and interaction information, that classical missense predictors cannot fully capture.

### Regulatory CNN Predictions

For non-coding variants, CADD v1.7 incorporates regulatory variant effect predictions from sequence-based convolutional neural networks trained on chromatin accessibility and related assays [@zhou_deepsea_2015; @schubach_cadd_2024]. These CNNs, exemplified by DeepSEA and similar architectures covered in Chapters 5 and 6, take raw DNA sequence as input and predict a battery of chromatin features including transcription factor binding, histone modifications, and DNase hypersensitivity across diverse cell types.

The variant effect predictions are computed as delta scores: the difference in predicted regulatory activity between reference and alternate alleles. Large magnitude deltas indicate variants predicted to substantially alter local chromatin state or transcription factor occupancy. These predictions provide a learned, sequence-based view of regulatory impact that complements the annotation-based epigenomic features derived from experimental data.

Although full-scale models like Enformer can predict a broad spectrum of regulatory readouts from large sequence contexts, their computational cost makes genome-wide integration challenging. CADD v1.7 instead uses smaller CNNs trained specifically on open-chromatin data, chosen to approximate Enformer-level performance on regulatory variant benchmarks while remaining tractable to run at scale. From CADD's perspective, these CNN outputs are simply additional features: for each variant, the model receives summary statistics describing the predicted impact on regulatory activity in different cell types.

By incorporating CNN-derived regulatory predictions, CADD v1.7 uses early sequence-to-function deep learning models as feature generators within its broader integrative framework. This represents an important architectural pattern that recurs throughout genomic deep learning: pretrained sequence models provide representations or predictions that are then combined with other information sources in downstream tasks.

### Extended Conservation Scores

CADD v1.7 updates its conservation and mutation-rate features to incorporate advances in comparative genomics and population genetics [@schubach_cadd_2024]. Deeper mammalian alignments from projects like Zoonomia, which sequenced over 200 mammalian species, provide substantially improved resolution for identifying constrained positions, particularly in non-coding regions where earlier alignments had limited power. The expanded phylogenetic scope allows detection of constraint that is specific to mammals or particular mammalian clades, complementing the broader vertebrate and eukaryotic conservation captured by earlier alignments.

These extended conservation metrics improve sensitivity for constrained elements in non-coding regions, provide more nuanced distinctions within moderately conserved regions, and complement the older GERP++ and phastCons scores. Improved models of genome-wide mutation rates further sharpen the distinction between true evolutionary constraint and regions with inherently low mutation rates. Earlier approaches sometimes conflated these signals: a region might appear conserved simply because few mutations arise there rather than because mutations are selectively removed. By incorporating refined mutation rate estimates derived from de novo mutation studies and population polymorphism patterns, CADD v1.7 can better distinguish these scenarios and assign appropriate deleteriousness scores.

These updates are particularly valuable for non-coding variant interpretation, where conservation signals are often the strongest available evidence for function. Improved detection of mammal-specific regulatory elements and better calibration against local mutation rates help identify pathogenic non-coding variants that earlier versions might have missed.

### Performance Improvements

CADD v1.7 is evaluated on several benchmark datasets that span different variant types and functional readouts [@schubach_cadd_2024]. Clinical variant benchmarks drawn from ClinVar and gnomAD compare pathogenic and benign variant sets, providing a coarse approximation of the clinical classification task that motivates CADD's development. Deep mutational scanning assays, summarized in resources like ProteinGym, offer experimentally measured variant effects for thousands of mutations across dozens of proteins, enabling evaluation against direct functional measurements rather than clinical labels [@notin_proteingym_2023]. Saturation mutagenesis reporter assays for promoters and enhancers capture regulatory variant effects with nucleotide resolution, testing CADD's performance on the non-coding variants that are often most challenging to interpret.

Across these benchmarks, incorporating PLM scores, regulatory CNN predictions, and updated conservation features yields consistent improvements in classification and ranking performance compared to earlier CADD versions. The gains are particularly pronounced for missense variants, where ESM-1v features provide substantial additional signal, and for non-coding variants in active regulatory regions, where CNN predictions complement annotation-based features. Stronger correlations with experimental fitness measurements for many proteins reflect the contribution of PLM features, while better prediction of expression changes from non-coding variants reflects the added CNN-based regulatory features.

These improvements validate the strategy of incorporating deep learning outputs as features while maintaining CADD's interpretable integrative framework. Importantly, CADD v1.7 remains an annotation-integration method: the underlying model is still a relatively simple generalized linear model; it is the feature set that has become increasingly deep learning-flavored.


## Benchmarking Against Alternative Approaches

CADD exists within a crowded landscape of deleteriousness predictors spanning four decades of methodological development. Benchmarking against alternative scores helps clarify both where CADD excels and where specialized tools may be preferable. Other approaches include genome-wide integrative scores such as DANN, Eigen, GWAVA, and LINSIGHT, as well as coding-specific ensemble predictors such as REVEL, M-CAP, and more recent deep-learning-based missense models [@rentzsch_cadd_2019].

### Coding Variants

For coding variants, especially missense changes, CADD competes with a crowded ecosystem of tools. Legacy single-task scores such as SIFT and PolyPhen pioneered sequence-based and structure-based prediction of amino acid substitution effects, using evolutionary conservation and physicochemical properties to identify potentially damaging missense variants [@ng_sift_2003; @adzhubei_polyphen_2010]. Integrative ensemble scores such as REVEL, M-CAP, and MetaSVM combine predictions from multiple individual tools, using machine learning to weight and integrate their outputs. Constraint-based metrics such as MPC provide model-based missense tolerability scores. Modern deep learning approaches exploit protein language models, structure prediction from AlphaFold, and end-to-end neural architectures that learn directly from sequence.

In systematic benchmarks across clinically annotated variants and deep mutational scanning datasets, CADD's combination of evolutionary, protein-level, and gene-context features yields performance that is competitive with or superior to many specialized scores for Mendelian disease variant prioritization [@rentzsch_cadd_2019; @schubach_cadd_2024]. The integration of ESM-1v features in version 1.7 closes much of the gap with pure PLM-based methods while retaining CADD's advantages in interpretability and genome-wide coverage. CADD's performance is particularly strong when variants must be ranked across diverse genes and consequence types, a setting that favors integrative approaches over methods tuned for specific protein families or variant classes.

However, for purely missense-focused tasks, specialized ensemble methods may have an advantage. Tools optimized for loss-of-function variant interpretation may capture nuances that CADD's genome-wide training misses. Structure-based methods incorporating AlphaFold predictions can model three-dimensional context that sequence-based features cannot fully capture. The appropriate choice of variant effect predictor depends on the specific application, available data, and interpretability requirements.

### REVEL and Other Ensemble Missense Scores

REVEL (Rare Exome Variant Ensemble Learner) represents a prominent missense-specific ensemble predictor widely used in clinical laboratories [@ioannidis_revel_2016]. It integrates predictions from a panel of individual tools, including SIFT, PolyPhen-2, PROVEAN, MutationAssessor, FATHMM, GERP++, phyloP, and phastCons, into a random forest model. The training data consists of pathogenic missense variants curated from ClinVar and other resources alongside rare putatively neutral missense variants from population datasets.

REVEL is restricted in scope to missense single-nucleotide variants in protein-coding regions. Its scores range from 0 to 1, with higher values implying greater likelihood of pathogenicity. Common heuristics treat scores above 0.5 or 0.7 as increasingly strong evidence for deleteriousness, though more stringent thresholds at or above 0.8 may be appropriate for high-specificity applications. REVEL is often incorporated into diagnostic pipelines and ACMG/AMP-style variant interpretation workflows as one of several supporting lines of computational evidence.

In comparison to CADD, REVEL often outperforms on missense-only benchmarks, reflecting its focused training objective and use of many specialized missense predictors. However, CADD offers broader coverage, scoring non-coding and indel variants and integrating regulatory and conservation features not captured by REVEL. From the standpoint of this book, REVEL illustrates how ensemble learning over pre-existing tools can yield strong performance within a narrow variant class, complementing CADD's genome-wide viewpoint.

### Non-coding Variants

Non-coding variant interpretation presents fundamentally greater challenges than coding variant prediction. Ground-truth pathogenic non-coding variants are far rarer in clinical databases and heavily biased toward a small number of well-studied regulatory elements, particularly canonical splice sites and a handful of characterized enhancers. The vast majority of the non-coding genome lacks reliable pathogenicity labels, making supervised approaches difficult and benchmark construction problematic.

Functional genomics assays provide an alternative view of non-coding function, but their interpretation is complicated by noise, cell-type specificity, and the uncertain relationship between biochemical activity and phenotypic consequence. A variant may alter transcription factor binding in a reporter assay yet have no detectable effect on gene expression or organismal phenotype. Conversely, subtle regulatory perturbations may have profound effects in specific developmental contexts that are not captured by standard assays.

Within this challenging landscape, CADD's integration of regulatory annotations and conservation allows it to rank plausible non-coding candidates genome-wide, particularly in promoters and enhancers covered by ENCODE and Roadmap data [@rentzsch_cadd_2019]. The addition of regulatory CNN predictions in version 1.7 provides learned sequence-based features that extend beyond annotation coverage. Specialized scores explicitly focused on regulatory function, such as GWAVA and LINSIGHT, integrate epigenomic and evolutionary features to prioritize non-coding variants. DeepSEA and related CNN-based methods predict regulatory activity and variant effects directly from DNA sequence [@zhou_deepsea_2015].

Benchmarking studies typically find that CADD is highly effective as a broad, genome-wide prioritization tool, often matching or approaching the performance of non-coding-specific scores on regulatory benchmarks [@rentzsch_cadd_2019]. Specialized sequence-based CNNs can outperform CADD for particular tasks, such as predicting the effect of variants in specific enhancers or promoters, but they are more computationally intensive and less straightforward to deploy as general-purpose annotation. CADD v1.7 narrows this gap by importing CNN-derived regulatory features into its annotation set, effectively blending sequence-based and integrative approaches.

However, CADD's performance on non-coding variants depends heavily on the availability and quality of underlying annotations. Variants in poorly annotated regions, including many distal enhancers and non-coding RNAs, receive scores driven primarily by conservation, which may miss recently evolved or lineage-specific functional elements.

### Population Frequency Correlation

Because CADD uses evolutionary depletion as its training signal, its scores naturally correlate with population allele frequencies. A basic sanity check for any deleteriousness score is this correlation: variants with higher predicted deleteriousness should, on average, be rarer in population datasets such as gnomAD, reflecting stronger purifying selection.

Common variants in gnomAD tend to have low CADD scores, reflecting the expectation that alleles reaching high frequency have survived purifying selection. Known pathogenic variants, such as truncating variants in severe Mendelian genes, tend to have high CADD scores and low allele frequencies. Very rare variants, particularly singletons observed in only one individual, show a broad distribution of scores with a substantial fraction in the high-score tail [@rentzsch_cadd_2019; @gnomAD]. A negative correlation between CADD and allele frequency is observed across variant classes, though the strength of this relationship varies by consequence, being strongest for protein-truncating variants and weaker for some synonymous changes.

This correlation is useful for many applications. High CADD scores often highlight variants under purifying selection, which are enriched for functional and potentially pathogenic alleles. The relationship provides a sanity check: if CADD assigned high scores to common variants, something would be wrong with either the model or the frequency data.

However, this correlation also means that CADD partially recapitulates frequency-based filtering. In downstream pipelines, it is important not to double-count this signal by applying both aggressive frequency cutoffs and strict CADD thresholds. Such redundant filtering can exclude variants that fail one criterion but might be genuinely pathogenic. The optimal strategy depends on the application: for highly penetrant Mendelian variants, frequency filtering alone may suffice; for variants with incomplete penetrance or population-specific effects, CADD provides complementary information beyond frequency.

### Limitations and Circularity with ClinVar

Despite its strengths, CADD has important limitations that should inform its use in research and clinical settings.

First, the proxy labels are imperfect. Simulated variants are not purely deleterious, and fixed human lineage variants can be mildly deleterious or linked to other fitness-modulating changes. CADD's labels are therefore noisy, and its scores should not be interpreted as precise probabilities of disease. Second, context matters in ways that CADD does not capture. The framework does not explicitly model gene-phenotype relationships, inheritance mode, or tissue-specific expression; it provides a general measure of deleteriousness rather than disease specificity.

Third, potential circularity between CADD scores and clinical databases such as ClinVar raises methodological concerns. Two forms of circularity are particularly relevant. Evaluation circularity arises when CADD is assessed on benchmark datasets that were themselves influenced by CADD. ClinVar submissions increasingly incorporate in silico evidence, including CADD scores, as part of their classification process. When we evaluate CADD on post-2014 ClinVar variants after clinical curation has already used CADD, we risk overestimating performance because the model is partially being judged against labels it helped create [@schubach_cadd_2024]. Variants with high CADD scores are more likely to be classified as pathogenic, and variants classified as pathogenic form the positive evaluation set, creating a feedback loop that inflates apparent performance.

Broader sociotechnical feedback affects model development even if CADD's core training labels derive from simulated versus observed variants rather than clinical databases. ClinVar and related resources still influence feature engineering, threshold selection, and choice of evaluation benchmarks. Over time, variants consistently prioritized by CADD are more likely to receive follow-up investigation, be published, and enter ClinVar as likely pathogenic, reinforcing the underlying signal. This feedback is not unique to CADD but affects any widely used predictive tool in genomics and medicine. As the field increasingly uses CADD and related scores to prioritize variants for experimental follow-up and clinical reporting, there is a risk that databases of known pathogenic variants become biased toward variants with high CADD scores.

These circularity concerns motivate several best practices for evaluation. Benchmarks should include datasets independent of clinical curation pipelines, such as deep mutational scanning experiments, reporter assays, and population-based burden tests where labels derive from experimental measurement rather than clinical judgment. Performance should be reported separately on pre-CADD and post-CADD ClinVar subsets when temporal stratification is possible. ClinVar-based evaluation should be treated as a sanity check confirming that CADD captures clinically relevant signals, not as the primary or sole measure of model quality.

These concerns foreshadow similar issues we will encounter in later chapters when genomic foundation models are evaluated on benchmarks that themselves rely on older predictive tools or clinical databases shaped by those tools.


## Significance for Genomic Deep Learning

CADD occupies an important historical position at the junction between hand-crafted feature integration and modern deep, self-supervised representation learning. It anticipates many of the themes that recur throughout this book while also highlighting enduring challenges. Several aspects of its design resonate throughout the models and methods covered in subsequent chapters, making it a valuable conceptual anchor for understanding the field's evolution.

The first connection is between annotation integration and multi-task deep models. CADD's strategy of combining dozens of heterogeneous annotations into a single score anticipates the multi-task learning frameworks that define modern genomic deep learning. Models like DeepSEA, Basset, and Enformer, covered in Chapters 5 through 7 and revisited in Chapter 11, predict hundreds of functional genomics readouts from sequence and then reuse these predictions as building blocks for downstream tasks. The conceptual structure is similar: learn to predict many weak signals, then combine them for variant interpretation. In CADD v1.7, the boundary between these approaches blurs as deep networks including ESM-1v and regulatory CNNs provide features that CADD integrates [@meier_esm-1v_2021; @zhou_deepsea_2015; @schubach_cadd_2024]. The distinction between "annotation-based" and "deep learning-based" methods becomes one of degree rather than kind.

The second connection is between evolutionary proxy labels and self-supervised learning. CADD's training on simulated versus observed variants uses the signature of selection as a rich, weak supervisory signal available across the entire genome [@kircher_general_2014; @rentzsch_cadd_2019]. This strategy is conceptually parallel to the masked language modeling objectives that define modern protein and DNA language models. In both cases, the labels derive not from expert curation but from statistical regularities in large datasets: which tokens (amino acids, nucleotides, or variants) are observed versus which are plausible but absent. The resulting models learn representations that transfer to diverse downstream tasks, from variant effect prediction to structure determination to regulatory sequence design. Chapters 8 through 10 develop this connection in detail for transformer-based foundation models.

The third connection concerns genome-wide coverage and scalability. By precomputing scores for all possible single-nucleotide substitutions in the reference genome, CADD demonstrated the feasibility and utility of generating genome-wide variant annotations for downstream reuse. Users need not run the full model for each query; they simply look up precomputed scores from distributed files. Many genomic foundation models now follow an analogous pattern, precomputing embeddings or predictions for every base or variant and exposing them as reusable resources. Just as modern foundation models provide reusable embeddings or zero-shot predictions across many tasks, CADD provides a universal deleteriousness prior that can be plugged into diverse analyses, from GWAS fine-mapping to rare disease diagnosis. The infrastructure for distributing and querying such precomputed annotations has become a standard component of genomic analysis pipelines.

The fourth connection is composability with deep learning. CADD is not a direct competitor to modern sequence-based deep models but rather an integrative framework that increasingly incorporates them as features. This "deep features plus shallow integrator" pattern appears repeatedly in practical deployments where interpretability, calibration, or computational constraints favor hybrid approaches over end-to-end neural networks. Clinical variant interpretation pipelines, in particular, often combine CADD-style integrative scores with deep learning predictions and expert review, leveraging the strengths of each approach. Deep representations can be integrated into existing statistical pipelines, clinical workflows, and decision-support systems without requiring full-stack neural architectures everywhere.

Finally, CADD highlights the limits of purely scalar scores. No single number can capture all dimensions of variant impact: tissue specificity, developmental timing, gene-environment interactions, or polygenic background. As genomic foundation models become more expressive, they will increasingly move beyond scalar "deleteriousness" toward richer predictions, such as cell-type-resolved gene expression changes and pathway-level perturbations. Nonetheless, CADD's conceptual framework of proxy labels, feature integration, and evolutionary depletion remains a valuable anchor for understanding how the field arrived at its current deep learning-dominated landscape.

As we move into the CNN-based sequence-to-function models of Part II and the transformer-based genomic foundation models of Parts III and IV, it is helpful to remember that CADD solved a difficult problem using tools available at the time. The challenge of variant prioritization under data scarcity and annotation heterogeneity does not disappear with more powerful models. The deep learning systems that follow expand on CADD's core ideas by learning representations directly from sequence and tying those representations to richer experimental readouts. Yet they still rely on many of the same data resources surveyed in @sec-data and confront many of the same challenges around evaluation bias, label circularity, and the fundamental difficulty of inferring causality from correlation. Understanding CADD's solutions and limitations provides essential context for appreciating both the advances and the persistent challenges in genomic deep learning.