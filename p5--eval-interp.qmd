# Part V: Evaluation and Reliability {.unnumbered}

The preceding sections have surveyed an impressive landscape of genomic foundation models, from convolutional architectures that learn regulatory grammar to transformer-based systems that capture long-range chromatin interactions. Yet the enthusiasm surrounding these advances must be tempered by rigorous assessment. A model's utility in genomics depends not merely on its architectural sophistication but on whether it genuinely captures biological signal, generalizes beyond its training distribution, and provides insights that translate to clinical or experimental settings. Part V addresses these critical questions, examining the frameworks, methodologies, and potential pitfalls that determine whether genomic AI models deliver on their promises.

Evaluating genomic models presents unique challenges that distinguish this domain from natural language processing or computer vision. Biological sequences contain nested hierarchies of functional elements, population-stratified variation, and evolutionary constraints that can masquerade as predictive signal. Standard machine learning metrics may obscure fundamental problems: a variant effect predictor might achieve impressive aggregate performance while systematically failing on clinically actionable mutations, or a regulatory model might exploit sequence artifacts rather than genuine enhancer logic. The chapters that follow develop a comprehensive framework for understanding what benchmarks actually measure, how evaluation methodology shapes conclusions, what confounders threaten validity, and how interpretability methods can distinguish genuine biological insight from spurious pattern matching.

We begin in @sec-benchmarks with a survey of established benchmarks in genomic deep learning, examining their construction, scope, and limitations. @sec-eval then develops principles for rigorous evaluation methodology, addressing issues of train-test contamination, metric selection, and clinical relevance that frequently compromise published comparisons. @sec-confound confronts the systematic biases and data leakage pathways that pervade genomic datasets, with particular attention to population stratification and linkage disequilibrium. Finally, @sec-interp explores interpretability methods that move beyond black-box prediction toward mechanistic understanding, examining both the promise and limitations of attribution approaches in the genomic context.