# Part V: Evaluation and Trust {.unnumbered}

Evaluating genomic models presents challenges that distinguish this domain from natural language processing or computer vision. Biological sequences contain evolutionary history: a model tested on homologous sequences may appear to generalize when it has merely memorized. Population structure creates spurious associations: a variant predictor may learn ancestry rather than pathogenicity. Nested functional hierarchies obscure what models actually capture: strong performance on common variants provides no guarantee of accuracy on the rare variants that drive most clinical decisions. Standard machine learning evaluation practices, developed for domains where training and test examples are approximately independent and identically distributed, become actively misleading when applied to genomic data without careful adaptation.

This part develops the frameworks and methodologies that determine whether genomic foundation models deliver on their promises. @sec-benchmarks surveys established benchmarks across protein, DNA, regulatory, and clinical domains, examining their construction and limitations while distinguishing meaningful signal from benchmark-specific artifacts. @sec-evaluation-principles addresses how to use benchmarks appropriately, developing principles for data splitting, metric selection, and statistical testing that produce trustworthy conclusions rather than inflated claims.

@sec-confounders confronts the systematic biases that pervade genomic datasets: population stratification that confounds genotype with ancestry, batch effects that encode technical rather than biological variation, and hidden correlations that models exploit without learning genuine biology. @sec-uncertainty examines calibration and uncertainty quantification, the methods that determine whether model outputs can inform decisions or require careful reinterpretation. @sec-interpretability explores how to move beyond black-box prediction toward mechanistic understanding, distinguishing faithful explanations that accurately reflect model computation from plausible explanations that merely satisfy human intuition. Together, these chapters provide the critical toolkit needed to evaluate claims about genomic AI and to deploy models responsibly in research and clinical settings.