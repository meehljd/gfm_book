# Sequence Design {#sec-ch28-design}

Genomic foundation models predict the consequences of sequence variation with increasing accuracy. A protein language model estimates whether a missense variant disrupts function. A regulatory model forecasts how a promoter mutation alters expression across cell types. These predictive capabilities represent genuine advances. Yet prediction alone cannot create a therapeutic protein that nature never evolved, design a promoter that drives expression only in diseased tissue, or engineer an mRNA vaccine against a novel pathogen. The gap between reading genomes and writing them defines one of the central challenges in translational biology: we can characterize biological sequences with unprecedented resolution, but translating that understanding into designed molecules remains largely empirical, expensive, and slow.

This asymmetry reflects a fundamental mismatch between what evolution produced and what therapeutics require. Evolution optimizes for reproductive fitness over geological timescales, producing sequences that satisfied survival constraints under ancestral conditions. Therapeutic applications demand sequences optimized for entirely different objectives: binding a specific epitope with high affinity, expressing at therapeutic levels in a particular tissue, or evading immune recognition while retaining function. The sequences we need often lie far from natural evolutionary trajectories, in regions of sequence space that foundation models have never observed during training. Navigating this *terra incognita* requires not just accurate oracles that score candidate sequences, but principled strategies for proposing, testing, and refining designs where model reliability is uncertain.

Foundation models have begun to address this challenge by providing both generative priors over plausible sequences and differentiable oracles that guide optimization. Protein language models sample novel sequences respecting the statistical patterns of natural proteins. Structure-aware diffusion models generate backbones and sequences simultaneously, enabling design of proteins with specified geometries. Regulatory sequence models predict expression outcomes across thousands of candidate promoters, enabling gradient-based optimization toward desired activity profiles. When coupled with high-throughput experimental assays in closed-loop design cycles, these capabilities are transforming biological engineering.


## Design Formalism {#sec-ch28-formalism}

**Sequence design** inverts the standard prediction problem. Where prediction maps from sequence to function (given sequence $x$, estimate property $f(x)$), design maps from desired function to sequence (given target property $y^\star$, find sequence $x^\star$ such that $f(x^\star) \approx y^\star$). This inversion is computationally challenging because biological sequence spaces are astronomically large. A 200-residue protein admits $20^{200}$ possible sequences, vastly exceeding the number of atoms in the observable universe. Even a modest 500-base-pair regulatory element spans $4^{500}$ possibilities. Exhaustive enumeration is impossible; intelligent search strategies are essential.

::: {#fig-design-formalism layout-ncol=2}
![**FIGURE PLACEHOLDER A**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20A)

![**FIGURE PLACEHOLDER B**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20B)

[Essential] Two-direction diagram. Top (Prediction Problem): Input sequence x → model f_θ → property f(x); arrow left to right; "Given sequence, estimate function." Bottom (Design Problem): Desired property y* → search for x* such that f(x*) ≈ y* → optimized sequence x*; arrow right to left; "Given function, find sequence." Design formulations: Optimization argmax f_θ(x), conditional generation x ~ p_θ(x|y), constrained optimization. Scale callout: 20^200 protein possibilities, 4^500 regulatory; "Exhaustive impossible—intelligent search required." FM roles: Generative prior, differentiable oracle, embedding function.
:::
The design objective can take several mathematical forms depending on the application. **Optimization problems** seek sequences that maximize (or minimize) a scalar objective, such as finding $x^\star = \arg\max_x f_\theta(x)$ where $f_\theta$ might represent predicted binding affinity, expression level, or stability. **Conditional generation** problems sample sequences from a distribution conditioned on desired properties, drawing $x \sim p_\theta(x \mid y)$ where $y$ specifies structural constraints, functional requirements, or context. **Constrained optimization** problems combine objective maximization with explicit constraints, seeking $x^\star = \arg\max_x f_\theta(x)$ subject to $c(x) \leq 0$, where constraints $c$ might enforce GC content limits, avoid restriction sites, or maintain similarity to natural sequences.

Foundation models contribute to design through multiple mechanisms. As **generative priors**, they assign higher probability to sequences resembling natural biology, regularizing optimization toward plausible regions of sequence space. As **differentiable oracles**, they enable gradient-based optimization where sequence modifications are guided by gradients of predicted properties. As **embedding functions**, they map discrete sequences into continuous spaces where interpolation and optimization become tractable (@sec-ch05-embeddings for representation fundamentals; @sec-ch08-pretraining-representations for how pretraining shapes these spaces). The challenge lies in searching enormous combinatorial spaces while remaining within regimes where these model-based estimates remain reliable.


## Protein Design with Language Models {#sec-ch28-protein-design}

Protein language models trained on evolutionary sequence databases (@sec-ch12-protein-lm) have emerged as effective tools for protein design, providing both generative sampling capabilities and fitness estimation for candidate sequences. The masked language modeling objectives that enable fitness estimation are detailed in @sec-ch08-mlm. The success of these approaches stems from a key insight: evolution has conducted billions of years of experiments on protein sequence space, and models trained on the surviving sequences implicitly encode constraints on what works.

::: {#fig-protein-design layout-ncol=2}
![**FIGURE PLACEHOLDER A**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20A)

![**FIGURE PLACEHOLDER B**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER%20B)

[Essential] Two-pathway comparison. Pathway A (Sequence-Based): Protein LM (ProGen, *ESM*-2) → generate by sampling/infilling → screen for properties → iterate with fitness-guided selection. Pathway B (Structure-Aware): RFdiffusion generates backbone from noise (conditioned on interface, topology, symmetry) → ProteinMPNN/*ESM*-IF inverse folds → multiple sequences, select by expression/stability. Comparison table: Prior knowledge, novel structures, compute, examples. Multi-objective: Binding, stability, expression, immunogenicity; Pareto frontier; FM oracles for each.
:::

### Sequence Generation from Language Model Priors {#sec-ch28-plm-generation}

Autoregressive protein language models such as *ProGen* and *ProtGPT2* generate novel protein sequences by sampling tokens sequentially from learned distributions [@madani_progen_2023; @ferruz_protgpt2_2022]. Given a partial sequence, the model predicts probability distributions over the next amino acid, enabling iterative extension until a complete protein emerges. This generation process can be unconditional (sampling from the full learned distribution) or conditional on control signals such as protein family annotations, organism of origin, or functional keywords.

The quality of generated sequences depends critically on how closely the sampling distribution matches functional proteins. Sequences sampled at low temperature (more deterministic) tend to resemble common protein families but may lack novelty. Sequences sampled at high temperature (more stochastic) exhibit greater diversity but risk straying into nonfunctional regions. Practical design workflows often generate large libraries of candidates across temperature ranges, then filter using downstream oracles for structure, stability, or function.

Masked language models like *ESM-2* support design through a different mechanism. Rather than generating sequences *de novo*, these models estimate the probability of each amino acid at each position given the surrounding context. Design proceeds by iterative refinement: starting from an initial sequence, positions are masked and resampled according to model predictions, gradually shifting the sequence toward higher-likelihood regions. This Gibbs-sampling-like procedure can be biased toward specific objectives by combining model likelihoods with scores from downstream predictors.

The key advantage of protein language model-based design lies in data efficiency. Because models are pretrained on millions of natural sequences, they generalize to design tasks with minimal task-specific data. A model fine-tuned on a few hundred functional variants can propose candidates across sequence space, extrapolating far beyond the training examples. This contrasts with traditional directed evolution approaches that require extensive experimental screening to navigate sequence space.

### Structure-Aware Design with Diffusion Models {#sec-ch28-structure-diffusion}

Structure-aware design addresses a fundamental limitation of sequence-only approaches: proteins function through three-dimensional structures, and sequence optimization without structural guidance may produce sequences that fail to fold correctly. The advent of accurate structure prediction (*AlphaFold2*, *ESMFold*; @sec-ch12-esmfold; @sec-ch12-alphafold) enables new design paradigms that jointly consider sequence and structure.

*RFdiffusion* exemplifies this approach by generating protein backbones through a **diffusion** process in three-dimensional coordinate space [@watson_rfdiffusion_2023]. Starting from random noise, the model iteratively denoises toward plausible backbone geometries, conditioned on design specifications such as target binding interfaces, desired topology, or symmetric assembly requirements. The resulting backbones represent novel structures not observed in nature but predicted to be physically realizable.

Converting designed backbones to sequences requires **inverse folding** models that predict amino acid sequences likely to adopt a given structure. *ProteinMPNN* and *ESM-IF* operate on this principle, taking backbone coordinates as input and outputting probability distributions over sequences predicted to fold onto that backbone[@dauparas_proteinmpnn_2022; @hsu_learning_2022]. *ESM-IF* leverages the representations learned by *ESM-2* to condition sequence generation on structural constraints, connecting the inverse folding task directly to the protein language model paradigm. The model can generate thousands of candidate sequences for a single backbone, enabling selection based on additional criteria such as expression likelihood or immunogenicity.

This two-stage pipeline (structure diffusion followed by inverse folding) has proven effective for creating novel proteins. Designed binders targeting challenging therapeutic targets, *de novo* enzymes with specified active site geometries, and symmetric protein assemblies with precise nanoscale dimensions have all been realized experimentally. *[Citation Needed]* The key insight is that structure provides a useful intermediate representation: rather than searching directly in the vast space of sequences, design proceeds through the more constrained space of physically realizable structures.

### Functional Conditioning and Multi-Objective Optimization {#sec-ch28-multi-objective}

Real therapeutic or industrial applications rarely optimize a single objective. A designed enzyme must not only be catalytically active but also stable at process temperatures, expressible in the production host, and resistant to proteolytic degradation. A therapeutic antibody must bind its target with high affinity while avoiding off-target interactions, maintaining solubility, and minimizing immunogenicity. These competing demands create multi-objective optimization problems where no single sequence optimizes all criteria simultaneously.

Multi-objective design produces **Pareto frontiers** of solutions representing different trade-offs among objectives. A sequence might achieve exceptional binding affinity at the cost of reduced stability, while another balances moderate affinity with excellent developability properties. Practitioners must select among Pareto-optimal solutions based on application-specific priorities, and foundation models increasingly support this selection by providing diverse oracles across multiple property dimensions.

Foundation models contribute to multi-objective design in three ways. Generative priors propose candidate sequences that satisfy basic plausibility constraints (foldability, expressibility) before optimization begins. Multiple differentiable oracles (for binding, stability, immunogenicity) enable gradient-based optimization toward Pareto frontiers. Embedding spaces support interpolation between sequences with different property profiles, enabling exploration of intermediate trade-offs. The combination of these capabilities makes foundation models central to modern protein design pipelines.


## Regulatory Sequence Design {#sec-ch28-regulatory-design}

Genomic foundation models trained on chromatin accessibility, transcription factor binding, and gene expression data enable design of synthetic regulatory elements with specified activity profiles. Unlike protein design where the sequence-to-function mapping operates through three-dimensional structure, regulatory design must account for the genomic and cellular context in which elements function. The functional genomics resources described in @sec-ch02-functional provide training data for these models, while the interpretability methods from @sec-ch24-attribution inform design strategies by revealing which sequence features drive predictions.

::: {#fig-regulatory-design}
![**FIGURE PLACEHOLDER**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER)

[High] Optimization workflow. Steps: (1) Initial sequence (natural promoter or random); (2) FM prediction (Enformer → activity across cell types); (3) Gradient computation (∂expression/∂position); (4) Sequence update (relaxed representation, gradient step, project back); (5) Multi-objective balancing (maximize in target tissue, minimize off-target, respect constraints). Output examples: Cell-type-specific enhancer, inducible promoter, compact element for gene therapy. Generative alternative sidebar: Diffusion or autoregressive; condition on cell type labels; diverse library for screening. Key insight: Same saliency for interpretation runs in reverse for design.
:::

### Promoter and Enhancer Engineering {#sec-ch28-promoter-enhancer}

Massively parallel reporter assays (MPRAs) have generated training data for models that predict expression levels from promoter and enhancer sequences (@sec-ch02-dms; @sec-ch02-mpra) [@deboer_deciphering_2020]. These models learn sequence determinants of regulatory activity, including transcription factor binding sites, spacing constraints between elements, and context-dependent interactions. Once trained, the same models serve as oracles for design: by evaluating expression predictions across millions of candidate sequences, optimization algorithms can identify synthetic regulatory elements with desired properties.

Gradient-based design treats the sequence-to-expression model as a differentiable function. Starting from an initial sequence, gradients of predicted expression with respect to input positions indicate which mutations would increase (or decrease) activity. Because sequences are discrete while gradients are continuous, optimization requires relaxation strategies that operate on "soft" sequence representations before projecting back to discrete nucleotides. These approaches leverage the same saliency map computations used for model interpretation (@sec-ch24-gradient-attribution), running the analysis in reverse to guide design rather than explain predictions.

Design objectives for regulatory elements extend beyond maximizing expression in a target context. Cell-type-specific enhancers should drive high expression in desired tissues while remaining inactive elsewhere. Inducible promoters should respond to specific signals while maintaining low basal activity. Compact regulatory elements are preferred for gene therapy applications where vector capacity is limited. These constraints transform simple optimization into multi-objective problems requiring careful balancing of competing requirements.

Generative models trained directly on regulatory sequences offer an alternative to optimization-based approaches. Autoregressive or diffusion models learn to sample novel enhancers and promoters that match the statistical properties of natural regulatory elements. Conditioning on cell type labels, chromatin state annotations, or other metadata enables generation of elements with targeted activity profiles. The advantage of generative approaches lies in their ability to produce diverse candidate libraries for experimental screening, rather than converging on a single optimized sequence that may exploit model artifacts rather than genuine biology.

### Splicing and RNA Processing Elements {#sec-ch28-splicing-design}

Models trained on splicing outcomes (*SpliceAI* and related architectures described in @sec-ch06-cnn; see also @sec-ch15-rna for RNA-specific foundation models) enable design of sequences that modulate RNA processing. Therapeutic applications include correcting pathogenic splice site mutations by strengthening weak splice sites or weakening aberrant ones, designing antisense oligonucleotides that redirect splicing to skip exons containing disease-causing mutations, and engineering alternative splicing outcomes to produce desired protein isoforms.

The design space for splicing elements encompasses splice site sequences themselves (the canonical GT-AG dinucleotides and surrounding intronic and exonic enhancers and silencers), branch point sequences, and auxiliary sequences that recruit splicing regulatory proteins. Foundation models that predict splicing patterns from local sequence context serve as oracles for evaluating candidate modifications, while gradient-based optimization identifies changes predicted to shift splicing toward therapeutic outcomes.

Design of splicing modulators requires particular attention to off-target effects. The splicing code is highly context-dependent, and sequence modifications intended to affect one splice site may inadvertently alter recognition of others. Genome-wide splicing models that predict effects across all splice sites provide essential off-target assessment, flagging candidate designs that would disrupt normal splicing at unintended locations.


## mRNA Design and Optimization {#sec-ch28-mrna-design}

The clinical success of mRNA vaccines has intensified interest in systematic approaches to mRNA sequence design. Unlike protein or regulatory element design where the primary challenge is achieving desired function, mRNA design must simultaneously optimize translation efficiency, molecular stability, immune evasion, and manufacturing tractability. Foundation models increasingly contribute to each of these objectives.

::: {#fig-mrna-optimization}
![**FIGURE PLACEHOLDER**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER)

[High] Multi-objective radar chart. Objectives (axes): Translation efficiency, mRNA stability, immunogenicity (minimize), manufacturing tractability, codon optimality. Design elements per objective: Translation (ribosome profiling models, avoid rare codons); Stability (UTR engineering, secondary structure); Immunogenicity (avoid TLR motifs, modified nucleosides); Manufacturing (GC content, complexity, yield). Trade-off visualization: Two candidate designs on same radar; Design A (high translation, moderate stability); Design B (balanced). UTR design callout: 5' affects ribosome recruitment, 3' affects stability/localization. Key insight: Codon synonymy creates vast space; FMs navigate tradeoffs.
:::

### Codon Optimization Principles {#sec-ch28-codon-optimization}

The genetic code is degenerate: sixty-one sense codons encode twenty amino acids, meaning that any protein sequence can be encoded by many different mRNA sequences. These synonymous sequences differ in translation efficiency, mRNA stability, and immunogenicity despite producing identical proteins. **Codon optimization** exploits this redundancy to improve therapeutic mRNA performance.

Traditional codon optimization relied on codon adaptation indices derived from highly expressed genes in target organisms. Codons frequently used in abundant proteins were assumed to be efficiently translated, leading to optimization strategies that maximize use of preferred codons. This approach oversimplifies the complex relationship between codon choice and expression. Translation elongation rate varies with codon-anticodon interactions, tRNA abundance, mRNA secondary structure, and ribosome queuing effects. Local codon context matters: rare codons following abundant ones may be translated efficiently, while runs of preferred codons can cause ribosome collisions.

Machine learning models trained on ribosome profiling data and reporter assays have begun to capture these context-dependent effects. *[Citation Needed]* These models predict translation efficiency from sequence features including codon frequencies, local secondary structure, and amino acid properties. Using such models as oracles, optimization algorithms can search for mRNA sequences that maximize predicted translation while avoiding problematic sequence features. The resulting designs often differ substantially from simple codon-frequency optimization, incorporating rare codons at specific positions to optimize local translation dynamics.

### Stability Engineering and UTR Design {#sec-ch28-utr-design}

mRNA stability in the cytoplasm determines the duration of protein production and thus the dose required for therapeutic effect. Stability is governed by multiple sequence features: the 5' and 3' **untranslated regions (UTRs)** that flank the coding sequence, the presence of destabilizing sequence motifs recognized by RNA-binding proteins, and secondary structures that protect against or expose the molecule to nucleases.

UTR engineering represents a particularly active area of foundation model application. Natural UTRs contain binding sites for regulatory proteins and microRNAs, sequences that affect ribosome recruitment, and structures that influence mRNA localization and stability. Foundation models trained on expression data across diverse UTR sequences learn which features promote stability and efficient translation. *[Citation Needed]* Design algorithms then search for synthetic UTRs that maximize these properties while avoiding sequences that trigger immune recognition or rapid degradation.

Chemical modifications of mRNA (pseudouridine, N1-methylpseudouridine, and other nucleoside analogs) dramatically improve stability and reduce immunogenicity. These modifications alter the sequence-function relationship in ways that current foundation models, trained primarily on natural RNA, may not fully capture. Emerging models that incorporate modification information promise to enable joint optimization of sequence and modification patterns.

### Immunogenicity Considerations {#sec-ch28-mrna-immunogenicity}

Exogenous mRNA triggers innate immune responses through pattern recognition receptors including Toll-like receptors (*TLR3*, *TLR7*, *TLR8*) and cytosolic sensors (*RIG-I*, *MDA5*). While some immune activation may be beneficial for vaccine applications, excessive inflammation limits dosing and causes adverse effects. For protein replacement therapies where repeated dosing is required, minimizing immunogenicity is essential.

The immunostimulatory potential of mRNA depends on sequence features including GC content, specific sequence motifs recognized by pattern receptors, and secondary structures that resemble viral replication intermediates. Foundation models that predict immunogenicity from sequence enable design of mRNAs that evade innate immune detection. *[Citation Needed]* These predictions must be balanced against other objectives: modifications that reduce immunogenicity may also reduce translation efficiency, creating multi-objective trade-offs that characterize mRNA design more broadly.


## Antibody and Vaccine Design {#sec-ch28-antibody-vaccine}

Antibody engineering represents one of the most commercially significant applications of computational protein design. The modular architecture of antibodies (framework regions that maintain structural integrity surrounding hypervariable **complementarity-determining regions (CDRs)** that mediate antigen recognition) creates a well-defined design problem: optimize CDR sequences to achieve desired binding properties while maintaining framework stability and developability.

::: {#fig-antibody-design}
![**FIGURE PLACEHOLDER**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER)

[High] Antibody-specific pipeline. Starting point: Initial antibody from immunization/display; known antigen target. Steps: (1) Initial characterization (affinity, specificity, stability, developability); (2) CDR optimization (FM-guided mutations; sample CDR variants; maintain binding, improve developability); (3) Framework engineering (humanization, stability, expression); (4) Lead optimization (multi-objective: affinity, specificity, half-life, immunogenicity, manufacturability). FM contributions: Embedding space identifies similar therapeutic antibodies; structure prediction without experimental structure; developability prediction (aggregation, viscosity); liability scanning (post-translational modification, deamidation).
:::

### CDR Optimization and Humanization {#sec-ch28-cdr-optimization}

Antibodies discovered through animal immunization or phage display often require optimization before therapeutic use. Non-human framework sequences may trigger immune responses in patients, necessitating **humanization** that replaces framework residues with human equivalents while preserving antigen binding. CDR sequences may require affinity maturation to achieve therapeutic potency or specificity optimization to reduce off-target binding.

Foundation models support antibody optimization through multiple mechanisms. Antibody-specific language models trained on paired heavy and light chain sequences learn the structural and functional constraints on CDR sequences. *[Citation Needed]* These models predict which mutations are compatible with the antibody fold and which are likely to disrupt structure. Given a parental antibody sequence, the models can propose libraries of variants enriched for functional candidates, reducing the experimental screening burden required to identify improved variants.

Structure-aware approaches enable more targeted design. Given a structure of the antibody-antigen complex (determined experimentally or predicted computationally via methods discussed in @sec-ch12-structure-prediction), optimization focuses on residues at the binding interface. Computational saturation mutagenesis predicts the effect of every possible amino acid substitution at each interface position, identifying combinations expected to improve affinity. These predictions guide the construction of focused libraries that explore the most promising region of sequence space.

### Vaccine Antigen Design {#sec-ch28-vaccine-design}

Vaccine development increasingly employs computational design to create immunogens that elicit protective immune responses. The challenge differs from therapeutic protein design: rather than optimizing for direct biological activity, vaccine antigens must be recognized by the immune system and induce antibodies or T cells that protect against pathogen challenge.

Foundation models contribute to vaccine design in several ways. **Epitope prediction** models identify regions of pathogen proteins most likely to be recognized by antibodies or T cells, guiding selection of vaccine targets. Structural models predict how mutations affect epitope conformation, enabling design of stabilized antigens that maintain native epitope structure during manufacturing and storage. Glycan shielding analysis predicts which epitopes will be accessible on the pathogen surface versus hidden by glycosylation, focusing vaccine design on exposed regions.

The rapid development of mRNA vaccines against SARS-CoV-2 demonstrated the potential of computational approaches to accelerate vaccine design. Structure-guided stabilization of the prefusion spike conformation, optimization of mRNA sequences for expression and stability, and prediction of variant effects on vaccine efficacy all benefited from computational modeling. *[Citation Needed]* Future vaccine development will increasingly integrate foundation model predictions throughout the design process.


## Closed-Loop Design-Build-Test-Learn Cycles {#sec-ch28-dbtl}

Foundation models achieve their full potential when integrated into iterative experimental workflows. The **design-build-test-learn (DBTL)** paradigm treats computational predictions as hypotheses to be tested experimentally, with results feeding back to improve both the designed molecules and the models that guide design. This closed-loop approach connects to the lab-in-the-loop concepts introduced in @sec-ch27-lab-in-loop.

::: {#fig-dbtl-cycle}
![**FIGURE PLACEHOLDER**](https://placehold.co/300x200?text=FIGURE%20PLACEHOLDER)

[Essential] Circular workflow. Stages: (1) DESIGN (FM proposes candidates; generative sampling or optimization; active learning selects informative candidates); (2) BUILD (automated synthesis, library construction, QC); (3) TEST (high-throughput assays: binding, activity, stability, expression; multiplexed: DMS, MPRA, Perturb-seq); (4) LEARN (results update model; improve predictions; identify failure modes). Active learning integration: Acquisition function balances exploitation/exploration; maximize expected information gain. Safety and oversight callouts: Safety filters at design; human review before build; stopping criteria. Key insight: FMs achieve full potential in iterative cycles; each round improves molecules and predictions.
:::

### Active Learning for Efficient Exploration {#sec-ch28-active-learning}

Experimental validation remains the bottleneck in biological design. Even high-throughput assays can test at most thousands to millions of variants, a tiny fraction of possible sequences. **Active learning** strategies select which experiments to perform by balancing two competing objectives: exploiting current model predictions to test sequences likely to succeed, and exploring regions of uncertainty to gather data that will improve the model.

**Bayesian optimization** provides a principled framework for this trade-off. A surrogate model (typically a Gaussian process or ensemble neural network) approximates the sequence-to-fitness mapping. **Acquisition functions** such as expected improvement or upper confidence bound combine predicted function values with uncertainty estimates to select informative test sequences. After each experimental round, the surrogate model is updated with new data, and the process repeats.

Foundation models enhance active learning by providing informative priors and features. Rather than learning sequence-to-function mappings from scratch, surrogate models can operate on protein language model embeddings that capture evolutionary relationships and structural constraints. These embeddings provide a meaningful notion of sequence similarity even before any task-specific data is available, accelerating the early rounds of optimization when labeled data is scarce.

### High-Throughput Experimentation Integration {#sec-ch28-high-throughput}

Modern experimental platforms generate data at scales well-matched to foundation model training. **Deep mutational scanning (DMS)** systematically characterizes thousands of single-mutant variants of a protein, mapping the functional landscape around a parental sequence (see @sec-ch02-dms for discussion of DMS data resources). Massively parallel reporter assays test tens of thousands of regulatory element variants in a single experiment. CRISPR screens introduce perturbations across the genome and measure phenotypic consequences.

These assays generate dense local maps of sequence-function relationships that complement the global patterns captured by foundation models. The integration is bidirectional: model predictions prioritize which variants to include in experimental libraries, and experimental results fine-tune models for improved accuracy in relevant sequence neighborhoods. After several DBTL cycles, the combined system (fine-tuned model plus accumulated experimental data) can often design sequences that substantially outperform the parental molecule.

The design of experiments themselves benefits from computational guidance. Rather than testing all possible single mutants, active learning identifies the most informative subset. Rather than random library construction, computational analysis identifies epistatic interactions that should be explored through combinatorial variants. The cost of DNA synthesis and high-throughput assays makes efficient experimental design increasingly important as design ambitions grow.


## Validation Requirements and Failure Modes {#sec-ch28-validation}

Computational design generates hypotheses; experimental validation determines whether those hypotheses are correct. The gap between predicted and observed performance represents the ultimate test of design methods, and understanding where predictions fail is essential for improving both models and design strategies. The evaluation principles discussed in @sec-ch20-benchmarks and uncertainty quantification from @sec-ch23-uncertainty apply directly to design validation.

### Validation Hierarchy {#sec-ch28-validation-hierarchy}

Designed sequences must pass through multiple validation stages before achieving real-world impact. Computational validation confirms that designs satisfy specified constraints and achieve predicted scores, filtering obvious failures before synthesis. *In vitro* validation tests whether designed proteins express, fold, and exhibit predicted activities in simplified experimental systems. *In vivo* validation assesses function in cellular or animal contexts where additional complexity may reveal unanticipated problems. Clinical validation, for therapeutic applications, determines whether designs are safe and effective in human patients.

Success rates decline at each stage of this hierarchy. Computationally promising designs often fail to express or fold correctly. Designs that succeed *in vitro* may lose activity in cellular contexts due to incorrect localization, unexpected degradation, or off-target interactions. Molecules that perform well in model organisms may fail in human clinical trials due to immunogenicity, toxicity, or pharmacokinetic limitations. The attrition from computational design to clinical success remains substantial, motivating continued improvement in predictive accuracy and earlier identification of failure modes.

### Characteristic Failure Patterns {#sec-ch28-failure-patterns}

Foundation model-guided design exhibits systematic failure modes that practitioners must recognize and mitigate. **Distribution shift** occurs when optimization pushes sequences into regions where model predictions are unreliable (@sec-ch21-distribution-shift for detailed discussion of distribution shift in genomic models; @sec-ch23-ood-detection for detection methods). A model trained on natural proteins may produce confident but incorrect predictions for designed sequences that lie far from training data. Regularization toward natural sequence statistics and uncertainty quantification help identify when designs have strayed beyond reliable prediction regimes.

**Mode collapse** in generative models produces designs that are variants of training sequences rather than genuinely novel molecules. When generated sequences can be matched to close homologs in training data, the design process has failed to create anything new. Novelty filters and diversity requirements during generation help ensure that computational design adds value beyond database retrieval.

**Reward hacking** occurs when optimization exploits model artifacts rather than genuine sequence-function relationships. A model might predict high expression for sequences containing spurious features that happen to correlate with expression in training data but have no causal effect. Ensemble methods, where designs must score highly across multiple independently trained models, provide some protection against hacking individual model weaknesses.

The most insidious failures involve properties that models cannot predict because they were absent from training data. A designed protein might aggregate under manufacturing conditions never encountered during model development. A regulatory element might be silenced by chromatin modifications specific to the therapeutic context. These failures can only be identified through experimental validation in relevant conditions, motivating the closed-loop DBTL approach that continuously tests designs in application-relevant settings.


## Practical Design Constraints {#sec-ch28-practical-constraints}

Beyond achieving desired function, practical design must satisfy numerous constraints arising from manufacturing, safety, and deployment requirements.

### Manufacturing and Developability {#sec-ch28-manufacturing}

Designed proteins must be producible at scale in expression systems such as bacteria, yeast, or mammalian cells. Expression levels, solubility, and purification behavior determine manufacturing feasibility and cost. Foundation models trained on expression data can predict which sequences are likely to express well, enabling design pipelines that optimize not only for function but for manufacturability. *[Citation Needed]*

For therapeutic proteins, **developability** encompasses additional properties including stability during storage, compatibility with formulation requirements, and behavior during analytical characterization. Aggregation propensity, chemical degradation sites (oxidation, deamidation), and glycosylation patterns all affect developability. Computational tools increasingly predict these properties from sequence, enabling their incorporation as design constraints.

### Safety and Biosecurity Considerations {#sec-ch28-biosecurity}

The same capabilities that enable beneficial design applications also raise biosecurity concerns. Generative models trained on pathogen sequences might in principle be used to design enhanced pathogens or reconstruct dangerous organisms. The dual-use potential of biological design technology requires ongoing attention to safety practices and governance frameworks.

Current foundation models do not provide straightforward paths to bioweapon development; designing a functional pathogen requires capabilities far beyond predicting sequence properties. As models improve and integrate with automated synthesis and testing platforms, the barrier to misuse may decrease. Responsible development practices, including careful consideration of training data, model access policies, and monitoring for concerning use patterns, are essential components of the foundation model ecosystem. These considerations connect to the broader discussion of safety and ethics in @sec-ch29-future.


## Algorithmic Search and Optimization {#sec-ch28-algorithms}

Design algorithms must navigate vast sequence spaces to identify candidates with desired properties. Several algorithmic paradigms have proven effective, each with characteristic strengths and limitations.

**Gradient-based optimization** treats foundation models as differentiable functions and computes gradients of objectives with respect to input sequence representations. Because sequences are discrete while gradients are continuous, optimization operates on relaxed representations (probability distributions over nucleotides or amino acids) that are projected back to discrete sequences for evaluation. This approach efficiently navigates high-dimensional spaces but can produce adversarial sequences that exploit model weaknesses rather than achieving genuine biological function.

**Evolutionary algorithms** maintain populations of candidate sequences that undergo mutation, recombination, and selection based on fitness scores from foundation model oracles or experimental assays. This approach naturally handles discrete sequence spaces and can maintain diversity to avoid local optima. Multi-objective evolutionary algorithms explicitly construct Pareto frontiers of solutions trading off competing objectives.

Bayesian optimization models the sequence-to-fitness mapping with a probabilistic surrogate (typically a Gaussian process or ensemble neural network) and uses acquisition functions to balance exploration of uncertain regions with exploitation of predicted optima. This approach is particularly effective when experimental evaluations are expensive and each design round must be carefully chosen.

**Monte Carlo methods** sample sequences from distributions defined by foundation model likelihoods, optionally biased toward high-scoring regions through importance weighting or Markov chain Monte Carlo. These approaches naturally integrate foundation model priors with task-specific objectives and can generate diverse candidate sets for experimental screening.

The choice among algorithmic approaches depends on the specific design problem, available computational resources, and experimental constraints. Many practical pipelines combine multiple approaches: generative sampling to produce initial candidate pools, gradient-based refinement to optimize specific objectives, and active learning to select informative experimental tests.


## From Understanding to Creating {#sec-ch28-conclusion}

Sequence design represents the frontier where foundation models transition from tools for understanding biology to engines for creating it. The field has advanced from designing individual stable proteins to engineering complex molecular machines, from optimizing isolated regulatory elements to programming cellular behavior, from incremental improvement of existing sequences to *de novo* creation of functions not found in nature. The constraints of natural evolution no longer bound the sequences we can consider; the statistical patterns of existing biology provide priors that guide exploration of novel territory.

The validation bottleneck persists as perhaps the most fundamental limitation. Computational design can propose candidates faster than experiments can test them, creating pressure to improve both predictive accuracy (reducing false positives that waste experimental resources) and experimental throughput (enabling more designs to be evaluated). Automated laboratories, standardized assay platforms, and improved experimental design methods all contribute to accelerating the design-build-test-learn cycle, but the gap between computational proposal and experimental validation remains substantial.

The transition from prediction to design amplifies both the potential benefits and the risks of these technologies. A model that predicts protein function enables analysis; a model that designs protein function enables creation. Ensuring that designed biology serves human flourishing while minimizing potential harms requires not just technical advances but thoughtful governance, inclusive deliberation about applications, and ongoing attention to safety. These broader considerations connect sequence design to regulatory, ethical, and societal dimensions (@sec-ch29-future), where the technical capabilities developed throughout genomic AI meet the human systems that will determine how they are used.