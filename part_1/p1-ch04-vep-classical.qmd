# Classical Variant Prediction {#sec-ch04-vep-classical}

**Conservation scores** measure evolutionary constraint, not disease relevance. Protein-level predictors estimate structural disruption, not clinical pathogenicity. Splice site algorithms identify sequence motifs, not functional consequences. Every classical variant effect predictor measures a proxy for what clinicians actually need to know: will this variant cause disease in this patient? The gap between measurable signal and clinical question is irreducible. Evolutionary conservation reflects reproductive fitness, not human health; protein structure does not determine disease penetrance; and splice motifs do not guarantee splicing outcomes. Classical methods achieve what they achieve by combining multiple imperfect proxies, hoping that their convergence approximatehs clinical truth.

The conceptual foundations and practical methods that dominated variant interpretation before the foundation model era reveal both genuine insights and systematic blind spots. The trajectory from single-signal predictors through increasingly sophisticated ensemble methods traces a persistent gap: what we can measure differs from what clinicians need to know. Conservation scores like PhyloP and **Genomic Evolutionary Rate Profiling (GERP)** quantify purifying selection across evolutionary time, identifying positions where variation is depleted relative to neutral expectations. Protein-level tools like *SIFT* and *PolyPhen-2* assess amino acid substitutions through sequence conservation and structural features. Splice predictors identify the sequence motifs that mark intron-exon boundaries. Each approach captures genuine biological signal, but each also fails in characteristic ways: conservation misses recently evolved human-specific functions, protein predictors cannot assess non-coding variants, splice algorithms miss cryptic sites and tissue-specific regulation.

The field's response was to develop integrative methods that combine multiple signals into unified scores. *CADD* receives particular attention here because it introduced design patterns that recur throughout genomic machine learning: using evolutionary signals as proxy labels, training on large-scale genomic data, integrating dozens of diverse annotations, and precomputing scores genome-wide for downstream reuse. *CADD* and its successors, including *REVEL*, *PrimateAI*, and *M-CAP*, remain in active clinical use today. Understanding their construction and limitations illuminates both what classical methods achieved and why the field ultimately moved toward learned representations (@sec-ch05-embeddings for learned representations, @sec-ch07-attention for attention mechanisms, @sec-ch10-defining for foundation model principles).

::: {#fig-variant-funnel}
![FIGURE PLACEHOLDER](../figs/part_1/ch04/01-fig-variant-funnel.png)

[Essential] Funnel diagram showing progressive reduction of variant burden through computational filters. Stages with approximate numbers: (1) Raw variants from WGS: ~4-5 million; (2) After common variant filter (gnomAD AF > 1%): ~100,000; (3) After consequence filter (coding, splice, UTR): ~25,000; (4) After conservation filter (phyloP > 2): ~5,000; (5) After ensemble predictor (CADD ≥ 20): ~500-1,000; (6) Expert review candidates: ~50-100. Annotate which tools/resources apply at each stage.
:::


## Conservation-Based Approaches {#sec-ch04-conservation}

A clinical geneticist evaluating a novel intronic variant faces an immediate problem: no functional annotation exists for most of the genome, and no clinical database has seen this specific change before. The variant lies outside any protein-coding region, no regulatory element overlaps it, and the patient's phenotype offers no clear mechanistic hypothesis. Yet one source of information spans the entire genome and predates any experimental annotation by billions of years. If a genomic position has remained unchanged across species separated by hundreds of millions of years of evolution, mutations at that position are likely to be deleterious. Natural selection has already performed the largest functional screen imaginable, running experiments across countless organisms over evolutionary time, and conservation scores quantify the results.

Conservation signals derive from the population variant catalogs described in @sec-ch02-gnomad, where patterns of variation across populations reveal which positions tolerate change. The variant calling quality from @sec-ch01-classical directly affects which variants appear in constraint calculations, potentially biasing constraint metrics in regions with systematic calling errors.

::: {#fig-conservation-scores layout-ncol=3}
![FIGURE PLACEHOLDER A](../figs/part_1/ch04/02-A-fig-conservation-scores.png)

![FIGURE PLACEHOLDER B](../figs/part_1/ch04/02-B-fig-conservation-scores.png)

![FIGURE PLACEHOLDER C](../figs/part_1/ch04/02-C-fig-conservation-scores.png)

[High] Multi-panel figure. Panel A: Multiple sequence alignment at a highly conserved position (same nucleotide across 30+ species) vs a neutrally evolving position (variable nucleotides). Show phylogenetic tree alongside alignment. Panel B: Distribution of phyloP or GERP scores genome-wide, with long right tail representing constrained elements. Mark threshold zones (e.g., phyloP > 2 = strong evidence). Panel C: Example intronic variant at deeply conserved position with no other annotation, illustrating how conservation provides evidence in annotation-sparse regions.
:::


### Evolutionary Constraint Metrics {#sec-ch04-constraint-metrics}

The logic of conservation is straightforward: if a position matters for survival or reproduction, mutations there will be removed by selection before they can spread through the population. Quantifying this signal requires comparing sequences across species to identify positions where substitutions occur less frequently than expected under neutral evolution. Conservation scores translate this evolutionary signal into numerical values that can inform variant interpretation.

PhyloP scores quantify the deviation of observed substitution rates from neutral expectation at individual positions[@siepel_phastcons_2005]. The score is computed by comparing the observed pattern of bases at each alignment column against a neutral evolutionary model (typically fit to ancestral repeat sequences that are assumed to evolve without selective constraint). Positive phyloP scores indicate conservation, meaning evolution is slower than expected under neutrality. Negative scores indicate acceleration, suggesting faster evolution that may reflect positive selection. A phyloP score of 2 indicates that the observed base is approximately 100-fold more conserved than expected under neutrality, providing strong evidence that mutations at this position have been systematically removed by selection.

GERP takes a complementary approach by estimating rejected substitutions at each position: the number of substitutions that would have been expected under neutrality but are absent from the observed alignment [@davydov_gerp_2010]. Large positive GERP scores indicate strong constraint. For a position conserved across 30 mammalian species, a GERP score of 5 implies that approximately five substitutions were rejected by selection over mammalian evolution. This interpretation connects directly to the biological process of **purifying selection** but depends on accurate neutral rate estimation and alignment quality.

**phastCons** provides element-level rather than position-level conservation by identifying contiguous stretches of constrained sequence [@siepel_phastcons_2005]. Using a **hidden Markov model**, phastCons classifies each position as belonging to a conserved or non-conserved state, then outputs the posterior probability of conservation. The resulting scores are smoother than position-level metrics, capturing functional elements that span multiple nucleotides even when individual positions show moderate conservation. This element-level view proves particularly valuable for identifying regulatory sequences where the overall constraint matters more than any single nucleotide. 

Conservation scores from phastCons and phyloP serve as foundational features throughout computational genomics. Integrative methods like CADD (@sec-ch04-cadd) combine conservation with dozens of other annotations to score variant deleteriousness. Fine-mapping algorithms use conservation to weight prior probabilities when prioritizing causal variants within GWAS loci (@sec-ch03-ld). Yet conservation measures evolutionary fitness, not disease relevance, and variants pathogenic in humans may be invisible to cross-species constraint. This evolutionary proxy problem creates fundamental limitations for clinical interpretation, examined in @sec-ch04-conservation-clinical-gap.


### What Conservation Measures Versus What Clinicians Need {#sec-ch04-conservation-clinical-gap}

Conservation scores measure evolutionary constraint: the degree to which a position has resisted substitution over millions of years. This is not the same as clinical relevance. A position can be evolutionarily constrained for functions unrelated to human disease, or clinically important despite modest conservation. The assumption underlying conservation-based interpretation is that positions under strong constraint are more likely to be functionally important and therefore more likely to cause disease when mutated. This assumption is often correct but not universally so.

The clinician wants to know: will this variant cause disease in my patient? Conservation provides indirect evidence: this position has been important for organismal fitness across evolutionary time. The gap between these questions creates interpretive challenges. A variant at a highly conserved position in a gene with no known disease association provides evolutionary evidence of functional importance but no direct path to clinical interpretation. Conversely, a variant at a modestly conserved position in a well-established disease gene may be clinically significant despite weak conservation signal.


### Clinical Application and Boundaries {#sec-ch04-conservation-boundaries}

Conservation scores prove particularly valuable for non-coding variant interpretation, where direct functional annotations are often incomplete or absent. A deeply conserved intronic position likely participates in splicing regulation, gene expression control, or other functional processes even if no explicit annotation overlaps it. Under ACMG-AMP guidelines for variant classification, strong conservation provides computational evidence (the PP3 criterion) supporting pathogenicity [@richards_standards_2015]. A variant falling at a position with phyloP greater than 2 and GERP greater than 4 carries significantly more weight than one at an unconserved position, even when no other annotation is available. These scores remain central to clinical variant interpretation workflows, as examined in @sec-ch25-clinical-risk, where they contribute evidence alongside population frequency, functional studies, and segregation data.

The boundaries of conservation-based approaches are equally important to recognize, and these boundaries are not merely technical inconveniences but reflect fundamental gaps in what evolutionary signal can reveal. Conservation requires evolutionary time to accumulate signal. Recently evolved functional elements, including human-specific regulatory sequences and primate-specific genes, may show little conservation despite genuine function. A position can be functionally critical in humans yet unconserved because the function arose too recently for selection to leave a detectable signature. The fraction of the human genome showing evidence of human-specific function since the human-chimpanzee split (estimated at several percent) presents exactly this challenge: important to human biology, yet invisible to conservation metrics. *[Citation Needed]*

Conservation patterns vary dramatically by functional context. Neural development genes tend to be highly conserved across vertebrates, while immune genes evolve rapidly under positive selection. Critically, lack of conservation does not prove neutrality: a position may be diverging under positive selection, or may serve lineage-specific functions absent in the comparison species.

Conservation scores also face technical challenges from alignment quality. In repetitive regions, **segmental duplications**, and rapidly evolving gene families, reliable alignments may be impossible to construct, leaving conservation scores undefined or unreliable precisely where variant interpretation is most difficult. The HLA region, immunoglobulin loci, and centromeric sequences are clinically important yet systematically difficult to assess by conservation. The regions most difficult to interpret computationally are frequently those of greatest clinical interest.

These boundaries do not diminish the value of conservation; they define where that value applies. Conservation provides information largely orthogonal to population frequency (which reflects recent human history rather than deep evolutionary constraint) and to functional genomics annotations (which capture biochemical activity rather than selective importance). Integrative methods such as *CADD* combine conservation with these other signals to achieve better performance than any single source. Protein language models, examined in @sec-ch12-protein-lm, learn conservation-like signals directly from sequence data without requiring explicit alignments, potentially addressing some technical limitations while introducing their own assumptions about what constitutes functional constraint.

::: {#box-acmg-amp .callout-note}
### ACMG-AMP Variant Classification Framework

The American College of Medical Genetics and Genomics and the Association for Molecular Pathology jointly established a standardized framework for clinical variant interpretation [@richards_standards_2015]. Variants are classified into five tiers: Pathogenic, Likely Pathogenic, **Variant of Uncertain Significance (VUS)**, Likely Benign, and Benign. Classification combines multiple evidence types, each assigned a strength level. Pathogenic evidence ranges from very strong (PVS) through strong (PS), moderate (PM), to supporting (PP). Benign evidence follows a parallel hierarchy: stand-alone (BA), strong (BS), and supporting (BP).

Computational predictions occupy the supporting tier: PP3 when algorithms predict a damaging effect, BP4 when they predict benign impact. This placement reflects appropriate caution. Computational evidence can contribute to classification but cannot establish pathogenicity or benign status independently. Multiple computational tools showing concordant predictions may strengthen the evidence, but the framework explicitly limits their weight. Variants classified primarily on computational grounds warrant flagging for reclassification as functional or clinical evidence emerges.

::: {#fig-conservation-scores layout-ncol=3}
![FIGURE PLACEHOLDER](../figs/part_1/ch04/03-box-acmg-amp.png)

Caption...
:::

:::


## Protein-Level Predictors {#sec-ch04-protein-predictors}

A diagnostic laboratory receives exome sequencing results for a 45-year-old woman with early-onset breast cancer and a family history suggesting hereditary cancer syndrome. Among hundreds of rare variants, one stands out: a missense change in *BRCA2* substituting glycine for arginine at a conserved position. Is this the explanation for her cancer, or an incidental finding? No previous case report exists for this exact variant. No functional assay has tested its effect. The question of whether this amino acid substitution disrupts *BRCA2* function determines whether her siblings should be tested and whether she qualifies for PARP inhibitor therapy. The clinical stakes could not be higher, yet the evidence available is entirely computational. Protein-level predictors attempt to answer such questions by encoding biological intuition about which amino acid changes matter.


### *SIFT*: Sequence Homology as Functional Constraint {#sec-ch04-sift}

Conservation scores can identify constrained positions, but they cannot distinguish which substitutions at those positions are tolerated. A position might be highly conserved overall yet accept certain amino acid changes that preserve function. For missense variants specifically, the relevant question is not whether the position is constrained but whether the specific amino acid substitution disrupts function. *SIFT* addresses this distinction by examining which amino acids have been accepted at each position across evolutionary history [@ng_sift_2003].

*SIFT* collects homologous protein sequences from diverse species, constructs a **multiple sequence alignment**, and examines which amino acids appear at each position across the alignment. Positions that are highly conserved (showing the same or similar amino acids across species) are predicted to be functionally important; substitutions introducing amino acids not observed at that position are predicted to be deleterious.

The method computes a normalized probability for each possible amino acid at each position based on the diversity observed in the alignment. The *SIFT* score for a substitution is the probability of observing the mutant amino acid, scaled by the position's overall diversity. Scores range from 0 to 1, with low scores (typically below 0.05) indicating predicted damage. A *SIFT* score of 0.01 for a particular missense variant indicates that the mutant amino acid is rarely or never observed at that position across the sequence family, suggesting functional constraint has prevented its fixation throughout evolution.

*SIFT's* simplicity is both its strength and its limitation. The method requires only protein sequence information and a database of homologs; it makes no assumptions about protein structure, physicochemistry, or mechanism of damage. This generality allows application to any protein with sufficient homologs in sequence databases. For proteins with few homologs, young gene families, or positions with limited alignment depth, predictions may be unreliable. The method captures only the evolutionary signal present in the alignment, missing functional constraints that arose recently or affect only a subset of species.


### *PolyPhen-2*: Integrating Structure and Sequence {#sec-ch04-polyphen}

*SIFT's* reliance on sequence alone ignores substantial information about how amino acid substitutions affect protein function. A glycine buried in a protein's hydrophobic core will disrupt structure differently than one on a surface loop. A substitution at a catalytic site matters more than one far from any functional region. *PolyPhen-2* extends sequence-based prediction by incorporating protein structure features and amino acid physicochemistry, recognizing that the same substitution can have different consequences depending on its structural context [@adzhubei_polyphen_2010].

The method uses a **naive Bayes classifier** trained to distinguish disease-causing mutations from neutral polymorphisms based on a collection of sequence-derived and structure-derived features. The feature set includes sequence conservation (similar to *SIFT*) but adds several structural descriptors when three-dimensional structure data is available: solvent accessibility (whether the position is buried or exposed), secondary structure context (α-helix, β-sheet, or random coil), and proximity to known functional sites. Amino acid physicochemical properties inform predictions about whether substitutions are conservative or radical. The Grantham distance, a measure of biochemical dissimilarity between amino acid pairs based on composition, polarity, and molecular volume, contributes to assessing substitution severity. *[Citation Needed]* Where Grantham distance derives from physicochemical properties, BLOSUM matrices capture empirical substitution frequencies observed across evolutionarily related proteins [@henikoff_amino_1992]. A glycine-to-arginine substitution (Grantham distance of 125) represents a far more radical change than a leucine-to-isoleucine substitution (Grantham distance of 5).

*PolyPhen-2* provides two models trained on different datasets: HumDiv, trained on disease-causing and neutral variants from protein sequence databases, and HumVar, trained on Mendelian disease mutations versus common human polymorphisms. The choice of training set affects score interpretation; HumVar produces more conservative predictions appropriate for clinical Mendelian disease variant classification, while HumDiv is more sensitive and may be preferable for research applications where missing a true positive is more costly than false positives.

*PolyPhen-2* scores range from 0 to 1, with higher scores indicating greater predicted deleteriousness. The output includes qualitative classifications (benign, possibly damaging, probably damaging) based on score thresholds. A *PolyPhen-2* score of 0.95 with a "probably damaging" classification indicates high confidence that the substitution disrupts protein function, though the clinical significance depends on additional evidence about the specific disease context.


### From Sequence to Function {#sec-ch04-sequence-to-function}

*PolyPhen-2*, *SIFT*, and similar tools answer a mechanistic question: does this amino acid substitution disrupt protein function? They assess whether the new residue fits the structural context, whether the position tolerates variation across species, and whether the physicochemical change is drastic. These are genuine molecular insights. A "probably damaging" designation from *PolyPhen-2* means the substitution likely impairs the protein's normal function, but the clinical significance of that impairment requires reasoning that protein-level predictors cannot provide.

Protein language models like *ESM-2* (@sec-ch12-esm-family) provide alternative approaches to variant effect prediction that learn evolutionary constraint from sequence alone, without explicit multiple sequence alignments. *ESM*-based variant scoring is examined in @sec-ch14-protein-vep, where zero-shot prediction paradigms avoid the limitations of supervised training on biased clinical labels


### Boundaries of Protein-Level Prediction {#sec-ch04-protein-boundaries}

Several fundamental boundaries constrain all protein-level predictors, and these boundaries are not merely technical inconveniences but reflect deep gaps in what sequence and structure analysis alone can reveal. Protein-level tools are restricted to missense variants; nonsense, frameshift, splice-altering, and non-coding variants lie entirely outside their scope. A patient's most important variant may be intronic or synonymous, yet protein-level predictors have nothing to say about it. This constraint is absolute: these methods analyze amino acid substitutions and cannot be extended to other variant types without fundamental redesign.

Protein-level predictors estimate impact on protein function without specifying the mechanism or clinical consequence. A variant predicted to damage function might impair enzymatic activity, disrupt protein folding, eliminate a binding interface, or alter stability. The clinical relevance depends on which function is affected and whether the phenotype results from **loss of function** or **gain of function**. A predicted-damaging variant in a tumor suppressor behaves very differently from one in an oncogene, yet protein-level predictors provide no information about this distinction. The same high score can indicate completely different clinical implications depending on biological context.

The terminology itself can mislead: "gain-of-function" sounds beneficial, yet these mutations cause some of the most severe human diseases. A gain-of-function variant does not improve the protein; it creates aberrant activity that the cell cannot regulate. In *FGFR3*, gain-of-function mutations cause the receptor to signal constitutively, driving achondroplasia by suppressing bone growth. In *PIK3CA*, activating mutations produce uncontrolled cell proliferation. In ion channels like *SCN1A*, gain-of-function can cause epileptic encephalopathy through neuronal hyperexcitability. These variants may preserve or even enhance protein structure and activity, precisely the opposite of what conservation-based predictors flag as damaging. A perfectly folded protein with enhanced catalytic activity will score as "tolerated" by methods designed to detect disruption, yet its clinical consequences may be devastating. Loss-of-function and gain-of-function mutations in the same gene can cause entirely different diseases: loss of *RET* function causes Hirschsprung disease (failed neural crest migration), while gain of *RET* function causes multiple endocrine neoplasia (tumor predisposition). Protein-level predictors cannot distinguish these mechanisms because they assess structural perturbation, not the direction of functional change.

These tools also provide no information about inheritance mode, **penetrance**, or expressivity. A strongly predicted-damaging variant in a gene with high tolerance to heterozygous loss may be clinically benign in carriers. Protein-level predictors cannot distinguish between a variant causing severe disease in homozygotes and one causing no disease at all when heterozygous. This distinction becomes critical when counseling families, where the mode of inheritance fundamentally changes recurrence risk and management recommendations.

Protein-level predictors inherit the training data biases present in their underlying databases. Disease mutations in training sets are enriched for severe, early-onset Mendelian conditions with clear inheritance patterns. Variants causing subtle effects, incomplete penetrance, or complex phenotypes may be systematically mispredicted. The well-studied genes that dominate training data may not generalize to poorly characterized genes where variants are most difficult to interpret.

*SIFT* and *PolyPhen-2* remain widely used in clinical practice and serve as features within more sophisticated ensemble methods. Their scores appear in diagnostic reports, contribute to ACMG-AMP classification criteria, and inform variant prioritization in research and clinical pipelines. Understanding their construction and limitations is essential for appropriate interpretation.


## *CADD* Framework {#sec-ch04-cadd}

The protein-level predictors and conservation scores examined above each capture one aspect of variant function, yet clinical interpretation requires weighing multiple lines of evidence simultaneously. A variant might fall in a conserved region, alter a moderately constrained amino acid, and overlap a predicted enhancer. How should these signals be combined? More fundamentally, how can we train a predictor when curated pathogenic variants number in the hundreds of thousands while the genome contains billions of possible mutations? These questions expose a fundamental tension: the variants we most need to interpret (rare, novel, never before seen) are precisely those for which training labels do not exist.

*CADD* addressed these challenges by reframing variant effect prediction as a large-scale machine learning problem [@kircher_general_2014; @rentzsch_cadd_2019]. The key insight was not better feature engineering or more sophisticated classification, but rather a reconceptualization of the labeling problem itself. Instead of training directly on small sets of known pathogenic versus benign variants, which are scarce and biased toward certain genes and variant types, *CADD* contrasts variants that have survived purifying selection in the human lineage with matched simulated variants that could have occurred but did not. This evolutionary proxy strategy transforms the labeling problem, yielding millions of training examples where curated datasets provide thousands.


### Evolutionary Proxy Training and Label Sources {#sec-ch04-cadd-training}

The conceptual foundation of *CADD* rests on constructing training labels from evolutionary signal rather than clinical curation. The method builds two proxy classes of variants that serve as training labels, each designed to approximate a category that cannot be observed directly. Understanding these label sources is essential because the same proxy labeling strategies reappear throughout genomic machine learning, including in the foundation models discussed in @sec-ch10-fm-principles and @sec-ch08-pretraining.

::: {#fig-cadd-training layout-ncol=3}
![FIGURE PLACEHOLDER A](../figs/part_1/ch04/04-A-fig-cadd-training.png)

![FIGURE PLACEHOLDER B](../figs/part_1/ch04/04-B-fig-cadd-training.png)

![FIGURE PLACEHOLDER C](../figs/part_1/ch04/04-C-fig-cadd-training.png)

[Essential] Three-panel conceptual figure. Panel A (Proxy-Neutral): Human-derived alleles fixed since human-chimpanzee split; these variants survived selection, representing tolerated changes. Show evolutionary tree with human branch highlighted. Panel B (Proxy-Deleterious): Simulated variants matching human mutational processes (trinucleotide context); these represent possible-but-not-observed mutations enriched for deleterious effects. Show simulation schematic with mutation spectrum. Panel C (Classification): SVM learning to distinguish classes based on annotation features; output is "evolutionary tolerance" score, not pathogenicity directly.
:::

The proxy-neutral class consists of variants that have been tolerated by purifying selection. *CADD* draws these from sequence differences that arose on the human lineage since the split from chimpanzees and became fixed or nearly fixed in modern humans. These are identified by their **derived allele frequency**: alleles that differ from the inferred ancestral state (typically determined by comparison to chimpanzee and other great ape sequences) and are present at very high frequency in human populations. Because these derived alleles have persisted over millions of years of evolution, most are presumed to be neutral or only weakly deleterious. This is not a perfect proxy: some observed alleles are genuinely pathogenic, particularly those with incomplete penetrance, late onset, or context-dependent effects. The proxy-neutral class is, on average, substantially enriched for tolerated alleles relative to a random sample of possible mutations.

The proxy-deleterious class is constructed by simulating mutations across the genome according to realistic mutational processes. The simulation matches local sequence context (typically using trinucleotide frequencies to capture the strong dependence of mutation rates on flanking bases). CpG dinucleotides, for example, have elevated mutation rates due to spontaneous deamination of methylated cytosines, and the simulation accounts for this by generating more CpG transitions. Regional variation in mutation rates, driven by factors including replication timing and chromatin state, is similarly incorporated.

The logic underlying this construction is subtle but powerful. Simulated variants represent changes that could plausibly occur under human mutational processes but are generally not observed at high frequency in population databases. The proxy-deleterious class as a whole is enriched for alleles disfavored by selection, because the set of possible mutations includes many that disrupt conserved elements, alter protein function, or perturb regulatory sequences. By contrasting this set with the proxy-neutral class (high derived allele frequency variants that survived selection), *CADD* learns to recognize the annotation signatures that distinguish variants under purifying selection from those that have been tolerated.

This proxy labeling strategy has important implications. *CADD* does not learn to distinguish pathogenic from benign variants directly; it learns to distinguish tolerated-by-evolution from possible-but-not-observed. The assumption is that variants depleted by selection are enriched for functional effects and therefore enriched for disease relevance. This assumption is often correct but introduces a systematic gap between what *CADD* measures (evolutionary tolerance) and what clinicians need (disease causation).


### Feature Integration {#sec-ch04-cadd-features}

Conservation scores measure evolutionary constraint. Protein-level predictors assess amino acid substitution severity. Regulatory annotations mark biochemically active regions. Each signal captures genuine biology, but no single annotation captures the full complexity of variant function. A missense variant in a constrained gene might be tolerated if it falls in an unconserved loop region; a synonymous variant might be pathogenic if it disrupts splicing. The power of *CADD* lies in learning how these heterogeneous signals interact, upweighting annotations that distinguish proxy-deleterious from proxy-neutral variants and downweighting those that do not.

*CADD* integrates more than 60 features, far exceeding what explicit combination rules could accommodate. Gene model annotations describe the local transcript and coding context of each variant. The most fundamental is the predicted sequence consequence: whether a variant is synonymous, missense, nonsense, frameshift, splice-site disrupting, or located in untranslated or intronic regions. Distance to exon-intron boundaries and proximity to canonical splice sites provide additional context. Gene-level attributes including constraint metrics (pLI, LOEUF from gnomAD) quantify how tolerant each gene is to damaging variation.

These constraint metrics derive from a fundamental concept in human genetics: **haploinsufficiency**. Most genes tolerate heterozygous loss because a single functional copy produces sufficient protein for normal function. Haploinsufficient genes are different; they require both copies to maintain adequate protein levels, making heterozygous loss-of-function variants pathogenic. The probability of loss-of-function intolerance (pLI) estimates the likelihood that a gene falls into this category based on the observed depletion of truncating variants in population databases. *[Citation Needed]* A pLI approaching 1.0 indicates that loss-of-function variants are nearly absent from healthy individuals, strong evidence that such variants cause disease or embryonic lethality. LOEUF (loss-of-function observed/expected upper bound fraction) refines this estimate by quantifying the ratio of observed to expected truncating variants with confidence bounds. Genes like *MECP2* (Rett syndrome) and many transcription factors exhibit strong haploinsufficiency; genes encoding metabolic enzymes often tolerate 50% reduction without clinical consequence. By incorporating these gene-level constraint metrics, *CADD* can weight identical variants differently depending on whether they occur in dosage-sensitive or dosage-tolerant genes.

*CADD* draws on three families of evidence. Evolutionary constraint from phyloP, GERP, and phastCons provides the conservation signals described earlier; incorporating multiple metrics computed from different alignments captures complementary aspects of selective pressure. For coding variants, amino acid substitution predictions from *SIFT* and *PolyPhen-2* assess structural and functional disruption, supplemented by physicochemical properties, Grantham distances, and domain annotations from Pfam. Non-coding variants receive context from ENCODE and Roadmap Epigenomics annotations capturing chromatin accessibility, histone modifications, and transcription factor binding.

Additional features capture local sequence context (GC content, CpG density), genomic architecture (segmental duplications, repetitive elements), and chromosomal position. The model learns how to weight and combine these heterogeneous signals from the data rather than from expert specification.

The feature engineering approach reaches a performance ceiling because manually designed features encode only what biologists already know. This limitation motivates the shift to learned representations examined in @sec-ch05-embeddings for tokenization strategies and @sec-ch09-feature-extraction for foundation model features. The contrast between hand-crafted features and learned representations illuminates the paradigm shift toward foundation models discussed in @sec-ch10-task-specific


### Model Architecture and Scoring {#sec-ch04-cadd-scoring}

Raw classifier outputs are not directly interpretable as probabilities or biological effect sizes. A clinician presented with a **support vector machine** decision value has no intuitive understanding of what that number means. To address this, *CADD* defines PHRED-scaled scores based on the rank of each variant among all possible single-nucleotide substitutions in the reference genome. A scaled score of 10 indicates that a variant falls in the top 10% of predicted deleteriousness. A score of 20 indicates the top 1%, and a score of 30 indicates the top 0.1%. This rank-based transformation ensures comparability across *CADD* versions and provides immediate interpretability: a clinician can understand that a score of 25 places this variant among the most extreme 0.3% of possible mutations without needing to understand the underlying classifier.

*CADD's* classifier operates on the high-dimensional feature vector assembled for each variant. The original *CADD* model used a linear support vector machine trained to discriminate proxy-neutral and proxy-deleterious variants based on approximately 30 million training examples. The choice of a linear model was deliberate and pragmatic: with tens of millions of training examples and dozens of features, a linear classifier is computationally tractable while capturing the main structure of the classification problem. *CADD* version 1.7 transitioned from the SVM to logistic regression, which offers comparable discriminative performance while providing native probability outputs and faster scoring of new variants. *[Citation Needed]*

In clinical laboratories, *CADD* scaled scores commonly serve as filters to enrich for potentially pathogenic variants. Typical thresholds range from 15 (top 3%) to 20 (top 1%) or higher. Variants with scores at or above 20 are considered moderately high deleteriousness candidates, while scores at or above 30 are frequently interpreted as strongly enriched for functional impact. A diagnostic pipeline might use *CADD* greater than or equal to 20 as an initial filter, reducing 25,000 exome variants to several hundred candidates for expert review. These filters serve as prioritization tools that reduce the variant burden to a manageable number rather than as definitive pathogenicity calls.


### Evolutionary Proxy Problem {#sec-ch04-proxy-problem}

*CADD's* training signal derives entirely from evolutionary history: variants that survived natural selection versus those depleted by it. This creates a fundamental mismatch with clinical questions. Evolution optimizes for reproductive fitness across populations and timescales; clinical genetics asks whether a specific variant causes disease in a specific patient.

The mismatch manifests in predictable ways. Constraint varies across tissues and developmental stages, but *CADD* assigns a single genome-wide score. A variant in a deeply conserved neural enhancer receives a high score regardless of whether the patient presents with a cardiac or neurological phenotype. The constraint is real, but its clinical relevance depends on context *CADD* cannot assess.

More fundamentally, purifying selection only removes variants that reduce fitness before or during reproductive years. Late-onset diseases like Alzheimer's or many cancers exert minimal selective pressure; variants causing these conditions may show little evolutionary depletion despite clear pathogenicity. Gain-of-function mutations present an even sharper challenge. A variant that creates a novel toxic function has no evolutionary precedent to deplete; *CADD's* framework cannot recognize pathogenic mechanisms that evolution never encountered.

These limitations are not failures of implementation but consequences of the proxy relationship between evolutionary constraint and disease causation. *CADD* measures what evolution preserved and eliminated. Whether that corresponds to clinical pathogenicity depends on whether the disease mechanism falls within evolution's purview.


## Other Ensemble Methods {#sec-ch04-ensemble-methods}

The clinical geneticist focused exclusively on rare missense variants in Mendelian disease faces a different optimization problem than the researcher screening the entire genome for regulatory variants. *CADD's* genome-wide generality may sacrifice accuracy within specific variant classes, accepting modest performance everywhere to achieve coverage anywhere. For diagnostic laboratories where missense variants in known disease genes dominate the caseload, specialized ensemble methods offer an alternative: models trained directly on curated disease variants, optimized for the specific task rather than general prioritization. This tension between generality and specialization recurs throughout computational biology, and different clinical contexts demand different tradeoffs.

Ensemble principles for combining multiple predictors connect to deep ensemble approaches for uncertainty quantification in @sec-ch23-deep-ensembles. Integration strategies that combine classical scores with foundation model predictions are examined in @sec-ch14-combining-evidence

### *REVEL* {#sec-ch04-revel}

A missense variant in a known disease gene presents a narrower interpretive challenge than an arbitrary variant anywhere in the genome. The variant is protein-coding, the gene has established disease associations, and the question is specifically whether this amino acid substitution is pathogenic. This focused scope permits a different training strategy than *CADD's* evolutionary proxy approach.

*REVEL* represents a missense-specific ensemble predictor widely used in clinical laboratories [@ioannidis_revel_2016].  Rather than training on evolutionary proxy labels, *REVEL* directly discriminates pathogenic missense variants (curated from HGMD and other disease databases) from rare putatively neutral missense variants observed in population datasets.

*REVEL* integrates predictions from a panel of individual tools: *SIFT*, *PolyPhen-2*, *PROVEAN*, *MutationAssessor*, *FATHMM*, GERP++, phyloP, and phastCons, among others. A **random forest** model learns to combine these scores, weighting each according to its discriminative power for the pathogenic versus neutral classification. The training set is carefully constructed to avoid label contamination, excluding variants present in both disease and population databases.

*REVEL* scores range from 0 to 1, with higher values implying greater pathogenicity likelihood. Common interpretation thresholds treat scores above 0.5 as supporting evidence for pathogenicity, with scores above 0.75 providing stronger evidence. *REVEL* is restricted to missense single-nucleotide variants, making it more specialized than *CADD* but often more accurate within its scope. This specialization reflects a deliberate choice: by giving up coverage of non-coding and structural variants, *REVEL* gains the ability to train on directly relevant labels rather than evolutionary proxies.


### *M-CAP* {#sec-ch04-mcap}

Diagnostic laboratories evaluating potential Mendelian disease variants face asymmetric consequences for errors. Calling a benign variant pathogenic can lead to unnecessary surgeries, psychological burden, and inappropriate cascade testing of family members. Missing a pathogenic variant delays diagnosis but typically permits later reclassification as evidence accumulates. This asymmetry argues for prioritizing specificity over sensitivity in clinical settings.

*M-CAP* addresses specifically the challenge of distinguishing pathogenic from benign rare missense variants in Mendelian disease contexts, with explicit attention to this asymmetry [@jagadeesh_m-cap_2016]. The method uses **gradient boosting** on a feature set including conservation scores, protein structure features, and amino acid properties.

*M-CAP* was explicitly designed to minimize false positives while maintaining reasonable sensitivity. The developers tuned their classifier to achieve less than 5% false positive rate on known pathogenic variants, accepting some reduction in sensitivity as a tradeoff. This design philosophy differs from methods that balance sensitivity and specificity equally, reflecting *M-CAP's* intended use in diagnostic settings where false positive pathogenicity calls have serious consequences.


### Comparison and Selection {#sec-ch04-ensemble-comparison}

No single ensemble method dominates across all variant types and clinical contexts. *CADD* provides the broadest coverage (genome-wide, all variant types) but may sacrifice accuracy within specific variant classes to achieve this generality. *REVEL* often outperforms *CADD* on missense-only benchmarks, reflecting its focused training objective. *M-CAP* prioritizes specificity over sensitivity, appropriate for clinical settings where avoiding false positives is paramount.

Clinical variant interpretation typically incorporates multiple computational scores rather than relying on any single predictor. Different scores may agree, providing stronger evidence, or disagree, flagging variants requiring careful manual review. A variant with *CADD* greater than or equal to 25, *REVEL* greater than or equal to 0.8, and *M-CAP* "possibly pathogenic" presents a consistent computational picture; one where *CADD* and *REVEL* disagree prompts closer examination of the underlying features. Understanding the construction, training data, and intended use case of each method is essential for appropriate interpretation. The integration of these scores into clinical workflows is examined in detail in @sec-ch25-clinical-risk and @sec-ch26-rare-disease, where computational evidence must be weighed alongside functional studies, segregation data, and clinical presentation.

::: {#fig-ensemble-performance}
![FIGURE PLACEHOLDER](../figs/part_1/ch04/05-fig-ensemble-performance.png)

[High] ROC curves (or precision-recall curves) comparing *CADD*, *REVEL*, and *M-CAP* on a held-out benchmark of missense variants. Include curves for individual component scores (*SIFT*, *PolyPhen-2*, phyloP) to show improvement from integration. Mark operating points corresponding to common clinical thresholds (*CADD* ≥ 20, *REVEL* ≥ 0.75, *M-CAP* "possibly pathogenic"). Annotate sensitivity and specificity at each threshold. Include note about benchmark circularity caveats.
:::


## Circularity and Ascertainment Bias {#sec-ch04-circularity}

A diagnostic laboratory classifies a novel missense variant as pathogenic based partly on its high *CADD* score. That classification enters ClinVar. Two years later, a benchmarking study evaluates *CADD* performance on ClinVar pathogenic variants and reports excellent accuracy. Is the high performance genuine, or has the benchmark been contaminated by the predictor's own influence on the labels it is evaluated against? This scenario illustrates the first of the pervasive problems affecting all variant effect predictors: circularity between scores and clinical databases. Compounding this circularity is **ascertainment bias** in available training and testing variants. These issues do not invalidate classical scores, but they counsel appropriate humility about performance claims and careful attention in both development and application. The broader methodological concerns around benchmark design and confounding are examined in @sec-ch22-confounding and @sec-ch20-benchmarks.

::: {#fig-circularity-problem}
![FIGURE PLACEHOLDER](../figs/part_1/ch04/06-fig-circularity-problem.png)

[High] Circular diagram illustrating the feedback loop between computational predictors and clinical databases. Show cycle: (1) Computational score (e.g., high *CADD*) influences clinical classification; (2) Classified variant enters ClinVar as "Pathogenic"; (3) Benchmarking study evaluates *CADD* on ClinVar variants; (4) High benchmark performance encourages clinical adoption; (5) Return to step 1. Indicate intervention points: temporal holdouts, functional assay ground truth, prospective evaluation. Use visual metaphor of self-reinforcing spiral.
:::


### Circularity Problem {#sec-ch04-circularity-definition}

ClinVar and similar clinical databases increasingly incorporate computational predictions as evidence supporting variant classification. When a clinical laboratory classifies a variant as pathogenic, the *CADD* score, *PolyPhen-2* prediction, or other computational evidence may have contributed to that determination. When *CADD* is subsequently evaluated on ClinVar pathogenic variants, its performance is artificially inflated: the benchmark contains variants that were labeled partly because *CADD* assigned them high scores. The predictor appears to perform well because it was already part of the labeling process.

This circularity operates through multiple pathways. Direct use occurs when clinical laboratories explicitly cite computational scores in their classifications. Indirect influence arises when computational predictions shape clinical suspicion, affecting which variants receive functional testing or expert review. Selection bias in benchmark construction can compound the problem: benchmark creators may preferentially include variants with strong computational evidence, excluding ambiguous cases that would provide a more stringent test.

The consequence is that benchmark performance may overestimate real-world utility. A method that has been widely adopted will appear to perform well on benchmarks populated by variants classified using that method, even if its true discriminative power is more limited. This concern applies to all established computational tools, including conservation scores, protein-level predictors, and ensemble methods. The more influential a method becomes, the more its benchmark performance becomes self-reinforcing.

Addressing circularity requires careful benchmark construction. Temporal holdouts (using only classifications made before a method's widespread adoption) can reduce but not eliminate the problem. Functional assays that directly measure variant effects provide ground truth independent of computational predictions but are available for only a small fraction of variants. Prospective evaluation on newly classified variants offers the cleanest test but requires patience and ongoing data collection. The foundation model evaluations discussed in @sec-ch14-vep-fm face these same challenges, and the confounding issues examined in @sec-ch22-confounding show how these problems persist and evolve as methods become more sophisticated.


### Ascertainment Bias {#sec-ch04-ascertainment}

Beyond circularity lies a more fundamental problem: the variants available for training and evaluation represent a systematically skewed sample of disease-causing mutations. Clinical databases are dominated by variants in well-studied genes, particularly those causing severe Mendelian phenotypes with clear inheritance patterns. Protein-coding variants are overrepresented because they are easier to interpret and more often tested. Variants in genes associated with common diagnostic panels appear frequently; those in rarely tested genes are sparse.

This ascertainment bias shapes what models learn and how they perform. A predictor trained predominantly on variants in constrained genes may learn that gene-level constraint is the primary signal for pathogenicity. When applied to variants in less constrained genes (where pathogenic variants also occur, but less frequently), the model may systematically underestimate risk. Similarly, models trained on European-ancestry samples may encode population-specific patterns that transfer poorly to other populations, compounding health disparities by providing less accurate predictions for underrepresented groups.

The consequences extend to evaluation. Benchmark variants inherit the ascertainment biases of their source databases. Strong performance on benchmark sets may not translate to the rare genes, unusual variant types, or underrepresented populations encountered in real clinical practice. Variants that are "easy" to classify (stop-gains in highly constrained genes) are overrepresented in benchmarks, while diagnostically challenging variants (missense variants in moderate-constraint genes, non-coding variants) are underrepresented. The benchmark tells us how well the method performs on the easy cases; it may reveal little about the hard cases where computational assistance is most needed.

Ascertainment bias in sequencing creates blind spots in difficult genomic regions (@sec-ch01-difficult). The circularity between training labels and evaluation benchmarks affects both classical and modern methods, as examined systematically in @sec-ch22-label-circularity. Benchmark construction strategies that mitigate these issues appear in @sec-ch20-benchmark-construction

### Implications for Clinical Use {#sec-ch04-clinical-implications}

These limitations do not render classical scores useless, but they counsel appropriate humility in interpretation. Computational predictions provide one line of evidence among several in variant interpretation. Strong scores in expected directions support clinical suspicion; unexpected scores prompt careful review. No computational score should override clear clinical or functional evidence, and borderline scores in complex cases may warrant agnosticism rather than confident prediction.

The ACMG-AMP framework for variant classification appropriately treats computational predictions as supporting evidence (PP3 for predictions supporting pathogenicity, BP4 for predictions supporting benign status) rather than standalone criteria [@richards_standards_2015]. Multiple lines of computational evidence may be combined, but the weight assigned should reflect the limitations outlined here. Variants classified primarily on computational grounds should be flagged for potential reclassification as additional evidence emerges. The ACMG-AMP framework's integration of computational evidence is detailed in @sec-ch26-acmg-amp for complete clinical workflows. Calibration of computational scores to ACMG evidence strength levels is examined in @sec-ch14-acmg-mapping for foundation model approaches.


## Limitations of the Feature Engineering Paradigm {#sec-ch04-feature-limitations}

Classical variant effect prediction achieved substantial success in prioritizing potentially pathogenic variants and established conceptual foundations that persist in modern methods. The integration of diverse annotations, use of evolutionary signals as proxy labels, and genome-wide precomputation all anticipate contemporary practices. Yet a fundamental tension remains: manually designed features encode only what biologists already know, and the complexity of genotype-phenotype relationships exceeds what explicit feature engineering can capture. The features are not wrong; they are incomplete in ways that cannot be remedied by adding more of the same.


### Feature Ceiling {#sec-ch04-feature-ceiling}

Feature-engineered methods encode human knowledge about which genomic properties matter for variant function. Conservation scores capture evolutionary constraint; protein-level predictors encode structural intuitions; regulatory annotations mark biochemically active regions. This encoded knowledge is valuable but necessarily incomplete. Biologists cannot specify all relevant patterns in advance, and the interactions between features may be too complex for simple combination rules to capture.

The performance of feature-engineered methods is therefore bounded by the quality and completeness of the features themselves. Adding more features provides diminishing returns as the most informative signals are exhausted. Interactions between features (a variant in a conserved enhancer within a constrained gene) may require explicit specification or rely on simple combination rules that miss nonlinear relationships. The linear SVM at the heart of *CADD* cannot represent the complex feature interactions that characterize biological regulation.


### Limited Context {#sec-ch04-limited-context}

Classical features typically describe variants in isolation or with minimal context. Conservation scores examine each position independently. Protein-level predictors consider amino acid substitutions without full protein context. Gene-level features apply uniformly across entire genes regardless of position-specific effects. This limited context prevents classical methods from learning the complex sequence patterns that determine variant effects.

A variant disrupting a critical transcription factor binding motif may escape detection if the motif is not annotated, even though the underlying sequence pattern is learnable from data. A missense variant at a protein-protein interface may be more damaging than one in a loop region, but capturing this distinction requires understanding protein structure and interactions that feature engineering incompletely represents. The local sequence context surrounding a variant often matters, but which contexts matter and how requires learning from data rather than specification by experts.


### Persistent Gap Between Measurement and Need {#sec-ch04-measurement-gap}

Each classical method measures something related to but distinct from clinical pathogenicity. Conservation scores measure evolutionary constraint. Protein-level predictors measure functional disruption. *CADD* measures evolutionary tolerance. Each provides genuine biological signal, but none directly answers the clinical question: will this variant cause disease in this patient?

This gap is not merely a limitation of specific methods but reflects something deeper about the variant interpretation problem. The clinically relevant question depends on context (which tissue, which genetic background, which environmental exposures) that no current method captures. Even perfect prediction of functional disruption would not resolve questions of penetrance, expressivity, and disease mechanism. Classical methods provide important evidence for variant interpretation, but they cannot substitute for the integrative clinical reasoning examined in @sec-ch25-clinical-risk.


### From Features to Representations {#sec-ch04-features-to-representations}

The transition from *CADD* to deep learning methods represents a fundamental shift in how variant effect prediction is approached: from encoding biological knowledge as hand-crafted features to learning representations directly from sequence data. Where *SIFT* computes conservation from explicit multiple sequence alignments, *ESM-2* learns similar signals implicitly through masked language modeling on protein sequences. Where *PolyPhen-2* engineers features from solved protein structures, *AlphaFold2* learns geometric constraints from evolutionary covariation (@sec-ch12-protein-lm). The tokenization strategies and embedding approaches that enable this representation learning are detailed in @sec-ch05-embeddings. The shift is real and consequential.

Yet learned representations do not automatically overcome the limitations that constrain classical methods. The circularity between training labels and evaluation benchmarks affects transformer-based predictors exactly as it affects logistic regression. A model trained on ClinVar pathogenic variants inherits ClinVar's ascertainment biases whether it uses 100 features or 100 million parameters. Rare variants remain difficult because they are rare in training data. Novel mechanisms remain invisible because no labeled examples exist. The variant effect prediction problem is fundamentally difficult, and methodology alone cannot resolve difficulties rooted in data availability and biological complexity. The zero-shot scoring paradigm (@sec-ch14-zeroshot-supervised) offers a partial escape from label circularity by deriving variant scores from unsupervised pretraining objectives rather than explicit pathogenicity annotations, though this approach introduces its own assumptions about what pretraining captures.

Classical methods remain valuable: as baselines that establish the performance floor modern methods must exceed, as interpretable components when understanding matters as much as prediction, and as reminders of what the field has learned about which signals carry predictive information. Foundation models have advanced variant effect prediction (@sec-ch14-vep-fm), but honest evaluation requires understanding what classical methods achieved and where all approaches, classical and modern alike, continue to struggle. The evaluation methodology required to fairly assess both classical and learned approaches is detailed in @sec-ch21-eval, with genomics-specific metric considerations in @sec-ch21-metrics-genomic-tasks.