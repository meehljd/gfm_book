# Part V: Evaluation and Trust {.unnumbered}

Evaluating genomic models presents challenges that distinguish this domain from natural language processing or computer vision. Biological sequences contain evolutionary history: a model tested on homologous sequences may appear to generalize when it has merely memorized. Population structure creates spurious associations: a variant predictor may learn ancestry rather than pathogenicity. Nested functional hierarchies obscure what models actually capture: strong performance on common variants provides no guarantee of accuracy on the rare variants that drive most clinical decisions. Standard machine learning evaluation practices, developed for domains where training and test examples are approximately independent and identically distributed, become actively misleading when applied to genomic data without careful adaptation.

Rigorous evaluation determines whether genomic foundation models deliver on their promises. Established benchmarks (@sec-ch20-benchmarks) across protein, DNA, regulatory, and clinical domains require careful examination of their construction and limitations, distinguishing meaningful signal from benchmark-specific artifacts. Principles for using benchmarks appropriately (@sec-ch21-eval), including data splitting, metric selection, and statistical testing, produce trustworthy conclusions rather than inflated claims.

Systematic biases pervade genomic datasets (@sec-ch22-confounding): population stratification confounds genotype with ancestry, batch effects encode technical rather than biological variation, and hidden correlations tempt models to exploit patterns without learning genuine biology. Calibration and uncertainty quantification (@sec-ch23-uncertainty) determine whether model outputs can inform decisions or require careful reinterpretation. Moving beyond black-box prediction toward mechanistic understanding (@sec-ch24-interpretability) requires distinguishing faithful explanations that accurately reflect model computation from plausible explanations that merely satisfy human intuition. This critical toolkit enables rigorous evaluation of genomic AI claims and responsible deployment in research and clinical settings.