# Classical Variant Prediction {#sec-vep-classical}

Conservation scores measure evolutionary constraint, not disease relevance. Protein-level predictors estimate structural disruption, not clinical pathogenicity. Splice site algorithms identify sequence motifs, not functional consequences. Every classical variant effect predictor measures a proxy for what clinicians actually need to know: will this variant cause disease in this patient? The gap between measurable signal and clinical question is irreducible. Evolutionary conservation reflects reproductive fitness, not human health; protein structure does not determine disease penetrance; and splice motifs do not guarantee splicing outcomes. Classical methods achieve what they achieve by combining multiple imperfect proxies, hoping that their convergence approximates clinical truth.

This chapter examines the conceptual foundations and practical methods that dominated variant interpretation before the foundation model era. The trajectory traces from single-signal predictors through increasingly sophisticated ensemble methods. Conservation scores like PhyloP and GERP quantify purifying selection across evolutionary time, identifying positions where variation is depleted relative to neutral expectations. Protein-level tools like SIFT and PolyPhen assess amino acid substitutions through sequence conservation and structural features. Splice predictors identify the sequence motifs that mark intron-exon boundaries. Each approach captures genuine biological signal, but each also fails in characteristic ways: conservation misses recently evolved human-specific functions, protein predictors cannot assess non-coding variants, splice algorithms miss cryptic sites and tissue-specific regulation.

The field's response was to develop integrative methods that combine multiple signals into unified scores. Combined Annotation-Dependent Depletion (CADD) receives particular attention here because it introduced design patterns that recur throughout genomic machine learning: using evolutionary signals as proxy labels, training on large-scale genomic data, integrating dozens of diverse annotations, and precomputing scores genome-wide for downstream reuse. CADD and its successors, including REVEL, PrimateAI, and M-CAP, remain in active clinical use today. Understanding their construction and limitations illuminates both what classical methods achieved and why the field ultimately moved toward the learned representations examined in the following chapter.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion:** The Variant Prioritization Funnel. Diagram showing how computational filters progressively reduce variant burden from millions of raw variants to tens of candidates for expert review. Starting panel shows approximately 4-5 million variants in a typical genome; subsequent panels show filtering by population frequency (removing common variants), consequence prediction (prioritizing coding and splice variants), conservation scores, and ensemble predictors like CADD. Final panel shows the handful of variants requiring manual curation. Annotate typical numbers at each stage to make the reduction concrete.
:::


## Conservation-Based Approaches

A clinical geneticist evaluating a novel intronic variant faces an immediate problem: no functional annotation exists for most of the genome, and no clinical database has seen this specific change before. The variant lies outside any protein-coding region, no regulatory element overlaps it, and the patient's phenotype offers no clear mechanistic hypothesis. Yet one source of information spans the entire genome and predates any experimental annotation by billions of years. If a genomic position has remained unchanged across species separated by hundreds of millions of years of evolution, mutations at that position are likely to be deleterious. **Natural selection has already performed the largest functional screen imaginable, running experiments across countless organisms over evolutionary time, and conservation scores quantify the results.**

### Measuring Evolutionary Constraint

The logic of conservation is straightforward: if a position matters for survival or reproduction, mutations there will be removed by selection before they can spread through the population. Quantifying this signal requires comparing sequences across species to identify positions where substitutions occur less frequently than expected under neutral evolution. **Conservation scores** translate this evolutionary signal into numerical values that can inform variant interpretation.

**PhyloP** scores quantify the deviation of observed substitution rates from neutral expectation at individual positions [@siepel_phastcons_2005]. The score is computed by comparing the observed pattern of bases at each alignment column against a neutral evolutionary model (typically fit to ancestral repeat sequences that are assumed to evolve without selective constraint). Positive phyloP scores indicate conservation, meaning evolution is slower than expected under neutrality. Negative scores indicate acceleration, suggesting faster evolution that may reflect positive selection. A phyloP score of 2 indicates that the observed base is approximately 100-fold more conserved than expected under neutrality, providing strong evidence that mutations at this position have been systematically removed by selection.

**Genomic Evolutionary Rate Profiling (GERP)** takes a complementary approach by estimating "rejected substitutions" at each position: the number of substitutions that would have been expected under neutrality but are absent from the observed alignment [@davydov_gerp_2010]. Large positive GERP scores indicate strong constraint. For a position conserved across 30 mammalian species, a GERP score of 5 implies that approximately five substitutions were rejected by selection over mammalian evolution. This interpretation connects directly to the biological process of purifying selection but depends on accurate neutral rate estimation and alignment quality.

**PhastCons** provides element-level rather than position-level conservation by identifying contiguous stretches of constrained sequence [@siepel_phastcons_2005]. Using a hidden Markov model, phastCons classifies each position as belonging to a conserved or non-conserved state, then outputs the posterior probability of conservation. The resulting scores are smoother than position-level metrics, capturing functional elements that span multiple nucleotides even when individual positions show moderate conservation. This element-level view proves particularly valuable for identifying regulatory sequences where the overall constraint matters more than any single nucleotide.

### What Conservation Measures Versus What Clinicians Need

Conservation scores measure evolutionary constraint: the degree to which a position has resisted substitution over millions of years. This is not the same as clinical relevance. A position can be evolutionarily constrained for functions unrelated to human disease, or clinically important despite modest conservation. The assumption underlying conservation-based interpretation is that positions under strong constraint are more likely to be functionally important and therefore more likely to cause disease when mutated. This assumption is often correct but not universally so.

The clinician wants to know: will this variant cause disease in my patient? Conservation provides indirect evidence: this position has been important for organismal fitness across evolutionary time. The gap between these questions creates interpretive challenges. A variant at a highly conserved position in a gene with no known disease association provides evolutionary evidence of functional importance but no direct path to clinical interpretation. Conversely, a variant at a modestly conserved position in a well-established disease gene may be clinically significant despite weak conservation signal.

### Clinical Application and Boundaries

Conservation scores prove particularly valuable for non-coding variant interpretation, where direct functional annotations are often incomplete or absent. A deeply conserved intronic position likely participates in splicing regulation, gene expression control, or other functional processes even if no explicit annotation overlaps it. Under ACMG-AMP guidelines for variant classification, strong conservation provides computational evidence (the PP3 criterion) supporting pathogenicity [@richards_standards_2015]. A variant falling at a position with phyloP greater than 2 and GERP greater than 4 carries significantly more weight than one at an unconserved position, even when no other annotation is available. These scores remain central to clinical variant interpretation workflows, as examined in @sec-clinical-risk, where they contribute evidence alongside population frequency, functional studies, and segregation data.

The boundaries of conservation-based approaches are equally important to recognize, and these boundaries are not merely technical inconveniences but reflect fundamental gaps in what evolutionary signal can reveal. Conservation requires evolutionary time to accumulate signal. Recently evolved functional elements, including human-specific regulatory sequences and primate-specific genes, may show little conservation despite genuine function. A position can be functionally critical in humans yet unconserved because the function arose too recently for selection to leave a detectable signature. The 3% of the human genome that shows evidence of human-specific function since the human-chimpanzee split presents exactly this challenge: important to human biology, yet invisible to conservation metrics.

Conservation reflects the aggregate of selective pressures across the species in the alignment, which may differ from the specific functional role in humans. A position conserved for its role in neural development across vertebrates may be less constrained for immune function, which evolves more rapidly. Lack of conservation does not prove neutrality; it may simply indicate rapid evolution under positive selection or lineage-specific function.

Conservation scores also face technical challenges from alignment quality. In repetitive regions, segmental duplications, and rapidly evolving gene families, reliable alignments may be impossible to construct, leaving conservation scores undefined or unreliable precisely where variant interpretation is most difficult. The HLA region, immunoglobulin loci, and centromeric sequences are clinically important yet systematically difficult to assess by conservation. **The regions most difficult to interpret computationally are frequently those of greatest clinical interest.**

These boundaries do not diminish the value of conservation; they define where that value applies. Conservation provides information largely orthogonal to population frequency (which reflects recent human history rather than deep evolutionary constraint) and to functional genomics annotations (which capture biochemical activity rather than selective importance). The integrative methods discussed later in this chapter combine conservation with these other signals to achieve better performance than any single source. Protein language models, examined in @sec-protein-lm, learn conservation-like signals directly from sequence data without requiring explicit alignments, potentially addressing some technical limitations while introducing their own assumptions about what constitutes functional constraint.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion:** Conservation Score Interpretation. Multi-panel figure showing: (A) Multiple sequence alignment across vertebrate species at a constrained position versus a neutral position, with corresponding phyloP scores annotated; (B) Distribution of GERP scores across the genome, highlighting the long tail of highly conserved positions that represent candidate functional elements; (C) Example of a deeply conserved intronic element with a clinical variant, showing how conservation provides evidence in the absence of other annotations.
:::


## Protein-Level Predictors

A diagnostic laboratory receives exome sequencing results for a 45-year-old woman with early-onset breast cancer and a family history suggesting hereditary cancer syndrome. Among hundreds of rare variants, one stands out: a missense change in *BRCA2* substituting glycine for arginine at a conserved position. Is this the explanation for her cancer, or an incidental finding? No previous case report exists for this exact variant. No functional assay has tested its effect. The question of whether this amino acid substitution disrupts *BRCA2* function determines whether her siblings should be tested and whether she qualifies for PARP inhibitor therapy. **The clinical stakes could not be higher, yet the evidence available is entirely computational.** Protein-level predictors attempt to answer such questions by encoding biological intuition about which amino acid changes matter.

### SIFT: Sequence Homology as Functional Constraint

Conservation scores can identify constrained positions, but they cannot distinguish which substitutions at those positions are tolerated. A position might be highly conserved overall yet accept certain amino acid changes that preserve function. For missense variants specifically, the relevant question is not whether the position is constrained but whether the specific amino acid substitution disrupts function. **Sorting Intolerant From Tolerant (SIFT)** addresses this distinction by examining which amino acids have been accepted at each position across evolutionary history [@ng_sift_2003].

SIFT collects homologous protein sequences from diverse species, constructs a multiple sequence alignment, and examines which amino acids appear at each position across the alignment. Positions that are highly conserved (showing the same or similar amino acids across species) are predicted to be functionally important; substitutions introducing amino acids not observed at that position are predicted to be deleterious.

The method computes a normalized probability for each possible amino acid at each position based on the diversity observed in the alignment. The SIFT score for a substitution is the probability of observing the mutant amino acid, scaled by the position's overall diversity. Scores range from 0 to 1, with low scores (typically below 0.05) indicating predicted damage. A SIFT score of 0.01 for a particular missense variant indicates that the mutant amino acid is rarely or never observed at that position across the sequence family, suggesting functional constraint has prevented its fixation throughout evolution.

SIFT's simplicity is both its strength and its limitation. The method requires only protein sequence information and a database of homologs; it makes no assumptions about protein structure, physicochemistry, or mechanism of damage. This generality allows application to any protein with sufficient homologs in sequence databases. For proteins with few homologs, young gene families, or positions with limited alignment depth, predictions may be unreliable. The method captures only the evolutionary signal present in the alignment, missing functional constraints that arose recently or affect only a subset of species.

### PolyPhen-2: Integrating Structure and Sequence

SIFT's reliance on sequence alone ignores substantial information about how amino acid substitutions affect protein function. A glycine buried in a protein's hydrophobic core will disrupt structure differently than one on a surface loop. A substitution at a catalytic site matters more than one far from any functional region. **Polymorphism Phenotyping (PolyPhen-2)** extends sequence-based prediction by incorporating protein structure features and amino acid physicochemistry, recognizing that the same substitution can have different consequences depending on its structural context [@adzhubei_polyphen_2010].

The method uses a naive Bayes classifier trained to distinguish disease-causing mutations from neutral polymorphisms based on a collection of sequence-derived and structure-derived features. The feature set includes sequence conservation (similar to SIFT) but adds several structural descriptors when three-dimensional structure data is available: solvent accessibility (whether the position is buried or exposed), secondary structure context (helix, sheet, or coil), and proximity to known functional sites. Amino acid physicochemical properties inform predictions about whether substitutions are conservative or radical. The **Grantham distance**, a measure of biochemical dissimilarity between amino acid pairs based on composition, polarity, and molecular volume, contributes to assessing substitution severity. A glycine-to-arginine substitution (Grantham distance of 125) represents a far more radical change than a leucine-to-isoleucine substitution (Grantham distance of 5).

PolyPhen-2 provides two models trained on different datasets: HumDiv, trained on disease-causing and neutral variants from protein sequence databases, and HumVar, trained on Mendelian disease mutations versus common human polymorphisms. The choice of training set affects score interpretation; HumVar produces more conservative predictions appropriate for clinical Mendelian disease variant classification, while HumDiv is more sensitive and may be preferable for research applications where missing a true positive is more costly than false positives.

PolyPhen-2 scores range from 0 to 1, with higher scores indicating greater predicted deleteriousness. The output includes qualitative classifications (benign, possibly damaging, probably damaging) based on score thresholds. A PolyPhen-2 score of 0.95 with a "probably damaging" classification indicates high confidence that the substitution disrupts protein function, though the clinical significance depends on additional evidence about the specific disease context.

### What Protein-Level Predictors Measure Versus What Clinicians Need

Protein-level predictors estimate the impact of amino acid substitutions on protein function. They answer the question: does this substitution disrupt how the protein works? This is related to but distinct from the clinical question: does this variant cause disease in this patient?

A substitution can disrupt protein function without causing disease (if the protein has redundant function, if heterozygous loss is tolerated, or if the disrupted function is not relevant to the phenotype). Conversely, a substitution can cause disease through mechanisms that protein-level predictors cannot assess: gain-of-function effects, dominant-negative interactions, or tissue-specific expression changes. The SIFT and PolyPhen-2 scores for our *BRCA2* variant estimate functional disruption, but the clinical interpretation requires additional reasoning about *BRCA2*'s role in DNA repair, the consequences of haploinsufficiency, and the patient's specific cancer phenotype.

This distinction becomes critical in clinical practice. A "probably damaging" PolyPhen-2 score for a variant in a gene with no established disease association provides evidence of functional impact but no direct clinical utility. A "benign" prediction for a variant in a gene where even mild functional reduction causes disease may be misleading if the prediction method is insufficiently sensitive. Understanding what these tools measure, and how that relates to clinical questions, is essential for appropriate use.

### Boundaries of Protein-Level Prediction

Several fundamental boundaries constrain all protein-level predictors, and these boundaries are not merely technical inconveniences but reflect deep gaps in what sequence and structure analysis alone can reveal. Protein-level tools are restricted to missense variants; nonsense, frameshift, splice-altering, and non-coding variants lie entirely outside their scope. A patient's most important variant may be intronic or synonymous, yet protein-level predictors have nothing to say about it. This constraint is absolute: these methods analyze amino acid substitutions and cannot be extended to other variant types without fundamental redesign.

Protein-level predictors estimate impact on protein function without specifying the mechanism or clinical consequence. A variant predicted to damage function might impair enzymatic activity, disrupt protein folding, eliminate a binding interface, or alter stability. The clinical relevance depends on which function is affected and whether the phenotype results from loss or gain of function. A predicted-damaging variant in a tumor suppressor behaves very differently from one in an oncogene, yet protein-level predictors provide no information about this distinction. The same high score can indicate completely different clinical implications depending on biological context.

These tools also provide no information about inheritance mode, penetrance, or expressivity. A strongly predicted-damaging variant in a gene with high tolerance to heterozygous loss may be clinically benign in carriers. Protein-level predictors cannot distinguish between a variant causing severe disease in homozygotes and one causing no disease at all when heterozygous. This distinction becomes critical when counseling families, where the mode of inheritance fundamentally changes recurrence risk and management recommendations.

Protein-level predictors inherit the training data biases present in their underlying databases. Disease mutations in training sets are enriched for severe, early-onset Mendelian conditions with clear inheritance patterns. Variants causing subtle effects, incomplete penetrance, or complex phenotypes may be systematically mispredicted. The well-studied genes that dominate training data may not generalize to poorly characterized genes where variants are most difficult to interpret.

SIFT and PolyPhen-2 remain widely used in clinical practice and serve as features within more sophisticated ensemble methods. Their scores appear in diagnostic reports, contribute to ACMG-AMP classification criteria, and inform variant prioritization in research and clinical pipelines. Understanding their construction and limitations is essential for appropriate interpretation.


## The CADD Framework

The protein-level predictors and conservation scores examined above each capture one aspect of variant function, yet clinical interpretation requires weighing multiple lines of evidence simultaneously. A variant might fall in a conserved region, alter a moderately constrained amino acid, and overlap a predicted enhancer. How should these signals be combined? More fundamentally, how can we train a predictor when curated pathogenic variants number in the thousands while the genome contains billions of possible mutations? These questions expose a fundamental tension: the variants we most need to interpret (rare, novel, never before seen) are precisely those for which training labels do not exist.

**Combined Annotation-Dependent Depletion (CADD)** addressed these challenges by reframing variant effect prediction as a large-scale machine learning problem [@kircher_general_2014; @rentzsch_cadd_2019]. The key insight was not better feature engineering or more sophisticated classification, but rather a reconceptualization of the labeling problem itself. Instead of training directly on small sets of known pathogenic versus benign variants, which are scarce and biased toward certain genes and variant types, CADD contrasts variants that have survived purifying selection in the human lineage with matched simulated variants that could have occurred but did not. **This evolutionary proxy strategy transforms the labeling problem, yielding millions of training examples where curated datasets provide thousands.**

### Evolutionary Proxy Training and Label Sources

The conceptual foundation of CADD rests on constructing training labels from evolutionary signal rather than clinical curation. The method builds two proxy classes of variants that serve as training labels, each designed to approximate a category that cannot be observed directly. Understanding these label sources is essential because the same proxy labeling strategies reappear throughout genomic machine learning, including in the foundation models discussed in @sec-fm-principles.

The **proxy-neutral class** consists of variants that have been tolerated by purifying selection. CADD draws these from sequence differences that arose on the human lineage since the split from chimpanzees and became fixed or nearly fixed in modern humans. These are identified by their **derived allele frequency**: alleles that differ from the inferred ancestral state (typically determined by comparison to chimpanzee and other great ape sequences) and are present at very high frequency in human populations. Because these derived alleles have persisted over millions of years of evolution, most are presumed to be neutral or only weakly deleterious. This is not a perfect proxy: some observed alleles are genuinely pathogenic, particularly those with incomplete penetrance, late onset, or context-dependent effects. The proxy-neutral class is, on average, substantially enriched for tolerated alleles relative to a random sample of possible mutations.

The **proxy-deleterious class** is constructed by simulating mutations across the genome according to realistic mutational processes. The simulation matches local sequence context (typically using trinucleotide frequencies to capture the strong dependence of mutation rates on flanking bases). CpG dinucleotides, for example, have elevated mutation rates due to spontaneous deamination of methylated cytosines, and the simulation accounts for this by generating more CpG transitions. Regional variation in mutation rates, driven by factors including replication timing and chromatin state, is similarly incorporated.

The logic underlying this construction is subtle but powerful. Simulated variants represent changes that could plausibly occur under human mutational processes but are generally not observed at high frequency in population databases. The proxy-deleterious class as a whole is enriched for alleles disfavored by selection, because the set of possible mutations includes many that disrupt conserved elements, alter protein function, or perturb regulatory sequences. By contrasting this set with the proxy-neutral class (high derived allele frequency variants that survived selection), CADD learns to recognize the annotation signatures that distinguish variants under purifying selection from those that have been tolerated.

This proxy labeling strategy has important implications. CADD does not learn to distinguish pathogenic from benign variants directly; it learns to distinguish tolerated-by-evolution from possible-but-not-observed. The assumption is that variants depleted by selection are enriched for functional effects and therefore enriched for disease relevance. This assumption is often correct but introduces a systematic gap between what CADD measures (evolutionary tolerance) and what clinicians need (disease causation).

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion:** Evolutionary Proxy Training in CADD. Conceptual illustration of the proxy-neutral and proxy-deleterious variant classes. Left panel shows human-derived alleles (high derived allele frequency) fixed since the human-chimpanzee split (proxy-neutral), representing variants that survived purifying selection. Right panel shows simulated variants matching human mutational processes (proxy-deleterious), representing the space of possible mutations enriched for deleterious effects. Center panel shows the classifier learning to distinguish these classes based on annotation features. Annotate the approximate training set sizes to emphasize scale advantage over curated labels.
:::

### Feature Integration

Conservation scores measure evolutionary constraint. Protein-level predictors assess amino acid substitution severity. Regulatory annotations mark biochemically active regions. Each signal captures genuine biology, but no single annotation captures the full complexity of variant function. A missense variant in a constrained gene might be tolerated if it falls in an unconserved loop region; a synonymous variant might be pathogenic if it disrupts splicing. **The power of CADD lies in learning how these heterogeneous signals interact, upweighting annotations that distinguish proxy-deleterious from proxy-neutral variants and downweighting those that do not.**

CADD integrates more than 60 features, far exceeding what explicit combination rules could accommodate. **Gene model annotations** describe the local transcript and coding context of each variant. The most fundamental is the predicted sequence consequence: whether a variant is synonymous, missense, nonsense, frameshift, splice-site disrupting, or located in untranslated or intronic regions. Distance to exon-intron boundaries and proximity to canonical splice sites provide additional context. Gene-level attributes including constraint metrics (pLI, LOEUF from gnomAD) quantify how tolerant each gene is to damaging variation.

**Conservation features** from phyloP, GERP, and phastCons provide the evolutionary signals described earlier. By incorporating multiple conservation metrics computed from different alignments and using different methodologies, CADD captures complementary aspects of evolutionary constraint.

**Protein-level predictions** from SIFT and PolyPhen-2 contribute assessments of amino acid substitution impact for coding variants. Amino acid physicochemical properties, Grantham distances, and domain annotations from databases like Pfam provide additional structural context.

**Regulatory annotations** derived from ENCODE and Roadmap Epigenomics data capture chromatin accessibility, histone modifications, and transcription factor binding. These features help prioritize non-coding variants that disrupt active regulatory regions.

Additional features capture local sequence context (GC content, CpG density), genomic architecture (segmental duplications, repetitive elements), and chromosomal position. The model learns how to weight and combine these heterogeneous signals from the data rather than from expert specification.

### Model Architecture and Scoring

Raw classifier outputs are not directly interpretable as probabilities or biological effect sizes. A clinician presented with a support vector machine decision value has no intuitive understanding of what that number means. To address this, CADD defines **PHRED-scaled scores** based on the rank of each variant among all possible single-nucleotide substitutions in the reference genome. A scaled score of 10 indicates that a variant falls in the top 10% of predicted deleteriousness. A score of 20 indicates the top 1%, and a score of 30 indicates the top 0.1%. This rank-based transformation ensures comparability across CADD versions and provides immediate interpretability: a clinician can understand that a score of 25 places this variant among the most extreme 0.3% of possible mutations without needing to understand the underlying classifier.

CADD's classifier operates on the high-dimensional feature vector assembled for each variant. The original CADD model uses a linear support vector machine trained to discriminate proxy-neutral and proxy-deleterious variants based on approximately 30 million training examples. The choice of a linear model was deliberate and pragmatic: with tens of millions of training examples and dozens of features, a linear SVM is computationally tractable while capturing the main structure of the classification problem.

In clinical laboratories, CADD scaled scores commonly serve as filters to enrich for potentially pathogenic variants. Typical thresholds range from 15 (top 3%) to 20 (top 1%) or higher. Variants with scores at or above 20 are considered moderately high deleteriousness candidates, while scores at or above 30 are frequently interpreted as strongly enriched for functional impact. A diagnostic pipeline might use CADD greater than or equal to 20 as an initial filter, reducing 25,000 exome variants to several hundred candidates for expert review. These filters serve as prioritization tools that reduce the variant burden to a manageable number rather than as definitive pathogenicity calls.

### What CADD Measures Versus What Clinicians Need

CADD measures the probability that a variant resembles those depleted by purifying selection rather than those tolerated over evolutionary time. This is a proxy for functional importance but not a direct measure of disease causation. The distinction matters in several clinical scenarios.

A variant can receive a high CADD score because it disrupts an evolutionarily constrained element that has no relevance to the patient's phenotype. A deeply conserved neural enhancer variant will score highly even in a patient with a cardiac phenotype if the constraint derives from neural function. CADD cannot distinguish which functions are relevant to which diseases.

Conversely, a variant can cause disease through mechanisms that leave no evolutionary signature. Gain-of-function mutations, dominant-negative effects, and tissue-specific pathogenic mechanisms may not be depleted by selection in the same way as loss-of-function alleles. A variant causing disease through a novel mechanism absent from evolutionary history will not be recognized by CADD's training framework.

CADD also cannot account for genetic background, environmental interactions, or incomplete penetrance. A variant might be highly deleterious in one genetic context and tolerated in another, but CADD assigns a single score regardless of context. These limitations are not unique to CADD; they reflect the fundamental gap between evolutionary proxy labels and clinical disease causation that affects all methods in this chapter.


## Other Ensemble Methods

The clinical geneticist focused exclusively on rare missense variants in Mendelian disease faces a different optimization problem than the researcher screening the entire genome for regulatory variants. CADD's genome-wide generality may sacrifice accuracy within specific variant classes, accepting modest performance everywhere to achieve coverage anywhere. For diagnostic laboratories where missense variants in known disease genes dominate the caseload, specialized ensemble methods offer an alternative: models trained directly on curated disease variants, optimized for the specific task rather than general prioritization. **This tension between generality and specialization recurs throughout computational biology, and different clinical contexts demand different tradeoffs.**

### REVEL

A missense variant in a known disease gene presents a narrower interpretive challenge than an arbitrary variant anywhere in the genome. The variant is protein-coding, the gene has established disease associations, and the question is specifically whether this amino acid substitution is pathogenic. This focused scope permits a different training strategy than CADD's evolutionary proxy approach.

**Rare Exome Variant Ensemble Learner (REVEL)** represents a missense-specific ensemble predictor widely used in clinical laboratories [@ioannidis_revel_2016]. Rather than training on evolutionary proxy labels, REVEL directly discriminates pathogenic missense variants (curated from HGMD and other disease databases) from rare putatively neutral missense variants observed in population datasets.

REVEL integrates predictions from a panel of individual tools: SIFT, PolyPhen-2, PROVEAN, MutationAssessor, FATHMM, GERP++, phyloP, and phastCons, among others. A random forest model learns to combine these scores, weighting each according to its discriminative power for the pathogenic versus neutral classification. The training set is carefully constructed to avoid label contamination, excluding variants present in both disease and population databases.

REVEL scores range from 0 to 1, with higher values implying greater pathogenicity likelihood. Common interpretation thresholds treat scores above 0.5 as supporting evidence for pathogenicity, with scores above 0.75 providing stronger evidence. REVEL is restricted to missense single-nucleotide variants, making it more specialized than CADD but often more accurate within its scope. This specialization reflects a deliberate choice: by giving up coverage of non-coding and structural variants, REVEL gains the ability to train on directly relevant labels rather than evolutionary proxies.

### M-CAP

Diagnostic laboratories evaluating potential Mendelian disease variants face asymmetric consequences for errors. Calling a benign variant pathogenic can lead to unnecessary surgeries, psychological burden, and inappropriate cascade testing of family members. Missing a pathogenic variant delays diagnosis but typically permits later reclassification as evidence accumulates. This asymmetry argues for prioritizing specificity over sensitivity in clinical settings.

**Mendelian Clinically Applicable Pathogenicity (M-CAP)** addresses specifically the challenge of distinguishing pathogenic from benign rare missense variants in Mendelian disease contexts, with explicit attention to this asymmetry [@jagadeesh_m-cap_2016]. The method uses gradient boosting on a feature set including conservation scores, protein structure features, and amino acid properties.

M-CAP was explicitly designed to minimize false positives while maintaining reasonable sensitivity. The developers tuned their classifier to achieve less than 5% false positive rate on known pathogenic variants, accepting some reduction in sensitivity as a tradeoff. This design philosophy differs from methods that balance sensitivity and specificity equally, reflecting M-CAP's intended use in diagnostic settings where false positive pathogenicity calls have serious consequences.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion:** Ensemble Method Comparison. Receiver operating characteristic (ROC) curves or precision-recall curves comparing CADD, REVEL, and M-CAP performance on a held-out benchmark of missense variants. Include curves showing individual component scores (SIFT, PolyPhen-2, phyloP) to illustrate the improvement from integration. Annotate the different operating points corresponding to clinical thresholds (e.g., CADD greater than or equal to 20, REVEL greater than or equal to 0.75, M-CAP "possibly pathogenic") to show where each method trades sensitivity for specificity.
:::

### Comparison and Selection

No single ensemble method dominates across all variant types and clinical contexts. CADD provides the broadest coverage (genome-wide, all variant types) but may sacrifice accuracy within specific variant classes to achieve this generality. REVEL often outperforms CADD on missense-only benchmarks, reflecting its focused training objective. M-CAP prioritizes specificity over sensitivity, appropriate for clinical settings where avoiding false positives is paramount.

Clinical variant interpretation typically incorporates multiple computational scores rather than relying on any single predictor. Different scores may agree, providing stronger evidence, or disagree, flagging variants requiring careful manual review. A variant with CADD greater than or equal to 25, REVEL greater than or equal to 0.8, and M-CAP "possibly pathogenic" presents a consistent computational picture; one where CADD and REVEL disagree prompts closer examination of the underlying features. Understanding the construction, training data, and intended use case of each method is essential for appropriate interpretation. The integration of these scores into clinical workflows is examined in detail in @sec-clinical-risk, where computational evidence must be weighed alongside functional studies, segregation data, and clinical presentation.


## Circularity and Ascertainment Bias

A diagnostic laboratory classifies a novel missense variant as pathogenic based partly on its high CADD score. That classification enters ClinVar. Two years later, a benchmarking study evaluates CADD performance on ClinVar pathogenic variants and reports excellent accuracy. Is the high performance genuine, or has the benchmark been contaminated by the predictor's own influence on the labels it is evaluated against? This scenario illustrates one of two pervasive problems that affect all variant effect predictors: circularity between scores and clinical databases. The second problem, **ascertainment bias** in available training and testing variants, compounds the first. **These issues do not invalidate classical scores, but they counsel appropriate humility about performance claims and careful attention in both development and application.**

### The Circularity Problem

ClinVar and similar clinical databases increasingly incorporate computational predictions as evidence supporting variant classification. When a clinical laboratory classifies a variant as pathogenic, the CADD score, PolyPhen-2 prediction, or other computational evidence may have contributed to that determination. When CADD is subsequently evaluated on ClinVar pathogenic variants, its performance is artificially inflated: the benchmark contains variants that were labeled partly because CADD assigned them high scores. **The predictor appears to perform well because it was already part of the labeling process.**

This circularity operates through multiple pathways. Direct use occurs when clinical laboratories explicitly cite computational scores in their classifications. Indirect influence arises when computational predictions shape clinical suspicion, affecting which variants receive functional testing or expert review. Selection bias in benchmark construction can compound the problem: benchmark creators may preferentially include variants with strong computational evidence, excluding ambiguous cases that would provide a more stringent test.

The consequence is that benchmark performance may overestimate real-world utility. A method that has been widely adopted will appear to perform well on benchmarks populated by variants classified using that method, even if its true discriminative power is more limited. This concern applies to all established computational tools, including conservation scores, protein-level predictors, and ensemble methods. The more influential a method becomes, the more its benchmark performance becomes self-reinforcing.

Addressing circularity requires careful benchmark construction. Temporal holdouts (using only classifications made before a method's widespread adoption) can reduce but not eliminate the problem. Functional assays that directly measure variant effects provide ground truth independent of computational predictions but are available for only a small fraction of variants. Prospective evaluation on newly classified variants offers the cleanest test but requires patience and ongoing data collection. The foundation model evaluations discussed in @sec-vep-fm face these same challenges, and the confounding issues examined in @sec-confounding show how these problems persist and evolve as methods become more sophisticated.

::: {.callout-warning .content-visible when-profile="draft"}
**Visual suggestion:** The Circularity Problem. Diagram illustrating how computational predictions and clinical databases can become entangled. Show the feedback loop: computational scores inform clinical classification, classified variants enter benchmarks, predictors are evaluated on these benchmarks, high benchmark performance encourages clinical use, cycle repeats. Indicate intervention points where temporal holdouts or functional assays can break the cycle. Use arrows to show direction of influence and highlight the self-reinforcing nature of the problem.
:::

### Ascertainment Bias

Beyond circularity lies a more fundamental problem: the variants available for training and evaluation represent a systematically skewed sample of disease-causing mutations. Clinical databases are dominated by variants in well-studied genes, particularly those causing severe Mendelian phenotypes with clear inheritance patterns. Protein-coding variants are overrepresented because they are easier to interpret and more often tested. Variants in genes associated with common diagnostic panels appear frequently; those in rarely tested genes are sparse.

This ascertainment bias shapes what models learn and how they perform. A predictor trained predominantly on variants in constrained genes may learn that gene-level constraint is the primary signal for pathogenicity. When applied to variants in less constrained genes (where pathogenic variants also occur, but less frequently), the model may systematically underestimate risk. Similarly, models trained on European-ancestry samples may encode population-specific patterns that transfer poorly to other populations, compounding health disparities by providing less accurate predictions for underrepresented groups.

The consequences extend to evaluation. Benchmark variants inherit the ascertainment biases of their source databases. Strong performance on benchmark sets may not translate to the rare genes, unusual variant types, or underrepresented populations encountered in real clinical practice. Variants that are "easy" to classify (stop-gains in highly constrained genes) are overrepresented in benchmarks, while diagnostically challenging variants (missense variants in moderate-constraint genes, non-coding variants) are underrepresented. **The benchmark tells us how well the method performs on the easy cases; it may reveal little about the hard cases where computational assistance is most needed.**

### Implications for Clinical Use

These limitations do not render classical scores useless, but they counsel appropriate humility in interpretation. Computational predictions provide one line of evidence among several in variant interpretation. Strong scores in expected directions support clinical suspicion; unexpected scores prompt careful review. No computational score should override clear clinical or functional evidence, and borderline scores in complex cases may warrant agnosticism rather than confident prediction.

The ACMG-AMP framework for variant classification appropriately treats computational predictions as supporting evidence (PP3 for predictions supporting pathogenicity, BP4 for predictions supporting benign status) rather than standalone criteria [@richards_standards_2015]. Multiple lines of computational evidence may be combined, but the weight assigned should reflect the limitations outlined here. Variants classified primarily on computational grounds should be flagged for potential reclassification as additional evidence emerges.


## Limitations of the Feature Engineering Paradigm

Classical variant effect prediction achieved substantial success in prioritizing potentially pathogenic variants and established conceptual foundations that persist in modern methods. The integration of diverse annotations, use of evolutionary signals as proxy labels, and genome-wide precomputation all anticipate contemporary practices. Yet a fundamental tension remains: manually designed features encode only what biologists already know, and the complexity of genotype-phenotype relationships exceeds what explicit feature engineering can capture. **The features are not wrong; they are incomplete in ways that cannot be remedied by adding more of the same.**

### The Feature Ceiling

Feature-engineered methods encode human knowledge about which genomic properties matter for variant function. Conservation scores capture evolutionary constraint; protein-level predictors encode structural intuitions; regulatory annotations mark biochemically active regions. This encoded knowledge is valuable but necessarily incomplete. Biologists cannot specify all relevant patterns in advance, and the interactions between features may be too complex for simple combination rules to capture.

The performance of feature-engineered methods is therefore bounded by the quality and completeness of the features themselves. Adding more features provides diminishing returns as the most informative signals are exhausted. Interactions between features (a variant in a conserved enhancer within a constrained gene) may require explicit specification or rely on simple combination rules that miss nonlinear relationships. The linear SVM at the heart of CADD cannot represent the complex feature interactions that characterize biological regulation.

### Limited Context

Classical features typically describe variants in isolation or with minimal context. Conservation scores examine each position independently. Protein-level predictors consider amino acid substitutions without full protein context. Gene-level features apply uniformly across entire genes regardless of position-specific effects. This limited context prevents classical methods from learning the complex sequence patterns that determine variant effects.

A variant disrupting a critical transcription factor binding motif may escape detection if the motif is not annotated, even though the underlying sequence pattern is learnable from data. A missense variant at a protein-protein interface may be more damaging than one in a loop region, but capturing this distinction requires understanding protein structure and interactions that feature engineering incompletely represents. The local sequence context surrounding a variant often matters, but which contexts matter and how requires learning from data rather than specification by experts.

### The Persistent Gap Between Measurement and Need

Throughout this chapter, we have seen how each classical method measures something related to but distinct from clinical pathogenicity. Conservation scores measure evolutionary constraint. Protein-level predictors measure functional disruption. CADD measures evolutionary tolerance. Each provides genuine biological signal, but none directly answers the clinical question: will this variant cause disease in this patient?

This gap is not merely a limitation of specific methods but reflects something deeper about the variant interpretation problem. The clinically relevant question depends on context (which tissue, which genetic background, which environmental exposures) that no current method captures. Even perfect prediction of functional disruption would not resolve questions of penetrance, expressivity, and disease mechanism. The methods in this chapter provide important evidence for variant interpretation, but they cannot substitute for the integrative clinical reasoning examined in @sec-clinical-risk.

### From Features to Representations

The transition from CADD to deep learning methods represents a fundamental shift in how variant effect prediction is approached: from encoding biological knowledge as hand-crafted features to learning representations directly from sequence data. Where SIFT computes conservation from explicit multiple sequence alignments, protein language models learn similar signals implicitly from sequence alone. Where PolyPhen-2 engineers features from solved protein structures, structure prediction models learn geometric constraints from evolutionary covariation. The shift is real and consequential.

Yet learned representations do not automatically overcome the limitations that constrain classical methods. The circularity between training labels and evaluation benchmarks affects transformer-based predictors exactly as it affects logistic regression. A model trained on ClinVar pathogenic variants inherits ClinVar's ascertainment biases whether it uses 100 features or 100 million parameters. Rare variants remain difficult because they are rare in training data. Novel mechanisms remain invisible because no labeled examples exist. The variant effect prediction problem is fundamentally difficult, and methodology alone cannot resolve difficulties rooted in data availability and biological complexity.

Classical methods remain valuable: as baselines that establish the performance floor modern methods must exceed, as interpretable components when understanding matters as much as prediction, and as reminders of what the field has learned about which signals carry predictive information. The chapters that follow examine how foundation models have advanced variant effect prediction (@sec-vep-fm), but honest evaluation requires understanding what classical methods achieved and where all approaches, classical and modern alike, continue to struggle.